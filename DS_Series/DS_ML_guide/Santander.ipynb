{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 산탄데르 고객 만족 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = pd.read_csv('data/santander/train.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] ==1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불만족 비율 0.04\n"
     ]
    }
   ],
   "source": [
    "print('불만족 비율 {0:.2f}'.format((unsatisfied_cnt/total_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>imp_op_var41_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult3</th>\n",
       "      <th>imp_op_var39_ult1</th>\n",
       "      <th>imp_sal_var16_ult1</th>\n",
       "      <th>ind_var1_0</th>\n",
       "      <th>ind_var1</th>\n",
       "      <th>ind_var2_0</th>\n",
       "      <th>ind_var2</th>\n",
       "      <th>ind_var5_0</th>\n",
       "      <th>ind_var5</th>\n",
       "      <th>ind_var6_0</th>\n",
       "      <th>ind_var6</th>\n",
       "      <th>ind_var8_0</th>\n",
       "      <th>ind_var8</th>\n",
       "      <th>ind_var12_0</th>\n",
       "      <th>ind_var12</th>\n",
       "      <th>ind_var13_0</th>\n",
       "      <th>ind_var13_corto_0</th>\n",
       "      <th>ind_var13_corto</th>\n",
       "      <th>ind_var13_largo_0</th>\n",
       "      <th>ind_var13_largo</th>\n",
       "      <th>ind_var13_medio_0</th>\n",
       "      <th>ind_var13_medio</th>\n",
       "      <th>ind_var13</th>\n",
       "      <th>ind_var14_0</th>\n",
       "      <th>ind_var14</th>\n",
       "      <th>ind_var17_0</th>\n",
       "      <th>ind_var17</th>\n",
       "      <th>ind_var18_0</th>\n",
       "      <th>ind_var18</th>\n",
       "      <th>ind_var19</th>\n",
       "      <th>ind_var20_0</th>\n",
       "      <th>ind_var20</th>\n",
       "      <th>ind_var24_0</th>\n",
       "      <th>ind_var24</th>\n",
       "      <th>ind_var25_cte</th>\n",
       "      <th>ind_var26_0</th>\n",
       "      <th>ind_var26_cte</th>\n",
       "      <th>ind_var26</th>\n",
       "      <th>ind_var25_0</th>\n",
       "      <th>ind_var25</th>\n",
       "      <th>ind_var27_0</th>\n",
       "      <th>ind_var28_0</th>\n",
       "      <th>ind_var28</th>\n",
       "      <th>ind_var27</th>\n",
       "      <th>ind_var29_0</th>\n",
       "      <th>ind_var29</th>\n",
       "      <th>ind_var30_0</th>\n",
       "      <th>ind_var30</th>\n",
       "      <th>ind_var31_0</th>\n",
       "      <th>ind_var31</th>\n",
       "      <th>ind_var32_cte</th>\n",
       "      <th>ind_var32_0</th>\n",
       "      <th>ind_var32</th>\n",
       "      <th>ind_var33_0</th>\n",
       "      <th>ind_var33</th>\n",
       "      <th>ind_var34_0</th>\n",
       "      <th>ind_var34</th>\n",
       "      <th>ind_var37_cte</th>\n",
       "      <th>ind_var37_0</th>\n",
       "      <th>ind_var37</th>\n",
       "      <th>ind_var39_0</th>\n",
       "      <th>ind_var40_0</th>\n",
       "      <th>ind_var40</th>\n",
       "      <th>ind_var41_0</th>\n",
       "      <th>ind_var41</th>\n",
       "      <th>ind_var39</th>\n",
       "      <th>ind_var44_0</th>\n",
       "      <th>ind_var44</th>\n",
       "      <th>ind_var46_0</th>\n",
       "      <th>ind_var46</th>\n",
       "      <th>num_var1_0</th>\n",
       "      <th>num_var1</th>\n",
       "      <th>num_var4</th>\n",
       "      <th>num_var5_0</th>\n",
       "      <th>num_var5</th>\n",
       "      <th>num_var6_0</th>\n",
       "      <th>num_var6</th>\n",
       "      <th>num_var8_0</th>\n",
       "      <th>num_var8</th>\n",
       "      <th>num_var12_0</th>\n",
       "      <th>num_var12</th>\n",
       "      <th>num_var13_0</th>\n",
       "      <th>num_var13_corto_0</th>\n",
       "      <th>num_var13_corto</th>\n",
       "      <th>num_var13_largo_0</th>\n",
       "      <th>num_var13_largo</th>\n",
       "      <th>num_var13_medio_0</th>\n",
       "      <th>num_var13_medio</th>\n",
       "      <th>num_var13</th>\n",
       "      <th>num_var14_0</th>\n",
       "      <th>num_var14</th>\n",
       "      <th>num_var17_0</th>\n",
       "      <th>num_var17</th>\n",
       "      <th>num_var18_0</th>\n",
       "      <th>num_var18</th>\n",
       "      <th>num_var20_0</th>\n",
       "      <th>num_var20</th>\n",
       "      <th>num_var24_0</th>\n",
       "      <th>num_var24</th>\n",
       "      <th>num_var26_0</th>\n",
       "      <th>num_var26</th>\n",
       "      <th>num_var25_0</th>\n",
       "      <th>num_var25</th>\n",
       "      <th>num_op_var40_hace2</th>\n",
       "      <th>num_op_var40_hace3</th>\n",
       "      <th>num_op_var40_ult1</th>\n",
       "      <th>num_op_var40_ult3</th>\n",
       "      <th>num_op_var41_hace2</th>\n",
       "      <th>num_op_var41_hace3</th>\n",
       "      <th>num_op_var41_ult1</th>\n",
       "      <th>num_op_var41_ult3</th>\n",
       "      <th>num_op_var39_hace2</th>\n",
       "      <th>num_op_var39_hace3</th>\n",
       "      <th>num_op_var39_ult1</th>\n",
       "      <th>num_op_var39_ult3</th>\n",
       "      <th>num_var27_0</th>\n",
       "      <th>num_var28_0</th>\n",
       "      <th>num_var28</th>\n",
       "      <th>num_var27</th>\n",
       "      <th>num_var29_0</th>\n",
       "      <th>num_var29</th>\n",
       "      <th>num_var30_0</th>\n",
       "      <th>num_var30</th>\n",
       "      <th>num_var31_0</th>\n",
       "      <th>num_var31</th>\n",
       "      <th>num_var32_0</th>\n",
       "      <th>num_var32</th>\n",
       "      <th>num_var33_0</th>\n",
       "      <th>num_var33</th>\n",
       "      <th>num_var34_0</th>\n",
       "      <th>num_var34</th>\n",
       "      <th>num_var35</th>\n",
       "      <th>num_var37_med_ult2</th>\n",
       "      <th>num_var37_0</th>\n",
       "      <th>num_var37</th>\n",
       "      <th>num_var39_0</th>\n",
       "      <th>num_var40_0</th>\n",
       "      <th>num_var40</th>\n",
       "      <th>num_var41_0</th>\n",
       "      <th>num_var41</th>\n",
       "      <th>num_var39</th>\n",
       "      <th>num_var42_0</th>\n",
       "      <th>num_var42</th>\n",
       "      <th>num_var44_0</th>\n",
       "      <th>num_var44</th>\n",
       "      <th>num_var46_0</th>\n",
       "      <th>num_var46</th>\n",
       "      <th>saldo_var1</th>\n",
       "      <th>saldo_var5</th>\n",
       "      <th>saldo_var6</th>\n",
       "      <th>saldo_var8</th>\n",
       "      <th>saldo_var12</th>\n",
       "      <th>saldo_var13_corto</th>\n",
       "      <th>saldo_var13_largo</th>\n",
       "      <th>saldo_var13_medio</th>\n",
       "      <th>saldo_var13</th>\n",
       "      <th>saldo_var14</th>\n",
       "      <th>saldo_var17</th>\n",
       "      <th>saldo_var18</th>\n",
       "      <th>saldo_var20</th>\n",
       "      <th>saldo_var24</th>\n",
       "      <th>saldo_var26</th>\n",
       "      <th>saldo_var25</th>\n",
       "      <th>saldo_var28</th>\n",
       "      <th>saldo_var27</th>\n",
       "      <th>saldo_var29</th>\n",
       "      <th>saldo_var30</th>\n",
       "      <th>saldo_var31</th>\n",
       "      <th>saldo_var32</th>\n",
       "      <th>saldo_var33</th>\n",
       "      <th>saldo_var34</th>\n",
       "      <th>saldo_var37</th>\n",
       "      <th>saldo_var40</th>\n",
       "      <th>saldo_var41</th>\n",
       "      <th>saldo_var42</th>\n",
       "      <th>saldo_var44</th>\n",
       "      <th>saldo_var46</th>\n",
       "      <th>var36</th>\n",
       "      <th>delta_imp_amort_var18_1y3</th>\n",
       "      <th>delta_imp_amort_var34_1y3</th>\n",
       "      <th>delta_imp_aport_var13_1y3</th>\n",
       "      <th>delta_imp_aport_var17_1y3</th>\n",
       "      <th>delta_imp_aport_var33_1y3</th>\n",
       "      <th>delta_imp_compra_var44_1y3</th>\n",
       "      <th>delta_imp_reemb_var13_1y3</th>\n",
       "      <th>delta_imp_reemb_var17_1y3</th>\n",
       "      <th>delta_imp_reemb_var33_1y3</th>\n",
       "      <th>delta_imp_trasp_var17_in_1y3</th>\n",
       "      <th>delta_imp_trasp_var17_out_1y3</th>\n",
       "      <th>delta_imp_trasp_var33_in_1y3</th>\n",
       "      <th>delta_imp_trasp_var33_out_1y3</th>\n",
       "      <th>delta_imp_venta_var44_1y3</th>\n",
       "      <th>delta_num_aport_var13_1y3</th>\n",
       "      <th>delta_num_aport_var17_1y3</th>\n",
       "      <th>delta_num_aport_var33_1y3</th>\n",
       "      <th>delta_num_compra_var44_1y3</th>\n",
       "      <th>delta_num_reemb_var13_1y3</th>\n",
       "      <th>delta_num_reemb_var17_1y3</th>\n",
       "      <th>delta_num_reemb_var33_1y3</th>\n",
       "      <th>delta_num_trasp_var17_in_1y3</th>\n",
       "      <th>delta_num_trasp_var17_out_1y3</th>\n",
       "      <th>delta_num_trasp_var33_in_1y3</th>\n",
       "      <th>delta_num_trasp_var33_out_1y3</th>\n",
       "      <th>delta_num_venta_var44_1y3</th>\n",
       "      <th>imp_amort_var18_hace3</th>\n",
       "      <th>imp_amort_var18_ult1</th>\n",
       "      <th>imp_amort_var34_hace3</th>\n",
       "      <th>imp_amort_var34_ult1</th>\n",
       "      <th>imp_aport_var13_hace3</th>\n",
       "      <th>imp_aport_var13_ult1</th>\n",
       "      <th>imp_aport_var17_hace3</th>\n",
       "      <th>imp_aport_var17_ult1</th>\n",
       "      <th>imp_aport_var33_hace3</th>\n",
       "      <th>imp_aport_var33_ult1</th>\n",
       "      <th>imp_var7_emit_ult1</th>\n",
       "      <th>imp_var7_recib_ult1</th>\n",
       "      <th>imp_compra_var44_hace3</th>\n",
       "      <th>imp_compra_var44_ult1</th>\n",
       "      <th>imp_reemb_var13_hace3</th>\n",
       "      <th>imp_reemb_var13_ult1</th>\n",
       "      <th>imp_reemb_var17_hace3</th>\n",
       "      <th>imp_reemb_var17_ult1</th>\n",
       "      <th>imp_reemb_var33_hace3</th>\n",
       "      <th>imp_reemb_var33_ult1</th>\n",
       "      <th>imp_var43_emit_ult1</th>\n",
       "      <th>imp_trans_var37_ult1</th>\n",
       "      <th>imp_trasp_var17_in_hace3</th>\n",
       "      <th>imp_trasp_var17_in_ult1</th>\n",
       "      <th>imp_trasp_var17_out_hace3</th>\n",
       "      <th>imp_trasp_var17_out_ult1</th>\n",
       "      <th>imp_trasp_var33_in_hace3</th>\n",
       "      <th>imp_trasp_var33_in_ult1</th>\n",
       "      <th>imp_trasp_var33_out_hace3</th>\n",
       "      <th>imp_trasp_var33_out_ult1</th>\n",
       "      <th>imp_venta_var44_hace3</th>\n",
       "      <th>imp_venta_var44_ult1</th>\n",
       "      <th>ind_var7_emit_ult1</th>\n",
       "      <th>ind_var7_recib_ult1</th>\n",
       "      <th>ind_var10_ult1</th>\n",
       "      <th>ind_var10cte_ult1</th>\n",
       "      <th>ind_var9_cte_ult1</th>\n",
       "      <th>ind_var9_ult1</th>\n",
       "      <th>ind_var43_emit_ult1</th>\n",
       "      <th>ind_var43_recib_ult1</th>\n",
       "      <th>var21</th>\n",
       "      <th>num_var2_0_ult1</th>\n",
       "      <th>num_var2_ult1</th>\n",
       "      <th>num_aport_var13_hace3</th>\n",
       "      <th>num_aport_var13_ult1</th>\n",
       "      <th>num_aport_var17_hace3</th>\n",
       "      <th>num_aport_var17_ult1</th>\n",
       "      <th>num_aport_var33_hace3</th>\n",
       "      <th>num_aport_var33_ult1</th>\n",
       "      <th>num_var7_emit_ult1</th>\n",
       "      <th>num_var7_recib_ult1</th>\n",
       "      <th>num_compra_var44_hace3</th>\n",
       "      <th>num_compra_var44_ult1</th>\n",
       "      <th>num_ent_var16_ult1</th>\n",
       "      <th>num_var22_hace2</th>\n",
       "      <th>num_var22_hace3</th>\n",
       "      <th>num_var22_ult1</th>\n",
       "      <th>num_var22_ult3</th>\n",
       "      <th>num_med_var22_ult3</th>\n",
       "      <th>num_med_var45_ult3</th>\n",
       "      <th>num_meses_var5_ult3</th>\n",
       "      <th>num_meses_var8_ult3</th>\n",
       "      <th>num_meses_var12_ult3</th>\n",
       "      <th>num_meses_var13_corto_ult3</th>\n",
       "      <th>num_meses_var13_largo_ult3</th>\n",
       "      <th>num_meses_var13_medio_ult3</th>\n",
       "      <th>num_meses_var17_ult3</th>\n",
       "      <th>num_meses_var29_ult3</th>\n",
       "      <th>num_meses_var33_ult3</th>\n",
       "      <th>num_meses_var39_vig_ult3</th>\n",
       "      <th>num_meses_var44_ult3</th>\n",
       "      <th>num_op_var39_comer_ult1</th>\n",
       "      <th>num_op_var39_comer_ult3</th>\n",
       "      <th>num_op_var40_comer_ult1</th>\n",
       "      <th>num_op_var40_comer_ult3</th>\n",
       "      <th>num_op_var40_efect_ult1</th>\n",
       "      <th>num_op_var40_efect_ult3</th>\n",
       "      <th>num_op_var41_comer_ult1</th>\n",
       "      <th>num_op_var41_comer_ult3</th>\n",
       "      <th>num_op_var41_efect_ult1</th>\n",
       "      <th>num_op_var41_efect_ult3</th>\n",
       "      <th>num_op_var39_efect_ult1</th>\n",
       "      <th>num_op_var39_efect_ult3</th>\n",
       "      <th>num_reemb_var13_hace3</th>\n",
       "      <th>num_reemb_var13_ult1</th>\n",
       "      <th>num_reemb_var17_hace3</th>\n",
       "      <th>num_reemb_var17_ult1</th>\n",
       "      <th>num_reemb_var33_hace3</th>\n",
       "      <th>num_reemb_var33_ult1</th>\n",
       "      <th>num_sal_var16_ult1</th>\n",
       "      <th>num_var43_emit_ult1</th>\n",
       "      <th>num_var43_recib_ult1</th>\n",
       "      <th>num_trasp_var11_ult1</th>\n",
       "      <th>num_trasp_var17_in_hace3</th>\n",
       "      <th>num_trasp_var17_in_ult1</th>\n",
       "      <th>num_trasp_var17_out_hace3</th>\n",
       "      <th>num_trasp_var17_out_ult1</th>\n",
       "      <th>num_trasp_var33_in_hace3</th>\n",
       "      <th>num_trasp_var33_in_ult1</th>\n",
       "      <th>num_trasp_var33_out_hace3</th>\n",
       "      <th>num_trasp_var33_out_ult1</th>\n",
       "      <th>num_venta_var44_hace3</th>\n",
       "      <th>num_venta_var44_ult1</th>\n",
       "      <th>num_var45_hace2</th>\n",
       "      <th>num_var45_hace3</th>\n",
       "      <th>num_var45_ult1</th>\n",
       "      <th>num_var45_ult3</th>\n",
       "      <th>saldo_var2_ult1</th>\n",
       "      <th>saldo_medio_var5_hace2</th>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_medio_var8_hace2</th>\n",
       "      <th>saldo_medio_var8_hace3</th>\n",
       "      <th>saldo_medio_var8_ult1</th>\n",
       "      <th>saldo_medio_var8_ult3</th>\n",
       "      <th>saldo_medio_var12_hace2</th>\n",
       "      <th>saldo_medio_var12_hace3</th>\n",
       "      <th>saldo_medio_var12_ult1</th>\n",
       "      <th>saldo_medio_var12_ult3</th>\n",
       "      <th>saldo_medio_var13_corto_hace2</th>\n",
       "      <th>saldo_medio_var13_corto_hace3</th>\n",
       "      <th>saldo_medio_var13_corto_ult1</th>\n",
       "      <th>saldo_medio_var13_corto_ult3</th>\n",
       "      <th>saldo_medio_var13_largo_hace2</th>\n",
       "      <th>saldo_medio_var13_largo_hace3</th>\n",
       "      <th>saldo_medio_var13_largo_ult1</th>\n",
       "      <th>saldo_medio_var13_largo_ult3</th>\n",
       "      <th>saldo_medio_var13_medio_hace2</th>\n",
       "      <th>saldo_medio_var13_medio_hace3</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var13_medio_ult3</th>\n",
       "      <th>saldo_medio_var17_hace2</th>\n",
       "      <th>saldo_medio_var17_hace3</th>\n",
       "      <th>saldo_medio_var17_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.00000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.00000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.00000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>3.160715</td>\n",
       "      <td>68.803937</td>\n",
       "      <td>113.056934</td>\n",
       "      <td>68.205140</td>\n",
       "      <td>113.225058</td>\n",
       "      <td>137.242763</td>\n",
       "      <td>68.618087</td>\n",
       "      <td>113.792410</td>\n",
       "      <td>140.403479</td>\n",
       "      <td>5.477676</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.663760</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.067522</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>0.052249</td>\n",
       "      <td>0.042936</td>\n",
       "      <td>0.041476</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.026427</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.995488</td>\n",
       "      <td>0.732833</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.00367</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>0.065259</td>\n",
       "      <td>0.065259</td>\n",
       "      <td>0.880755</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.879282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>1.079440</td>\n",
       "      <td>2.894041</td>\n",
       "      <td>1.999171</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.09854</td>\n",
       "      <td>0.085793</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>0.138003</td>\n",
       "      <td>0.167719</td>\n",
       "      <td>0.130308</td>\n",
       "      <td>0.124507</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.159826</td>\n",
       "      <td>0.072691</td>\n",
       "      <td>0.01614</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.127664</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.089384</td>\n",
       "      <td>0.089384</td>\n",
       "      <td>0.085162</td>\n",
       "      <td>0.085162</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.057024</td>\n",
       "      <td>0.078295</td>\n",
       "      <td>1.601144</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>2.858840</td>\n",
       "      <td>4.553907</td>\n",
       "      <td>1.621389</td>\n",
       "      <td>0.094949</td>\n",
       "      <td>2.915864</td>\n",
       "      <td>4.632202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>3.371863</td>\n",
       "      <td>2.382873</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>3.299369</td>\n",
       "      <td>0.263536</td>\n",
       "      <td>0.418785</td>\n",
       "      <td>0.418785</td>\n",
       "      <td>2.724941</td>\n",
       "      <td>0.034294</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>2.699250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>3.204144</td>\n",
       "      <td>2.217995</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.844911e+01</td>\n",
       "      <td>1028.468235</td>\n",
       "      <td>0.414475</td>\n",
       "      <td>141.226784</td>\n",
       "      <td>6.021616e+03</td>\n",
       "      <td>4993.752970</td>\n",
       "      <td>1.493682e+03</td>\n",
       "      <td>0.513023</td>\n",
       "      <td>6.487948e+03</td>\n",
       "      <td>69.096200</td>\n",
       "      <td>1.834059e+02</td>\n",
       "      <td>4.340963e+01</td>\n",
       "      <td>27.399456</td>\n",
       "      <td>5.925120e+03</td>\n",
       "      <td>76.081633</td>\n",
       "      <td>72.735693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414475</td>\n",
       "      <td>1.367967e+04</td>\n",
       "      <td>2.922910e+02</td>\n",
       "      <td>3.345941</td>\n",
       "      <td>12.532333</td>\n",
       "      <td>0.670876</td>\n",
       "      <td>36.907194</td>\n",
       "      <td>4.368602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.191725e+03</td>\n",
       "      <td>96.352738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.449079</td>\n",
       "      <td>2.630887e+05</td>\n",
       "      <td>2.630887e+05</td>\n",
       "      <td>4.867140e+07</td>\n",
       "      <td>5.130229e+06</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>9.208103e+06</td>\n",
       "      <td>4.998685e+06</td>\n",
       "      <td>2.630887e+06</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>5.261773e+05</td>\n",
       "      <td>5.261773e+05</td>\n",
       "      <td>6.577217e+05</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>5.524862e+06</td>\n",
       "      <td>4.867140e+07</td>\n",
       "      <td>5.130229e+06</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>9.208103e+06</td>\n",
       "      <td>4.998685e+06</td>\n",
       "      <td>2.630887e+06</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>5.261773e+05</td>\n",
       "      <td>5.261773e+05</td>\n",
       "      <td>6.577217e+05</td>\n",
       "      <td>1.315443e+05</td>\n",
       "      <td>5.524862e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>2823.949089</td>\n",
       "      <td>619.585010</td>\n",
       "      <td>9.878877e+01</td>\n",
       "      <td>31.105323</td>\n",
       "      <td>2.985793</td>\n",
       "      <td>0.048145</td>\n",
       "      <td>2.721454</td>\n",
       "      <td>1.276982e+02</td>\n",
       "      <td>13.964581</td>\n",
       "      <td>1.167825e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.180243</td>\n",
       "      <td>0.158210</td>\n",
       "      <td>12.569401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>8.541207e+02</td>\n",
       "      <td>1.932954e+03</td>\n",
       "      <td>1.874808</td>\n",
       "      <td>2.512678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.913616</td>\n",
       "      <td>2.789772</td>\n",
       "      <td>0.314701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039463</td>\n",
       "      <td>3.787137</td>\n",
       "      <td>8.143383e+01</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.092160</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.066588</td>\n",
       "      <td>0.129308</td>\n",
       "      <td>32.549329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075888</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.187964</td>\n",
       "      <td>1.298698</td>\n",
       "      <td>1.184886</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>3.044238</td>\n",
       "      <td>0.635872</td>\n",
       "      <td>4.024665</td>\n",
       "      <td>1.979979</td>\n",
       "      <td>0.053604</td>\n",
       "      <td>0.102052</td>\n",
       "      <td>0.098921</td>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>1.592791</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>2.194791</td>\n",
       "      <td>3.607064</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>0.144830</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>2.119811</td>\n",
       "      <td>3.462234</td>\n",
       "      <td>0.719416</td>\n",
       "      <td>1.212155</td>\n",
       "      <td>0.721902</td>\n",
       "      <td>1.215825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>0.814996</td>\n",
       "      <td>0.120679</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>5.393212</td>\n",
       "      <td>3.894396</td>\n",
       "      <td>4.363496</td>\n",
       "      <td>13.651105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1579.135311</td>\n",
       "      <td>8.913659e+02</td>\n",
       "      <td>1077.256756</td>\n",
       "      <td>1048.856447</td>\n",
       "      <td>68.275452</td>\n",
       "      <td>9.505287</td>\n",
       "      <td>124.620962</td>\n",
       "      <td>110.026575</td>\n",
       "      <td>3.997023e+03</td>\n",
       "      <td>613.534443</td>\n",
       "      <td>5.703008e+03</td>\n",
       "      <td>4.401002e+03</td>\n",
       "      <td>3639.419939</td>\n",
       "      <td>556.184178</td>\n",
       "      <td>4852.261814</td>\n",
       "      <td>3857.848542</td>\n",
       "      <td>771.227449</td>\n",
       "      <td>162.170439</td>\n",
       "      <td>9.569502e+02</td>\n",
       "      <td>7.509563e+02</td>\n",
       "      <td>0.175324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513023</td>\n",
       "      <td>0.344174</td>\n",
       "      <td>9.117181e+01</td>\n",
       "      <td>3.646318e+01</td>\n",
       "      <td>1.310316e+02</td>\n",
       "      <td>1.092169e+02</td>\n",
       "      <td>0.213071</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.253907</td>\n",
       "      <td>0.186630</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>95.268204</td>\n",
       "      <td>319.605516</td>\n",
       "      <td>512.154823</td>\n",
       "      <td>531.897917</td>\n",
       "      <td>950.086398</td>\n",
       "      <td>697.712596</td>\n",
       "      <td>535.473750</td>\n",
       "      <td>953.578624</td>\n",
       "      <td>712.767240</td>\n",
       "      <td>465.391149</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.061221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200535</td>\n",
       "      <td>0.472425</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.178202</td>\n",
       "      <td>0.166674</td>\n",
       "      <td>0.250925</td>\n",
       "      <td>0.208316</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.202714</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>0.099486</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.219703</td>\n",
       "      <td>0.151962</td>\n",
       "      <td>0.072617</td>\n",
       "      <td>0.042414</td>\n",
       "      <td>0.038012</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.064643</td>\n",
       "      <td>0.060146</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.201434</td>\n",
       "      <td>0.190919</td>\n",
       "      <td>0.160403</td>\n",
       "      <td>0.155021</td>\n",
       "      <td>0.163705</td>\n",
       "      <td>0.155021</td>\n",
       "      <td>0.151921</td>\n",
       "      <td>0.151921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.442483</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.06047</td>\n",
       "      <td>0.034767</td>\n",
       "      <td>0.032826</td>\n",
       "      <td>0.032826</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.246984</td>\n",
       "      <td>0.246984</td>\n",
       "      <td>0.324079</td>\n",
       "      <td>0.106244</td>\n",
       "      <td>0.060901</td>\n",
       "      <td>0.325802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060901</td>\n",
       "      <td>0.043331</td>\n",
       "      <td>0.041159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320379</td>\n",
       "      <td>0.184626</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.656479</td>\n",
       "      <td>1.431902</td>\n",
       "      <td>0.030774</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.53493</td>\n",
       "      <td>0.500022</td>\n",
       "      <td>0.890236</td>\n",
       "      <td>0.637259</td>\n",
       "      <td>0.745822</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.598746</td>\n",
       "      <td>0.404822</td>\n",
       "      <td>0.381373</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.713022</td>\n",
       "      <td>0.610815</td>\n",
       "      <td>0.22426</td>\n",
       "      <td>0.362480</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.180437</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>0.608482</td>\n",
       "      <td>0.573662</td>\n",
       "      <td>0.628596</td>\n",
       "      <td>0.628596</td>\n",
       "      <td>0.612110</td>\n",
       "      <td>0.612110</td>\n",
       "      <td>0.897618</td>\n",
       "      <td>0.180762</td>\n",
       "      <td>1.827374</td>\n",
       "      <td>2.558216</td>\n",
       "      <td>7.322004</td>\n",
       "      <td>1.215218</td>\n",
       "      <td>10.886314</td>\n",
       "      <td>16.891801</td>\n",
       "      <td>7.389539</td>\n",
       "      <td>1.228510</td>\n",
       "      <td>11.112899</td>\n",
       "      <td>17.175900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030774</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>1.336654</td>\n",
       "      <td>1.642787</td>\n",
       "      <td>0.406624</td>\n",
       "      <td>0.331609</td>\n",
       "      <td>0.139702</td>\n",
       "      <td>0.139702</td>\n",
       "      <td>0.101457</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>2.868217</td>\n",
       "      <td>1.650273</td>\n",
       "      <td>2.241141</td>\n",
       "      <td>2.241141</td>\n",
       "      <td>1.139159</td>\n",
       "      <td>0.319285</td>\n",
       "      <td>0.182702</td>\n",
       "      <td>1.105297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182702</td>\n",
       "      <td>0.944123</td>\n",
       "      <td>1.497703</td>\n",
       "      <td>0.131350</td>\n",
       "      <td>0.123477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.093747e+04</td>\n",
       "      <td>9852.140073</td>\n",
       "      <td>83.096797</td>\n",
       "      <td>2515.656302</td>\n",
       "      <td>4.814471e+04</td>\n",
       "      <td>32619.134245</td>\n",
       "      <td>2.001649e+04</td>\n",
       "      <td>113.597559</td>\n",
       "      <td>3.841675e+04</td>\n",
       "      <td>2839.618964</td>\n",
       "      <td>2.269813e+04</td>\n",
       "      <td>1.093497e+04</td>\n",
       "      <td>2477.810744</td>\n",
       "      <td>4.800853e+04</td>\n",
       "      <td>739.776626</td>\n",
       "      <td>726.882669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.096797</td>\n",
       "      <td>6.301408e+04</td>\n",
       "      <td>2.331640e+04</td>\n",
       "      <td>126.680152</td>\n",
       "      <td>797.839557</td>\n",
       "      <td>141.448598</td>\n",
       "      <td>472.098863</td>\n",
       "      <td>113.968756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.914531e+04</td>\n",
       "      <td>5218.428365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.362719</td>\n",
       "      <td>5.129183e+07</td>\n",
       "      <td>5.129183e+07</td>\n",
       "      <td>6.959537e+08</td>\n",
       "      <td>2.264435e+08</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>3.033108e+08</td>\n",
       "      <td>2.235230e+08</td>\n",
       "      <td>1.621798e+08</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>7.253665e+07</td>\n",
       "      <td>7.253665e+07</td>\n",
       "      <td>8.109791e+07</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>2.349869e+08</td>\n",
       "      <td>6.959537e+08</td>\n",
       "      <td>2.264435e+08</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>3.033108e+08</td>\n",
       "      <td>2.235230e+08</td>\n",
       "      <td>1.621798e+08</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>7.253665e+07</td>\n",
       "      <td>7.253665e+07</td>\n",
       "      <td>8.109791e+07</td>\n",
       "      <td>3.626904e+07</td>\n",
       "      <td>2.349869e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.320958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.099461</td>\n",
       "      <td>25334.468106</td>\n",
       "      <td>11252.995089</td>\n",
       "      <td>2.212072e+04</td>\n",
       "      <td>2457.091282</td>\n",
       "      <td>226.862984</td>\n",
       "      <td>6.022692</td>\n",
       "      <td>554.249437</td>\n",
       "      <td>6.368997e+03</td>\n",
       "      <td>1151.510862</td>\n",
       "      <td>1.362044e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2859.736591</td>\n",
       "      <td>43.621319</td>\n",
       "      <td>1093.133883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.352285</td>\n",
       "      <td>1.425589e+04</td>\n",
       "      <td>2.535572e+04</td>\n",
       "      <td>388.245022</td>\n",
       "      <td>508.968831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>357.405330</td>\n",
       "      <td>323.814261</td>\n",
       "      <td>53.408085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.880712</td>\n",
       "      <td>811.976086</td>\n",
       "      <td>1.128241e+04</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.272642</td>\n",
       "      <td>0.289254</td>\n",
       "      <td>0.295782</td>\n",
       "      <td>0.280235</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.335543</td>\n",
       "      <td>393.834939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.552499</td>\n",
       "      <td>0.288757</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.069663</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>0.018846</td>\n",
       "      <td>0.228782</td>\n",
       "      <td>0.099111</td>\n",
       "      <td>0.315453</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>3.450268</td>\n",
       "      <td>3.263333</td>\n",
       "      <td>2.104410</td>\n",
       "      <td>6.206116</td>\n",
       "      <td>1.835267</td>\n",
       "      <td>10.930334</td>\n",
       "      <td>1.298924</td>\n",
       "      <td>0.334908</td>\n",
       "      <td>0.487687</td>\n",
       "      <td>0.486064</td>\n",
       "      <td>0.213095</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.077648</td>\n",
       "      <td>0.013570</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.719655</td>\n",
       "      <td>0.088174</td>\n",
       "      <td>9.131406</td>\n",
       "      <td>14.919726</td>\n",
       "      <td>2.089408</td>\n",
       "      <td>4.288145</td>\n",
       "      <td>0.147172</td>\n",
       "      <td>0.202068</td>\n",
       "      <td>8.799494</td>\n",
       "      <td>14.140650</td>\n",
       "      <td>3.210999</td>\n",
       "      <td>5.160396</td>\n",
       "      <td>3.226314</td>\n",
       "      <td>5.181092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.098523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.154949</td>\n",
       "      <td>2.215853</td>\n",
       "      <td>3.557660</td>\n",
       "      <td>1.172148</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.026651</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.026652</td>\n",
       "      <td>0.264256</td>\n",
       "      <td>14.496095</td>\n",
       "      <td>10.416821</td>\n",
       "      <td>14.406485</td>\n",
       "      <td>33.304012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12148.452398</td>\n",
       "      <td>9.888597e+03</td>\n",
       "      <td>9614.906985</td>\n",
       "      <td>8189.948852</td>\n",
       "      <td>1733.838226</td>\n",
       "      <td>519.389157</td>\n",
       "      <td>2205.249804</td>\n",
       "      <td>1935.305713</td>\n",
       "      <td>3.777314e+04</td>\n",
       "      <td>9292.752726</td>\n",
       "      <td>4.620254e+04</td>\n",
       "      <td>3.550718e+04</td>\n",
       "      <td>26359.174223</td>\n",
       "      <td>7182.642532</td>\n",
       "      <td>31886.615189</td>\n",
       "      <td>25572.245055</td>\n",
       "      <td>13082.155867</td>\n",
       "      <td>4698.868075</td>\n",
       "      <td>1.600698e+04</td>\n",
       "      <td>1.242252e+04</td>\n",
       "      <td>34.625518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.597559</td>\n",
       "      <td>73.376513</td>\n",
       "      <td>1.539248e+04</td>\n",
       "      <td>8.612395e+03</td>\n",
       "      <td>1.495653e+04</td>\n",
       "      <td>1.308216e+04</td>\n",
       "      <td>41.820444</td>\n",
       "      <td>0.526626</td>\n",
       "      <td>52.078775</td>\n",
       "      <td>31.879418</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.000000e-01</td>\n",
       "      <td>-2895.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4942.260000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.942260e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.942260e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-128.370000</td>\n",
       "      <td>-8.040000e+00</td>\n",
       "      <td>-922.380000</td>\n",
       "      <td>-476.070000</td>\n",
       "      <td>-287.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3401.340000</td>\n",
       "      <td>-1844.520000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.900000e-01</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.359950e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.221750e+01</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>83.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>16566.810000</td>\n",
       "      <td>45990.000000</td>\n",
       "      <td>131100.000000</td>\n",
       "      <td>47598.090000</td>\n",
       "      <td>45990.000000</td>\n",
       "      <td>131100.000000</td>\n",
       "      <td>47598.090000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>619329.150000</td>\n",
       "      <td>19531.800000</td>\n",
       "      <td>240045.000000</td>\n",
       "      <td>3.008077e+06</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>6.119500e+06</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>455858.160000</td>\n",
       "      <td>3.008077e+06</td>\n",
       "      <td>69756.720000</td>\n",
       "      <td>69756.720000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19531.800000</td>\n",
       "      <td>3.458077e+06</td>\n",
       "      <td>6.119500e+06</td>\n",
       "      <td>12210.780000</td>\n",
       "      <td>142078.800000</td>\n",
       "      <td>36000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>8192.610000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.008077e+06</td>\n",
       "      <td>740006.610000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15691.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096.020000</td>\n",
       "      <td>840000.000000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>6.083692e+06</td>\n",
       "      <td>432457.320000</td>\n",
       "      <td>36000.000000</td>\n",
       "      <td>1260.000000</td>\n",
       "      <td>145384.920000</td>\n",
       "      <td>1.039260e+06</td>\n",
       "      <td>210001.350000</td>\n",
       "      <td>3.410059e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>12027.150000</td>\n",
       "      <td>182132.970000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1.155003e+06</td>\n",
       "      <td>2.310003e+06</td>\n",
       "      <td>96781.440000</td>\n",
       "      <td>133730.580000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69622.290000</td>\n",
       "      <td>49581.270000</td>\n",
       "      <td>13207.320000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>209834.400000</td>\n",
       "      <td>2.754476e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>812137.260000</td>\n",
       "      <td>1.542339e+06</td>\n",
       "      <td>601428.600000</td>\n",
       "      <td>544365.570000</td>\n",
       "      <td>231351.990000</td>\n",
       "      <td>77586.210000</td>\n",
       "      <td>228031.800000</td>\n",
       "      <td>177582.000000</td>\n",
       "      <td>3.000538e+06</td>\n",
       "      <td>668335.320000</td>\n",
       "      <td>3.004186e+06</td>\n",
       "      <td>2.272859e+06</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>304838.700000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>840000.000000</td>\n",
       "      <td>534000.000000</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>1.034483e+06</td>\n",
       "      <td>7741.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>18870.990000</td>\n",
       "      <td>4.210084e+06</td>\n",
       "      <td>2.368559e+06</td>\n",
       "      <td>3.998687e+06</td>\n",
       "      <td>3.525777e+06</td>\n",
       "      <td>10430.010000</td>\n",
       "      <td>145.200000</td>\n",
       "      <td>13793.670000</td>\n",
       "      <td>7331.340000</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  \\\n",
       "count             76020.000000             76020.000000       76020.000000   \n",
       "mean                  0.412946                 0.567352           3.160715   \n",
       "std                  30.604864                36.513513          95.268204   \n",
       "min                   0.000000                 0.000000           0.000000   \n",
       "25%                   0.000000                 0.000000           0.000000   \n",
       "50%                   0.000000                 0.000000           0.000000   \n",
       "75%                   0.000000                 0.000000           0.000000   \n",
       "max                6600.000000              6600.000000        8237.820000   \n",
       "\n",
       "       imp_op_var41_comer_ult1  imp_op_var41_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 68.803937               113.056934   \n",
       "std                 319.605516               512.154823   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             16566.810000   \n",
       "\n",
       "       imp_op_var41_efect_ult1  imp_op_var41_efect_ult3  imp_op_var41_ult1  \\\n",
       "count             76020.000000             76020.000000       76020.000000   \n",
       "mean                 68.205140               113.225058         137.242763   \n",
       "std                 531.897917               950.086398         697.712596   \n",
       "min                   0.000000                 0.000000           0.000000   \n",
       "25%                   0.000000                 0.000000           0.000000   \n",
       "50%                   0.000000                 0.000000           0.000000   \n",
       "75%                   0.000000                 0.000000           0.000000   \n",
       "max               45990.000000            131100.000000       47598.090000   \n",
       "\n",
       "       imp_op_var39_efect_ult1  imp_op_var39_efect_ult3  imp_op_var39_ult1  \\\n",
       "count             76020.000000             76020.000000       76020.000000   \n",
       "mean                 68.618087               113.792410         140.403479   \n",
       "std                 535.473750               953.578624         712.767240   \n",
       "min                   0.000000                 0.000000           0.000000   \n",
       "25%                   0.000000                 0.000000           0.000000   \n",
       "50%                   0.000000                 0.000000           0.000000   \n",
       "75%                   0.000000                 0.000000           0.000000   \n",
       "max               45990.000000            131100.000000       47598.090000   \n",
       "\n",
       "       imp_sal_var16_ult1    ind_var1_0      ind_var1  ind_var2_0  ind_var2  \\\n",
       "count        76020.000000  76020.000000  76020.000000     76020.0   76020.0   \n",
       "mean             5.477676      0.011458      0.003762         0.0       0.0   \n",
       "std            465.391149      0.106425      0.061221         0.0       0.0   \n",
       "min              0.000000      0.000000      0.000000         0.0       0.0   \n",
       "25%              0.000000      0.000000      0.000000         0.0       0.0   \n",
       "50%              0.000000      0.000000      0.000000         0.0       0.0   \n",
       "75%              0.000000      0.000000      0.000000         0.0       0.0   \n",
       "max         105000.000000      1.000000      1.000000         0.0       0.0   \n",
       "\n",
       "         ind_var5_0      ind_var5    ind_var6_0      ind_var6    ind_var8_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.958024      0.663760      0.000105      0.000026      0.032833   \n",
       "std        0.200535      0.472425      0.010258      0.005129      0.178202   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ind_var8   ind_var12_0     ind_var12   ind_var13_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.028598      0.067522      0.045462      0.052249   \n",
       "std        0.166674      0.250925      0.208316      0.222531   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ind_var13_corto_0  ind_var13_corto  ind_var13_largo_0  ind_var13_largo  \\\n",
       "count       76020.000000     76020.000000       76020.000000     76020.000000   \n",
       "mean            0.042936         0.041476           0.010168         0.009997   \n",
       "std             0.202714         0.199390           0.100325         0.099486   \n",
       "min             0.000000         0.000000           0.000000         0.000000   \n",
       "25%             0.000000         0.000000           0.000000         0.000000   \n",
       "50%             0.000000         0.000000           0.000000         0.000000   \n",
       "75%             0.000000         0.000000           0.000000         0.000000   \n",
       "max             1.000000         1.000000           1.000000         1.000000   \n",
       "\n",
       "       ind_var13_medio_0  ind_var13_medio     ind_var13   ind_var14_0  \\\n",
       "count       76020.000000     76020.000000  76020.000000  76020.000000   \n",
       "mean            0.000026         0.000026      0.050855      0.023652   \n",
       "std             0.005129         0.005129      0.219703      0.151962   \n",
       "min             0.000000         0.000000      0.000000      0.000000   \n",
       "25%             0.000000         0.000000      0.000000      0.000000   \n",
       "50%             0.000000         0.000000      0.000000      0.000000   \n",
       "75%             0.000000         0.000000      0.000000      0.000000   \n",
       "max             1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "          ind_var14   ind_var17_0     ind_var17   ind_var18_0     ind_var18  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.005301      0.001802      0.001447      0.000026      0.000026   \n",
       "std        0.072617      0.042414      0.038012      0.005129      0.005129   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          ind_var19   ind_var20_0     ind_var20   ind_var24_0     ind_var24  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.004196      0.003631      0.002697      0.042370      0.037885   \n",
       "std        0.064643      0.060146      0.051860      0.201434      0.190919   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ind_var25_cte   ind_var26_0  ind_var26_cte     ind_var26   ind_var25_0  \\\n",
       "count   76020.000000  76020.000000   76020.000000  76020.000000  76020.000000   \n",
       "mean        0.026427      0.024638       0.027559      0.024638      0.023639   \n",
       "std         0.160403      0.155021       0.163705      0.155021      0.151921   \n",
       "min         0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "max         1.000000      1.000000       1.000000      1.000000      1.000000   \n",
       "\n",
       "          ind_var25  ind_var27_0  ind_var28_0  ind_var28  ind_var27  \\\n",
       "count  76020.000000      76020.0      76020.0    76020.0    76020.0   \n",
       "mean       0.023639          0.0          0.0        0.0        0.0   \n",
       "std        0.151921          0.0          0.0        0.0        0.0   \n",
       "min        0.000000          0.0          0.0        0.0        0.0   \n",
       "25%        0.000000          0.0          0.0        0.0        0.0   \n",
       "50%        0.000000          0.0          0.0        0.0        0.0   \n",
       "75%        0.000000          0.0          0.0        0.0        0.0   \n",
       "max        1.000000          0.0          0.0        0.0        0.0   \n",
       "\n",
       "        ind_var29_0     ind_var29   ind_var30_0     ind_var30   ind_var31_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.000105      0.000026      0.995488      0.732833      0.004275   \n",
       "std        0.010258      0.005129      0.067020      0.442483      0.065245   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         ind_var31  ind_var32_cte   ind_var32_0     ind_var32   ind_var33_0  \\\n",
       "count  76020.00000   76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.00367       0.001210      0.001079      0.001079      0.000750   \n",
       "std        0.06047       0.034767      0.032826      0.032826      0.027372   \n",
       "min        0.00000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.00000       0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.00000       0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.00000       0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.00000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          ind_var33   ind_var34_0     ind_var34  ind_var37_cte   ind_var37_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000   76020.000000  76020.000000   \n",
       "mean       0.000631      0.000026      0.000026       0.072297      0.065259   \n",
       "std        0.025120      0.005129      0.005129       0.258980      0.246984   \n",
       "min        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000       1.000000      1.000000   \n",
       "\n",
       "          ind_var37   ind_var39_0   ind_var40_0     ind_var40   ind_var41_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.065259      0.880755      0.011418      0.003723      0.879282   \n",
       "std        0.246984      0.324079      0.106244      0.060901      0.325802   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "50%        0.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "75%        0.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ind_var41     ind_var39   ind_var44_0     ind_var44  ind_var46_0  \\\n",
       "count    76020.0  76020.000000  76020.000000  76020.000000      76020.0   \n",
       "mean         0.0      0.003723      0.001881      0.001697          0.0   \n",
       "std          0.0      0.060901      0.043331      0.041159          0.0   \n",
       "min          0.0      0.000000      0.000000      0.000000          0.0   \n",
       "25%          0.0      0.000000      0.000000      0.000000          0.0   \n",
       "50%          0.0      0.000000      0.000000      0.000000          0.0   \n",
       "75%          0.0      0.000000      0.000000      0.000000          0.0   \n",
       "max          0.0      1.000000      1.000000      1.000000          0.0   \n",
       "\n",
       "       ind_var46    num_var1_0      num_var1      num_var4    num_var5_0  \\\n",
       "count    76020.0  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean         0.0      0.034451      0.011326      1.079440      2.894041   \n",
       "std          0.0      0.320379      0.184626      0.909566      0.656479   \n",
       "min          0.0      0.000000      0.000000      0.000000      0.000000   \n",
       "25%          0.0      0.000000      0.000000      0.000000      3.000000   \n",
       "50%          0.0      0.000000      0.000000      1.000000      3.000000   \n",
       "75%          0.0      0.000000      0.000000      1.000000      3.000000   \n",
       "max          0.0      6.000000      6.000000      7.000000     15.000000   \n",
       "\n",
       "           num_var5    num_var6_0      num_var6   num_var8_0      num_var8  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.00000  76020.000000   \n",
       "mean       1.999171      0.000316      0.000079      0.09854      0.085793   \n",
       "std        1.431902      0.030774      0.015388      0.53493      0.500022   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%        3.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%        3.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "max       15.000000      3.000000      3.000000      6.00000      3.000000   \n",
       "\n",
       "        num_var12_0     num_var12   num_var13_0  num_var13_corto_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000       76020.000000   \n",
       "mean       0.211247      0.138003      0.167719           0.130308   \n",
       "std        0.890236      0.637259      0.745822           0.618826   \n",
       "min        0.000000      0.000000      0.000000           0.000000   \n",
       "25%        0.000000      0.000000      0.000000           0.000000   \n",
       "50%        0.000000      0.000000      0.000000           0.000000   \n",
       "75%        0.000000      0.000000      0.000000           0.000000   \n",
       "max      111.000000     15.000000     18.000000           6.000000   \n",
       "\n",
       "       num_var13_corto  num_var13_largo_0  num_var13_largo  num_var13_medio_0  \\\n",
       "count     76020.000000       76020.000000     76020.000000       76020.000000   \n",
       "mean          0.124507           0.037332         0.035241           0.000079   \n",
       "std           0.598746           0.404822         0.381373           0.015388   \n",
       "min           0.000000           0.000000         0.000000           0.000000   \n",
       "25%           0.000000           0.000000         0.000000           0.000000   \n",
       "50%           0.000000           0.000000         0.000000           0.000000   \n",
       "75%           0.000000           0.000000         0.000000           0.000000   \n",
       "max           6.000000          18.000000        18.000000           3.000000   \n",
       "\n",
       "       num_var13_medio     num_var13   num_var14_0    num_var14   num_var17_0  \\\n",
       "count     76020.000000  76020.000000  76020.000000  76020.00000  76020.000000   \n",
       "mean          0.000079      0.159826      0.072691      0.01614      0.011878   \n",
       "std           0.015388      0.713022      0.610815      0.22426      0.362480   \n",
       "min           0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%           0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%           0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "max           3.000000     18.000000    111.000000     12.00000     36.000000   \n",
       "\n",
       "          num_var17   num_var18_0     num_var18   num_var20_0     num_var20  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.008879      0.000079      0.000079      0.010892      0.008090   \n",
       "std        0.288768      0.015388      0.015388      0.180437      0.155579   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       27.000000      3.000000      3.000000      3.000000      3.000000   \n",
       "\n",
       "        num_var24_0     num_var24   num_var26_0     num_var26   num_var25_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.127664      0.113773      0.089384      0.089384      0.085162   \n",
       "std        0.608482      0.573662      0.628596      0.628596      0.612110   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000      6.000000     33.000000     33.000000     33.000000   \n",
       "\n",
       "          num_var25  num_op_var40_hace2  num_op_var40_hace3  \\\n",
       "count  76020.000000        76020.000000        76020.000000   \n",
       "mean       0.085162            0.020245            0.001026   \n",
       "std        0.612110            0.897618            0.180762   \n",
       "min        0.000000            0.000000            0.000000   \n",
       "25%        0.000000            0.000000            0.000000   \n",
       "50%        0.000000            0.000000            0.000000   \n",
       "75%        0.000000            0.000000            0.000000   \n",
       "max       33.000000          117.000000           48.000000   \n",
       "\n",
       "       num_op_var40_ult1  num_op_var40_ult3  num_op_var41_hace2  \\\n",
       "count       76020.000000       76020.000000        76020.000000   \n",
       "mean            0.057024           0.078295            1.601144   \n",
       "std             1.827374           2.558216            7.322004   \n",
       "min             0.000000           0.000000            0.000000   \n",
       "25%             0.000000           0.000000            0.000000   \n",
       "50%             0.000000           0.000000            0.000000   \n",
       "75%             0.000000           0.000000            0.000000   \n",
       "max           234.000000         351.000000          249.000000   \n",
       "\n",
       "       num_op_var41_hace3  num_op_var41_ult1  num_op_var41_ult3  \\\n",
       "count        76020.000000       76020.000000       76020.000000   \n",
       "mean             0.093923           2.858840           4.553907   \n",
       "std              1.215218          10.886314          16.891801   \n",
       "min              0.000000           0.000000           0.000000   \n",
       "25%              0.000000           0.000000           0.000000   \n",
       "50%              0.000000           0.000000           0.000000   \n",
       "75%              0.000000           0.000000           0.000000   \n",
       "max             81.000000         468.000000         468.000000   \n",
       "\n",
       "       num_op_var39_hace2  num_op_var39_hace3  num_op_var39_ult1  \\\n",
       "count        76020.000000        76020.000000       76020.000000   \n",
       "mean             1.621389            0.094949           2.915864   \n",
       "std              7.389539            1.228510          11.112899   \n",
       "min              0.000000            0.000000           0.000000   \n",
       "25%              0.000000            0.000000           0.000000   \n",
       "50%              0.000000            0.000000           0.000000   \n",
       "75%              0.000000            0.000000           0.000000   \n",
       "max            249.000000           81.000000         468.000000   \n",
       "\n",
       "       num_op_var39_ult3  num_var27_0  num_var28_0  num_var28  num_var27  \\\n",
       "count       76020.000000      76020.0      76020.0    76020.0    76020.0   \n",
       "mean            4.632202          0.0          0.0        0.0        0.0   \n",
       "std            17.175900          0.0          0.0        0.0        0.0   \n",
       "min             0.000000          0.0          0.0        0.0        0.0   \n",
       "25%             0.000000          0.0          0.0        0.0        0.0   \n",
       "50%             0.000000          0.0          0.0        0.0        0.0   \n",
       "75%             0.000000          0.0          0.0        0.0        0.0   \n",
       "max           468.000000          0.0          0.0        0.0        0.0   \n",
       "\n",
       "        num_var29_0     num_var29   num_var30_0     num_var30   num_var31_0  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.000316      0.000079      3.371863      2.382873      0.020126   \n",
       "std        0.030774      0.015388      1.336654      1.642787      0.406624   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      3.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      3.000000      3.000000      0.000000   \n",
       "75%        0.000000      0.000000      3.000000      3.000000      0.000000   \n",
       "max        3.000000      3.000000    114.000000     33.000000     36.000000   \n",
       "\n",
       "          num_var31   num_var32_0     num_var32   num_var33_0     num_var33  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.016062      0.004223      0.004223      0.002565      0.002092   \n",
       "std        0.331609      0.139702      0.139702      0.101457      0.086338   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       27.000000     12.000000     12.000000     12.000000      6.000000   \n",
       "\n",
       "        num_var34_0     num_var34     num_var35  num_var37_med_ult2  \\\n",
       "count  76020.000000  76020.000000  76020.000000        76020.000000   \n",
       "mean       0.000079      0.000079      3.299369            0.263536   \n",
       "std        0.015388      0.015388      2.868217            1.650273   \n",
       "min        0.000000      0.000000      0.000000            0.000000   \n",
       "25%        0.000000      0.000000      0.000000            0.000000   \n",
       "50%        0.000000      0.000000      3.000000            0.000000   \n",
       "75%        0.000000      0.000000      3.000000            0.000000   \n",
       "max        3.000000      3.000000     36.000000          105.000000   \n",
       "\n",
       "        num_var37_0     num_var37   num_var39_0   num_var40_0     num_var40  \\\n",
       "count  76020.000000  76020.000000  76020.000000  76020.000000  76020.000000   \n",
       "mean       0.418785      0.418785      2.724941      0.034294      0.011168   \n",
       "std        2.241141      2.241141      1.139159      0.319285      0.182702   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      3.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      3.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      3.000000      0.000000      0.000000   \n",
       "max      114.000000    114.000000     33.000000      6.000000      3.000000   \n",
       "\n",
       "        num_var41_0  num_var41     num_var39   num_var42_0     num_var42  \\\n",
       "count  76020.000000    76020.0  76020.000000  76020.000000  76020.000000   \n",
       "mean       2.699250        0.0      0.011168      3.204144      2.217995   \n",
       "std        1.105297        0.0      0.182702      0.944123      1.497703   \n",
       "min        0.000000        0.0      0.000000      0.000000      0.000000   \n",
       "25%        3.000000        0.0      0.000000      3.000000      0.000000   \n",
       "50%        3.000000        0.0      0.000000      3.000000      3.000000   \n",
       "75%        3.000000        0.0      0.000000      3.000000      3.000000   \n",
       "max       33.000000        0.0      3.000000    114.000000     18.000000   \n",
       "\n",
       "        num_var44_0     num_var44  num_var46_0  num_var46    saldo_var1  \\\n",
       "count  76020.000000  76020.000000      76020.0    76020.0  7.602000e+04   \n",
       "mean       0.005683      0.005091          0.0        0.0  4.844911e+01   \n",
       "std        0.131350      0.123477          0.0        0.0  1.093747e+04   \n",
       "min        0.000000      0.000000          0.0        0.0 -9.000000e-01   \n",
       "25%        0.000000      0.000000          0.0        0.0  0.000000e+00   \n",
       "50%        0.000000      0.000000          0.0        0.0  0.000000e+00   \n",
       "75%        0.000000      0.000000          0.0        0.0  0.000000e+00   \n",
       "max        6.000000      3.000000          0.0        0.0  3.000000e+06   \n",
       "\n",
       "          saldo_var5    saldo_var6     saldo_var8   saldo_var12  \\\n",
       "count   76020.000000  76020.000000   76020.000000  7.602000e+04   \n",
       "mean     1028.468235      0.414475     141.226784  6.021616e+03   \n",
       "std      9852.140073     83.096797    2515.656302  4.814471e+04   \n",
       "min     -2895.720000      0.000000   -4942.260000  0.000000e+00   \n",
       "25%         0.000000      0.000000       0.000000  0.000000e+00   \n",
       "50%         3.000000      0.000000       0.000000  0.000000e+00   \n",
       "75%        90.000000      0.000000       0.000000  0.000000e+00   \n",
       "max    619329.150000  19531.800000  240045.000000  3.008077e+06   \n",
       "\n",
       "       saldo_var13_corto  saldo_var13_largo  saldo_var13_medio   saldo_var13  \\\n",
       "count       76020.000000       7.602000e+04       76020.000000  7.602000e+04   \n",
       "mean         4993.752970       1.493682e+03           0.513023  6.487948e+03   \n",
       "std         32619.134245       2.001649e+04         113.597559  3.841675e+04   \n",
       "min             0.000000       0.000000e+00           0.000000  0.000000e+00   \n",
       "25%             0.000000       0.000000e+00           0.000000  0.000000e+00   \n",
       "50%             0.000000       0.000000e+00           0.000000  0.000000e+00   \n",
       "75%             0.000000       0.000000e+00           0.000000  0.000000e+00   \n",
       "max        450000.000000       1.500000e+06       30000.000000  1.500000e+06   \n",
       "\n",
       "         saldo_var14   saldo_var17   saldo_var18    saldo_var20   saldo_var24  \\\n",
       "count   76020.000000  7.602000e+04  7.602000e+04   76020.000000  7.602000e+04   \n",
       "mean       69.096200  1.834059e+02  4.340963e+01      27.399456  5.925120e+03   \n",
       "std      2839.618964  2.269813e+04  1.093497e+04    2477.810744  4.800853e+04   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000  0.000000e+00   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00       0.000000  0.000000e+00   \n",
       "50%         0.000000  0.000000e+00  0.000000e+00       0.000000  0.000000e+00   \n",
       "75%         0.000000  0.000000e+00  0.000000e+00       0.000000  0.000000e+00   \n",
       "max    450000.000000  6.119500e+06  3.000000e+06  455858.160000  3.008077e+06   \n",
       "\n",
       "        saldo_var26   saldo_var25  saldo_var28  saldo_var27   saldo_var29  \\\n",
       "count  76020.000000  76020.000000      76020.0      76020.0  76020.000000   \n",
       "mean      76.081633     72.735693          0.0          0.0      0.414475   \n",
       "std      739.776626    726.882669          0.0          0.0     83.096797   \n",
       "min        0.000000      0.000000          0.0          0.0      0.000000   \n",
       "25%        0.000000      0.000000          0.0          0.0      0.000000   \n",
       "50%        0.000000      0.000000          0.0          0.0      0.000000   \n",
       "75%        0.000000      0.000000          0.0          0.0      0.000000   \n",
       "max    69756.720000  69756.720000          0.0          0.0  19531.800000   \n",
       "\n",
       "        saldo_var30   saldo_var31   saldo_var32    saldo_var33   saldo_var34  \\\n",
       "count  7.602000e+04  7.602000e+04  76020.000000   76020.000000  76020.000000   \n",
       "mean   1.367967e+04  2.922910e+02      3.345941      12.532333      0.670876   \n",
       "std    6.301408e+04  2.331640e+04    126.680152     797.839557    141.448598   \n",
       "min   -4.942260e+03  0.000000e+00      0.000000       0.000000      0.000000   \n",
       "25%    0.000000e+00  0.000000e+00      0.000000       0.000000      0.000000   \n",
       "50%    3.000000e+00  0.000000e+00      0.000000       0.000000      0.000000   \n",
       "75%    2.359950e+02  0.000000e+00      0.000000       0.000000      0.000000   \n",
       "max    3.458077e+06  6.119500e+06  12210.780000  142078.800000  36000.000000   \n",
       "\n",
       "        saldo_var37   saldo_var40  saldo_var41   saldo_var42    saldo_var44  \\\n",
       "count  76020.000000  76020.000000      76020.0  7.602000e+04   76020.000000   \n",
       "mean      36.907194      4.368602          0.0  7.191725e+03      96.352738   \n",
       "std      472.098863    113.968756          0.0  4.914531e+04    5218.428365   \n",
       "min        0.000000     -0.900000          0.0 -4.942260e+03       0.000000   \n",
       "25%        0.000000      0.000000          0.0  0.000000e+00       0.000000   \n",
       "50%        0.000000      0.000000          0.0  3.000000e+00       0.000000   \n",
       "75%        0.000000      0.000000          0.0  1.200000e+02       0.000000   \n",
       "max    60000.000000   8192.610000          0.0  3.008077e+06  740006.610000   \n",
       "\n",
       "       saldo_var46         var36  delta_imp_amort_var18_1y3  \\\n",
       "count      76020.0  76020.000000               7.602000e+04   \n",
       "mean           0.0     40.449079               2.630887e+05   \n",
       "std            0.0     47.362719               5.129183e+07   \n",
       "min            0.0      0.000000               0.000000e+00   \n",
       "25%            0.0      2.000000               0.000000e+00   \n",
       "50%            0.0      3.000000               0.000000e+00   \n",
       "75%            0.0     99.000000               0.000000e+00   \n",
       "max            0.0     99.000000               1.000000e+10   \n",
       "\n",
       "       delta_imp_amort_var34_1y3  delta_imp_aport_var13_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                2.630887e+05               4.867140e+07   \n",
       "std                 5.129183e+07               6.959537e+08   \n",
       "min                 0.000000e+00              -1.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_imp_aport_var17_1y3  delta_imp_aport_var33_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                5.130229e+06               1.315443e+05   \n",
       "std                 2.264435e+08               3.626904e+07   \n",
       "min                -1.000000e+00              -1.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_imp_compra_var44_1y3  delta_imp_reemb_var13_1y3  \\\n",
       "count                7.602000e+04               7.602000e+04   \n",
       "mean                 9.208103e+06               4.998685e+06   \n",
       "std                  3.033108e+08               2.235230e+08   \n",
       "min                 -1.000000e+00               0.000000e+00   \n",
       "25%                  0.000000e+00               0.000000e+00   \n",
       "50%                  0.000000e+00               0.000000e+00   \n",
       "75%                  0.000000e+00               0.000000e+00   \n",
       "max                  1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_imp_reemb_var17_1y3  delta_imp_reemb_var33_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                2.630887e+06               1.315443e+05   \n",
       "std                 1.621798e+08               3.626904e+07   \n",
       "min                -1.000000e+00               0.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_imp_trasp_var17_in_1y3  delta_imp_trasp_var17_out_1y3  \\\n",
       "count                  7.602000e+04                   7.602000e+04   \n",
       "mean                   5.261773e+05                   5.261773e+05   \n",
       "std                    7.253665e+07                   7.253665e+07   \n",
       "min                   -1.000000e+00                   0.000000e+00   \n",
       "25%                    0.000000e+00                   0.000000e+00   \n",
       "50%                    0.000000e+00                   0.000000e+00   \n",
       "75%                    0.000000e+00                   0.000000e+00   \n",
       "max                    1.000000e+10                   1.000000e+10   \n",
       "\n",
       "       delta_imp_trasp_var33_in_1y3  delta_imp_trasp_var33_out_1y3  \\\n",
       "count                  7.602000e+04                   7.602000e+04   \n",
       "mean                   6.577217e+05                   1.315443e+05   \n",
       "std                    8.109791e+07                   3.626904e+07   \n",
       "min                   -1.000000e+00                   0.000000e+00   \n",
       "25%                    0.000000e+00                   0.000000e+00   \n",
       "50%                    0.000000e+00                   0.000000e+00   \n",
       "75%                    0.000000e+00                   0.000000e+00   \n",
       "max                    1.000000e+10                   1.000000e+10   \n",
       "\n",
       "       delta_imp_venta_var44_1y3  delta_num_aport_var13_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                5.524862e+06               4.867140e+07   \n",
       "std                 2.349869e+08               6.959537e+08   \n",
       "min                -1.000000e+00              -1.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_num_aport_var17_1y3  delta_num_aport_var33_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                5.130229e+06               1.315443e+05   \n",
       "std                 2.264435e+08               3.626904e+07   \n",
       "min                -1.000000e+00              -1.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_num_compra_var44_1y3  delta_num_reemb_var13_1y3  \\\n",
       "count                7.602000e+04               7.602000e+04   \n",
       "mean                 9.208103e+06               4.998685e+06   \n",
       "std                  3.033108e+08               2.235230e+08   \n",
       "min                 -1.000000e+00               0.000000e+00   \n",
       "25%                  0.000000e+00               0.000000e+00   \n",
       "50%                  0.000000e+00               0.000000e+00   \n",
       "75%                  0.000000e+00               0.000000e+00   \n",
       "max                  1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_num_reemb_var17_1y3  delta_num_reemb_var33_1y3  \\\n",
       "count               7.602000e+04               7.602000e+04   \n",
       "mean                2.630887e+06               1.315443e+05   \n",
       "std                 1.621798e+08               3.626904e+07   \n",
       "min                -1.000000e+00               0.000000e+00   \n",
       "25%                 0.000000e+00               0.000000e+00   \n",
       "50%                 0.000000e+00               0.000000e+00   \n",
       "75%                 0.000000e+00               0.000000e+00   \n",
       "max                 1.000000e+10               1.000000e+10   \n",
       "\n",
       "       delta_num_trasp_var17_in_1y3  delta_num_trasp_var17_out_1y3  \\\n",
       "count                  7.602000e+04                   7.602000e+04   \n",
       "mean                   5.261773e+05                   5.261773e+05   \n",
       "std                    7.253665e+07                   7.253665e+07   \n",
       "min                   -1.000000e+00                   0.000000e+00   \n",
       "25%                    0.000000e+00                   0.000000e+00   \n",
       "50%                    0.000000e+00                   0.000000e+00   \n",
       "75%                    0.000000e+00                   0.000000e+00   \n",
       "max                    1.000000e+10                   1.000000e+10   \n",
       "\n",
       "       delta_num_trasp_var33_in_1y3  delta_num_trasp_var33_out_1y3  \\\n",
       "count                  7.602000e+04                   7.602000e+04   \n",
       "mean                   6.577217e+05                   1.315443e+05   \n",
       "std                    8.109791e+07                   3.626904e+07   \n",
       "min                   -1.000000e+00                   0.000000e+00   \n",
       "25%                    0.000000e+00                   0.000000e+00   \n",
       "50%                    0.000000e+00                   0.000000e+00   \n",
       "75%                    0.000000e+00                   0.000000e+00   \n",
       "max                    1.000000e+10                   1.000000e+10   \n",
       "\n",
       "       delta_num_venta_var44_1y3  imp_amort_var18_hace3  imp_amort_var18_ult1  \\\n",
       "count               7.602000e+04                76020.0          76020.000000   \n",
       "mean                5.524862e+06                    0.0              0.231189   \n",
       "std                 2.349869e+08                    0.0             57.320958   \n",
       "min                -1.000000e+00                    0.0              0.000000   \n",
       "25%                 0.000000e+00                    0.0              0.000000   \n",
       "50%                 0.000000e+00                    0.0              0.000000   \n",
       "75%                 0.000000e+00                    0.0              0.000000   \n",
       "max                 1.000000e+10                    0.0          15691.800000   \n",
       "\n",
       "       imp_amort_var34_hace3  imp_amort_var34_ult1  imp_aport_var13_hace3  \\\n",
       "count                76020.0          76020.000000           76020.000000   \n",
       "mean                     0.0              0.018051            2823.949089   \n",
       "std                      0.0              4.099461           25334.468106   \n",
       "min                      0.0              0.000000               0.000000   \n",
       "25%                      0.0              0.000000               0.000000   \n",
       "50%                      0.0              0.000000               0.000000   \n",
       "75%                      0.0              0.000000               0.000000   \n",
       "max                      0.0           1096.020000          840000.000000   \n",
       "\n",
       "       imp_aport_var13_ult1  imp_aport_var17_hace3  imp_aport_var17_ult1  \\\n",
       "count          76020.000000           7.602000e+04          76020.000000   \n",
       "mean             619.585010           9.878877e+01             31.105323   \n",
       "std            11252.995089           2.212072e+04           2457.091282   \n",
       "min                0.000000           0.000000e+00              0.000000   \n",
       "25%                0.000000           0.000000e+00              0.000000   \n",
       "50%                0.000000           0.000000e+00              0.000000   \n",
       "75%                0.000000           0.000000e+00              0.000000   \n",
       "max           450000.000000           6.083692e+06         432457.320000   \n",
       "\n",
       "       imp_aport_var33_hace3  imp_aport_var33_ult1  imp_var7_emit_ult1  \\\n",
       "count           76020.000000          76020.000000        76020.000000   \n",
       "mean                2.985793              0.048145            2.721454   \n",
       "std               226.862984              6.022692          554.249437   \n",
       "min                 0.000000              0.000000            0.000000   \n",
       "25%                 0.000000              0.000000            0.000000   \n",
       "50%                 0.000000              0.000000            0.000000   \n",
       "75%                 0.000000              0.000000            0.000000   \n",
       "max             36000.000000           1260.000000       145384.920000   \n",
       "\n",
       "       imp_var7_recib_ult1  imp_compra_var44_hace3  imp_compra_var44_ult1  \\\n",
       "count         7.602000e+04            76020.000000           7.602000e+04   \n",
       "mean          1.276982e+02               13.964581           1.167825e+02   \n",
       "std           6.368997e+03             1151.510862           1.362044e+04   \n",
       "min           0.000000e+00                0.000000           0.000000e+00   \n",
       "25%           0.000000e+00                0.000000           0.000000e+00   \n",
       "50%           0.000000e+00                0.000000           0.000000e+00   \n",
       "75%           0.000000e+00                0.000000           0.000000e+00   \n",
       "max           1.039260e+06           210001.350000           3.410059e+06   \n",
       "\n",
       "       imp_reemb_var13_hace3  imp_reemb_var13_ult1  imp_reemb_var17_hace3  \\\n",
       "count                76020.0          76020.000000           76020.000000   \n",
       "mean                     0.0             46.180243               0.158210   \n",
       "std                      0.0           2859.736591              43.621319   \n",
       "min                      0.0              0.000000               0.000000   \n",
       "25%                      0.0              0.000000               0.000000   \n",
       "50%                      0.0              0.000000               0.000000   \n",
       "75%                      0.0              0.000000               0.000000   \n",
       "max                      0.0         450000.000000           12027.150000   \n",
       "\n",
       "       imp_reemb_var17_ult1  imp_reemb_var33_hace3  imp_reemb_var33_ult1  \\\n",
       "count          76020.000000                76020.0          76020.000000   \n",
       "mean              12.569401                    0.0              0.015785   \n",
       "std             1093.133883                    0.0              4.352285   \n",
       "min                0.000000                    0.0              0.000000   \n",
       "25%                0.000000                    0.0              0.000000   \n",
       "50%                0.000000                    0.0              0.000000   \n",
       "75%                0.000000                    0.0              0.000000   \n",
       "max           182132.970000                    0.0           1200.000000   \n",
       "\n",
       "       imp_var43_emit_ult1  imp_trans_var37_ult1  imp_trasp_var17_in_hace3  \\\n",
       "count         7.602000e+04          7.602000e+04              76020.000000   \n",
       "mean          8.541207e+02          1.932954e+03                  1.874808   \n",
       "std           1.425589e+04          2.535572e+04                388.245022   \n",
       "min           0.000000e+00          0.000000e+00                  0.000000   \n",
       "25%           0.000000e+00          0.000000e+00                  0.000000   \n",
       "50%           0.000000e+00          0.000000e+00                  0.000000   \n",
       "75%           0.000000e+00          0.000000e+00                  0.000000   \n",
       "max           1.155003e+06          2.310003e+06              96781.440000   \n",
       "\n",
       "       imp_trasp_var17_in_ult1  imp_trasp_var17_out_hace3  \\\n",
       "count             76020.000000                    76020.0   \n",
       "mean                  2.512678                        0.0   \n",
       "std                 508.968831                        0.0   \n",
       "min                   0.000000                        0.0   \n",
       "25%                   0.000000                        0.0   \n",
       "50%                   0.000000                        0.0   \n",
       "75%                   0.000000                        0.0   \n",
       "max              133730.580000                        0.0   \n",
       "\n",
       "       imp_trasp_var17_out_ult1  imp_trasp_var33_in_hace3  \\\n",
       "count              76020.000000              76020.000000   \n",
       "mean                   1.913616                  2.789772   \n",
       "std                  357.405330                323.814261   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    0.000000                  0.000000   \n",
       "75%                    0.000000                  0.000000   \n",
       "max                69622.290000              49581.270000   \n",
       "\n",
       "       imp_trasp_var33_in_ult1  imp_trasp_var33_out_hace3  \\\n",
       "count             76020.000000                    76020.0   \n",
       "mean                  0.314701                        0.0   \n",
       "std                  53.408085                        0.0   \n",
       "min                   0.000000                        0.0   \n",
       "25%                   0.000000                        0.0   \n",
       "50%                   0.000000                        0.0   \n",
       "75%                   0.000000                        0.0   \n",
       "max               13207.320000                        0.0   \n",
       "\n",
       "       imp_trasp_var33_out_ult1  imp_venta_var44_hace3  imp_venta_var44_ult1  \\\n",
       "count              76020.000000           76020.000000          7.602000e+04   \n",
       "mean                   0.039463               3.787137          8.143383e+01   \n",
       "std                   10.880712             811.976086          1.128241e+04   \n",
       "min                    0.000000               0.000000          0.000000e+00   \n",
       "25%                    0.000000               0.000000          0.000000e+00   \n",
       "50%                    0.000000               0.000000          0.000000e+00   \n",
       "75%                    0.000000               0.000000          0.000000e+00   \n",
       "max                 3000.000000          209834.400000          2.754476e+06   \n",
       "\n",
       "       ind_var7_emit_ult1  ind_var7_recib_ult1  ind_var10_ult1  \\\n",
       "count        76020.000000         76020.000000    76020.000000   \n",
       "mean             0.000039             0.002697        0.080873   \n",
       "std              0.006282             0.051860        0.272642   \n",
       "min              0.000000             0.000000        0.000000   \n",
       "25%              0.000000             0.000000        0.000000   \n",
       "50%              0.000000             0.000000        0.000000   \n",
       "75%              0.000000             0.000000        0.000000   \n",
       "max              1.000000             1.000000        1.000000   \n",
       "\n",
       "       ind_var10cte_ult1  ind_var9_cte_ult1  ind_var9_ult1  \\\n",
       "count       76020.000000       76020.000000   76020.000000   \n",
       "mean            0.092160           0.096869       0.085912   \n",
       "std             0.289254           0.295782       0.280235   \n",
       "min             0.000000           0.000000       0.000000   \n",
       "25%             0.000000           0.000000       0.000000   \n",
       "50%             0.000000           0.000000       0.000000   \n",
       "75%             0.000000           0.000000       0.000000   \n",
       "max             1.000000           1.000000       1.000000   \n",
       "\n",
       "       ind_var43_emit_ult1  ind_var43_recib_ult1         var21  \\\n",
       "count         76020.000000          76020.000000  76020.000000   \n",
       "mean              0.066588              0.129308     32.549329   \n",
       "std               0.249308              0.335543    393.834939   \n",
       "min               0.000000              0.000000      0.000000   \n",
       "25%               0.000000              0.000000      0.000000   \n",
       "50%               0.000000              0.000000      0.000000   \n",
       "75%               0.000000              0.000000      0.000000   \n",
       "max               1.000000              1.000000  30000.000000   \n",
       "\n",
       "       num_var2_0_ult1  num_var2_ult1  num_aport_var13_hace3  \\\n",
       "count          76020.0        76020.0           76020.000000   \n",
       "mean               0.0            0.0               0.075888   \n",
       "std                0.0            0.0               0.552499   \n",
       "min                0.0            0.0               0.000000   \n",
       "25%                0.0            0.0               0.000000   \n",
       "50%                0.0            0.0               0.000000   \n",
       "75%                0.0            0.0               0.000000   \n",
       "max                0.0            0.0              24.000000   \n",
       "\n",
       "       num_aport_var13_ult1  num_aport_var17_hace3  num_aport_var17_ult1  \\\n",
       "count          76020.000000           76020.000000          76020.000000   \n",
       "mean               0.017956               0.001539              0.003394   \n",
       "std                0.288757               0.104919              0.174059   \n",
       "min                0.000000               0.000000              0.000000   \n",
       "25%                0.000000               0.000000              0.000000   \n",
       "50%                0.000000               0.000000              0.000000   \n",
       "75%                0.000000               0.000000              0.000000   \n",
       "max               30.000000              12.000000             21.000000   \n",
       "\n",
       "       num_aport_var33_hace3  num_aport_var33_ult1  num_var7_emit_ult1  \\\n",
       "count           76020.000000          76020.000000        76020.000000   \n",
       "mean                0.001066              0.000316            0.000118   \n",
       "std                 0.069663              0.034407            0.018846   \n",
       "min                 0.000000              0.000000            0.000000   \n",
       "25%                 0.000000              0.000000            0.000000   \n",
       "50%                 0.000000              0.000000            0.000000   \n",
       "75%                 0.000000              0.000000            0.000000   \n",
       "max                12.000000              6.000000            3.000000   \n",
       "\n",
       "       num_var7_recib_ult1  num_compra_var44_hace3  num_compra_var44_ult1  \\\n",
       "count         76020.000000            76020.000000           76020.000000   \n",
       "mean              0.010300                0.001855               0.007537   \n",
       "std               0.228782                0.099111               0.315453   \n",
       "min               0.000000                0.000000               0.000000   \n",
       "25%               0.000000                0.000000               0.000000   \n",
       "50%               0.000000                0.000000               0.000000   \n",
       "75%               0.000000                0.000000               0.000000   \n",
       "max              24.000000                9.000000              39.000000   \n",
       "\n",
       "       num_ent_var16_ult1  num_var22_hace2  num_var22_hace3  num_var22_ult1  \\\n",
       "count        76020.000000     76020.000000     76020.000000    76020.000000   \n",
       "mean             0.187964         1.298698         1.184886        0.560655   \n",
       "std              0.995016         3.450268         3.263333        2.104410   \n",
       "min              0.000000         0.000000         0.000000        0.000000   \n",
       "25%              0.000000         0.000000         0.000000        0.000000   \n",
       "50%              0.000000         0.000000         0.000000        0.000000   \n",
       "75%              0.000000         0.000000         0.000000        0.000000   \n",
       "max             60.000000       123.000000       108.000000       96.000000   \n",
       "\n",
       "       num_var22_ult3  num_med_var22_ult3  num_med_var45_ult3  \\\n",
       "count    76020.000000        76020.000000        76020.000000   \n",
       "mean         3.044238            0.635872            4.024665   \n",
       "std          6.206116            1.835267           10.930334   \n",
       "min          0.000000            0.000000            0.000000   \n",
       "25%          0.000000            0.000000            0.000000   \n",
       "50%          0.000000            0.000000            0.000000   \n",
       "75%          3.000000            0.000000            3.000000   \n",
       "max        234.000000           78.000000          267.000000   \n",
       "\n",
       "       num_meses_var5_ult3  num_meses_var8_ult3  num_meses_var12_ult3  \\\n",
       "count         76020.000000         76020.000000          76020.000000   \n",
       "mean              1.979979             0.053604              0.102052   \n",
       "std               1.298924             0.334908              0.487687   \n",
       "min               0.000000             0.000000              0.000000   \n",
       "25%               0.000000             0.000000              0.000000   \n",
       "50%               3.000000             0.000000              0.000000   \n",
       "75%               3.000000             0.000000              0.000000   \n",
       "max               3.000000             3.000000              3.000000   \n",
       "\n",
       "       num_meses_var13_corto_ult3  num_meses_var13_largo_ult3  \\\n",
       "count                76020.000000                76020.000000   \n",
       "mean                     0.098921                    0.017403   \n",
       "std                      0.486064                    0.213095   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.000000   \n",
       "75%                      0.000000                    0.000000   \n",
       "max                      3.000000                    3.000000   \n",
       "\n",
       "       num_meses_var13_medio_ult3  num_meses_var17_ult3  num_meses_var29_ult3  \\\n",
       "count                76020.000000          76020.000000          76020.000000   \n",
       "mean                     0.000053              0.002960              0.000105   \n",
       "std                      0.010258              0.077648              0.013570   \n",
       "min                      0.000000              0.000000              0.000000   \n",
       "25%                      0.000000              0.000000              0.000000   \n",
       "50%                      0.000000              0.000000              0.000000   \n",
       "75%                      0.000000              0.000000              0.000000   \n",
       "max                      2.000000              3.000000              2.000000   \n",
       "\n",
       "       num_meses_var33_ult3  num_meses_var39_vig_ult3  num_meses_var44_ult3  \\\n",
       "count          76020.000000              76020.000000          76020.000000   \n",
       "mean               0.001513                  1.592791              0.003578   \n",
       "std                0.062487                  0.719655              0.088174   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  1.000000              0.000000   \n",
       "50%                0.000000                  2.000000              0.000000   \n",
       "75%                0.000000                  2.000000              0.000000   \n",
       "max                3.000000                  3.000000              3.000000   \n",
       "\n",
       "       num_op_var39_comer_ult1  num_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  2.194791                 3.607064   \n",
       "std                   9.131406                14.919726   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                 438.000000               600.000000   \n",
       "\n",
       "       num_op_var40_comer_ult1  num_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  0.074980                 0.144830   \n",
       "std                   2.089408                 4.288145   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                 210.000000               582.000000   \n",
       "\n",
       "       num_op_var40_efect_ult1  num_op_var40_efect_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  0.002486                 0.003670   \n",
       "std                   0.147172                 0.202068   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                  24.000000                24.000000   \n",
       "\n",
       "       num_op_var41_comer_ult1  num_op_var41_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  2.119811                 3.462234   \n",
       "std                   8.799494                14.140650   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                 438.000000               438.000000   \n",
       "\n",
       "       num_op_var41_efect_ult1  num_op_var41_efect_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  0.719416                 1.212155   \n",
       "std                   3.210999                 5.160396   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                  90.000000               156.000000   \n",
       "\n",
       "       num_op_var39_efect_ult1  num_op_var39_efect_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  0.721902                 1.215825   \n",
       "std                   3.226314                 5.181092   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                  90.000000               156.000000   \n",
       "\n",
       "       num_reemb_var13_hace3  num_reemb_var13_ult1  num_reemb_var17_hace3  \\\n",
       "count                76020.0          76020.000000           76020.000000   \n",
       "mean                     0.0              0.001500               0.000039   \n",
       "std                      0.0              0.067057               0.010881   \n",
       "min                      0.0              0.000000               0.000000   \n",
       "25%                      0.0              0.000000               0.000000   \n",
       "50%                      0.0              0.000000               0.000000   \n",
       "75%                      0.0              0.000000               0.000000   \n",
       "max                      0.0              3.000000               3.000000   \n",
       "\n",
       "       num_reemb_var17_ult1  num_reemb_var33_hace3  num_reemb_var33_ult1  \\\n",
       "count          76020.000000                76020.0          76020.000000   \n",
       "mean               0.001184                    0.0              0.000039   \n",
       "std                0.098523                    0.0              0.010881   \n",
       "min                0.000000                    0.0              0.000000   \n",
       "25%                0.000000                    0.0              0.000000   \n",
       "50%                0.000000                    0.0              0.000000   \n",
       "75%                0.000000                    0.0              0.000000   \n",
       "max               21.000000                    0.0              3.000000   \n",
       "\n",
       "       num_sal_var16_ult1  num_var43_emit_ult1  num_var43_recib_ult1  \\\n",
       "count        76020.000000         76020.000000          76020.000000   \n",
       "mean             0.004933             0.392818              0.814996   \n",
       "std              0.154949             2.215853              3.557660   \n",
       "min              0.000000             0.000000              0.000000   \n",
       "25%              0.000000             0.000000              0.000000   \n",
       "50%              0.000000             0.000000              0.000000   \n",
       "75%              0.000000             0.000000              0.000000   \n",
       "max             15.000000           180.000000            264.000000   \n",
       "\n",
       "       num_trasp_var11_ult1  num_trasp_var17_in_hace3  \\\n",
       "count          76020.000000              76020.000000   \n",
       "mean               0.120679                  0.000118   \n",
       "std                1.172148                  0.024330   \n",
       "min                0.000000                  0.000000   \n",
       "25%                0.000000                  0.000000   \n",
       "50%                0.000000                  0.000000   \n",
       "75%                0.000000                  0.000000   \n",
       "max               93.000000                  6.000000   \n",
       "\n",
       "       num_trasp_var17_in_ult1  num_trasp_var17_out_hace3  \\\n",
       "count             76020.000000                    76020.0   \n",
       "mean                  0.000158                        0.0   \n",
       "std                   0.021761                        0.0   \n",
       "min                   0.000000                        0.0   \n",
       "25%                   0.000000                        0.0   \n",
       "50%                   0.000000                        0.0   \n",
       "75%                   0.000000                        0.0   \n",
       "max                   3.000000                        0.0   \n",
       "\n",
       "       num_trasp_var17_out_ult1  num_trasp_var33_in_hace3  \\\n",
       "count              76020.000000              76020.000000   \n",
       "mean                   0.000158                  0.000237   \n",
       "std                    0.021761                  0.026651   \n",
       "min                    0.000000                  0.000000   \n",
       "25%                    0.000000                  0.000000   \n",
       "50%                    0.000000                  0.000000   \n",
       "75%                    0.000000                  0.000000   \n",
       "max                    3.000000                  3.000000   \n",
       "\n",
       "       num_trasp_var33_in_ult1  num_trasp_var33_out_hace3  \\\n",
       "count             76020.000000                    76020.0   \n",
       "mean                  0.000237                        0.0   \n",
       "std                   0.030775                        0.0   \n",
       "min                   0.000000                        0.0   \n",
       "25%                   0.000000                        0.0   \n",
       "50%                   0.000000                        0.0   \n",
       "75%                   0.000000                        0.0   \n",
       "max                   6.000000                        0.0   \n",
       "\n",
       "       num_trasp_var33_out_ult1  num_venta_var44_hace3  num_venta_var44_ult1  \\\n",
       "count              76020.000000           76020.000000          76020.000000   \n",
       "mean                   0.000039               0.000158              0.004420   \n",
       "std                    0.010881               0.026652              0.264256   \n",
       "min                    0.000000               0.000000              0.000000   \n",
       "25%                    0.000000               0.000000              0.000000   \n",
       "50%                    0.000000               0.000000              0.000000   \n",
       "75%                    0.000000               0.000000              0.000000   \n",
       "max                    3.000000               6.000000             39.000000   \n",
       "\n",
       "       num_var45_hace2  num_var45_hace3  num_var45_ult1  num_var45_ult3  \\\n",
       "count     76020.000000     76020.000000    76020.000000    76020.000000   \n",
       "mean          5.393212         3.894396        4.363496       13.651105   \n",
       "std          14.496095        10.416821       14.406485       33.304012   \n",
       "min           0.000000         0.000000        0.000000        0.000000   \n",
       "25%           0.000000         0.000000        0.000000        0.000000   \n",
       "50%           0.000000         0.000000        0.000000        0.000000   \n",
       "75%           3.000000         3.000000        3.000000       12.000000   \n",
       "max         342.000000       339.000000      510.000000      801.000000   \n",
       "\n",
       "       saldo_var2_ult1  saldo_medio_var5_hace2  saldo_medio_var5_hace3  \\\n",
       "count          76020.0            76020.000000            7.602000e+04   \n",
       "mean               0.0             1579.135311            8.913659e+02   \n",
       "std                0.0            12148.452398            9.888597e+03   \n",
       "min                0.0             -128.370000           -8.040000e+00   \n",
       "25%                0.0                0.000000            0.000000e+00   \n",
       "50%                0.0                3.000000            9.900000e-01   \n",
       "75%                0.0               90.000000            1.221750e+01   \n",
       "max                0.0           812137.260000            1.542339e+06   \n",
       "\n",
       "       saldo_medio_var5_ult1  saldo_medio_var5_ult3  saldo_medio_var8_hace2  \\\n",
       "count           76020.000000           76020.000000            76020.000000   \n",
       "mean             1077.256756            1048.856447               68.275452   \n",
       "std              9614.906985            8189.948852             1733.838226   \n",
       "min              -922.380000            -476.070000             -287.670000   \n",
       "25%                 0.000000               0.000000                0.000000   \n",
       "50%                 3.000000               2.730000                0.000000   \n",
       "75%                90.000000              83.790000                0.000000   \n",
       "max            601428.600000          544365.570000           231351.990000   \n",
       "\n",
       "       saldo_medio_var8_hace3  saldo_medio_var8_ult1  saldo_medio_var8_ult3  \\\n",
       "count            76020.000000           76020.000000           76020.000000   \n",
       "mean                 9.505287             124.620962             110.026575   \n",
       "std                519.389157            2205.249804            1935.305713   \n",
       "min                  0.000000           -3401.340000           -1844.520000   \n",
       "25%                  0.000000               0.000000               0.000000   \n",
       "50%                  0.000000               0.000000               0.000000   \n",
       "75%                  0.000000               0.000000               0.000000   \n",
       "max              77586.210000          228031.800000          177582.000000   \n",
       "\n",
       "       saldo_medio_var12_hace2  saldo_medio_var12_hace3  \\\n",
       "count             7.602000e+04             76020.000000   \n",
       "mean              3.997023e+03               613.534443   \n",
       "std               3.777314e+04              9292.752726   \n",
       "min               0.000000e+00                 0.000000   \n",
       "25%               0.000000e+00                 0.000000   \n",
       "50%               0.000000e+00                 0.000000   \n",
       "75%               0.000000e+00                 0.000000   \n",
       "max               3.000538e+06            668335.320000   \n",
       "\n",
       "       saldo_medio_var12_ult1  saldo_medio_var12_ult3  \\\n",
       "count            7.602000e+04            7.602000e+04   \n",
       "mean             5.703008e+03            4.401002e+03   \n",
       "std              4.620254e+04            3.550718e+04   \n",
       "min              0.000000e+00            0.000000e+00   \n",
       "25%              0.000000e+00            0.000000e+00   \n",
       "50%              0.000000e+00            0.000000e+00   \n",
       "75%              0.000000e+00            0.000000e+00   \n",
       "max              3.004186e+06            2.272859e+06   \n",
       "\n",
       "       saldo_medio_var13_corto_hace2  saldo_medio_var13_corto_hace3  \\\n",
       "count                   76020.000000                   76020.000000   \n",
       "mean                     3639.419939                     556.184178   \n",
       "std                     26359.174223                    7182.642532   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                         0.000000                       0.000000   \n",
       "50%                         0.000000                       0.000000   \n",
       "75%                         0.000000                       0.000000   \n",
       "max                    450000.000000                  304838.700000   \n",
       "\n",
       "       saldo_medio_var13_corto_ult1  saldo_medio_var13_corto_ult3  \\\n",
       "count                  76020.000000                  76020.000000   \n",
       "mean                    4852.261814                   3857.848542   \n",
       "std                    31886.615189                  25572.245055   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                   450000.000000                 450000.000000   \n",
       "\n",
       "       saldo_medio_var13_largo_hace2  saldo_medio_var13_largo_hace3  \\\n",
       "count                   76020.000000                   76020.000000   \n",
       "mean                      771.227449                     162.170439   \n",
       "std                     13082.155867                    4698.868075   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                         0.000000                       0.000000   \n",
       "50%                         0.000000                       0.000000   \n",
       "75%                         0.000000                       0.000000   \n",
       "max                    840000.000000                  534000.000000   \n",
       "\n",
       "       saldo_medio_var13_largo_ult1  saldo_medio_var13_largo_ult3  \\\n",
       "count                  7.602000e+04                  7.602000e+04   \n",
       "mean                   9.569502e+02                  7.509563e+02   \n",
       "std                    1.600698e+04                  1.242252e+04   \n",
       "min                    0.000000e+00                  0.000000e+00   \n",
       "25%                    0.000000e+00                  0.000000e+00   \n",
       "50%                    0.000000e+00                  0.000000e+00   \n",
       "75%                    0.000000e+00                  0.000000e+00   \n",
       "max                    1.500000e+06                  1.034483e+06   \n",
       "\n",
       "       saldo_medio_var13_medio_hace2  saldo_medio_var13_medio_hace3  \\\n",
       "count                   76020.000000                        76020.0   \n",
       "mean                        0.175324                            0.0   \n",
       "std                        34.625518                            0.0   \n",
       "min                         0.000000                            0.0   \n",
       "25%                         0.000000                            0.0   \n",
       "50%                         0.000000                            0.0   \n",
       "75%                         0.000000                            0.0   \n",
       "max                      7741.950000                            0.0   \n",
       "\n",
       "       saldo_medio_var13_medio_ult1  saldo_medio_var13_medio_ult3  \\\n",
       "count                  76020.000000                  76020.000000   \n",
       "mean                       0.513023                      0.344174   \n",
       "std                      113.597559                     73.376513   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                    30000.000000                  18870.990000   \n",
       "\n",
       "       saldo_medio_var17_hace2  saldo_medio_var17_hace3  \\\n",
       "count             7.602000e+04             7.602000e+04   \n",
       "mean              9.117181e+01             3.646318e+01   \n",
       "std               1.539248e+04             8.612395e+03   \n",
       "min              -3.000000e-02             0.000000e+00   \n",
       "25%               0.000000e+00             0.000000e+00   \n",
       "50%               0.000000e+00             0.000000e+00   \n",
       "75%               0.000000e+00             0.000000e+00   \n",
       "max               4.210084e+06             2.368559e+06   \n",
       "\n",
       "       saldo_medio_var17_ult1  saldo_medio_var17_ult3  \\\n",
       "count            7.602000e+04            7.602000e+04   \n",
       "mean             1.310316e+02            1.092169e+02   \n",
       "std              1.495653e+04            1.308216e+04   \n",
       "min              0.000000e+00            0.000000e+00   \n",
       "25%              0.000000e+00            0.000000e+00   \n",
       "50%              0.000000e+00            0.000000e+00   \n",
       "75%              0.000000e+00            0.000000e+00   \n",
       "max              3.998687e+06            3.525777e+06   \n",
       "\n",
       "       saldo_medio_var29_hace2  saldo_medio_var29_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  0.213071                 0.001910   \n",
       "std                  41.820444                 0.526626   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               10430.010000               145.200000   \n",
       "\n",
       "       saldo_medio_var29_ult1  saldo_medio_var29_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                 0.253907                0.186630   \n",
       "std                 52.078775               31.879418   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max              13793.670000             7331.340000   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       " 1           105\n",
       " 13           98\n",
       " 7            97\n",
       " 4            86\n",
       " 12           85\n",
       "Name: var3, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.var3.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df['var3'].replace(-999999, 2,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df.drop('ID', axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처와 레이블 분리 \n",
    "\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size = 0.2, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape : (60816, 369), 테스트 세트 Shape : (15204, 369)\n",
      "학습 세트 레이블 값 분포 비율\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "테스트 세트 레이블 값 분포 비율\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('학습 세트 Shape : {0}, 테스트 세트 Shape : {1}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "print('학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/ train_cnt)\n",
    "\n",
    "print('\\n테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비대칭한 데이터 세트 임으로 클래스인 Target의 값 분포도가 학습 데이터와 테스트 데이터 세트에 모두 비숫하게 추출되었는지 확인 필요. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:00:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.82005\tvalidation_1-auc:0.81157\n",
      "[1]\tvalidation_0-auc:0.83400\tvalidation_1-auc:0.82452\n",
      "[2]\tvalidation_0-auc:0.83870\tvalidation_1-auc:0.82746\n",
      "[3]\tvalidation_0-auc:0.84419\tvalidation_1-auc:0.82922\n",
      "[4]\tvalidation_0-auc:0.84783\tvalidation_1-auc:0.83298\n",
      "[5]\tvalidation_0-auc:0.85125\tvalidation_1-auc:0.83500\n",
      "[6]\tvalidation_0-auc:0.85501\tvalidation_1-auc:0.83653\n",
      "[7]\tvalidation_0-auc:0.85830\tvalidation_1-auc:0.83782\n",
      "[8]\tvalidation_0-auc:0.86143\tvalidation_1-auc:0.83802\n",
      "[9]\tvalidation_0-auc:0.86452\tvalidation_1-auc:0.83914\n",
      "[10]\tvalidation_0-auc:0.86717\tvalidation_1-auc:0.83954\n",
      "[11]\tvalidation_0-auc:0.87013\tvalidation_1-auc:0.83983\n",
      "[12]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.84033\n",
      "[13]\tvalidation_0-auc:0.87620\tvalidation_1-auc:0.84054\n",
      "[14]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.84135\n",
      "[15]\tvalidation_0-auc:0.88072\tvalidation_1-auc:0.84117\n",
      "[16]\tvalidation_0-auc:0.88237\tvalidation_1-auc:0.84101\n",
      "[17]\tvalidation_0-auc:0.88352\tvalidation_1-auc:0.84071\n",
      "[18]\tvalidation_0-auc:0.88457\tvalidation_1-auc:0.84052\n",
      "[19]\tvalidation_0-auc:0.88592\tvalidation_1-auc:0.84023\n",
      "[20]\tvalidation_0-auc:0.88788\tvalidation_1-auc:0.84012\n",
      "[21]\tvalidation_0-auc:0.88845\tvalidation_1-auc:0.84022\n",
      "[22]\tvalidation_0-auc:0.88980\tvalidation_1-auc:0.84007\n",
      "[23]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.84009\n",
      "[24]\tvalidation_0-auc:0.89193\tvalidation_1-auc:0.83974\n",
      "[25]\tvalidation_0-auc:0.89253\tvalidation_1-auc:0.84015\n",
      "[26]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.84101\n",
      "[27]\tvalidation_0-auc:0.89386\tvalidation_1-auc:0.84088\n",
      "[28]\tvalidation_0-auc:0.89416\tvalidation_1-auc:0.84074\n",
      "[29]\tvalidation_0-auc:0.89660\tvalidation_1-auc:0.83999\n",
      "[30]\tvalidation_0-auc:0.89738\tvalidation_1-auc:0.83959\n",
      "[31]\tvalidation_0-auc:0.89911\tvalidation_1-auc:0.83952\n",
      "[32]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83901\n",
      "[33]\tvalidation_0-auc:0.90250\tvalidation_1-auc:0.83885\n",
      "[34]\tvalidation_0-auc:0.90275\tvalidation_1-auc:0.83887\n",
      "[35]\tvalidation_0-auc:0.90290\tvalidation_1-auc:0.83864\n",
      "[36]\tvalidation_0-auc:0.90460\tvalidation_1-auc:0.83834\n",
      "[37]\tvalidation_0-auc:0.90497\tvalidation_1-auc:0.83810\n",
      "[38]\tvalidation_0-auc:0.90515\tvalidation_1-auc:0.83810\n",
      "[39]\tvalidation_0-auc:0.90533\tvalidation_1-auc:0.83813\n",
      "[40]\tvalidation_0-auc:0.90574\tvalidation_1-auc:0.83776\n",
      "[41]\tvalidation_0-auc:0.90690\tvalidation_1-auc:0.83720\n",
      "[42]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83684\n",
      "[43]\tvalidation_0-auc:0.90736\tvalidation_1-auc:0.83672\n",
      "[44]\tvalidation_0-auc:0.90758\tvalidation_1-auc:0.83674\n",
      "[45]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.83693\n",
      "[46]\tvalidation_0-auc:0.90777\tvalidation_1-auc:0.83686\n",
      "[47]\tvalidation_0-auc:0.90791\tvalidation_1-auc:0.83678\n",
      "[48]\tvalidation_0-auc:0.90829\tvalidation_1-auc:0.83694\n",
      "[49]\tvalidation_0-auc:0.90869\tvalidation_1-auc:0.83676\n",
      "[50]\tvalidation_0-auc:0.90890\tvalidation_1-auc:0.83655\n",
      "[51]\tvalidation_0-auc:0.91067\tvalidation_1-auc:0.83669\n",
      "[52]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83641\n",
      "[53]\tvalidation_0-auc:0.91352\tvalidation_1-auc:0.83690\n",
      "[54]\tvalidation_0-auc:0.91386\tvalidation_1-auc:0.83693\n",
      "[55]\tvalidation_0-auc:0.91406\tvalidation_1-auc:0.83681\n",
      "[56]\tvalidation_0-auc:0.91545\tvalidation_1-auc:0.83680\n",
      "[57]\tvalidation_0-auc:0.91556\tvalidation_1-auc:0.83667\n",
      "[58]\tvalidation_0-auc:0.91628\tvalidation_1-auc:0.83664\n",
      "[59]\tvalidation_0-auc:0.91725\tvalidation_1-auc:0.83591\n",
      "[60]\tvalidation_0-auc:0.91762\tvalidation_1-auc:0.83576\n",
      "[61]\tvalidation_0-auc:0.91784\tvalidation_1-auc:0.83534\n",
      "[62]\tvalidation_0-auc:0.91872\tvalidation_1-auc:0.83513\n",
      "[63]\tvalidation_0-auc:0.91892\tvalidation_1-auc:0.83510\n",
      "[64]\tvalidation_0-auc:0.91896\tvalidation_1-auc:0.83508\n",
      "[65]\tvalidation_0-auc:0.91907\tvalidation_1-auc:0.83518\n",
      "[66]\tvalidation_0-auc:0.91970\tvalidation_1-auc:0.83510\n",
      "[67]\tvalidation_0-auc:0.91982\tvalidation_1-auc:0.83523\n",
      "[68]\tvalidation_0-auc:0.92007\tvalidation_1-auc:0.83457\n",
      "[69]\tvalidation_0-auc:0.92015\tvalidation_1-auc:0.83460\n",
      "[70]\tvalidation_0-auc:0.92024\tvalidation_1-auc:0.83446\n",
      "[71]\tvalidation_0-auc:0.92037\tvalidation_1-auc:0.83462\n",
      "[72]\tvalidation_0-auc:0.92087\tvalidation_1-auc:0.83394\n",
      "[73]\tvalidation_0-auc:0.92094\tvalidation_1-auc:0.83410\n",
      "[74]\tvalidation_0-auc:0.92133\tvalidation_1-auc:0.83394\n",
      "[75]\tvalidation_0-auc:0.92141\tvalidation_1-auc:0.83368\n",
      "[76]\tvalidation_0-auc:0.92321\tvalidation_1-auc:0.83413\n",
      "[77]\tvalidation_0-auc:0.92415\tvalidation_1-auc:0.83359\n",
      "[78]\tvalidation_0-auc:0.92503\tvalidation_1-auc:0.83353\n",
      "[79]\tvalidation_0-auc:0.92539\tvalidation_1-auc:0.83293\n",
      "[80]\tvalidation_0-auc:0.92577\tvalidation_1-auc:0.83253\n",
      "[81]\tvalidation_0-auc:0.92677\tvalidation_1-auc:0.83187\n",
      "[82]\tvalidation_0-auc:0.92706\tvalidation_1-auc:0.83230\n",
      "[83]\tvalidation_0-auc:0.92800\tvalidation_1-auc:0.83216\n",
      "[84]\tvalidation_0-auc:0.92822\tvalidation_1-auc:0.83206\n",
      "[85]\tvalidation_0-auc:0.92870\tvalidation_1-auc:0.83196\n",
      "[86]\tvalidation_0-auc:0.92875\tvalidation_1-auc:0.83200\n",
      "[87]\tvalidation_0-auc:0.92881\tvalidation_1-auc:0.83208\n",
      "[88]\tvalidation_0-auc:0.92919\tvalidation_1-auc:0.83174\n",
      "[89]\tvalidation_0-auc:0.92940\tvalidation_1-auc:0.83160\n",
      "[90]\tvalidation_0-auc:0.92948\tvalidation_1-auc:0.83155\n",
      "[91]\tvalidation_0-auc:0.92959\tvalidation_1-auc:0.83165\n",
      "[92]\tvalidation_0-auc:0.92964\tvalidation_1-auc:0.83172\n",
      "[93]\tvalidation_0-auc:0.93031\tvalidation_1-auc:0.83160\n",
      "[94]\tvalidation_0-auc:0.93032\tvalidation_1-auc:0.83150\n",
      "[95]\tvalidation_0-auc:0.93037\tvalidation_1-auc:0.83132\n",
      "[96]\tvalidation_0-auc:0.93083\tvalidation_1-auc:0.83090\n",
      "[97]\tvalidation_0-auc:0.93091\tvalidation_1-auc:0.83091\n",
      "[98]\tvalidation_0-auc:0.93168\tvalidation_1-auc:0.83066\n",
      "[99]\tvalidation_0-auc:0.93245\tvalidation_1-auc:0.83058\n",
      "[100]\tvalidation_0-auc:0.93286\tvalidation_1-auc:0.83029\n",
      "[101]\tvalidation_0-auc:0.93361\tvalidation_1-auc:0.82955\n",
      "[102]\tvalidation_0-auc:0.93359\tvalidation_1-auc:0.82962\n",
      "[103]\tvalidation_0-auc:0.93435\tvalidation_1-auc:0.82893\n",
      "[104]\tvalidation_0-auc:0.93446\tvalidation_1-auc:0.82837\n",
      "[105]\tvalidation_0-auc:0.93480\tvalidation_1-auc:0.82815\n",
      "[106]\tvalidation_0-auc:0.93579\tvalidation_1-auc:0.82744\n",
      "[107]\tvalidation_0-auc:0.93583\tvalidation_1-auc:0.82728\n",
      "[108]\tvalidation_0-auc:0.93610\tvalidation_1-auc:0.82651\n",
      "[109]\tvalidation_0-auc:0.93617\tvalidation_1-auc:0.82650\n",
      "[110]\tvalidation_0-auc:0.93659\tvalidation_1-auc:0.82621\n",
      "[111]\tvalidation_0-auc:0.93663\tvalidation_1-auc:0.82620\n",
      "[112]\tvalidation_0-auc:0.93710\tvalidation_1-auc:0.82591\n",
      "[113]\tvalidation_0-auc:0.93781\tvalidation_1-auc:0.82498\n",
      "ROC AUC : 0.8413\n"
     ]
    }
   ],
   "source": [
    "# n_estimators = 500, random_state = 156 \n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators = 500, random_state = 156, silent = True)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "           eval_metric = 'auc', eval_set = [(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1], average = 'macro')\n",
    "\n",
    "print('ROC AUC : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72255\tvalidation_1-auc:0.72640\n",
      "[1]\tvalidation_0-auc:0.74625\tvalidation_1-auc:0.75051\n",
      "[2]\tvalidation_0-auc:0.81675\tvalidation_1-auc:0.81906\n",
      "[3]\tvalidation_0-auc:0.82734\tvalidation_1-auc:0.82620\n",
      "[4]\tvalidation_0-auc:0.83559\tvalidation_1-auc:0.83410\n",
      "[5]\tvalidation_0-auc:0.83854\tvalidation_1-auc:0.83449\n",
      "[6]\tvalidation_0-auc:0.83653\tvalidation_1-auc:0.83319\n",
      "[7]\tvalidation_0-auc:0.84281\tvalidation_1-auc:0.83717\n",
      "[8]\tvalidation_0-auc:0.84240\tvalidation_1-auc:0.83435\n",
      "[9]\tvalidation_0-auc:0.84139\tvalidation_1-auc:0.83315\n",
      "[10]\tvalidation_0-auc:0.84795\tvalidation_1-auc:0.83874\n",
      "[11]\tvalidation_0-auc:0.85114\tvalidation_1-auc:0.84039\n",
      "[12]\tvalidation_0-auc:0.85300\tvalidation_1-auc:0.84080\n",
      "[13]\tvalidation_0-auc:0.85371\tvalidation_1-auc:0.84205\n",
      "[14]\tvalidation_0-auc:0.85534\tvalidation_1-auc:0.84046\n",
      "[15]\tvalidation_0-auc:0.85838\tvalidation_1-auc:0.84232\n",
      "[16]\tvalidation_0-auc:0.85907\tvalidation_1-auc:0.84237\n",
      "[17]\tvalidation_0-auc:0.86128\tvalidation_1-auc:0.84349\n",
      "[18]\tvalidation_0-auc:0.86381\tvalidation_1-auc:0.84277\n",
      "[19]\tvalidation_0-auc:0.86511\tvalidation_1-auc:0.84199\n",
      "[20]\tvalidation_0-auc:0.86654\tvalidation_1-auc:0.84090\n",
      "[21]\tvalidation_0-auc:0.86793\tvalidation_1-auc:0.84168\n",
      "[22]\tvalidation_0-auc:0.86824\tvalidation_1-auc:0.84167\n",
      "[23]\tvalidation_0-auc:0.86853\tvalidation_1-auc:0.84166\n",
      "[24]\tvalidation_0-auc:0.86930\tvalidation_1-auc:0.84163\n",
      "[25]\tvalidation_0-auc:0.87135\tvalidation_1-auc:0.84092\n",
      "[26]\tvalidation_0-auc:0.87217\tvalidation_1-auc:0.84046\n",
      "[27]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.84092\n",
      "[28]\tvalidation_0-auc:0.87432\tvalidation_1-auc:0.84108\n",
      "[29]\tvalidation_0-auc:0.87511\tvalidation_1-auc:0.84109\n",
      "[30]\tvalidation_0-auc:0.87564\tvalidation_1-auc:0.84091\n",
      "[31]\tvalidation_0-auc:0.87579\tvalidation_1-auc:0.84028\n",
      "[32]\tvalidation_0-auc:0.87703\tvalidation_1-auc:0.84000\n",
      "[33]\tvalidation_0-auc:0.87724\tvalidation_1-auc:0.84017\n",
      "[34]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.84017\n",
      "[35]\tvalidation_0-auc:0.87779\tvalidation_1-auc:0.83966\n",
      "[36]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83940\n",
      "[37]\tvalidation_0-auc:0.87835\tvalidation_1-auc:0.83930\n",
      "[38]\tvalidation_0-auc:0.87910\tvalidation_1-auc:0.83856\n",
      "[39]\tvalidation_0-auc:0.87964\tvalidation_1-auc:0.83800\n",
      "[40]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.83786\n",
      "[41]\tvalidation_0-auc:0.88032\tvalidation_1-auc:0.83749\n",
      "[42]\tvalidation_0-auc:0.88147\tvalidation_1-auc:0.83756\n",
      "[43]\tvalidation_0-auc:0.88160\tvalidation_1-auc:0.83778\n",
      "[44]\tvalidation_0-auc:0.88180\tvalidation_1-auc:0.83778\n",
      "[45]\tvalidation_0-auc:0.88189\tvalidation_1-auc:0.83795\n",
      "[46]\tvalidation_0-auc:0.88208\tvalidation_1-auc:0.83771\n",
      "[17:02:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70777\tvalidation_1-auc:0.71616\n",
      "[1]\tvalidation_0-auc:0.73724\tvalidation_1-auc:0.74060\n",
      "[2]\tvalidation_0-auc:0.81563\tvalidation_1-auc:0.81740\n",
      "[3]\tvalidation_0-auc:0.82812\tvalidation_1-auc:0.82909\n",
      "[4]\tvalidation_0-auc:0.83599\tvalidation_1-auc:0.83365\n",
      "[5]\tvalidation_0-auc:0.83874\tvalidation_1-auc:0.83416\n",
      "[6]\tvalidation_0-auc:0.83636\tvalidation_1-auc:0.83476\n",
      "[7]\tvalidation_0-auc:0.84421\tvalidation_1-auc:0.83623\n",
      "[8]\tvalidation_0-auc:0.84338\tvalidation_1-auc:0.83352\n",
      "[9]\tvalidation_0-auc:0.84075\tvalidation_1-auc:0.83271\n",
      "[10]\tvalidation_0-auc:0.84952\tvalidation_1-auc:0.83787\n",
      "[11]\tvalidation_0-auc:0.85314\tvalidation_1-auc:0.84149\n",
      "[12]\tvalidation_0-auc:0.85506\tvalidation_1-auc:0.84169\n",
      "[13]\tvalidation_0-auc:0.85601\tvalidation_1-auc:0.84186\n",
      "[14]\tvalidation_0-auc:0.85705\tvalidation_1-auc:0.84189\n",
      "[15]\tvalidation_0-auc:0.85957\tvalidation_1-auc:0.84255\n",
      "[16]\tvalidation_0-auc:0.86000\tvalidation_1-auc:0.84220\n",
      "[17]\tvalidation_0-auc:0.86151\tvalidation_1-auc:0.84348\n",
      "[18]\tvalidation_0-auc:0.86332\tvalidation_1-auc:0.84397\n",
      "[19]\tvalidation_0-auc:0.86408\tvalidation_1-auc:0.84374\n",
      "[20]\tvalidation_0-auc:0.86507\tvalidation_1-auc:0.84352\n",
      "[21]\tvalidation_0-auc:0.86652\tvalidation_1-auc:0.84346\n",
      "[22]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.84328\n",
      "[23]\tvalidation_0-auc:0.86788\tvalidation_1-auc:0.84239\n",
      "[24]\tvalidation_0-auc:0.86829\tvalidation_1-auc:0.84207\n",
      "[25]\tvalidation_0-auc:0.87017\tvalidation_1-auc:0.84143\n",
      "[26]\tvalidation_0-auc:0.87132\tvalidation_1-auc:0.84102\n",
      "[27]\tvalidation_0-auc:0.87284\tvalidation_1-auc:0.84122\n",
      "[28]\tvalidation_0-auc:0.87332\tvalidation_1-auc:0.84146\n",
      "[29]\tvalidation_0-auc:0.87427\tvalidation_1-auc:0.84136\n",
      "[30]\tvalidation_0-auc:0.87462\tvalidation_1-auc:0.84166\n",
      "[31]\tvalidation_0-auc:0.87473\tvalidation_1-auc:0.84169\n",
      "[32]\tvalidation_0-auc:0.87520\tvalidation_1-auc:0.84151\n",
      "[33]\tvalidation_0-auc:0.87653\tvalidation_1-auc:0.84161\n",
      "[34]\tvalidation_0-auc:0.87688\tvalidation_1-auc:0.84190\n",
      "[35]\tvalidation_0-auc:0.87705\tvalidation_1-auc:0.84124\n",
      "[36]\tvalidation_0-auc:0.87781\tvalidation_1-auc:0.84088\n",
      "[37]\tvalidation_0-auc:0.87828\tvalidation_1-auc:0.84071\n",
      "[38]\tvalidation_0-auc:0.87950\tvalidation_1-auc:0.83999\n",
      "[39]\tvalidation_0-auc:0.87977\tvalidation_1-auc:0.83983\n",
      "[40]\tvalidation_0-auc:0.88049\tvalidation_1-auc:0.83976\n",
      "[41]\tvalidation_0-auc:0.88131\tvalidation_1-auc:0.83964\n",
      "[42]\tvalidation_0-auc:0.88137\tvalidation_1-auc:0.83972\n",
      "[43]\tvalidation_0-auc:0.88157\tvalidation_1-auc:0.83975\n",
      "[44]\tvalidation_0-auc:0.88170\tvalidation_1-auc:0.83965\n",
      "[45]\tvalidation_0-auc:0.88193\tvalidation_1-auc:0.83962\n",
      "[46]\tvalidation_0-auc:0.88239\tvalidation_1-auc:0.83947\n",
      "[47]\tvalidation_0-auc:0.88270\tvalidation_1-auc:0.83936\n",
      "[48]\tvalidation_0-auc:0.88379\tvalidation_1-auc:0.83872\n",
      "[17:03:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71427\tvalidation_1-auc:0.72188\n",
      "[1]\tvalidation_0-auc:0.74087\tvalidation_1-auc:0.74421\n",
      "[2]\tvalidation_0-auc:0.81713\tvalidation_1-auc:0.81760\n",
      "[3]\tvalidation_0-auc:0.82914\tvalidation_1-auc:0.82649\n",
      "[4]\tvalidation_0-auc:0.83644\tvalidation_1-auc:0.83559\n",
      "[5]\tvalidation_0-auc:0.84168\tvalidation_1-auc:0.83747\n",
      "[6]\tvalidation_0-auc:0.83967\tvalidation_1-auc:0.83644\n",
      "[7]\tvalidation_0-auc:0.84644\tvalidation_1-auc:0.84031\n",
      "[8]\tvalidation_0-auc:0.84500\tvalidation_1-auc:0.83784\n",
      "[9]\tvalidation_0-auc:0.84307\tvalidation_1-auc:0.83670\n",
      "[10]\tvalidation_0-auc:0.84963\tvalidation_1-auc:0.83927\n",
      "[11]\tvalidation_0-auc:0.85238\tvalidation_1-auc:0.84193\n",
      "[12]\tvalidation_0-auc:0.85578\tvalidation_1-auc:0.84339\n",
      "[13]\tvalidation_0-auc:0.85755\tvalidation_1-auc:0.84287\n",
      "[14]\tvalidation_0-auc:0.85835\tvalidation_1-auc:0.84120\n",
      "[15]\tvalidation_0-auc:0.86158\tvalidation_1-auc:0.84214\n",
      "[16]\tvalidation_0-auc:0.86201\tvalidation_1-auc:0.84192\n",
      "[17]\tvalidation_0-auc:0.86404\tvalidation_1-auc:0.84256\n",
      "[18]\tvalidation_0-auc:0.86629\tvalidation_1-auc:0.84251\n",
      "[19]\tvalidation_0-auc:0.86695\tvalidation_1-auc:0.84257\n",
      "[20]\tvalidation_0-auc:0.86850\tvalidation_1-auc:0.84277\n",
      "[21]\tvalidation_0-auc:0.87005\tvalidation_1-auc:0.84260\n",
      "[22]\tvalidation_0-auc:0.87106\tvalidation_1-auc:0.84215\n",
      "[23]\tvalidation_0-auc:0.87161\tvalidation_1-auc:0.84218\n",
      "[24]\tvalidation_0-auc:0.87167\tvalidation_1-auc:0.84229\n",
      "[25]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.84197\n",
      "[26]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.84184\n",
      "[27]\tvalidation_0-auc:0.87530\tvalidation_1-auc:0.84201\n",
      "[28]\tvalidation_0-auc:0.87589\tvalidation_1-auc:0.84200\n",
      "[29]\tvalidation_0-auc:0.87675\tvalidation_1-auc:0.84149\n",
      "[30]\tvalidation_0-auc:0.87764\tvalidation_1-auc:0.84082\n",
      "[31]\tvalidation_0-auc:0.87812\tvalidation_1-auc:0.84026\n",
      "[32]\tvalidation_0-auc:0.87950\tvalidation_1-auc:0.83995\n",
      "[33]\tvalidation_0-auc:0.88025\tvalidation_1-auc:0.83996\n",
      "[34]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83981\n",
      "[35]\tvalidation_0-auc:0.88084\tvalidation_1-auc:0.83971\n",
      "[36]\tvalidation_0-auc:0.88117\tvalidation_1-auc:0.83989\n",
      "[37]\tvalidation_0-auc:0.88162\tvalidation_1-auc:0.84057\n",
      "[38]\tvalidation_0-auc:0.88199\tvalidation_1-auc:0.84064\n",
      "[39]\tvalidation_0-auc:0.88221\tvalidation_1-auc:0.84074\n",
      "[40]\tvalidation_0-auc:0.88236\tvalidation_1-auc:0.84049\n",
      "[41]\tvalidation_0-auc:0.88263\tvalidation_1-auc:0.84030\n",
      "[17:03:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70172\tvalidation_1-auc:0.71158\n",
      "[1]\tvalidation_0-auc:0.73534\tvalidation_1-auc:0.74277\n",
      "[2]\tvalidation_0-auc:0.81703\tvalidation_1-auc:0.81887\n",
      "[3]\tvalidation_0-auc:0.82942\tvalidation_1-auc:0.82872\n",
      "[4]\tvalidation_0-auc:0.83715\tvalidation_1-auc:0.83600\n",
      "[5]\tvalidation_0-auc:0.84120\tvalidation_1-auc:0.83456\n",
      "[6]\tvalidation_0-auc:0.84035\tvalidation_1-auc:0.83646\n",
      "[7]\tvalidation_0-auc:0.84565\tvalidation_1-auc:0.83754\n",
      "[8]\tvalidation_0-auc:0.84537\tvalidation_1-auc:0.83804\n",
      "[9]\tvalidation_0-auc:0.84352\tvalidation_1-auc:0.83600\n",
      "[10]\tvalidation_0-auc:0.84964\tvalidation_1-auc:0.84041\n",
      "[11]\tvalidation_0-auc:0.85322\tvalidation_1-auc:0.84252\n",
      "[12]\tvalidation_0-auc:0.85662\tvalidation_1-auc:0.84253\n",
      "[13]\tvalidation_0-auc:0.85735\tvalidation_1-auc:0.84213\n",
      "[14]\tvalidation_0-auc:0.85876\tvalidation_1-auc:0.84083\n",
      "[15]\tvalidation_0-auc:0.86128\tvalidation_1-auc:0.84240\n",
      "[16]\tvalidation_0-auc:0.86235\tvalidation_1-auc:0.84146\n",
      "[17]\tvalidation_0-auc:0.86367\tvalidation_1-auc:0.84172\n",
      "[18]\tvalidation_0-auc:0.86591\tvalidation_1-auc:0.84174\n",
      "[19]\tvalidation_0-auc:0.86755\tvalidation_1-auc:0.84166\n",
      "[20]\tvalidation_0-auc:0.86826\tvalidation_1-auc:0.84194\n",
      "[21]\tvalidation_0-auc:0.86929\tvalidation_1-auc:0.84181\n",
      "[22]\tvalidation_0-auc:0.86971\tvalidation_1-auc:0.84116\n",
      "[23]\tvalidation_0-auc:0.87026\tvalidation_1-auc:0.84096\n",
      "[24]\tvalidation_0-auc:0.87122\tvalidation_1-auc:0.84022\n",
      "[25]\tvalidation_0-auc:0.87258\tvalidation_1-auc:0.84047\n",
      "[26]\tvalidation_0-auc:0.87363\tvalidation_1-auc:0.84021\n",
      "[27]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.84088\n",
      "[28]\tvalidation_0-auc:0.87494\tvalidation_1-auc:0.84025\n",
      "[29]\tvalidation_0-auc:0.87609\tvalidation_1-auc:0.83985\n",
      "[30]\tvalidation_0-auc:0.87631\tvalidation_1-auc:0.83983\n",
      "[31]\tvalidation_0-auc:0.87661\tvalidation_1-auc:0.83950\n",
      "[32]\tvalidation_0-auc:0.87743\tvalidation_1-auc:0.83934\n",
      "[33]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.83916\n",
      "[34]\tvalidation_0-auc:0.87812\tvalidation_1-auc:0.83908\n",
      "[35]\tvalidation_0-auc:0.87868\tvalidation_1-auc:0.83837\n",
      "[36]\tvalidation_0-auc:0.87892\tvalidation_1-auc:0.83839\n",
      "[37]\tvalidation_0-auc:0.87915\tvalidation_1-auc:0.83847\n",
      "[38]\tvalidation_0-auc:0.87994\tvalidation_1-auc:0.83861\n",
      "[39]\tvalidation_0-auc:0.88031\tvalidation_1-auc:0.83831\n",
      "[40]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.83828\n",
      "[41]\tvalidation_0-auc:0.88117\tvalidation_1-auc:0.83806\n",
      "[42]\tvalidation_0-auc:0.88172\tvalidation_1-auc:0.83796\n",
      "[17:03:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71927\tvalidation_1-auc:0.72073\n",
      "[1]\tvalidation_0-auc:0.74590\tvalidation_1-auc:0.74597\n",
      "[2]\tvalidation_0-auc:0.81912\tvalidation_1-auc:0.81581\n",
      "[3]\tvalidation_0-auc:0.83168\tvalidation_1-auc:0.82750\n",
      "[4]\tvalidation_0-auc:0.83887\tvalidation_1-auc:0.83347\n",
      "[5]\tvalidation_0-auc:0.84086\tvalidation_1-auc:0.83313\n",
      "[6]\tvalidation_0-auc:0.84075\tvalidation_1-auc:0.83430\n",
      "[7]\tvalidation_0-auc:0.84752\tvalidation_1-auc:0.83714\n",
      "[8]\tvalidation_0-auc:0.84712\tvalidation_1-auc:0.83559\n",
      "[9]\tvalidation_0-auc:0.84642\tvalidation_1-auc:0.83511\n",
      "[10]\tvalidation_0-auc:0.85265\tvalidation_1-auc:0.83900\n",
      "[11]\tvalidation_0-auc:0.85589\tvalidation_1-auc:0.84162\n",
      "[12]\tvalidation_0-auc:0.85824\tvalidation_1-auc:0.84340\n",
      "[13]\tvalidation_0-auc:0.85938\tvalidation_1-auc:0.84525\n",
      "[14]\tvalidation_0-auc:0.86085\tvalidation_1-auc:0.84460\n",
      "[15]\tvalidation_0-auc:0.86384\tvalidation_1-auc:0.84506\n",
      "[16]\tvalidation_0-auc:0.86415\tvalidation_1-auc:0.84467\n",
      "[17]\tvalidation_0-auc:0.86573\tvalidation_1-auc:0.84515\n",
      "[18]\tvalidation_0-auc:0.86798\tvalidation_1-auc:0.84440\n",
      "[19]\tvalidation_0-auc:0.86871\tvalidation_1-auc:0.84392\n",
      "[20]\tvalidation_0-auc:0.86966\tvalidation_1-auc:0.84364\n",
      "[21]\tvalidation_0-auc:0.87036\tvalidation_1-auc:0.84322\n",
      "[22]\tvalidation_0-auc:0.87092\tvalidation_1-auc:0.84324\n",
      "[23]\tvalidation_0-auc:0.87119\tvalidation_1-auc:0.84346\n",
      "[24]\tvalidation_0-auc:0.87165\tvalidation_1-auc:0.84354\n",
      "[25]\tvalidation_0-auc:0.87331\tvalidation_1-auc:0.84277\n",
      "[26]\tvalidation_0-auc:0.87431\tvalidation_1-auc:0.84186\n",
      "[27]\tvalidation_0-auc:0.87605\tvalidation_1-auc:0.84120\n",
      "[28]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.84060\n",
      "[29]\tvalidation_0-auc:0.87859\tvalidation_1-auc:0.84066\n",
      "[30]\tvalidation_0-auc:0.87878\tvalidation_1-auc:0.84080\n",
      "[31]\tvalidation_0-auc:0.87949\tvalidation_1-auc:0.84137\n",
      "[32]\tvalidation_0-auc:0.88043\tvalidation_1-auc:0.84132\n",
      "[33]\tvalidation_0-auc:0.88096\tvalidation_1-auc:0.84105\n",
      "[34]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.84076\n",
      "[35]\tvalidation_0-auc:0.88181\tvalidation_1-auc:0.84059\n",
      "[36]\tvalidation_0-auc:0.88209\tvalidation_1-auc:0.84052\n",
      "[37]\tvalidation_0-auc:0.88234\tvalidation_1-auc:0.84052\n",
      "[38]\tvalidation_0-auc:0.88295\tvalidation_1-auc:0.84012\n",
      "[39]\tvalidation_0-auc:0.88337\tvalidation_1-auc:0.84014\n",
      "[40]\tvalidation_0-auc:0.88381\tvalidation_1-auc:0.83980\n",
      "[41]\tvalidation_0-auc:0.88391\tvalidation_1-auc:0.83981\n",
      "[42]\tvalidation_0-auc:0.88408\tvalidation_1-auc:0.83980\n",
      "[17:03:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72246\tvalidation_1-auc:0.72509\n",
      "[1]\tvalidation_0-auc:0.74499\tvalidation_1-auc:0.75002\n",
      "[2]\tvalidation_0-auc:0.81724\tvalidation_1-auc:0.82145\n",
      "[3]\tvalidation_0-auc:0.82773\tvalidation_1-auc:0.82776\n",
      "[4]\tvalidation_0-auc:0.83538\tvalidation_1-auc:0.83561\n",
      "[5]\tvalidation_0-auc:0.83807\tvalidation_1-auc:0.83561\n",
      "[6]\tvalidation_0-auc:0.83569\tvalidation_1-auc:0.83282\n",
      "[7]\tvalidation_0-auc:0.84205\tvalidation_1-auc:0.83616\n",
      "[8]\tvalidation_0-auc:0.84198\tvalidation_1-auc:0.83349\n",
      "[9]\tvalidation_0-auc:0.84127\tvalidation_1-auc:0.83382\n",
      "[10]\tvalidation_0-auc:0.84884\tvalidation_1-auc:0.83811\n",
      "[11]\tvalidation_0-auc:0.85108\tvalidation_1-auc:0.83911\n",
      "[12]\tvalidation_0-auc:0.85420\tvalidation_1-auc:0.83954\n",
      "[13]\tvalidation_0-auc:0.85547\tvalidation_1-auc:0.83978\n",
      "[14]\tvalidation_0-auc:0.85666\tvalidation_1-auc:0.84062\n",
      "[15]\tvalidation_0-auc:0.85893\tvalidation_1-auc:0.84120\n",
      "[16]\tvalidation_0-auc:0.85958\tvalidation_1-auc:0.84202\n",
      "[17]\tvalidation_0-auc:0.86037\tvalidation_1-auc:0.84296\n",
      "[18]\tvalidation_0-auc:0.86317\tvalidation_1-auc:0.84350\n",
      "[19]\tvalidation_0-auc:0.86406\tvalidation_1-auc:0.84287\n",
      "[20]\tvalidation_0-auc:0.86458\tvalidation_1-auc:0.84229\n",
      "[21]\tvalidation_0-auc:0.86552\tvalidation_1-auc:0.84141\n",
      "[22]\tvalidation_0-auc:0.86623\tvalidation_1-auc:0.84190\n",
      "[23]\tvalidation_0-auc:0.86671\tvalidation_1-auc:0.84211\n",
      "[24]\tvalidation_0-auc:0.86709\tvalidation_1-auc:0.84141\n",
      "[25]\tvalidation_0-auc:0.86885\tvalidation_1-auc:0.84096\n",
      "[26]\tvalidation_0-auc:0.86955\tvalidation_1-auc:0.84052\n",
      "[27]\tvalidation_0-auc:0.86987\tvalidation_1-auc:0.84057\n",
      "[28]\tvalidation_0-auc:0.87069\tvalidation_1-auc:0.84070\n",
      "[29]\tvalidation_0-auc:0.87194\tvalidation_1-auc:0.84029\n",
      "[30]\tvalidation_0-auc:0.87245\tvalidation_1-auc:0.84002\n",
      "[31]\tvalidation_0-auc:0.87361\tvalidation_1-auc:0.83997\n",
      "[32]\tvalidation_0-auc:0.87451\tvalidation_1-auc:0.84024\n",
      "[33]\tvalidation_0-auc:0.87496\tvalidation_1-auc:0.84060\n",
      "[34]\tvalidation_0-auc:0.87519\tvalidation_1-auc:0.84083\n",
      "[35]\tvalidation_0-auc:0.87576\tvalidation_1-auc:0.84081\n",
      "[36]\tvalidation_0-auc:0.87589\tvalidation_1-auc:0.84071\n",
      "[37]\tvalidation_0-auc:0.87595\tvalidation_1-auc:0.84075\n",
      "[38]\tvalidation_0-auc:0.87609\tvalidation_1-auc:0.84046\n",
      "[39]\tvalidation_0-auc:0.87638\tvalidation_1-auc:0.84038\n",
      "[40]\tvalidation_0-auc:0.87714\tvalidation_1-auc:0.84033\n",
      "[41]\tvalidation_0-auc:0.87741\tvalidation_1-auc:0.84018\n",
      "[42]\tvalidation_0-auc:0.87768\tvalidation_1-auc:0.84014\n",
      "[43]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.84016\n",
      "[44]\tvalidation_0-auc:0.87834\tvalidation_1-auc:0.84038\n",
      "[45]\tvalidation_0-auc:0.87868\tvalidation_1-auc:0.84010\n",
      "[46]\tvalidation_0-auc:0.87876\tvalidation_1-auc:0.84001\n",
      "[47]\tvalidation_0-auc:0.87897\tvalidation_1-auc:0.83996\n",
      "[48]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.83992\n",
      "[17:04:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70779\tvalidation_1-auc:0.71610\n",
      "[1]\tvalidation_0-auc:0.73759\tvalidation_1-auc:0.74109\n",
      "[2]\tvalidation_0-auc:0.81661\tvalidation_1-auc:0.81699\n",
      "[3]\tvalidation_0-auc:0.82893\tvalidation_1-auc:0.82693\n",
      "[4]\tvalidation_0-auc:0.83925\tvalidation_1-auc:0.83530\n",
      "[5]\tvalidation_0-auc:0.84113\tvalidation_1-auc:0.83429\n",
      "[6]\tvalidation_0-auc:0.83799\tvalidation_1-auc:0.83587\n",
      "[7]\tvalidation_0-auc:0.84605\tvalidation_1-auc:0.83828\n",
      "[8]\tvalidation_0-auc:0.84472\tvalidation_1-auc:0.83692\n",
      "[9]\tvalidation_0-auc:0.84182\tvalidation_1-auc:0.83535\n",
      "[10]\tvalidation_0-auc:0.85005\tvalidation_1-auc:0.84039\n",
      "[11]\tvalidation_0-auc:0.85399\tvalidation_1-auc:0.84213\n",
      "[12]\tvalidation_0-auc:0.85670\tvalidation_1-auc:0.84097\n",
      "[13]\tvalidation_0-auc:0.85702\tvalidation_1-auc:0.84211\n",
      "[14]\tvalidation_0-auc:0.85732\tvalidation_1-auc:0.84099\n",
      "[15]\tvalidation_0-auc:0.85967\tvalidation_1-auc:0.84301\n",
      "[16]\tvalidation_0-auc:0.86035\tvalidation_1-auc:0.84265\n",
      "[17]\tvalidation_0-auc:0.86111\tvalidation_1-auc:0.84335\n",
      "[18]\tvalidation_0-auc:0.86282\tvalidation_1-auc:0.84401\n",
      "[19]\tvalidation_0-auc:0.86389\tvalidation_1-auc:0.84362\n",
      "[20]\tvalidation_0-auc:0.86478\tvalidation_1-auc:0.84358\n",
      "[21]\tvalidation_0-auc:0.86613\tvalidation_1-auc:0.84354\n",
      "[22]\tvalidation_0-auc:0.86654\tvalidation_1-auc:0.84293\n",
      "[23]\tvalidation_0-auc:0.86714\tvalidation_1-auc:0.84264\n",
      "[24]\tvalidation_0-auc:0.86732\tvalidation_1-auc:0.84237\n",
      "[25]\tvalidation_0-auc:0.86876\tvalidation_1-auc:0.84253\n",
      "[26]\tvalidation_0-auc:0.86982\tvalidation_1-auc:0.84154\n",
      "[27]\tvalidation_0-auc:0.87129\tvalidation_1-auc:0.84122\n",
      "[28]\tvalidation_0-auc:0.87205\tvalidation_1-auc:0.84086\n",
      "[29]\tvalidation_0-auc:0.87270\tvalidation_1-auc:0.84050\n",
      "[30]\tvalidation_0-auc:0.87285\tvalidation_1-auc:0.84041\n",
      "[31]\tvalidation_0-auc:0.87424\tvalidation_1-auc:0.84032\n",
      "[32]\tvalidation_0-auc:0.87469\tvalidation_1-auc:0.83966\n",
      "[33]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83966\n",
      "[34]\tvalidation_0-auc:0.87608\tvalidation_1-auc:0.83907\n",
      "[35]\tvalidation_0-auc:0.87626\tvalidation_1-auc:0.83886\n",
      "[36]\tvalidation_0-auc:0.87655\tvalidation_1-auc:0.83869\n",
      "[37]\tvalidation_0-auc:0.87677\tvalidation_1-auc:0.83834\n",
      "[38]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.83785\n",
      "[39]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.83771\n",
      "[40]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.83789\n",
      "[41]\tvalidation_0-auc:0.87971\tvalidation_1-auc:0.83817\n",
      "[42]\tvalidation_0-auc:0.87998\tvalidation_1-auc:0.83800\n",
      "[43]\tvalidation_0-auc:0.88011\tvalidation_1-auc:0.83782\n",
      "[44]\tvalidation_0-auc:0.88084\tvalidation_1-auc:0.83783\n",
      "[45]\tvalidation_0-auc:0.88118\tvalidation_1-auc:0.83798\n",
      "[46]\tvalidation_0-auc:0.88215\tvalidation_1-auc:0.83830\n",
      "[47]\tvalidation_0-auc:0.88255\tvalidation_1-auc:0.83866\n",
      "[48]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.83815\n",
      "[17:04:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71437\tvalidation_1-auc:0.72210\n",
      "[1]\tvalidation_0-auc:0.74281\tvalidation_1-auc:0.74540\n",
      "[2]\tvalidation_0-auc:0.81691\tvalidation_1-auc:0.81803\n",
      "[3]\tvalidation_0-auc:0.83137\tvalidation_1-auc:0.82920\n",
      "[4]\tvalidation_0-auc:0.83715\tvalidation_1-auc:0.83594\n",
      "[5]\tvalidation_0-auc:0.84106\tvalidation_1-auc:0.83723\n",
      "[6]\tvalidation_0-auc:0.83892\tvalidation_1-auc:0.83622\n",
      "[7]\tvalidation_0-auc:0.84542\tvalidation_1-auc:0.83992\n",
      "[8]\tvalidation_0-auc:0.84441\tvalidation_1-auc:0.83734\n",
      "[9]\tvalidation_0-auc:0.84358\tvalidation_1-auc:0.83561\n",
      "[10]\tvalidation_0-auc:0.84903\tvalidation_1-auc:0.83870\n",
      "[11]\tvalidation_0-auc:0.85261\tvalidation_1-auc:0.83992\n",
      "[12]\tvalidation_0-auc:0.85494\tvalidation_1-auc:0.84113\n",
      "[13]\tvalidation_0-auc:0.85628\tvalidation_1-auc:0.84036\n",
      "[14]\tvalidation_0-auc:0.85712\tvalidation_1-auc:0.83931\n",
      "[15]\tvalidation_0-auc:0.86043\tvalidation_1-auc:0.84060\n",
      "[16]\tvalidation_0-auc:0.86065\tvalidation_1-auc:0.84040\n",
      "[17]\tvalidation_0-auc:0.86185\tvalidation_1-auc:0.84137\n",
      "[18]\tvalidation_0-auc:0.86408\tvalidation_1-auc:0.84166\n",
      "[19]\tvalidation_0-auc:0.86498\tvalidation_1-auc:0.84121\n",
      "[20]\tvalidation_0-auc:0.86554\tvalidation_1-auc:0.84095\n",
      "[21]\tvalidation_0-auc:0.86678\tvalidation_1-auc:0.84133\n",
      "[22]\tvalidation_0-auc:0.86724\tvalidation_1-auc:0.84132\n",
      "[23]\tvalidation_0-auc:0.86793\tvalidation_1-auc:0.84130\n",
      "[24]\tvalidation_0-auc:0.86819\tvalidation_1-auc:0.84135\n",
      "[25]\tvalidation_0-auc:0.86886\tvalidation_1-auc:0.84123\n",
      "[26]\tvalidation_0-auc:0.86984\tvalidation_1-auc:0.84132\n",
      "[27]\tvalidation_0-auc:0.87062\tvalidation_1-auc:0.84047\n",
      "[28]\tvalidation_0-auc:0.87112\tvalidation_1-auc:0.84052\n",
      "[29]\tvalidation_0-auc:0.87199\tvalidation_1-auc:0.84095\n",
      "[30]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.84060\n",
      "[31]\tvalidation_0-auc:0.87339\tvalidation_1-auc:0.84098\n",
      "[32]\tvalidation_0-auc:0.87393\tvalidation_1-auc:0.84047\n",
      "[33]\tvalidation_0-auc:0.87464\tvalidation_1-auc:0.84026\n",
      "[34]\tvalidation_0-auc:0.87488\tvalidation_1-auc:0.83993\n",
      "[35]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.83996\n",
      "[36]\tvalidation_0-auc:0.87586\tvalidation_1-auc:0.83974\n",
      "[37]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.83963\n",
      "[38]\tvalidation_0-auc:0.87733\tvalidation_1-auc:0.83995\n",
      "[39]\tvalidation_0-auc:0.87747\tvalidation_1-auc:0.83986\n",
      "[40]\tvalidation_0-auc:0.87764\tvalidation_1-auc:0.83977\n",
      "[41]\tvalidation_0-auc:0.87853\tvalidation_1-auc:0.83931\n",
      "[42]\tvalidation_0-auc:0.87942\tvalidation_1-auc:0.83964\n",
      "[43]\tvalidation_0-auc:0.87962\tvalidation_1-auc:0.83987\n",
      "[44]\tvalidation_0-auc:0.87969\tvalidation_1-auc:0.83951\n",
      "[45]\tvalidation_0-auc:0.87991\tvalidation_1-auc:0.83912\n",
      "[46]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.83913\n",
      "[47]\tvalidation_0-auc:0.88019\tvalidation_1-auc:0.83914\n",
      "[48]\tvalidation_0-auc:0.88053\tvalidation_1-auc:0.83887\n",
      "[17:04:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70210\tvalidation_1-auc:0.71087\n",
      "[1]\tvalidation_0-auc:0.73511\tvalidation_1-auc:0.74116\n",
      "[2]\tvalidation_0-auc:0.81665\tvalidation_1-auc:0.81791\n",
      "[3]\tvalidation_0-auc:0.83071\tvalidation_1-auc:0.82852\n",
      "[4]\tvalidation_0-auc:0.83880\tvalidation_1-auc:0.83467\n",
      "[5]\tvalidation_0-auc:0.84100\tvalidation_1-auc:0.83436\n",
      "[6]\tvalidation_0-auc:0.83889\tvalidation_1-auc:0.83227\n",
      "[7]\tvalidation_0-auc:0.84578\tvalidation_1-auc:0.83524\n",
      "[8]\tvalidation_0-auc:0.84480\tvalidation_1-auc:0.83296\n",
      "[9]\tvalidation_0-auc:0.84215\tvalidation_1-auc:0.83120\n",
      "[10]\tvalidation_0-auc:0.84798\tvalidation_1-auc:0.83512\n",
      "[11]\tvalidation_0-auc:0.85125\tvalidation_1-auc:0.83798\n",
      "[12]\tvalidation_0-auc:0.85447\tvalidation_1-auc:0.83909\n",
      "[13]\tvalidation_0-auc:0.85541\tvalidation_1-auc:0.83949\n",
      "[14]\tvalidation_0-auc:0.85626\tvalidation_1-auc:0.83873\n",
      "[15]\tvalidation_0-auc:0.85861\tvalidation_1-auc:0.84078\n",
      "[16]\tvalidation_0-auc:0.85865\tvalidation_1-auc:0.84101\n",
      "[17]\tvalidation_0-auc:0.86035\tvalidation_1-auc:0.84153\n",
      "[18]\tvalidation_0-auc:0.86180\tvalidation_1-auc:0.84138\n",
      "[19]\tvalidation_0-auc:0.86332\tvalidation_1-auc:0.84241\n",
      "[20]\tvalidation_0-auc:0.86432\tvalidation_1-auc:0.84217\n",
      "[21]\tvalidation_0-auc:0.86532\tvalidation_1-auc:0.84223\n",
      "[22]\tvalidation_0-auc:0.86576\tvalidation_1-auc:0.84205\n",
      "[23]\tvalidation_0-auc:0.86607\tvalidation_1-auc:0.84256\n",
      "[24]\tvalidation_0-auc:0.86629\tvalidation_1-auc:0.84255\n",
      "[25]\tvalidation_0-auc:0.86786\tvalidation_1-auc:0.84143\n",
      "[26]\tvalidation_0-auc:0.86902\tvalidation_1-auc:0.84066\n",
      "[27]\tvalidation_0-auc:0.87061\tvalidation_1-auc:0.84104\n",
      "[28]\tvalidation_0-auc:0.87156\tvalidation_1-auc:0.84125\n",
      "[29]\tvalidation_0-auc:0.87226\tvalidation_1-auc:0.84095\n",
      "[30]\tvalidation_0-auc:0.87275\tvalidation_1-auc:0.84064\n",
      "[31]\tvalidation_0-auc:0.87300\tvalidation_1-auc:0.84039\n",
      "[32]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.84043\n",
      "[33]\tvalidation_0-auc:0.87432\tvalidation_1-auc:0.84038\n",
      "[34]\tvalidation_0-auc:0.87459\tvalidation_1-auc:0.83992\n",
      "[35]\tvalidation_0-auc:0.87526\tvalidation_1-auc:0.83983\n",
      "[36]\tvalidation_0-auc:0.87544\tvalidation_1-auc:0.83970\n",
      "[37]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.83969\n",
      "[38]\tvalidation_0-auc:0.87614\tvalidation_1-auc:0.83984\n",
      "[39]\tvalidation_0-auc:0.87658\tvalidation_1-auc:0.83942\n",
      "[40]\tvalidation_0-auc:0.87703\tvalidation_1-auc:0.83897\n",
      "[41]\tvalidation_0-auc:0.87718\tvalidation_1-auc:0.83891\n",
      "[42]\tvalidation_0-auc:0.87790\tvalidation_1-auc:0.83892\n",
      "[43]\tvalidation_0-auc:0.87804\tvalidation_1-auc:0.83881\n",
      "[44]\tvalidation_0-auc:0.87842\tvalidation_1-auc:0.83881\n",
      "[45]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83855\n",
      "[46]\tvalidation_0-auc:0.87863\tvalidation_1-auc:0.83853\n",
      "[47]\tvalidation_0-auc:0.87920\tvalidation_1-auc:0.83911\n",
      "[48]\tvalidation_0-auc:0.87930\tvalidation_1-auc:0.83866\n",
      "[49]\tvalidation_0-auc:0.87971\tvalidation_1-auc:0.83827\n",
      "[50]\tvalidation_0-auc:0.87984\tvalidation_1-auc:0.83808\n",
      "[51]\tvalidation_0-auc:0.88001\tvalidation_1-auc:0.83822\n",
      "[52]\tvalidation_0-auc:0.88027\tvalidation_1-auc:0.83823\n",
      "[17:05:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72303\tvalidation_1-auc:0.72052\n",
      "[1]\tvalidation_0-auc:0.74632\tvalidation_1-auc:0.74456\n",
      "[2]\tvalidation_0-auc:0.81534\tvalidation_1-auc:0.81063\n",
      "[3]\tvalidation_0-auc:0.83070\tvalidation_1-auc:0.82628\n",
      "[4]\tvalidation_0-auc:0.83906\tvalidation_1-auc:0.83302\n",
      "[5]\tvalidation_0-auc:0.84072\tvalidation_1-auc:0.83484\n",
      "[6]\tvalidation_0-auc:0.83976\tvalidation_1-auc:0.83399\n",
      "[7]\tvalidation_0-auc:0.84598\tvalidation_1-auc:0.83683\n",
      "[8]\tvalidation_0-auc:0.84452\tvalidation_1-auc:0.83455\n",
      "[9]\tvalidation_0-auc:0.84403\tvalidation_1-auc:0.83414\n",
      "[10]\tvalidation_0-auc:0.85036\tvalidation_1-auc:0.83938\n",
      "[11]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.84241\n",
      "[12]\tvalidation_0-auc:0.85550\tvalidation_1-auc:0.84214\n",
      "[13]\tvalidation_0-auc:0.85647\tvalidation_1-auc:0.84350\n",
      "[14]\tvalidation_0-auc:0.85778\tvalidation_1-auc:0.84283\n",
      "[15]\tvalidation_0-auc:0.86013\tvalidation_1-auc:0.84387\n",
      "[16]\tvalidation_0-auc:0.86070\tvalidation_1-auc:0.84380\n",
      "[17]\tvalidation_0-auc:0.86229\tvalidation_1-auc:0.84463\n",
      "[18]\tvalidation_0-auc:0.86399\tvalidation_1-auc:0.84456\n",
      "[19]\tvalidation_0-auc:0.86496\tvalidation_1-auc:0.84383\n",
      "[20]\tvalidation_0-auc:0.86586\tvalidation_1-auc:0.84364\n",
      "[21]\tvalidation_0-auc:0.86732\tvalidation_1-auc:0.84385\n",
      "[22]\tvalidation_0-auc:0.86762\tvalidation_1-auc:0.84404\n",
      "[23]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.84401\n",
      "[24]\tvalidation_0-auc:0.86861\tvalidation_1-auc:0.84385\n",
      "[25]\tvalidation_0-auc:0.87020\tvalidation_1-auc:0.84310\n",
      "[26]\tvalidation_0-auc:0.87165\tvalidation_1-auc:0.84345\n",
      "[27]\tvalidation_0-auc:0.87259\tvalidation_1-auc:0.84352\n",
      "[28]\tvalidation_0-auc:0.87342\tvalidation_1-auc:0.84291\n",
      "[29]\tvalidation_0-auc:0.87395\tvalidation_1-auc:0.84241\n",
      "[30]\tvalidation_0-auc:0.87472\tvalidation_1-auc:0.84274\n",
      "[31]\tvalidation_0-auc:0.87500\tvalidation_1-auc:0.84276\n",
      "[32]\tvalidation_0-auc:0.87547\tvalidation_1-auc:0.84315\n",
      "[33]\tvalidation_0-auc:0.87561\tvalidation_1-auc:0.84306\n",
      "[34]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.84281\n",
      "[35]\tvalidation_0-auc:0.87631\tvalidation_1-auc:0.84281\n",
      "[36]\tvalidation_0-auc:0.87661\tvalidation_1-auc:0.84274\n",
      "[37]\tvalidation_0-auc:0.87694\tvalidation_1-auc:0.84281\n",
      "[38]\tvalidation_0-auc:0.87764\tvalidation_1-auc:0.84259\n",
      "[39]\tvalidation_0-auc:0.87816\tvalidation_1-auc:0.84286\n",
      "[40]\tvalidation_0-auc:0.87884\tvalidation_1-auc:0.84283\n",
      "[41]\tvalidation_0-auc:0.87905\tvalidation_1-auc:0.84249\n",
      "[42]\tvalidation_0-auc:0.87915\tvalidation_1-auc:0.84251\n",
      "[43]\tvalidation_0-auc:0.87923\tvalidation_1-auc:0.84225\n",
      "[44]\tvalidation_0-auc:0.87977\tvalidation_1-auc:0.84214\n",
      "[45]\tvalidation_0-auc:0.87995\tvalidation_1-auc:0.84179\n",
      "[46]\tvalidation_0-auc:0.88095\tvalidation_1-auc:0.84181\n",
      "[47]\tvalidation_0-auc:0.88231\tvalidation_1-auc:0.84112\n",
      "[17:05:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72639\tvalidation_1-auc:0.72601\n",
      "[1]\tvalidation_0-auc:0.75224\tvalidation_1-auc:0.75153\n",
      "[2]\tvalidation_0-auc:0.82217\tvalidation_1-auc:0.82113\n",
      "[3]\tvalidation_0-auc:0.83673\tvalidation_1-auc:0.82951\n",
      "[4]\tvalidation_0-auc:0.84638\tvalidation_1-auc:0.83670\n",
      "[5]\tvalidation_0-auc:0.85219\tvalidation_1-auc:0.83521\n",
      "[6]\tvalidation_0-auc:0.85130\tvalidation_1-auc:0.83217\n",
      "[7]\tvalidation_0-auc:0.85969\tvalidation_1-auc:0.83852\n",
      "[8]\tvalidation_0-auc:0.86009\tvalidation_1-auc:0.83696\n",
      "[9]\tvalidation_0-auc:0.85939\tvalidation_1-auc:0.83404\n",
      "[10]\tvalidation_0-auc:0.86731\tvalidation_1-auc:0.83810\n",
      "[11]\tvalidation_0-auc:0.87262\tvalidation_1-auc:0.83826\n",
      "[12]\tvalidation_0-auc:0.87568\tvalidation_1-auc:0.83738\n",
      "[13]\tvalidation_0-auc:0.87701\tvalidation_1-auc:0.83765\n",
      "[14]\tvalidation_0-auc:0.87928\tvalidation_1-auc:0.83520\n",
      "[15]\tvalidation_0-auc:0.88167\tvalidation_1-auc:0.83715\n",
      "[16]\tvalidation_0-auc:0.88314\tvalidation_1-auc:0.83693\n",
      "[17]\tvalidation_0-auc:0.88453\tvalidation_1-auc:0.83803\n",
      "[18]\tvalidation_0-auc:0.88710\tvalidation_1-auc:0.83887\n",
      "[19]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.83816\n",
      "[20]\tvalidation_0-auc:0.88848\tvalidation_1-auc:0.83698\n",
      "[21]\tvalidation_0-auc:0.89052\tvalidation_1-auc:0.83708\n",
      "[22]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83664\n",
      "[23]\tvalidation_0-auc:0.89165\tvalidation_1-auc:0.83559\n",
      "[24]\tvalidation_0-auc:0.89199\tvalidation_1-auc:0.83560\n",
      "[25]\tvalidation_0-auc:0.89426\tvalidation_1-auc:0.83427\n",
      "[26]\tvalidation_0-auc:0.89608\tvalidation_1-auc:0.83434\n",
      "[27]\tvalidation_0-auc:0.89727\tvalidation_1-auc:0.83392\n",
      "[28]\tvalidation_0-auc:0.89842\tvalidation_1-auc:0.83323\n",
      "[29]\tvalidation_0-auc:0.89988\tvalidation_1-auc:0.83294\n",
      "[30]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.83283\n",
      "[31]\tvalidation_0-auc:0.90017\tvalidation_1-auc:0.83250\n",
      "[32]\tvalidation_0-auc:0.90061\tvalidation_1-auc:0.83201\n",
      "[33]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.83282\n",
      "[34]\tvalidation_0-auc:0.90180\tvalidation_1-auc:0.83289\n",
      "[35]\tvalidation_0-auc:0.90256\tvalidation_1-auc:0.83244\n",
      "[36]\tvalidation_0-auc:0.90427\tvalidation_1-auc:0.83337\n",
      "[37]\tvalidation_0-auc:0.90434\tvalidation_1-auc:0.83362\n",
      "[38]\tvalidation_0-auc:0.90455\tvalidation_1-auc:0.83343\n",
      "[39]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.83319\n",
      "[40]\tvalidation_0-auc:0.90472\tvalidation_1-auc:0.83320\n",
      "[41]\tvalidation_0-auc:0.90488\tvalidation_1-auc:0.83338\n",
      "[42]\tvalidation_0-auc:0.90505\tvalidation_1-auc:0.83322\n",
      "[43]\tvalidation_0-auc:0.90538\tvalidation_1-auc:0.83310\n",
      "[44]\tvalidation_0-auc:0.90623\tvalidation_1-auc:0.83235\n",
      "[45]\tvalidation_0-auc:0.90668\tvalidation_1-auc:0.83231\n",
      "[46]\tvalidation_0-auc:0.90729\tvalidation_1-auc:0.83214\n",
      "[47]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.83231\n",
      "[48]\tvalidation_0-auc:0.90790\tvalidation_1-auc:0.83224\n",
      "[17:05:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72535\tvalidation_1-auc:0.72958\n",
      "[1]\tvalidation_0-auc:0.74528\tvalidation_1-auc:0.74810\n",
      "[2]\tvalidation_0-auc:0.82478\tvalidation_1-auc:0.82025\n",
      "[3]\tvalidation_0-auc:0.83996\tvalidation_1-auc:0.83054\n",
      "[4]\tvalidation_0-auc:0.84920\tvalidation_1-auc:0.83513\n",
      "[5]\tvalidation_0-auc:0.85384\tvalidation_1-auc:0.83629\n",
      "[6]\tvalidation_0-auc:0.85254\tvalidation_1-auc:0.83549\n",
      "[7]\tvalidation_0-auc:0.85988\tvalidation_1-auc:0.83648\n",
      "[8]\tvalidation_0-auc:0.86031\tvalidation_1-auc:0.83437\n",
      "[9]\tvalidation_0-auc:0.85908\tvalidation_1-auc:0.83310\n",
      "[10]\tvalidation_0-auc:0.86623\tvalidation_1-auc:0.83943\n",
      "[11]\tvalidation_0-auc:0.87206\tvalidation_1-auc:0.84077\n",
      "[12]\tvalidation_0-auc:0.87507\tvalidation_1-auc:0.84152\n",
      "[13]\tvalidation_0-auc:0.87647\tvalidation_1-auc:0.84083\n",
      "[14]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.84003\n",
      "[15]\tvalidation_0-auc:0.88098\tvalidation_1-auc:0.84177\n",
      "[16]\tvalidation_0-auc:0.88133\tvalidation_1-auc:0.84129\n",
      "[17]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.84311\n",
      "[18]\tvalidation_0-auc:0.88633\tvalidation_1-auc:0.84359\n",
      "[19]\tvalidation_0-auc:0.88708\tvalidation_1-auc:0.84268\n",
      "[20]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.84263\n",
      "[21]\tvalidation_0-auc:0.89058\tvalidation_1-auc:0.84261\n",
      "[22]\tvalidation_0-auc:0.89145\tvalidation_1-auc:0.84249\n",
      "[23]\tvalidation_0-auc:0.89171\tvalidation_1-auc:0.84200\n",
      "[24]\tvalidation_0-auc:0.89195\tvalidation_1-auc:0.84182\n",
      "[25]\tvalidation_0-auc:0.89327\tvalidation_1-auc:0.83993\n",
      "[26]\tvalidation_0-auc:0.89372\tvalidation_1-auc:0.83927\n",
      "[27]\tvalidation_0-auc:0.89505\tvalidation_1-auc:0.83883\n",
      "[28]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.83868\n",
      "[29]\tvalidation_0-auc:0.89759\tvalidation_1-auc:0.83812\n",
      "[30]\tvalidation_0-auc:0.89822\tvalidation_1-auc:0.83830\n",
      "[31]\tvalidation_0-auc:0.89829\tvalidation_1-auc:0.83824\n",
      "[32]\tvalidation_0-auc:0.89898\tvalidation_1-auc:0.83902\n",
      "[33]\tvalidation_0-auc:0.90013\tvalidation_1-auc:0.83932\n",
      "[34]\tvalidation_0-auc:0.90069\tvalidation_1-auc:0.83891\n",
      "[35]\tvalidation_0-auc:0.90096\tvalidation_1-auc:0.83863\n",
      "[36]\tvalidation_0-auc:0.90161\tvalidation_1-auc:0.83886\n",
      "[37]\tvalidation_0-auc:0.90197\tvalidation_1-auc:0.83875\n",
      "[38]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83860\n",
      "[39]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.83779\n",
      "[40]\tvalidation_0-auc:0.90393\tvalidation_1-auc:0.83754\n",
      "[41]\tvalidation_0-auc:0.90432\tvalidation_1-auc:0.83772\n",
      "[42]\tvalidation_0-auc:0.90615\tvalidation_1-auc:0.83870\n",
      "[43]\tvalidation_0-auc:0.90718\tvalidation_1-auc:0.83870\n",
      "[44]\tvalidation_0-auc:0.90789\tvalidation_1-auc:0.83855\n",
      "[45]\tvalidation_0-auc:0.90800\tvalidation_1-auc:0.83876\n",
      "[46]\tvalidation_0-auc:0.90814\tvalidation_1-auc:0.83855\n",
      "[47]\tvalidation_0-auc:0.90815\tvalidation_1-auc:0.83852\n",
      "[48]\tvalidation_0-auc:0.90819\tvalidation_1-auc:0.83853\n",
      "[17:06:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71583\tvalidation_1-auc:0.72180\n",
      "[1]\tvalidation_0-auc:0.74738\tvalidation_1-auc:0.74834\n",
      "[2]\tvalidation_0-auc:0.82289\tvalidation_1-auc:0.81775\n",
      "[3]\tvalidation_0-auc:0.84046\tvalidation_1-auc:0.82925\n",
      "[4]\tvalidation_0-auc:0.84962\tvalidation_1-auc:0.83716\n",
      "[5]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.83846\n",
      "[6]\tvalidation_0-auc:0.85487\tvalidation_1-auc:0.83363\n",
      "[7]\tvalidation_0-auc:0.86201\tvalidation_1-auc:0.83662\n",
      "[8]\tvalidation_0-auc:0.86060\tvalidation_1-auc:0.83505\n",
      "[9]\tvalidation_0-auc:0.85899\tvalidation_1-auc:0.83302\n",
      "[10]\tvalidation_0-auc:0.86727\tvalidation_1-auc:0.83718\n",
      "[11]\tvalidation_0-auc:0.87388\tvalidation_1-auc:0.83846\n",
      "[12]\tvalidation_0-auc:0.87789\tvalidation_1-auc:0.84012\n",
      "[13]\tvalidation_0-auc:0.87956\tvalidation_1-auc:0.83847\n",
      "[14]\tvalidation_0-auc:0.88151\tvalidation_1-auc:0.83591\n",
      "[15]\tvalidation_0-auc:0.88420\tvalidation_1-auc:0.83729\n",
      "[16]\tvalidation_0-auc:0.88479\tvalidation_1-auc:0.83716\n",
      "[17]\tvalidation_0-auc:0.88608\tvalidation_1-auc:0.83911\n",
      "[18]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83920\n",
      "[19]\tvalidation_0-auc:0.89035\tvalidation_1-auc:0.83826\n",
      "[20]\tvalidation_0-auc:0.89122\tvalidation_1-auc:0.83869\n",
      "[21]\tvalidation_0-auc:0.89360\tvalidation_1-auc:0.83867\n",
      "[22]\tvalidation_0-auc:0.89391\tvalidation_1-auc:0.83798\n",
      "[23]\tvalidation_0-auc:0.89485\tvalidation_1-auc:0.83746\n",
      "[24]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.83716\n",
      "[25]\tvalidation_0-auc:0.89628\tvalidation_1-auc:0.83650\n",
      "[26]\tvalidation_0-auc:0.89725\tvalidation_1-auc:0.83683\n",
      "[27]\tvalidation_0-auc:0.89809\tvalidation_1-auc:0.83738\n",
      "[28]\tvalidation_0-auc:0.89993\tvalidation_1-auc:0.83757\n",
      "[29]\tvalidation_0-auc:0.90123\tvalidation_1-auc:0.83826\n",
      "[30]\tvalidation_0-auc:0.90168\tvalidation_1-auc:0.83758\n",
      "[31]\tvalidation_0-auc:0.90175\tvalidation_1-auc:0.83754\n",
      "[32]\tvalidation_0-auc:0.90231\tvalidation_1-auc:0.83681\n",
      "[33]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.83676\n",
      "[34]\tvalidation_0-auc:0.90316\tvalidation_1-auc:0.83673\n",
      "[35]\tvalidation_0-auc:0.90326\tvalidation_1-auc:0.83682\n",
      "[36]\tvalidation_0-auc:0.90491\tvalidation_1-auc:0.83605\n",
      "[37]\tvalidation_0-auc:0.90533\tvalidation_1-auc:0.83578\n",
      "[38]\tvalidation_0-auc:0.90542\tvalidation_1-auc:0.83576\n",
      "[39]\tvalidation_0-auc:0.90595\tvalidation_1-auc:0.83534\n",
      "[40]\tvalidation_0-auc:0.90594\tvalidation_1-auc:0.83518\n",
      "[41]\tvalidation_0-auc:0.90628\tvalidation_1-auc:0.83510\n",
      "[17:06:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70366\tvalidation_1-auc:0.71066\n",
      "[1]\tvalidation_0-auc:0.74464\tvalidation_1-auc:0.74774\n",
      "[2]\tvalidation_0-auc:0.82286\tvalidation_1-auc:0.82049\n",
      "[3]\tvalidation_0-auc:0.83895\tvalidation_1-auc:0.82925\n",
      "[4]\tvalidation_0-auc:0.84796\tvalidation_1-auc:0.83518\n",
      "[5]\tvalidation_0-auc:0.85341\tvalidation_1-auc:0.83440\n",
      "[6]\tvalidation_0-auc:0.85254\tvalidation_1-auc:0.83160\n",
      "[7]\tvalidation_0-auc:0.85945\tvalidation_1-auc:0.83480\n",
      "[8]\tvalidation_0-auc:0.86103\tvalidation_1-auc:0.83244\n",
      "[9]\tvalidation_0-auc:0.85956\tvalidation_1-auc:0.83305\n",
      "[10]\tvalidation_0-auc:0.86715\tvalidation_1-auc:0.83717\n",
      "[11]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.83969\n",
      "[12]\tvalidation_0-auc:0.87680\tvalidation_1-auc:0.84149\n",
      "[13]\tvalidation_0-auc:0.87939\tvalidation_1-auc:0.84043\n",
      "[14]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.83886\n",
      "[15]\tvalidation_0-auc:0.88417\tvalidation_1-auc:0.84024\n",
      "[16]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.83980\n",
      "[17]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.84140\n",
      "[18]\tvalidation_0-auc:0.88917\tvalidation_1-auc:0.84117\n",
      "[19]\tvalidation_0-auc:0.89008\tvalidation_1-auc:0.84029\n",
      "[20]\tvalidation_0-auc:0.89082\tvalidation_1-auc:0.83991\n",
      "[21]\tvalidation_0-auc:0.89377\tvalidation_1-auc:0.84005\n",
      "[22]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.83949\n",
      "[23]\tvalidation_0-auc:0.89445\tvalidation_1-auc:0.84007\n",
      "[24]\tvalidation_0-auc:0.89518\tvalidation_1-auc:0.83929\n",
      "[25]\tvalidation_0-auc:0.89678\tvalidation_1-auc:0.83864\n",
      "[26]\tvalidation_0-auc:0.89719\tvalidation_1-auc:0.83877\n",
      "[27]\tvalidation_0-auc:0.89792\tvalidation_1-auc:0.83860\n",
      "[28]\tvalidation_0-auc:0.89882\tvalidation_1-auc:0.83940\n",
      "[29]\tvalidation_0-auc:0.89966\tvalidation_1-auc:0.83894\n",
      "[30]\tvalidation_0-auc:0.90001\tvalidation_1-auc:0.83887\n",
      "[31]\tvalidation_0-auc:0.90044\tvalidation_1-auc:0.83866\n",
      "[32]\tvalidation_0-auc:0.90141\tvalidation_1-auc:0.83899\n",
      "[33]\tvalidation_0-auc:0.90152\tvalidation_1-auc:0.83895\n",
      "[34]\tvalidation_0-auc:0.90318\tvalidation_1-auc:0.83856\n",
      "[35]\tvalidation_0-auc:0.90335\tvalidation_1-auc:0.83851\n",
      "[36]\tvalidation_0-auc:0.90405\tvalidation_1-auc:0.83785\n",
      "[37]\tvalidation_0-auc:0.90449\tvalidation_1-auc:0.83800\n",
      "[38]\tvalidation_0-auc:0.90457\tvalidation_1-auc:0.83803\n",
      "[39]\tvalidation_0-auc:0.90455\tvalidation_1-auc:0.83797\n",
      "[40]\tvalidation_0-auc:0.90472\tvalidation_1-auc:0.83795\n",
      "[41]\tvalidation_0-auc:0.90476\tvalidation_1-auc:0.83806\n",
      "[17:06:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72300\tvalidation_1-auc:0.71831\n",
      "[1]\tvalidation_0-auc:0.75384\tvalidation_1-auc:0.74773\n",
      "[2]\tvalidation_0-auc:0.82533\tvalidation_1-auc:0.81770\n",
      "[3]\tvalidation_0-auc:0.84237\tvalidation_1-auc:0.82853\n",
      "[4]\tvalidation_0-auc:0.84904\tvalidation_1-auc:0.83134\n",
      "[5]\tvalidation_0-auc:0.85344\tvalidation_1-auc:0.83373\n",
      "[6]\tvalidation_0-auc:0.85340\tvalidation_1-auc:0.83278\n",
      "[7]\tvalidation_0-auc:0.86158\tvalidation_1-auc:0.83661\n",
      "[8]\tvalidation_0-auc:0.86292\tvalidation_1-auc:0.83405\n",
      "[9]\tvalidation_0-auc:0.86237\tvalidation_1-auc:0.83275\n",
      "[10]\tvalidation_0-auc:0.86900\tvalidation_1-auc:0.83706\n",
      "[11]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.83878\n",
      "[12]\tvalidation_0-auc:0.87744\tvalidation_1-auc:0.83972\n",
      "[13]\tvalidation_0-auc:0.87854\tvalidation_1-auc:0.83982\n",
      "[14]\tvalidation_0-auc:0.88073\tvalidation_1-auc:0.83836\n",
      "[15]\tvalidation_0-auc:0.88323\tvalidation_1-auc:0.83889\n",
      "[16]\tvalidation_0-auc:0.88414\tvalidation_1-auc:0.83882\n",
      "[17]\tvalidation_0-auc:0.88591\tvalidation_1-auc:0.84124\n",
      "[18]\tvalidation_0-auc:0.88772\tvalidation_1-auc:0.84168\n",
      "[19]\tvalidation_0-auc:0.88905\tvalidation_1-auc:0.84184\n",
      "[20]\tvalidation_0-auc:0.88997\tvalidation_1-auc:0.84201\n",
      "[21]\tvalidation_0-auc:0.89260\tvalidation_1-auc:0.84130\n",
      "[22]\tvalidation_0-auc:0.89307\tvalidation_1-auc:0.84124\n",
      "[23]\tvalidation_0-auc:0.89326\tvalidation_1-auc:0.84099\n",
      "[24]\tvalidation_0-auc:0.89348\tvalidation_1-auc:0.84113\n",
      "[25]\tvalidation_0-auc:0.89534\tvalidation_1-auc:0.84024\n",
      "[26]\tvalidation_0-auc:0.89677\tvalidation_1-auc:0.83969\n",
      "[27]\tvalidation_0-auc:0.89796\tvalidation_1-auc:0.83950\n",
      "[28]\tvalidation_0-auc:0.89979\tvalidation_1-auc:0.83893\n",
      "[29]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.83846\n",
      "[30]\tvalidation_0-auc:0.90159\tvalidation_1-auc:0.83900\n",
      "[31]\tvalidation_0-auc:0.90204\tvalidation_1-auc:0.83901\n",
      "[32]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.83883\n",
      "[33]\tvalidation_0-auc:0.90300\tvalidation_1-auc:0.83872\n",
      "[34]\tvalidation_0-auc:0.90440\tvalidation_1-auc:0.83896\n",
      "[35]\tvalidation_0-auc:0.90448\tvalidation_1-auc:0.83891\n",
      "[36]\tvalidation_0-auc:0.90469\tvalidation_1-auc:0.83906\n",
      "[37]\tvalidation_0-auc:0.90504\tvalidation_1-auc:0.83877\n",
      "[38]\tvalidation_0-auc:0.90515\tvalidation_1-auc:0.83895\n",
      "[39]\tvalidation_0-auc:0.90541\tvalidation_1-auc:0.83862\n",
      "[40]\tvalidation_0-auc:0.90560\tvalidation_1-auc:0.83833\n",
      "[41]\tvalidation_0-auc:0.90596\tvalidation_1-auc:0.83861\n",
      "[42]\tvalidation_0-auc:0.90637\tvalidation_1-auc:0.83847\n",
      "[43]\tvalidation_0-auc:0.90649\tvalidation_1-auc:0.83858\n",
      "[44]\tvalidation_0-auc:0.90704\tvalidation_1-auc:0.83843\n",
      "[45]\tvalidation_0-auc:0.90743\tvalidation_1-auc:0.83813\n",
      "[46]\tvalidation_0-auc:0.90750\tvalidation_1-auc:0.83795\n",
      "[47]\tvalidation_0-auc:0.90769\tvalidation_1-auc:0.83730\n",
      "[48]\tvalidation_0-auc:0.90858\tvalidation_1-auc:0.83684\n",
      "[49]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.83661\n",
      "[17:07:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72681\tvalidation_1-auc:0.72631\n",
      "[1]\tvalidation_0-auc:0.76028\tvalidation_1-auc:0.75763\n",
      "[2]\tvalidation_0-auc:0.82457\tvalidation_1-auc:0.81775\n",
      "[3]\tvalidation_0-auc:0.83875\tvalidation_1-auc:0.83041\n",
      "[4]\tvalidation_0-auc:0.84903\tvalidation_1-auc:0.83630\n",
      "[5]\tvalidation_0-auc:0.85300\tvalidation_1-auc:0.83721\n",
      "[6]\tvalidation_0-auc:0.85051\tvalidation_1-auc:0.83276\n",
      "[7]\tvalidation_0-auc:0.85959\tvalidation_1-auc:0.83348\n",
      "[8]\tvalidation_0-auc:0.85839\tvalidation_1-auc:0.83083\n",
      "[9]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.82995\n",
      "[10]\tvalidation_0-auc:0.86449\tvalidation_1-auc:0.83360\n",
      "[11]\tvalidation_0-auc:0.86859\tvalidation_1-auc:0.83488\n",
      "[12]\tvalidation_0-auc:0.87149\tvalidation_1-auc:0.83500\n",
      "[13]\tvalidation_0-auc:0.87244\tvalidation_1-auc:0.83514\n",
      "[14]\tvalidation_0-auc:0.87460\tvalidation_1-auc:0.83579\n",
      "[15]\tvalidation_0-auc:0.87740\tvalidation_1-auc:0.83656\n",
      "[16]\tvalidation_0-auc:0.87755\tvalidation_1-auc:0.83690\n",
      "[17]\tvalidation_0-auc:0.87915\tvalidation_1-auc:0.83756\n",
      "[18]\tvalidation_0-auc:0.88205\tvalidation_1-auc:0.83778\n",
      "[19]\tvalidation_0-auc:0.88267\tvalidation_1-auc:0.83710\n",
      "[20]\tvalidation_0-auc:0.88331\tvalidation_1-auc:0.83572\n",
      "[21]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.83643\n",
      "[22]\tvalidation_0-auc:0.88543\tvalidation_1-auc:0.83666\n",
      "[23]\tvalidation_0-auc:0.88596\tvalidation_1-auc:0.83650\n",
      "[24]\tvalidation_0-auc:0.88688\tvalidation_1-auc:0.83643\n",
      "[25]\tvalidation_0-auc:0.88837\tvalidation_1-auc:0.83570\n",
      "[26]\tvalidation_0-auc:0.88947\tvalidation_1-auc:0.83462\n",
      "[27]\tvalidation_0-auc:0.89037\tvalidation_1-auc:0.83432\n",
      "[28]\tvalidation_0-auc:0.89127\tvalidation_1-auc:0.83401\n",
      "[29]\tvalidation_0-auc:0.89258\tvalidation_1-auc:0.83322\n",
      "[30]\tvalidation_0-auc:0.89323\tvalidation_1-auc:0.83319\n",
      "[31]\tvalidation_0-auc:0.89351\tvalidation_1-auc:0.83313\n",
      "[32]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.83318\n",
      "[33]\tvalidation_0-auc:0.89401\tvalidation_1-auc:0.83311\n",
      "[34]\tvalidation_0-auc:0.89587\tvalidation_1-auc:0.83312\n",
      "[35]\tvalidation_0-auc:0.89624\tvalidation_1-auc:0.83301\n",
      "[36]\tvalidation_0-auc:0.89779\tvalidation_1-auc:0.83285\n",
      "[37]\tvalidation_0-auc:0.89789\tvalidation_1-auc:0.83281\n",
      "[38]\tvalidation_0-auc:0.89823\tvalidation_1-auc:0.83254\n",
      "[39]\tvalidation_0-auc:0.89860\tvalidation_1-auc:0.83142\n",
      "[40]\tvalidation_0-auc:0.89914\tvalidation_1-auc:0.83155\n",
      "[41]\tvalidation_0-auc:0.89945\tvalidation_1-auc:0.83108\n",
      "[42]\tvalidation_0-auc:0.89955\tvalidation_1-auc:0.83126\n",
      "[43]\tvalidation_0-auc:0.89996\tvalidation_1-auc:0.83139\n",
      "[44]\tvalidation_0-auc:0.90008\tvalidation_1-auc:0.83112\n",
      "[45]\tvalidation_0-auc:0.90071\tvalidation_1-auc:0.83156\n",
      "[46]\tvalidation_0-auc:0.90099\tvalidation_1-auc:0.83201\n",
      "[47]\tvalidation_0-auc:0.90147\tvalidation_1-auc:0.83121\n",
      "[48]\tvalidation_0-auc:0.90163\tvalidation_1-auc:0.83090\n",
      "[17:07:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72503\tvalidation_1-auc:0.72959\n",
      "[1]\tvalidation_0-auc:0.74611\tvalidation_1-auc:0.74921\n",
      "[2]\tvalidation_0-auc:0.82500\tvalidation_1-auc:0.82085\n",
      "[3]\tvalidation_0-auc:0.83970\tvalidation_1-auc:0.82672\n",
      "[4]\tvalidation_0-auc:0.84906\tvalidation_1-auc:0.83465\n",
      "[5]\tvalidation_0-auc:0.85198\tvalidation_1-auc:0.83482\n",
      "[6]\tvalidation_0-auc:0.85059\tvalidation_1-auc:0.83490\n",
      "[7]\tvalidation_0-auc:0.85949\tvalidation_1-auc:0.83669\n",
      "[8]\tvalidation_0-auc:0.85819\tvalidation_1-auc:0.83462\n",
      "[9]\tvalidation_0-auc:0.85724\tvalidation_1-auc:0.83337\n",
      "[10]\tvalidation_0-auc:0.86462\tvalidation_1-auc:0.83790\n",
      "[11]\tvalidation_0-auc:0.86891\tvalidation_1-auc:0.83909\n",
      "[12]\tvalidation_0-auc:0.87156\tvalidation_1-auc:0.84069\n",
      "[13]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83947\n",
      "[14]\tvalidation_0-auc:0.87402\tvalidation_1-auc:0.83934\n",
      "[15]\tvalidation_0-auc:0.87645\tvalidation_1-auc:0.84125\n",
      "[16]\tvalidation_0-auc:0.87712\tvalidation_1-auc:0.83948\n",
      "[17]\tvalidation_0-auc:0.87897\tvalidation_1-auc:0.84039\n",
      "[18]\tvalidation_0-auc:0.88118\tvalidation_1-auc:0.84070\n",
      "[19]\tvalidation_0-auc:0.88241\tvalidation_1-auc:0.83949\n",
      "[20]\tvalidation_0-auc:0.88331\tvalidation_1-auc:0.83893\n",
      "[21]\tvalidation_0-auc:0.88453\tvalidation_1-auc:0.83897\n",
      "[22]\tvalidation_0-auc:0.88502\tvalidation_1-auc:0.83868\n",
      "[23]\tvalidation_0-auc:0.88521\tvalidation_1-auc:0.83836\n",
      "[24]\tvalidation_0-auc:0.88631\tvalidation_1-auc:0.83724\n",
      "[25]\tvalidation_0-auc:0.88763\tvalidation_1-auc:0.83676\n",
      "[26]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.83681\n",
      "[27]\tvalidation_0-auc:0.88922\tvalidation_1-auc:0.83654\n",
      "[28]\tvalidation_0-auc:0.88948\tvalidation_1-auc:0.83685\n",
      "[29]\tvalidation_0-auc:0.89011\tvalidation_1-auc:0.83634\n",
      "[30]\tvalidation_0-auc:0.89031\tvalidation_1-auc:0.83620\n",
      "[31]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83682\n",
      "[32]\tvalidation_0-auc:0.89276\tvalidation_1-auc:0.83676\n",
      "[33]\tvalidation_0-auc:0.89424\tvalidation_1-auc:0.83659\n",
      "[34]\tvalidation_0-auc:0.89506\tvalidation_1-auc:0.83657\n",
      "[35]\tvalidation_0-auc:0.89595\tvalidation_1-auc:0.83659\n",
      "[36]\tvalidation_0-auc:0.89629\tvalidation_1-auc:0.83611\n",
      "[37]\tvalidation_0-auc:0.89679\tvalidation_1-auc:0.83556\n",
      "[38]\tvalidation_0-auc:0.89686\tvalidation_1-auc:0.83532\n",
      "[39]\tvalidation_0-auc:0.89716\tvalidation_1-auc:0.83496\n",
      "[40]\tvalidation_0-auc:0.89767\tvalidation_1-auc:0.83517\n",
      "[41]\tvalidation_0-auc:0.89872\tvalidation_1-auc:0.83602\n",
      "[42]\tvalidation_0-auc:0.89906\tvalidation_1-auc:0.83602\n",
      "[43]\tvalidation_0-auc:0.89908\tvalidation_1-auc:0.83578\n",
      "[44]\tvalidation_0-auc:0.89947\tvalidation_1-auc:0.83560\n",
      "[45]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.83522\n",
      "[17:08:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71572\tvalidation_1-auc:0.72202\n",
      "[1]\tvalidation_0-auc:0.75162\tvalidation_1-auc:0.74826\n",
      "[2]\tvalidation_0-auc:0.82547\tvalidation_1-auc:0.82164\n",
      "[3]\tvalidation_0-auc:0.84125\tvalidation_1-auc:0.83126\n",
      "[4]\tvalidation_0-auc:0.84790\tvalidation_1-auc:0.83795\n",
      "[5]\tvalidation_0-auc:0.85242\tvalidation_1-auc:0.83836\n",
      "[6]\tvalidation_0-auc:0.85118\tvalidation_1-auc:0.83609\n",
      "[7]\tvalidation_0-auc:0.85924\tvalidation_1-auc:0.83748\n",
      "[8]\tvalidation_0-auc:0.85906\tvalidation_1-auc:0.83527\n",
      "[9]\tvalidation_0-auc:0.85661\tvalidation_1-auc:0.83353\n",
      "[10]\tvalidation_0-auc:0.86420\tvalidation_1-auc:0.83867\n",
      "[11]\tvalidation_0-auc:0.86930\tvalidation_1-auc:0.83936\n",
      "[12]\tvalidation_0-auc:0.87322\tvalidation_1-auc:0.84211\n",
      "[13]\tvalidation_0-auc:0.87356\tvalidation_1-auc:0.84166\n",
      "[14]\tvalidation_0-auc:0.87477\tvalidation_1-auc:0.84075\n",
      "[15]\tvalidation_0-auc:0.87744\tvalidation_1-auc:0.84148\n",
      "[16]\tvalidation_0-auc:0.87781\tvalidation_1-auc:0.84132\n",
      "[17]\tvalidation_0-auc:0.88018\tvalidation_1-auc:0.84161\n",
      "[18]\tvalidation_0-auc:0.88223\tvalidation_1-auc:0.84168\n",
      "[19]\tvalidation_0-auc:0.88278\tvalidation_1-auc:0.84094\n",
      "[20]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.84057\n",
      "[21]\tvalidation_0-auc:0.88545\tvalidation_1-auc:0.84101\n",
      "[22]\tvalidation_0-auc:0.88590\tvalidation_1-auc:0.84073\n",
      "[23]\tvalidation_0-auc:0.88642\tvalidation_1-auc:0.84059\n",
      "[24]\tvalidation_0-auc:0.88661\tvalidation_1-auc:0.84008\n",
      "[25]\tvalidation_0-auc:0.88823\tvalidation_1-auc:0.83975\n",
      "[26]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.83958\n",
      "[27]\tvalidation_0-auc:0.88982\tvalidation_1-auc:0.84026\n",
      "[28]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.83981\n",
      "[29]\tvalidation_0-auc:0.89108\tvalidation_1-auc:0.83905\n",
      "[30]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.83846\n",
      "[31]\tvalidation_0-auc:0.89228\tvalidation_1-auc:0.83814\n",
      "[32]\tvalidation_0-auc:0.89260\tvalidation_1-auc:0.83776\n",
      "[33]\tvalidation_0-auc:0.89343\tvalidation_1-auc:0.83830\n",
      "[34]\tvalidation_0-auc:0.89426\tvalidation_1-auc:0.83818\n",
      "[35]\tvalidation_0-auc:0.89471\tvalidation_1-auc:0.83854\n",
      "[36]\tvalidation_0-auc:0.89498\tvalidation_1-auc:0.83859\n",
      "[37]\tvalidation_0-auc:0.89628\tvalidation_1-auc:0.83836\n",
      "[38]\tvalidation_0-auc:0.89654\tvalidation_1-auc:0.83771\n",
      "[39]\tvalidation_0-auc:0.89717\tvalidation_1-auc:0.83756\n",
      "[40]\tvalidation_0-auc:0.89740\tvalidation_1-auc:0.83752\n",
      "[41]\tvalidation_0-auc:0.89767\tvalidation_1-auc:0.83747\n",
      "[42]\tvalidation_0-auc:0.89787\tvalidation_1-auc:0.83727\n",
      "[17:08:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71966\tvalidation_1-auc:0.72513\n",
      "[1]\tvalidation_0-auc:0.74933\tvalidation_1-auc:0.75434\n",
      "[2]\tvalidation_0-auc:0.82448\tvalidation_1-auc:0.81895\n",
      "[3]\tvalidation_0-auc:0.83839\tvalidation_1-auc:0.82623\n",
      "[4]\tvalidation_0-auc:0.84660\tvalidation_1-auc:0.83357\n",
      "[5]\tvalidation_0-auc:0.85233\tvalidation_1-auc:0.83478\n",
      "[6]\tvalidation_0-auc:0.85129\tvalidation_1-auc:0.83239\n",
      "[7]\tvalidation_0-auc:0.85768\tvalidation_1-auc:0.83589\n",
      "[8]\tvalidation_0-auc:0.85850\tvalidation_1-auc:0.83395\n",
      "[9]\tvalidation_0-auc:0.85739\tvalidation_1-auc:0.83155\n",
      "[10]\tvalidation_0-auc:0.86526\tvalidation_1-auc:0.83599\n",
      "[11]\tvalidation_0-auc:0.86925\tvalidation_1-auc:0.83864\n",
      "[12]\tvalidation_0-auc:0.87186\tvalidation_1-auc:0.84072\n",
      "[13]\tvalidation_0-auc:0.87273\tvalidation_1-auc:0.83910\n",
      "[14]\tvalidation_0-auc:0.87416\tvalidation_1-auc:0.83855\n",
      "[15]\tvalidation_0-auc:0.87706\tvalidation_1-auc:0.83951\n",
      "[16]\tvalidation_0-auc:0.87682\tvalidation_1-auc:0.83951\n",
      "[17]\tvalidation_0-auc:0.87808\tvalidation_1-auc:0.84108\n",
      "[18]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.84199\n",
      "[19]\tvalidation_0-auc:0.88082\tvalidation_1-auc:0.84116\n",
      "[20]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.84128\n",
      "[21]\tvalidation_0-auc:0.88343\tvalidation_1-auc:0.84113\n",
      "[22]\tvalidation_0-auc:0.88388\tvalidation_1-auc:0.84040\n",
      "[23]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.84087\n",
      "[24]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.84098\n",
      "[25]\tvalidation_0-auc:0.88650\tvalidation_1-auc:0.84076\n",
      "[26]\tvalidation_0-auc:0.88714\tvalidation_1-auc:0.84080\n",
      "[27]\tvalidation_0-auc:0.88784\tvalidation_1-auc:0.84119\n",
      "[28]\tvalidation_0-auc:0.88830\tvalidation_1-auc:0.84156\n",
      "[29]\tvalidation_0-auc:0.88940\tvalidation_1-auc:0.84149\n",
      "[30]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.84194\n",
      "[31]\tvalidation_0-auc:0.89036\tvalidation_1-auc:0.84199\n",
      "[32]\tvalidation_0-auc:0.89139\tvalidation_1-auc:0.84198\n",
      "[33]\tvalidation_0-auc:0.89293\tvalidation_1-auc:0.84174\n",
      "[34]\tvalidation_0-auc:0.89398\tvalidation_1-auc:0.84141\n",
      "[35]\tvalidation_0-auc:0.89416\tvalidation_1-auc:0.84115\n",
      "[36]\tvalidation_0-auc:0.89428\tvalidation_1-auc:0.84110\n",
      "[37]\tvalidation_0-auc:0.89447\tvalidation_1-auc:0.84103\n",
      "[38]\tvalidation_0-auc:0.89506\tvalidation_1-auc:0.84116\n",
      "[39]\tvalidation_0-auc:0.89519\tvalidation_1-auc:0.84104\n",
      "[40]\tvalidation_0-auc:0.89520\tvalidation_1-auc:0.84044\n",
      "[41]\tvalidation_0-auc:0.89523\tvalidation_1-auc:0.84064\n",
      "[42]\tvalidation_0-auc:0.89532\tvalidation_1-auc:0.84055\n",
      "[43]\tvalidation_0-auc:0.89534\tvalidation_1-auc:0.84074\n",
      "[44]\tvalidation_0-auc:0.89602\tvalidation_1-auc:0.84024\n",
      "[45]\tvalidation_0-auc:0.89704\tvalidation_1-auc:0.83885\n",
      "[46]\tvalidation_0-auc:0.89743\tvalidation_1-auc:0.83893\n",
      "[47]\tvalidation_0-auc:0.89755\tvalidation_1-auc:0.83880\n",
      "[48]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.83840\n",
      "[49]\tvalidation_0-auc:0.89854\tvalidation_1-auc:0.83800\n",
      "[50]\tvalidation_0-auc:0.89961\tvalidation_1-auc:0.83790\n",
      "[51]\tvalidation_0-auc:0.90052\tvalidation_1-auc:0.83656\n",
      "[52]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83525\n",
      "[53]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83495\n",
      "[54]\tvalidation_0-auc:0.90169\tvalidation_1-auc:0.83478\n",
      "[55]\tvalidation_0-auc:0.90206\tvalidation_1-auc:0.83452\n",
      "[56]\tvalidation_0-auc:0.90248\tvalidation_1-auc:0.83409\n",
      "[57]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.83386\n",
      "[58]\tvalidation_0-auc:0.90287\tvalidation_1-auc:0.83374\n",
      "[59]\tvalidation_0-auc:0.90290\tvalidation_1-auc:0.83364\n",
      "[60]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.83394\n",
      "[61]\tvalidation_0-auc:0.90370\tvalidation_1-auc:0.83362\n",
      "[17:08:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72503\tvalidation_1-auc:0.71955\n",
      "[1]\tvalidation_0-auc:0.76149\tvalidation_1-auc:0.75265\n",
      "[2]\tvalidation_0-auc:0.82822\tvalidation_1-auc:0.81854\n",
      "[3]\tvalidation_0-auc:0.84183\tvalidation_1-auc:0.82753\n",
      "[4]\tvalidation_0-auc:0.85092\tvalidation_1-auc:0.83415\n",
      "[5]\tvalidation_0-auc:0.85369\tvalidation_1-auc:0.83488\n",
      "[6]\tvalidation_0-auc:0.85254\tvalidation_1-auc:0.83703\n",
      "[7]\tvalidation_0-auc:0.86110\tvalidation_1-auc:0.83754\n",
      "[8]\tvalidation_0-auc:0.86148\tvalidation_1-auc:0.83327\n",
      "[9]\tvalidation_0-auc:0.86063\tvalidation_1-auc:0.83288\n",
      "[10]\tvalidation_0-auc:0.86754\tvalidation_1-auc:0.83986\n",
      "[11]\tvalidation_0-auc:0.87134\tvalidation_1-auc:0.84073\n",
      "[12]\tvalidation_0-auc:0.87382\tvalidation_1-auc:0.84151\n",
      "[13]\tvalidation_0-auc:0.87518\tvalidation_1-auc:0.84079\n",
      "[14]\tvalidation_0-auc:0.87594\tvalidation_1-auc:0.83949\n",
      "[15]\tvalidation_0-auc:0.87836\tvalidation_1-auc:0.84140\n",
      "[16]\tvalidation_0-auc:0.87899\tvalidation_1-auc:0.84054\n",
      "[17]\tvalidation_0-auc:0.88067\tvalidation_1-auc:0.84281\n",
      "[18]\tvalidation_0-auc:0.88271\tvalidation_1-auc:0.84386\n",
      "[19]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.84391\n",
      "[20]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.84383\n",
      "[21]\tvalidation_0-auc:0.88673\tvalidation_1-auc:0.84272\n",
      "[22]\tvalidation_0-auc:0.88707\tvalidation_1-auc:0.84282\n",
      "[23]\tvalidation_0-auc:0.88781\tvalidation_1-auc:0.84295\n",
      "[24]\tvalidation_0-auc:0.88865\tvalidation_1-auc:0.84259\n",
      "[25]\tvalidation_0-auc:0.88972\tvalidation_1-auc:0.84213\n",
      "[26]\tvalidation_0-auc:0.89125\tvalidation_1-auc:0.84157\n",
      "[27]\tvalidation_0-auc:0.89274\tvalidation_1-auc:0.84236\n",
      "[28]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.84180\n",
      "[29]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.84120\n",
      "[30]\tvalidation_0-auc:0.89551\tvalidation_1-auc:0.84100\n",
      "[31]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.84039\n",
      "[32]\tvalidation_0-auc:0.89667\tvalidation_1-auc:0.84030\n",
      "[33]\tvalidation_0-auc:0.89745\tvalidation_1-auc:0.83986\n",
      "[34]\tvalidation_0-auc:0.89821\tvalidation_1-auc:0.83951\n",
      "[35]\tvalidation_0-auc:0.89836\tvalidation_1-auc:0.83929\n",
      "[36]\tvalidation_0-auc:0.89849\tvalidation_1-auc:0.83984\n",
      "[37]\tvalidation_0-auc:0.89881\tvalidation_1-auc:0.83930\n",
      "[38]\tvalidation_0-auc:0.89915\tvalidation_1-auc:0.83939\n",
      "[39]\tvalidation_0-auc:0.89952\tvalidation_1-auc:0.83909\n",
      "[40]\tvalidation_0-auc:0.90023\tvalidation_1-auc:0.83874\n",
      "[41]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83883\n",
      "[42]\tvalidation_0-auc:0.90091\tvalidation_1-auc:0.83852\n",
      "[43]\tvalidation_0-auc:0.90115\tvalidation_1-auc:0.83841\n",
      "[44]\tvalidation_0-auc:0.90125\tvalidation_1-auc:0.83829\n",
      "[45]\tvalidation_0-auc:0.90173\tvalidation_1-auc:0.83806\n",
      "[46]\tvalidation_0-auc:0.90199\tvalidation_1-auc:0.83804\n",
      "[47]\tvalidation_0-auc:0.90212\tvalidation_1-auc:0.83800\n",
      "[48]\tvalidation_0-auc:0.90224\tvalidation_1-auc:0.83794\n",
      "[49]\tvalidation_0-auc:0.90236\tvalidation_1-auc:0.83773\n",
      "[17:09:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72163\tvalidation_1-auc:0.72829\n",
      "[1]\tvalidation_0-auc:0.74495\tvalidation_1-auc:0.75133\n",
      "[2]\tvalidation_0-auc:0.81633\tvalidation_1-auc:0.81723\n",
      "[3]\tvalidation_0-auc:0.82915\tvalidation_1-auc:0.82745\n",
      "[4]\tvalidation_0-auc:0.83624\tvalidation_1-auc:0.83264\n",
      "[5]\tvalidation_0-auc:0.83963\tvalidation_1-auc:0.83414\n",
      "[6]\tvalidation_0-auc:0.83815\tvalidation_1-auc:0.82965\n",
      "[7]\tvalidation_0-auc:0.84439\tvalidation_1-auc:0.83419\n",
      "[8]\tvalidation_0-auc:0.84341\tvalidation_1-auc:0.83116\n",
      "[9]\tvalidation_0-auc:0.84359\tvalidation_1-auc:0.82939\n",
      "[10]\tvalidation_0-auc:0.85194\tvalidation_1-auc:0.83486\n",
      "[11]\tvalidation_0-auc:0.85602\tvalidation_1-auc:0.83763\n",
      "[12]\tvalidation_0-auc:0.85961\tvalidation_1-auc:0.83876\n",
      "[13]\tvalidation_0-auc:0.86073\tvalidation_1-auc:0.83744\n",
      "[14]\tvalidation_0-auc:0.86287\tvalidation_1-auc:0.83787\n",
      "[15]\tvalidation_0-auc:0.86419\tvalidation_1-auc:0.83930\n",
      "[16]\tvalidation_0-auc:0.86628\tvalidation_1-auc:0.84008\n",
      "[17]\tvalidation_0-auc:0.86730\tvalidation_1-auc:0.83991\n",
      "[18]\tvalidation_0-auc:0.86843\tvalidation_1-auc:0.83932\n",
      "[19]\tvalidation_0-auc:0.86938\tvalidation_1-auc:0.84034\n",
      "[20]\tvalidation_0-auc:0.87056\tvalidation_1-auc:0.84027\n",
      "[21]\tvalidation_0-auc:0.87132\tvalidation_1-auc:0.83966\n",
      "[22]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.83935\n",
      "[23]\tvalidation_0-auc:0.87260\tvalidation_1-auc:0.83996\n",
      "[24]\tvalidation_0-auc:0.87323\tvalidation_1-auc:0.83930\n",
      "[25]\tvalidation_0-auc:0.87340\tvalidation_1-auc:0.83942\n",
      "[26]\tvalidation_0-auc:0.87445\tvalidation_1-auc:0.83973\n",
      "[27]\tvalidation_0-auc:0.87484\tvalidation_1-auc:0.83981\n",
      "[28]\tvalidation_0-auc:0.87538\tvalidation_1-auc:0.83976\n",
      "[29]\tvalidation_0-auc:0.87597\tvalidation_1-auc:0.83927\n",
      "[30]\tvalidation_0-auc:0.87620\tvalidation_1-auc:0.83920\n",
      "[31]\tvalidation_0-auc:0.87755\tvalidation_1-auc:0.83939\n",
      "[32]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.83898\n",
      "[33]\tvalidation_0-auc:0.87883\tvalidation_1-auc:0.83902\n",
      "[34]\tvalidation_0-auc:0.87960\tvalidation_1-auc:0.83865\n",
      "[35]\tvalidation_0-auc:0.88054\tvalidation_1-auc:0.83864\n",
      "[36]\tvalidation_0-auc:0.88077\tvalidation_1-auc:0.83888\n",
      "[37]\tvalidation_0-auc:0.88092\tvalidation_1-auc:0.83907\n",
      "[38]\tvalidation_0-auc:0.88114\tvalidation_1-auc:0.83908\n",
      "[39]\tvalidation_0-auc:0.88132\tvalidation_1-auc:0.83929\n",
      "[40]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.83947\n",
      "[41]\tvalidation_0-auc:0.88277\tvalidation_1-auc:0.83939\n",
      "[42]\tvalidation_0-auc:0.88299\tvalidation_1-auc:0.83940\n",
      "[43]\tvalidation_0-auc:0.88311\tvalidation_1-auc:0.83949\n",
      "[44]\tvalidation_0-auc:0.88423\tvalidation_1-auc:0.83887\n",
      "[45]\tvalidation_0-auc:0.88454\tvalidation_1-auc:0.83866\n",
      "[46]\tvalidation_0-auc:0.88462\tvalidation_1-auc:0.83847\n",
      "[47]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.83840\n",
      "[48]\tvalidation_0-auc:0.88603\tvalidation_1-auc:0.83772\n",
      "[49]\tvalidation_0-auc:0.88626\tvalidation_1-auc:0.83789\n",
      "[17:09:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73484\tvalidation_1-auc:0.74158\n",
      "[1]\tvalidation_0-auc:0.75173\tvalidation_1-auc:0.75690\n",
      "[2]\tvalidation_0-auc:0.81897\tvalidation_1-auc:0.81705\n",
      "[3]\tvalidation_0-auc:0.83223\tvalidation_1-auc:0.83207\n",
      "[4]\tvalidation_0-auc:0.84006\tvalidation_1-auc:0.83483\n",
      "[5]\tvalidation_0-auc:0.84295\tvalidation_1-auc:0.83543\n",
      "[6]\tvalidation_0-auc:0.84184\tvalidation_1-auc:0.83019\n",
      "[7]\tvalidation_0-auc:0.84827\tvalidation_1-auc:0.83486\n",
      "[8]\tvalidation_0-auc:0.84798\tvalidation_1-auc:0.83162\n",
      "[9]\tvalidation_0-auc:0.84724\tvalidation_1-auc:0.83334\n",
      "[10]\tvalidation_0-auc:0.85336\tvalidation_1-auc:0.83683\n",
      "[11]\tvalidation_0-auc:0.85735\tvalidation_1-auc:0.83923\n",
      "[12]\tvalidation_0-auc:0.85942\tvalidation_1-auc:0.84113\n",
      "[13]\tvalidation_0-auc:0.86011\tvalidation_1-auc:0.84125\n",
      "[14]\tvalidation_0-auc:0.86127\tvalidation_1-auc:0.84128\n",
      "[15]\tvalidation_0-auc:0.86256\tvalidation_1-auc:0.84037\n",
      "[16]\tvalidation_0-auc:0.86345\tvalidation_1-auc:0.84018\n",
      "[17]\tvalidation_0-auc:0.86485\tvalidation_1-auc:0.84006\n",
      "[18]\tvalidation_0-auc:0.86616\tvalidation_1-auc:0.83963\n",
      "[19]\tvalidation_0-auc:0.86723\tvalidation_1-auc:0.84080\n",
      "[20]\tvalidation_0-auc:0.86848\tvalidation_1-auc:0.84057\n",
      "[21]\tvalidation_0-auc:0.86944\tvalidation_1-auc:0.84041\n",
      "[22]\tvalidation_0-auc:0.87094\tvalidation_1-auc:0.83988\n",
      "[23]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.84007\n",
      "[24]\tvalidation_0-auc:0.87266\tvalidation_1-auc:0.83982\n",
      "[25]\tvalidation_0-auc:0.87426\tvalidation_1-auc:0.83967\n",
      "[26]\tvalidation_0-auc:0.87505\tvalidation_1-auc:0.83882\n",
      "[27]\tvalidation_0-auc:0.87538\tvalidation_1-auc:0.83834\n",
      "[28]\tvalidation_0-auc:0.87586\tvalidation_1-auc:0.83824\n",
      "[29]\tvalidation_0-auc:0.87608\tvalidation_1-auc:0.83828\n",
      "[30]\tvalidation_0-auc:0.87661\tvalidation_1-auc:0.83817\n",
      "[31]\tvalidation_0-auc:0.87708\tvalidation_1-auc:0.83858\n",
      "[32]\tvalidation_0-auc:0.87829\tvalidation_1-auc:0.83710\n",
      "[33]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.83691\n",
      "[34]\tvalidation_0-auc:0.87894\tvalidation_1-auc:0.83705\n",
      "[35]\tvalidation_0-auc:0.88006\tvalidation_1-auc:0.83741\n",
      "[36]\tvalidation_0-auc:0.88020\tvalidation_1-auc:0.83755\n",
      "[37]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.83747\n",
      "[38]\tvalidation_0-auc:0.88193\tvalidation_1-auc:0.83639\n",
      "[39]\tvalidation_0-auc:0.88222\tvalidation_1-auc:0.83641\n",
      "[40]\tvalidation_0-auc:0.88268\tvalidation_1-auc:0.83668\n",
      "[41]\tvalidation_0-auc:0.88327\tvalidation_1-auc:0.83615\n",
      "[42]\tvalidation_0-auc:0.88344\tvalidation_1-auc:0.83603\n",
      "[43]\tvalidation_0-auc:0.88394\tvalidation_1-auc:0.83587\n",
      "[17:10:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73500\tvalidation_1-auc:0.74141\n",
      "[1]\tvalidation_0-auc:0.75473\tvalidation_1-auc:0.75496\n",
      "[2]\tvalidation_0-auc:0.81567\tvalidation_1-auc:0.81525\n",
      "[3]\tvalidation_0-auc:0.83132\tvalidation_1-auc:0.83022\n",
      "[4]\tvalidation_0-auc:0.83889\tvalidation_1-auc:0.83468\n",
      "[5]\tvalidation_0-auc:0.84466\tvalidation_1-auc:0.83703\n",
      "[6]\tvalidation_0-auc:0.84310\tvalidation_1-auc:0.83404\n",
      "[7]\tvalidation_0-auc:0.84725\tvalidation_1-auc:0.83637\n",
      "[8]\tvalidation_0-auc:0.84631\tvalidation_1-auc:0.83490\n",
      "[9]\tvalidation_0-auc:0.84505\tvalidation_1-auc:0.83451\n",
      "[10]\tvalidation_0-auc:0.85228\tvalidation_1-auc:0.83828\n",
      "[11]\tvalidation_0-auc:0.85639\tvalidation_1-auc:0.84005\n",
      "[12]\tvalidation_0-auc:0.85937\tvalidation_1-auc:0.84099\n",
      "[13]\tvalidation_0-auc:0.86038\tvalidation_1-auc:0.84052\n",
      "[14]\tvalidation_0-auc:0.86270\tvalidation_1-auc:0.84138\n",
      "[15]\tvalidation_0-auc:0.86410\tvalidation_1-auc:0.84138\n",
      "[16]\tvalidation_0-auc:0.86636\tvalidation_1-auc:0.84215\n",
      "[17]\tvalidation_0-auc:0.86698\tvalidation_1-auc:0.84250\n",
      "[18]\tvalidation_0-auc:0.86819\tvalidation_1-auc:0.84137\n",
      "[19]\tvalidation_0-auc:0.86895\tvalidation_1-auc:0.84103\n",
      "[20]\tvalidation_0-auc:0.86985\tvalidation_1-auc:0.84143\n",
      "[21]\tvalidation_0-auc:0.87114\tvalidation_1-auc:0.84066\n",
      "[22]\tvalidation_0-auc:0.87195\tvalidation_1-auc:0.84041\n",
      "[23]\tvalidation_0-auc:0.87251\tvalidation_1-auc:0.84032\n",
      "[24]\tvalidation_0-auc:0.87335\tvalidation_1-auc:0.84004\n",
      "[25]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.83939\n",
      "[26]\tvalidation_0-auc:0.87563\tvalidation_1-auc:0.83890\n",
      "[27]\tvalidation_0-auc:0.87618\tvalidation_1-auc:0.83876\n",
      "[28]\tvalidation_0-auc:0.87645\tvalidation_1-auc:0.83889\n",
      "[29]\tvalidation_0-auc:0.87677\tvalidation_1-auc:0.83864\n",
      "[30]\tvalidation_0-auc:0.87710\tvalidation_1-auc:0.83847\n",
      "[31]\tvalidation_0-auc:0.87741\tvalidation_1-auc:0.83853\n",
      "[32]\tvalidation_0-auc:0.87896\tvalidation_1-auc:0.83884\n",
      "[33]\tvalidation_0-auc:0.87933\tvalidation_1-auc:0.83912\n",
      "[34]\tvalidation_0-auc:0.88003\tvalidation_1-auc:0.83851\n",
      "[35]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.83885\n",
      "[36]\tvalidation_0-auc:0.88034\tvalidation_1-auc:0.83876\n",
      "[37]\tvalidation_0-auc:0.88039\tvalidation_1-auc:0.83880\n",
      "[38]\tvalidation_0-auc:0.88082\tvalidation_1-auc:0.83803\n",
      "[39]\tvalidation_0-auc:0.88115\tvalidation_1-auc:0.83774\n",
      "[40]\tvalidation_0-auc:0.88171\tvalidation_1-auc:0.83755\n",
      "[41]\tvalidation_0-auc:0.88184\tvalidation_1-auc:0.83739\n",
      "[42]\tvalidation_0-auc:0.88210\tvalidation_1-auc:0.83780\n",
      "[43]\tvalidation_0-auc:0.88313\tvalidation_1-auc:0.83691\n",
      "[44]\tvalidation_0-auc:0.88338\tvalidation_1-auc:0.83673\n",
      "[45]\tvalidation_0-auc:0.88413\tvalidation_1-auc:0.83635\n",
      "[46]\tvalidation_0-auc:0.88530\tvalidation_1-auc:0.83583\n",
      "[47]\tvalidation_0-auc:0.88539\tvalidation_1-auc:0.83598\n",
      "[17:10:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71318\tvalidation_1-auc:0.71927\n",
      "[1]\tvalidation_0-auc:0.74184\tvalidation_1-auc:0.74329\n",
      "[2]\tvalidation_0-auc:0.81698\tvalidation_1-auc:0.82083\n",
      "[3]\tvalidation_0-auc:0.82941\tvalidation_1-auc:0.83071\n",
      "[4]\tvalidation_0-auc:0.83605\tvalidation_1-auc:0.83412\n",
      "[5]\tvalidation_0-auc:0.84178\tvalidation_1-auc:0.83724\n",
      "[6]\tvalidation_0-auc:0.83924\tvalidation_1-auc:0.83371\n",
      "[7]\tvalidation_0-auc:0.84603\tvalidation_1-auc:0.83662\n",
      "[8]\tvalidation_0-auc:0.84538\tvalidation_1-auc:0.83501\n",
      "[9]\tvalidation_0-auc:0.84484\tvalidation_1-auc:0.83323\n",
      "[10]\tvalidation_0-auc:0.85075\tvalidation_1-auc:0.83548\n",
      "[11]\tvalidation_0-auc:0.85411\tvalidation_1-auc:0.83836\n",
      "[12]\tvalidation_0-auc:0.85781\tvalidation_1-auc:0.83945\n",
      "[13]\tvalidation_0-auc:0.85849\tvalidation_1-auc:0.83805\n",
      "[14]\tvalidation_0-auc:0.86080\tvalidation_1-auc:0.83763\n",
      "[15]\tvalidation_0-auc:0.86236\tvalidation_1-auc:0.83812\n",
      "[16]\tvalidation_0-auc:0.86426\tvalidation_1-auc:0.83684\n",
      "[17]\tvalidation_0-auc:0.86514\tvalidation_1-auc:0.83748\n",
      "[18]\tvalidation_0-auc:0.86677\tvalidation_1-auc:0.83827\n",
      "[19]\tvalidation_0-auc:0.86754\tvalidation_1-auc:0.83811\n",
      "[20]\tvalidation_0-auc:0.86818\tvalidation_1-auc:0.83846\n",
      "[21]\tvalidation_0-auc:0.86932\tvalidation_1-auc:0.83790\n",
      "[22]\tvalidation_0-auc:0.87144\tvalidation_1-auc:0.83686\n",
      "[23]\tvalidation_0-auc:0.87264\tvalidation_1-auc:0.83640\n",
      "[24]\tvalidation_0-auc:0.87328\tvalidation_1-auc:0.83653\n",
      "[25]\tvalidation_0-auc:0.87361\tvalidation_1-auc:0.83633\n",
      "[26]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.83599\n",
      "[27]\tvalidation_0-auc:0.87563\tvalidation_1-auc:0.83582\n",
      "[28]\tvalidation_0-auc:0.87681\tvalidation_1-auc:0.83546\n",
      "[29]\tvalidation_0-auc:0.87725\tvalidation_1-auc:0.83528\n",
      "[30]\tvalidation_0-auc:0.87745\tvalidation_1-auc:0.83512\n",
      "[31]\tvalidation_0-auc:0.87779\tvalidation_1-auc:0.83520\n",
      "[32]\tvalidation_0-auc:0.87831\tvalidation_1-auc:0.83492\n",
      "[33]\tvalidation_0-auc:0.87853\tvalidation_1-auc:0.83498\n",
      "[34]\tvalidation_0-auc:0.87886\tvalidation_1-auc:0.83520\n",
      "[35]\tvalidation_0-auc:0.87961\tvalidation_1-auc:0.83546\n",
      "[36]\tvalidation_0-auc:0.88001\tvalidation_1-auc:0.83522\n",
      "[37]\tvalidation_0-auc:0.88094\tvalidation_1-auc:0.83506\n",
      "[38]\tvalidation_0-auc:0.88194\tvalidation_1-auc:0.83464\n",
      "[39]\tvalidation_0-auc:0.88209\tvalidation_1-auc:0.83466\n",
      "[40]\tvalidation_0-auc:0.88268\tvalidation_1-auc:0.83453\n",
      "[41]\tvalidation_0-auc:0.88279\tvalidation_1-auc:0.83429\n",
      "[17:10:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73552\tvalidation_1-auc:0.73895\n",
      "[1]\tvalidation_0-auc:0.75405\tvalidation_1-auc:0.75518\n",
      "[2]\tvalidation_0-auc:0.81948\tvalidation_1-auc:0.81804\n",
      "[3]\tvalidation_0-auc:0.83217\tvalidation_1-auc:0.83091\n",
      "[4]\tvalidation_0-auc:0.83860\tvalidation_1-auc:0.83317\n",
      "[5]\tvalidation_0-auc:0.84251\tvalidation_1-auc:0.83456\n",
      "[6]\tvalidation_0-auc:0.84255\tvalidation_1-auc:0.83279\n",
      "[7]\tvalidation_0-auc:0.84836\tvalidation_1-auc:0.83643\n",
      "[8]\tvalidation_0-auc:0.84763\tvalidation_1-auc:0.83611\n",
      "[9]\tvalidation_0-auc:0.84759\tvalidation_1-auc:0.83434\n",
      "[10]\tvalidation_0-auc:0.85338\tvalidation_1-auc:0.83787\n",
      "[11]\tvalidation_0-auc:0.85726\tvalidation_1-auc:0.83984\n",
      "[12]\tvalidation_0-auc:0.86018\tvalidation_1-auc:0.84092\n",
      "[13]\tvalidation_0-auc:0.86047\tvalidation_1-auc:0.84136\n",
      "[14]\tvalidation_0-auc:0.86200\tvalidation_1-auc:0.84219\n",
      "[15]\tvalidation_0-auc:0.86403\tvalidation_1-auc:0.84315\n",
      "[16]\tvalidation_0-auc:0.86591\tvalidation_1-auc:0.84267\n",
      "[17]\tvalidation_0-auc:0.86750\tvalidation_1-auc:0.84176\n",
      "[18]\tvalidation_0-auc:0.86918\tvalidation_1-auc:0.84180\n",
      "[19]\tvalidation_0-auc:0.87014\tvalidation_1-auc:0.84128\n",
      "[20]\tvalidation_0-auc:0.87195\tvalidation_1-auc:0.84133\n",
      "[21]\tvalidation_0-auc:0.87344\tvalidation_1-auc:0.84233\n",
      "[22]\tvalidation_0-auc:0.87410\tvalidation_1-auc:0.84236\n",
      "[23]\tvalidation_0-auc:0.87527\tvalidation_1-auc:0.84264\n",
      "[24]\tvalidation_0-auc:0.87589\tvalidation_1-auc:0.84277\n",
      "[25]\tvalidation_0-auc:0.87671\tvalidation_1-auc:0.84261\n",
      "[26]\tvalidation_0-auc:0.87807\tvalidation_1-auc:0.84244\n",
      "[27]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.84203\n",
      "[28]\tvalidation_0-auc:0.87881\tvalidation_1-auc:0.84192\n",
      "[29]\tvalidation_0-auc:0.87940\tvalidation_1-auc:0.84227\n",
      "[30]\tvalidation_0-auc:0.88022\tvalidation_1-auc:0.84208\n",
      "[31]\tvalidation_0-auc:0.88050\tvalidation_1-auc:0.84209\n",
      "[32]\tvalidation_0-auc:0.88146\tvalidation_1-auc:0.84258\n",
      "[33]\tvalidation_0-auc:0.88158\tvalidation_1-auc:0.84259\n",
      "[34]\tvalidation_0-auc:0.88199\tvalidation_1-auc:0.84254\n",
      "[35]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.84245\n",
      "[36]\tvalidation_0-auc:0.88317\tvalidation_1-auc:0.84238\n",
      "[37]\tvalidation_0-auc:0.88332\tvalidation_1-auc:0.84234\n",
      "[38]\tvalidation_0-auc:0.88404\tvalidation_1-auc:0.84188\n",
      "[39]\tvalidation_0-auc:0.88450\tvalidation_1-auc:0.84154\n",
      "[40]\tvalidation_0-auc:0.88485\tvalidation_1-auc:0.84130\n",
      "[41]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.84126\n",
      "[42]\tvalidation_0-auc:0.88601\tvalidation_1-auc:0.84142\n",
      "[43]\tvalidation_0-auc:0.88667\tvalidation_1-auc:0.84083\n",
      "[44]\tvalidation_0-auc:0.88731\tvalidation_1-auc:0.84065\n",
      "[45]\tvalidation_0-auc:0.88786\tvalidation_1-auc:0.84044\n",
      "[17:11:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72325\tvalidation_1-auc:0.73144\n",
      "[1]\tvalidation_0-auc:0.74667\tvalidation_1-auc:0.75509\n",
      "[2]\tvalidation_0-auc:0.81648\tvalidation_1-auc:0.82026\n",
      "[3]\tvalidation_0-auc:0.82929\tvalidation_1-auc:0.82901\n",
      "[4]\tvalidation_0-auc:0.83606\tvalidation_1-auc:0.83349\n",
      "[5]\tvalidation_0-auc:0.84005\tvalidation_1-auc:0.83435\n",
      "[6]\tvalidation_0-auc:0.83867\tvalidation_1-auc:0.83072\n",
      "[7]\tvalidation_0-auc:0.84432\tvalidation_1-auc:0.83449\n",
      "[8]\tvalidation_0-auc:0.84260\tvalidation_1-auc:0.83085\n",
      "[9]\tvalidation_0-auc:0.84255\tvalidation_1-auc:0.82958\n",
      "[10]\tvalidation_0-auc:0.85032\tvalidation_1-auc:0.83320\n",
      "[11]\tvalidation_0-auc:0.85419\tvalidation_1-auc:0.83678\n",
      "[12]\tvalidation_0-auc:0.85701\tvalidation_1-auc:0.83764\n",
      "[13]\tvalidation_0-auc:0.85794\tvalidation_1-auc:0.83687\n",
      "[14]\tvalidation_0-auc:0.85958\tvalidation_1-auc:0.83828\n",
      "[15]\tvalidation_0-auc:0.86115\tvalidation_1-auc:0.83949\n",
      "[16]\tvalidation_0-auc:0.86247\tvalidation_1-auc:0.83944\n",
      "[17]\tvalidation_0-auc:0.86356\tvalidation_1-auc:0.83957\n",
      "[18]\tvalidation_0-auc:0.86432\tvalidation_1-auc:0.83893\n",
      "[19]\tvalidation_0-auc:0.86553\tvalidation_1-auc:0.83923\n",
      "[20]\tvalidation_0-auc:0.86613\tvalidation_1-auc:0.83930\n",
      "[21]\tvalidation_0-auc:0.86703\tvalidation_1-auc:0.83931\n",
      "[22]\tvalidation_0-auc:0.86777\tvalidation_1-auc:0.83823\n",
      "[23]\tvalidation_0-auc:0.86842\tvalidation_1-auc:0.83838\n",
      "[24]\tvalidation_0-auc:0.86864\tvalidation_1-auc:0.83852\n",
      "[25]\tvalidation_0-auc:0.86905\tvalidation_1-auc:0.83905\n",
      "[26]\tvalidation_0-auc:0.87018\tvalidation_1-auc:0.83954\n",
      "[27]\tvalidation_0-auc:0.87138\tvalidation_1-auc:0.83840\n",
      "[28]\tvalidation_0-auc:0.87233\tvalidation_1-auc:0.83816\n",
      "[29]\tvalidation_0-auc:0.87258\tvalidation_1-auc:0.83799\n",
      "[30]\tvalidation_0-auc:0.87274\tvalidation_1-auc:0.83802\n",
      "[31]\tvalidation_0-auc:0.87310\tvalidation_1-auc:0.83798\n",
      "[32]\tvalidation_0-auc:0.87361\tvalidation_1-auc:0.83785\n",
      "[33]\tvalidation_0-auc:0.87376\tvalidation_1-auc:0.83783\n",
      "[34]\tvalidation_0-auc:0.87424\tvalidation_1-auc:0.83789\n",
      "[35]\tvalidation_0-auc:0.87555\tvalidation_1-auc:0.83826\n",
      "[36]\tvalidation_0-auc:0.87580\tvalidation_1-auc:0.83831\n",
      "[37]\tvalidation_0-auc:0.87655\tvalidation_1-auc:0.83842\n",
      "[38]\tvalidation_0-auc:0.87679\tvalidation_1-auc:0.83779\n",
      "[39]\tvalidation_0-auc:0.87770\tvalidation_1-auc:0.83742\n",
      "[40]\tvalidation_0-auc:0.87801\tvalidation_1-auc:0.83761\n",
      "[41]\tvalidation_0-auc:0.87817\tvalidation_1-auc:0.83773\n",
      "[42]\tvalidation_0-auc:0.87832\tvalidation_1-auc:0.83781\n",
      "[43]\tvalidation_0-auc:0.87887\tvalidation_1-auc:0.83731\n",
      "[44]\tvalidation_0-auc:0.87953\tvalidation_1-auc:0.83686\n",
      "[45]\tvalidation_0-auc:0.87979\tvalidation_1-auc:0.83652\n",
      "[46]\tvalidation_0-auc:0.88034\tvalidation_1-auc:0.83664\n",
      "[47]\tvalidation_0-auc:0.88060\tvalidation_1-auc:0.83635\n",
      "[17:11:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73769\tvalidation_1-auc:0.74321\n",
      "[1]\tvalidation_0-auc:0.75397\tvalidation_1-auc:0.75921\n",
      "[2]\tvalidation_0-auc:0.81954\tvalidation_1-auc:0.81718\n",
      "[3]\tvalidation_0-auc:0.83458\tvalidation_1-auc:0.83267\n",
      "[4]\tvalidation_0-auc:0.84066\tvalidation_1-auc:0.83452\n",
      "[5]\tvalidation_0-auc:0.84281\tvalidation_1-auc:0.83579\n",
      "[6]\tvalidation_0-auc:0.84235\tvalidation_1-auc:0.83108\n",
      "[7]\tvalidation_0-auc:0.84896\tvalidation_1-auc:0.83487\n",
      "[8]\tvalidation_0-auc:0.84819\tvalidation_1-auc:0.83116\n",
      "[9]\tvalidation_0-auc:0.84748\tvalidation_1-auc:0.83341\n",
      "[10]\tvalidation_0-auc:0.85338\tvalidation_1-auc:0.83644\n",
      "[11]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.83854\n",
      "[12]\tvalidation_0-auc:0.85861\tvalidation_1-auc:0.84034\n",
      "[13]\tvalidation_0-auc:0.85875\tvalidation_1-auc:0.83960\n",
      "[14]\tvalidation_0-auc:0.86104\tvalidation_1-auc:0.84092\n",
      "[15]\tvalidation_0-auc:0.86202\tvalidation_1-auc:0.84159\n",
      "[16]\tvalidation_0-auc:0.86324\tvalidation_1-auc:0.84120\n",
      "[17]\tvalidation_0-auc:0.86411\tvalidation_1-auc:0.84058\n",
      "[18]\tvalidation_0-auc:0.86548\tvalidation_1-auc:0.84003\n",
      "[19]\tvalidation_0-auc:0.86649\tvalidation_1-auc:0.84103\n",
      "[20]\tvalidation_0-auc:0.86779\tvalidation_1-auc:0.84087\n",
      "[21]\tvalidation_0-auc:0.86884\tvalidation_1-auc:0.84043\n",
      "[22]\tvalidation_0-auc:0.87000\tvalidation_1-auc:0.83986\n",
      "[23]\tvalidation_0-auc:0.87057\tvalidation_1-auc:0.83962\n",
      "[24]\tvalidation_0-auc:0.87093\tvalidation_1-auc:0.83982\n",
      "[25]\tvalidation_0-auc:0.87189\tvalidation_1-auc:0.83988\n",
      "[26]\tvalidation_0-auc:0.87302\tvalidation_1-auc:0.83971\n",
      "[27]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.83971\n",
      "[28]\tvalidation_0-auc:0.87453\tvalidation_1-auc:0.83969\n",
      "[29]\tvalidation_0-auc:0.87464\tvalidation_1-auc:0.83939\n",
      "[30]\tvalidation_0-auc:0.87558\tvalidation_1-auc:0.83927\n",
      "[31]\tvalidation_0-auc:0.87573\tvalidation_1-auc:0.83938\n",
      "[32]\tvalidation_0-auc:0.87636\tvalidation_1-auc:0.83904\n",
      "[33]\tvalidation_0-auc:0.87666\tvalidation_1-auc:0.83887\n",
      "[34]\tvalidation_0-auc:0.87699\tvalidation_1-auc:0.83837\n",
      "[35]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.83807\n",
      "[36]\tvalidation_0-auc:0.87740\tvalidation_1-auc:0.83801\n",
      "[37]\tvalidation_0-auc:0.87771\tvalidation_1-auc:0.83826\n",
      "[38]\tvalidation_0-auc:0.87802\tvalidation_1-auc:0.83829\n",
      "[39]\tvalidation_0-auc:0.87826\tvalidation_1-auc:0.83796\n",
      "[40]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.83854\n",
      "[41]\tvalidation_0-auc:0.87930\tvalidation_1-auc:0.83806\n",
      "[42]\tvalidation_0-auc:0.87939\tvalidation_1-auc:0.83790\n",
      "[43]\tvalidation_0-auc:0.87952\tvalidation_1-auc:0.83780\n",
      "[44]\tvalidation_0-auc:0.87979\tvalidation_1-auc:0.83821\n",
      "[45]\tvalidation_0-auc:0.87997\tvalidation_1-auc:0.83829\n",
      "[17:12:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73724\tvalidation_1-auc:0.74108\n",
      "[1]\tvalidation_0-auc:0.75600\tvalidation_1-auc:0.75384\n",
      "[2]\tvalidation_0-auc:0.81624\tvalidation_1-auc:0.81529\n",
      "[3]\tvalidation_0-auc:0.83115\tvalidation_1-auc:0.82981\n",
      "[4]\tvalidation_0-auc:0.83881\tvalidation_1-auc:0.83412\n",
      "[5]\tvalidation_0-auc:0.84479\tvalidation_1-auc:0.83702\n",
      "[6]\tvalidation_0-auc:0.84196\tvalidation_1-auc:0.83424\n",
      "[7]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.83558\n",
      "[8]\tvalidation_0-auc:0.84593\tvalidation_1-auc:0.83441\n",
      "[9]\tvalidation_0-auc:0.84384\tvalidation_1-auc:0.83449\n",
      "[10]\tvalidation_0-auc:0.85137\tvalidation_1-auc:0.83785\n",
      "[11]\tvalidation_0-auc:0.85567\tvalidation_1-auc:0.84098\n",
      "[12]\tvalidation_0-auc:0.85844\tvalidation_1-auc:0.84203\n",
      "[13]\tvalidation_0-auc:0.85947\tvalidation_1-auc:0.84143\n",
      "[14]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.84267\n",
      "[15]\tvalidation_0-auc:0.86280\tvalidation_1-auc:0.84277\n",
      "[16]\tvalidation_0-auc:0.86428\tvalidation_1-auc:0.84274\n",
      "[17]\tvalidation_0-auc:0.86459\tvalidation_1-auc:0.84252\n",
      "[18]\tvalidation_0-auc:0.86599\tvalidation_1-auc:0.84283\n",
      "[19]\tvalidation_0-auc:0.86662\tvalidation_1-auc:0.84291\n",
      "[20]\tvalidation_0-auc:0.86764\tvalidation_1-auc:0.84249\n",
      "[21]\tvalidation_0-auc:0.86895\tvalidation_1-auc:0.84175\n",
      "[22]\tvalidation_0-auc:0.87008\tvalidation_1-auc:0.84166\n",
      "[23]\tvalidation_0-auc:0.87046\tvalidation_1-auc:0.84165\n",
      "[24]\tvalidation_0-auc:0.87059\tvalidation_1-auc:0.84178\n",
      "[25]\tvalidation_0-auc:0.87106\tvalidation_1-auc:0.84162\n",
      "[26]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.84140\n",
      "[27]\tvalidation_0-auc:0.87212\tvalidation_1-auc:0.84114\n",
      "[28]\tvalidation_0-auc:0.87236\tvalidation_1-auc:0.84147\n",
      "[29]\tvalidation_0-auc:0.87257\tvalidation_1-auc:0.84161\n",
      "[30]\tvalidation_0-auc:0.87357\tvalidation_1-auc:0.84081\n",
      "[31]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.84122\n",
      "[32]\tvalidation_0-auc:0.87560\tvalidation_1-auc:0.84084\n",
      "[33]\tvalidation_0-auc:0.87577\tvalidation_1-auc:0.84113\n",
      "[34]\tvalidation_0-auc:0.87590\tvalidation_1-auc:0.84100\n",
      "[35]\tvalidation_0-auc:0.87603\tvalidation_1-auc:0.84058\n",
      "[36]\tvalidation_0-auc:0.87690\tvalidation_1-auc:0.84037\n",
      "[37]\tvalidation_0-auc:0.87733\tvalidation_1-auc:0.84059\n",
      "[38]\tvalidation_0-auc:0.87767\tvalidation_1-auc:0.84028\n",
      "[39]\tvalidation_0-auc:0.87773\tvalidation_1-auc:0.84032\n",
      "[40]\tvalidation_0-auc:0.87792\tvalidation_1-auc:0.84032\n",
      "[41]\tvalidation_0-auc:0.87848\tvalidation_1-auc:0.84072\n",
      "[42]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.84087\n",
      "[43]\tvalidation_0-auc:0.87908\tvalidation_1-auc:0.84042\n",
      "[44]\tvalidation_0-auc:0.87973\tvalidation_1-auc:0.83991\n",
      "[45]\tvalidation_0-auc:0.88060\tvalidation_1-auc:0.84018\n",
      "[46]\tvalidation_0-auc:0.88063\tvalidation_1-auc:0.84023\n",
      "[47]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.84013\n",
      "[48]\tvalidation_0-auc:0.88231\tvalidation_1-auc:0.83974\n",
      "[17:12:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71320\tvalidation_1-auc:0.71915\n",
      "[1]\tvalidation_0-auc:0.75018\tvalidation_1-auc:0.75280\n",
      "[2]\tvalidation_0-auc:0.81871\tvalidation_1-auc:0.81855\n",
      "[3]\tvalidation_0-auc:0.83136\tvalidation_1-auc:0.83192\n",
      "[4]\tvalidation_0-auc:0.83841\tvalidation_1-auc:0.83588\n",
      "[5]\tvalidation_0-auc:0.84223\tvalidation_1-auc:0.83728\n",
      "[6]\tvalidation_0-auc:0.83973\tvalidation_1-auc:0.83308\n",
      "[7]\tvalidation_0-auc:0.84501\tvalidation_1-auc:0.83648\n",
      "[8]\tvalidation_0-auc:0.84521\tvalidation_1-auc:0.83227\n",
      "[9]\tvalidation_0-auc:0.84470\tvalidation_1-auc:0.83409\n",
      "[10]\tvalidation_0-auc:0.85034\tvalidation_1-auc:0.83622\n",
      "[11]\tvalidation_0-auc:0.85470\tvalidation_1-auc:0.83950\n",
      "[12]\tvalidation_0-auc:0.85686\tvalidation_1-auc:0.84026\n",
      "[13]\tvalidation_0-auc:0.85792\tvalidation_1-auc:0.83973\n",
      "[14]\tvalidation_0-auc:0.85974\tvalidation_1-auc:0.84122\n",
      "[15]\tvalidation_0-auc:0.86059\tvalidation_1-auc:0.84137\n",
      "[16]\tvalidation_0-auc:0.86180\tvalidation_1-auc:0.84189\n",
      "[17]\tvalidation_0-auc:0.86315\tvalidation_1-auc:0.84157\n",
      "[18]\tvalidation_0-auc:0.86374\tvalidation_1-auc:0.84080\n",
      "[19]\tvalidation_0-auc:0.86419\tvalidation_1-auc:0.84106\n",
      "[20]\tvalidation_0-auc:0.86503\tvalidation_1-auc:0.84112\n",
      "[21]\tvalidation_0-auc:0.86685\tvalidation_1-auc:0.84120\n",
      "[22]\tvalidation_0-auc:0.86828\tvalidation_1-auc:0.84144\n",
      "[23]\tvalidation_0-auc:0.86871\tvalidation_1-auc:0.84124\n",
      "[24]\tvalidation_0-auc:0.86926\tvalidation_1-auc:0.84136\n",
      "[25]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.84145\n",
      "[26]\tvalidation_0-auc:0.87012\tvalidation_1-auc:0.84080\n",
      "[27]\tvalidation_0-auc:0.87104\tvalidation_1-auc:0.84049\n",
      "[28]\tvalidation_0-auc:0.87128\tvalidation_1-auc:0.84035\n",
      "[29]\tvalidation_0-auc:0.87177\tvalidation_1-auc:0.84039\n",
      "[30]\tvalidation_0-auc:0.87234\tvalidation_1-auc:0.84030\n",
      "[31]\tvalidation_0-auc:0.87249\tvalidation_1-auc:0.84005\n",
      "[32]\tvalidation_0-auc:0.87271\tvalidation_1-auc:0.83961\n",
      "[33]\tvalidation_0-auc:0.87289\tvalidation_1-auc:0.83951\n",
      "[34]\tvalidation_0-auc:0.87331\tvalidation_1-auc:0.83890\n",
      "[35]\tvalidation_0-auc:0.87370\tvalidation_1-auc:0.83866\n",
      "[36]\tvalidation_0-auc:0.87404\tvalidation_1-auc:0.83849\n",
      "[37]\tvalidation_0-auc:0.87426\tvalidation_1-auc:0.83883\n",
      "[38]\tvalidation_0-auc:0.87472\tvalidation_1-auc:0.83804\n",
      "[39]\tvalidation_0-auc:0.87484\tvalidation_1-auc:0.83810\n",
      "[40]\tvalidation_0-auc:0.87504\tvalidation_1-auc:0.83817\n",
      "[41]\tvalidation_0-auc:0.87516\tvalidation_1-auc:0.83794\n",
      "[42]\tvalidation_0-auc:0.87580\tvalidation_1-auc:0.83816\n",
      "[43]\tvalidation_0-auc:0.87598\tvalidation_1-auc:0.83789\n",
      "[44]\tvalidation_0-auc:0.87638\tvalidation_1-auc:0.83786\n",
      "[45]\tvalidation_0-auc:0.87661\tvalidation_1-auc:0.83781\n",
      "[17:12:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73616\tvalidation_1-auc:0.73830\n",
      "[1]\tvalidation_0-auc:0.75504\tvalidation_1-auc:0.75641\n",
      "[2]\tvalidation_0-auc:0.82175\tvalidation_1-auc:0.81927\n",
      "[3]\tvalidation_0-auc:0.83236\tvalidation_1-auc:0.82923\n",
      "[4]\tvalidation_0-auc:0.83724\tvalidation_1-auc:0.83086\n",
      "[5]\tvalidation_0-auc:0.83960\tvalidation_1-auc:0.83207\n",
      "[6]\tvalidation_0-auc:0.84066\tvalidation_1-auc:0.83049\n",
      "[7]\tvalidation_0-auc:0.84775\tvalidation_1-auc:0.83539\n",
      "[8]\tvalidation_0-auc:0.84788\tvalidation_1-auc:0.83450\n",
      "[9]\tvalidation_0-auc:0.84749\tvalidation_1-auc:0.83418\n",
      "[10]\tvalidation_0-auc:0.85433\tvalidation_1-auc:0.83893\n",
      "[11]\tvalidation_0-auc:0.85801\tvalidation_1-auc:0.84156\n",
      "[12]\tvalidation_0-auc:0.86037\tvalidation_1-auc:0.84171\n",
      "[13]\tvalidation_0-auc:0.86062\tvalidation_1-auc:0.84191\n",
      "[14]\tvalidation_0-auc:0.86175\tvalidation_1-auc:0.84225\n",
      "[15]\tvalidation_0-auc:0.86308\tvalidation_1-auc:0.84276\n",
      "[16]\tvalidation_0-auc:0.86425\tvalidation_1-auc:0.84285\n",
      "[17]\tvalidation_0-auc:0.86536\tvalidation_1-auc:0.84272\n",
      "[18]\tvalidation_0-auc:0.86634\tvalidation_1-auc:0.84215\n",
      "[19]\tvalidation_0-auc:0.86722\tvalidation_1-auc:0.84220\n",
      "[20]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.84257\n",
      "[21]\tvalidation_0-auc:0.86868\tvalidation_1-auc:0.84190\n",
      "[22]\tvalidation_0-auc:0.87026\tvalidation_1-auc:0.84164\n",
      "[23]\tvalidation_0-auc:0.87072\tvalidation_1-auc:0.84167\n",
      "[24]\tvalidation_0-auc:0.87105\tvalidation_1-auc:0.84176\n",
      "[25]\tvalidation_0-auc:0.87201\tvalidation_1-auc:0.84179\n",
      "[26]\tvalidation_0-auc:0.87250\tvalidation_1-auc:0.84233\n",
      "[27]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.84238\n",
      "[28]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.84168\n",
      "[29]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.84200\n",
      "[30]\tvalidation_0-auc:0.87455\tvalidation_1-auc:0.84120\n",
      "[31]\tvalidation_0-auc:0.87477\tvalidation_1-auc:0.84125\n",
      "[32]\tvalidation_0-auc:0.87552\tvalidation_1-auc:0.84094\n",
      "[33]\tvalidation_0-auc:0.87569\tvalidation_1-auc:0.84094\n",
      "[34]\tvalidation_0-auc:0.87588\tvalidation_1-auc:0.84057\n",
      "[35]\tvalidation_0-auc:0.87629\tvalidation_1-auc:0.84086\n",
      "[36]\tvalidation_0-auc:0.87636\tvalidation_1-auc:0.84064\n",
      "[37]\tvalidation_0-auc:0.87653\tvalidation_1-auc:0.84090\n",
      "[38]\tvalidation_0-auc:0.87699\tvalidation_1-auc:0.84034\n",
      "[39]\tvalidation_0-auc:0.87775\tvalidation_1-auc:0.84091\n",
      "[40]\tvalidation_0-auc:0.87817\tvalidation_1-auc:0.84110\n",
      "[41]\tvalidation_0-auc:0.87847\tvalidation_1-auc:0.84069\n",
      "[42]\tvalidation_0-auc:0.87953\tvalidation_1-auc:0.84111\n",
      "[43]\tvalidation_0-auc:0.87968\tvalidation_1-auc:0.84108\n",
      "[44]\tvalidation_0-auc:0.88002\tvalidation_1-auc:0.84109\n",
      "[45]\tvalidation_0-auc:0.88115\tvalidation_1-auc:0.84091\n",
      "[17:13:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72973\tvalidation_1-auc:0.73220\n",
      "[1]\tvalidation_0-auc:0.76013\tvalidation_1-auc:0.76419\n",
      "[2]\tvalidation_0-auc:0.82707\tvalidation_1-auc:0.82178\n",
      "[3]\tvalidation_0-auc:0.84181\tvalidation_1-auc:0.82914\n",
      "[4]\tvalidation_0-auc:0.84788\tvalidation_1-auc:0.83344\n",
      "[5]\tvalidation_0-auc:0.85521\tvalidation_1-auc:0.83573\n",
      "[6]\tvalidation_0-auc:0.85498\tvalidation_1-auc:0.83155\n",
      "[7]\tvalidation_0-auc:0.86250\tvalidation_1-auc:0.83774\n",
      "[8]\tvalidation_0-auc:0.86256\tvalidation_1-auc:0.83304\n",
      "[9]\tvalidation_0-auc:0.86311\tvalidation_1-auc:0.83044\n",
      "[10]\tvalidation_0-auc:0.86964\tvalidation_1-auc:0.83325\n",
      "[11]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.83511\n",
      "[12]\tvalidation_0-auc:0.88020\tvalidation_1-auc:0.83539\n",
      "[13]\tvalidation_0-auc:0.88207\tvalidation_1-auc:0.83630\n",
      "[14]\tvalidation_0-auc:0.88399\tvalidation_1-auc:0.83709\n",
      "[15]\tvalidation_0-auc:0.88596\tvalidation_1-auc:0.83987\n",
      "[16]\tvalidation_0-auc:0.88787\tvalidation_1-auc:0.83978\n",
      "[17]\tvalidation_0-auc:0.89005\tvalidation_1-auc:0.83876\n",
      "[18]\tvalidation_0-auc:0.89067\tvalidation_1-auc:0.83809\n",
      "[19]\tvalidation_0-auc:0.89128\tvalidation_1-auc:0.83860\n",
      "[20]\tvalidation_0-auc:0.89210\tvalidation_1-auc:0.83849\n",
      "[21]\tvalidation_0-auc:0.89326\tvalidation_1-auc:0.83746\n",
      "[22]\tvalidation_0-auc:0.89476\tvalidation_1-auc:0.83741\n",
      "[23]\tvalidation_0-auc:0.89544\tvalidation_1-auc:0.83698\n",
      "[24]\tvalidation_0-auc:0.89599\tvalidation_1-auc:0.83683\n",
      "[25]\tvalidation_0-auc:0.89630\tvalidation_1-auc:0.83678\n",
      "[26]\tvalidation_0-auc:0.89657\tvalidation_1-auc:0.83646\n",
      "[27]\tvalidation_0-auc:0.89707\tvalidation_1-auc:0.83610\n",
      "[28]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.83593\n",
      "[29]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83540\n",
      "[30]\tvalidation_0-auc:0.89843\tvalidation_1-auc:0.83538\n",
      "[31]\tvalidation_0-auc:0.89880\tvalidation_1-auc:0.83523\n",
      "[32]\tvalidation_0-auc:0.89906\tvalidation_1-auc:0.83545\n",
      "[33]\tvalidation_0-auc:0.89948\tvalidation_1-auc:0.83551\n",
      "[34]\tvalidation_0-auc:0.89972\tvalidation_1-auc:0.83559\n",
      "[35]\tvalidation_0-auc:0.90109\tvalidation_1-auc:0.83611\n",
      "[36]\tvalidation_0-auc:0.90141\tvalidation_1-auc:0.83632\n",
      "[37]\tvalidation_0-auc:0.90173\tvalidation_1-auc:0.83579\n",
      "[38]\tvalidation_0-auc:0.90232\tvalidation_1-auc:0.83661\n",
      "[39]\tvalidation_0-auc:0.90251\tvalidation_1-auc:0.83645\n",
      "[40]\tvalidation_0-auc:0.90261\tvalidation_1-auc:0.83610\n",
      "[41]\tvalidation_0-auc:0.90275\tvalidation_1-auc:0.83599\n",
      "[42]\tvalidation_0-auc:0.90360\tvalidation_1-auc:0.83610\n",
      "[43]\tvalidation_0-auc:0.90365\tvalidation_1-auc:0.83602\n",
      "[44]\tvalidation_0-auc:0.90496\tvalidation_1-auc:0.83658\n",
      "[45]\tvalidation_0-auc:0.90509\tvalidation_1-auc:0.83670\n",
      "[17:13:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74104\tvalidation_1-auc:0.74600\n",
      "[1]\tvalidation_0-auc:0.76544\tvalidation_1-auc:0.76334\n",
      "[2]\tvalidation_0-auc:0.82987\tvalidation_1-auc:0.81857\n",
      "[3]\tvalidation_0-auc:0.84477\tvalidation_1-auc:0.82939\n",
      "[4]\tvalidation_0-auc:0.85159\tvalidation_1-auc:0.83308\n",
      "[5]\tvalidation_0-auc:0.85726\tvalidation_1-auc:0.83428\n",
      "[6]\tvalidation_0-auc:0.85667\tvalidation_1-auc:0.83288\n",
      "[7]\tvalidation_0-auc:0.86241\tvalidation_1-auc:0.83567\n",
      "[8]\tvalidation_0-auc:0.86352\tvalidation_1-auc:0.83336\n",
      "[9]\tvalidation_0-auc:0.86436\tvalidation_1-auc:0.83220\n",
      "[10]\tvalidation_0-auc:0.87167\tvalidation_1-auc:0.83402\n",
      "[11]\tvalidation_0-auc:0.87632\tvalidation_1-auc:0.83762\n",
      "[12]\tvalidation_0-auc:0.88064\tvalidation_1-auc:0.83906\n",
      "[13]\tvalidation_0-auc:0.88169\tvalidation_1-auc:0.83732\n",
      "[14]\tvalidation_0-auc:0.88459\tvalidation_1-auc:0.83886\n",
      "[15]\tvalidation_0-auc:0.88697\tvalidation_1-auc:0.84044\n",
      "[16]\tvalidation_0-auc:0.88909\tvalidation_1-auc:0.83908\n",
      "[17]\tvalidation_0-auc:0.89041\tvalidation_1-auc:0.83960\n",
      "[18]\tvalidation_0-auc:0.89198\tvalidation_1-auc:0.83873\n",
      "[19]\tvalidation_0-auc:0.89301\tvalidation_1-auc:0.83857\n",
      "[20]\tvalidation_0-auc:0.89382\tvalidation_1-auc:0.83897\n",
      "[21]\tvalidation_0-auc:0.89456\tvalidation_1-auc:0.83845\n",
      "[22]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.83820\n",
      "[23]\tvalidation_0-auc:0.89607\tvalidation_1-auc:0.83817\n",
      "[24]\tvalidation_0-auc:0.89736\tvalidation_1-auc:0.83843\n",
      "[25]\tvalidation_0-auc:0.89746\tvalidation_1-auc:0.83833\n",
      "[26]\tvalidation_0-auc:0.89819\tvalidation_1-auc:0.83835\n",
      "[27]\tvalidation_0-auc:0.89867\tvalidation_1-auc:0.83840\n",
      "[28]\tvalidation_0-auc:0.90011\tvalidation_1-auc:0.83807\n",
      "[29]\tvalidation_0-auc:0.90041\tvalidation_1-auc:0.83813\n",
      "[30]\tvalidation_0-auc:0.90057\tvalidation_1-auc:0.83771\n",
      "[31]\tvalidation_0-auc:0.90072\tvalidation_1-auc:0.83744\n",
      "[32]\tvalidation_0-auc:0.90243\tvalidation_1-auc:0.83677\n",
      "[33]\tvalidation_0-auc:0.90273\tvalidation_1-auc:0.83725\n",
      "[34]\tvalidation_0-auc:0.90284\tvalidation_1-auc:0.83733\n",
      "[35]\tvalidation_0-auc:0.90297\tvalidation_1-auc:0.83707\n",
      "[36]\tvalidation_0-auc:0.90399\tvalidation_1-auc:0.83652\n",
      "[37]\tvalidation_0-auc:0.90476\tvalidation_1-auc:0.83568\n",
      "[38]\tvalidation_0-auc:0.90610\tvalidation_1-auc:0.83518\n",
      "[39]\tvalidation_0-auc:0.90726\tvalidation_1-auc:0.83497\n",
      "[40]\tvalidation_0-auc:0.90793\tvalidation_1-auc:0.83460\n",
      "[41]\tvalidation_0-auc:0.90927\tvalidation_1-auc:0.83414\n",
      "[42]\tvalidation_0-auc:0.90929\tvalidation_1-auc:0.83406\n",
      "[43]\tvalidation_0-auc:0.90936\tvalidation_1-auc:0.83412\n",
      "[44]\tvalidation_0-auc:0.90964\tvalidation_1-auc:0.83405\n",
      "[45]\tvalidation_0-auc:0.91097\tvalidation_1-auc:0.83403\n",
      "[17:14:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74195\tvalidation_1-auc:0.74456\n",
      "[1]\tvalidation_0-auc:0.76631\tvalidation_1-auc:0.76284\n",
      "[2]\tvalidation_0-auc:0.82672\tvalidation_1-auc:0.81869\n",
      "[3]\tvalidation_0-auc:0.84185\tvalidation_1-auc:0.83176\n",
      "[4]\tvalidation_0-auc:0.84993\tvalidation_1-auc:0.83539\n",
      "[5]\tvalidation_0-auc:0.85696\tvalidation_1-auc:0.83808\n",
      "[6]\tvalidation_0-auc:0.85590\tvalidation_1-auc:0.83441\n",
      "[7]\tvalidation_0-auc:0.86126\tvalidation_1-auc:0.83485\n",
      "[8]\tvalidation_0-auc:0.86307\tvalidation_1-auc:0.83323\n",
      "[9]\tvalidation_0-auc:0.86356\tvalidation_1-auc:0.82983\n",
      "[10]\tvalidation_0-auc:0.87121\tvalidation_1-auc:0.83425\n",
      "[11]\tvalidation_0-auc:0.87811\tvalidation_1-auc:0.83728\n",
      "[12]\tvalidation_0-auc:0.88179\tvalidation_1-auc:0.83985\n",
      "[13]\tvalidation_0-auc:0.88268\tvalidation_1-auc:0.83856\n",
      "[14]\tvalidation_0-auc:0.88704\tvalidation_1-auc:0.83922\n",
      "[15]\tvalidation_0-auc:0.88846\tvalidation_1-auc:0.83907\n",
      "[16]\tvalidation_0-auc:0.88967\tvalidation_1-auc:0.83954\n",
      "[17]\tvalidation_0-auc:0.89067\tvalidation_1-auc:0.84009\n",
      "[18]\tvalidation_0-auc:0.89261\tvalidation_1-auc:0.83956\n",
      "[19]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.84063\n",
      "[20]\tvalidation_0-auc:0.89446\tvalidation_1-auc:0.84019\n",
      "[21]\tvalidation_0-auc:0.89650\tvalidation_1-auc:0.83989\n",
      "[22]\tvalidation_0-auc:0.89675\tvalidation_1-auc:0.83940\n",
      "[23]\tvalidation_0-auc:0.89784\tvalidation_1-auc:0.83892\n",
      "[24]\tvalidation_0-auc:0.89821\tvalidation_1-auc:0.83916\n",
      "[25]\tvalidation_0-auc:0.89839\tvalidation_1-auc:0.83900\n",
      "[26]\tvalidation_0-auc:0.89860\tvalidation_1-auc:0.83864\n",
      "[27]\tvalidation_0-auc:0.89877\tvalidation_1-auc:0.83830\n",
      "[28]\tvalidation_0-auc:0.90068\tvalidation_1-auc:0.83677\n",
      "[29]\tvalidation_0-auc:0.90080\tvalidation_1-auc:0.83718\n",
      "[30]\tvalidation_0-auc:0.90115\tvalidation_1-auc:0.83705\n",
      "[31]\tvalidation_0-auc:0.90149\tvalidation_1-auc:0.83702\n",
      "[32]\tvalidation_0-auc:0.90289\tvalidation_1-auc:0.83636\n",
      "[33]\tvalidation_0-auc:0.90306\tvalidation_1-auc:0.83660\n",
      "[34]\tvalidation_0-auc:0.90369\tvalidation_1-auc:0.83631\n",
      "[35]\tvalidation_0-auc:0.90428\tvalidation_1-auc:0.83563\n",
      "[36]\tvalidation_0-auc:0.90535\tvalidation_1-auc:0.83579\n",
      "[37]\tvalidation_0-auc:0.90543\tvalidation_1-auc:0.83582\n",
      "[38]\tvalidation_0-auc:0.90550\tvalidation_1-auc:0.83595\n",
      "[39]\tvalidation_0-auc:0.90575\tvalidation_1-auc:0.83585\n",
      "[40]\tvalidation_0-auc:0.90582\tvalidation_1-auc:0.83532\n",
      "[41]\tvalidation_0-auc:0.90651\tvalidation_1-auc:0.83530\n",
      "[42]\tvalidation_0-auc:0.90668\tvalidation_1-auc:0.83535\n",
      "[43]\tvalidation_0-auc:0.90745\tvalidation_1-auc:0.83452\n",
      "[44]\tvalidation_0-auc:0.90891\tvalidation_1-auc:0.83405\n",
      "[45]\tvalidation_0-auc:0.90914\tvalidation_1-auc:0.83382\n",
      "[46]\tvalidation_0-auc:0.90914\tvalidation_1-auc:0.83358\n",
      "[47]\tvalidation_0-auc:0.90920\tvalidation_1-auc:0.83392\n",
      "[48]\tvalidation_0-auc:0.90937\tvalidation_1-auc:0.83392\n",
      "[17:14:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71778\tvalidation_1-auc:0.72229\n",
      "[1]\tvalidation_0-auc:0.75524\tvalidation_1-auc:0.75307\n",
      "[2]\tvalidation_0-auc:0.82371\tvalidation_1-auc:0.81479\n",
      "[3]\tvalidation_0-auc:0.84130\tvalidation_1-auc:0.83163\n",
      "[4]\tvalidation_0-auc:0.84832\tvalidation_1-auc:0.83518\n",
      "[5]\tvalidation_0-auc:0.85433\tvalidation_1-auc:0.83590\n",
      "[6]\tvalidation_0-auc:0.85460\tvalidation_1-auc:0.83157\n",
      "[7]\tvalidation_0-auc:0.86139\tvalidation_1-auc:0.83345\n",
      "[8]\tvalidation_0-auc:0.86170\tvalidation_1-auc:0.83162\n",
      "[9]\tvalidation_0-auc:0.86381\tvalidation_1-auc:0.83060\n",
      "[10]\tvalidation_0-auc:0.87181\tvalidation_1-auc:0.83591\n",
      "[11]\tvalidation_0-auc:0.87520\tvalidation_1-auc:0.83784\n",
      "[12]\tvalidation_0-auc:0.87947\tvalidation_1-auc:0.84031\n",
      "[13]\tvalidation_0-auc:0.88064\tvalidation_1-auc:0.84043\n",
      "[14]\tvalidation_0-auc:0.88363\tvalidation_1-auc:0.84275\n",
      "[15]\tvalidation_0-auc:0.88554\tvalidation_1-auc:0.84339\n",
      "[16]\tvalidation_0-auc:0.88691\tvalidation_1-auc:0.84315\n",
      "[17]\tvalidation_0-auc:0.88806\tvalidation_1-auc:0.84250\n",
      "[18]\tvalidation_0-auc:0.88954\tvalidation_1-auc:0.84205\n",
      "[19]\tvalidation_0-auc:0.89078\tvalidation_1-auc:0.84231\n",
      "[20]\tvalidation_0-auc:0.89129\tvalidation_1-auc:0.84230\n",
      "[21]\tvalidation_0-auc:0.89280\tvalidation_1-auc:0.84179\n",
      "[22]\tvalidation_0-auc:0.89349\tvalidation_1-auc:0.84091\n",
      "[23]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.84047\n",
      "[24]\tvalidation_0-auc:0.89487\tvalidation_1-auc:0.83988\n",
      "[25]\tvalidation_0-auc:0.89551\tvalidation_1-auc:0.83918\n",
      "[26]\tvalidation_0-auc:0.89594\tvalidation_1-auc:0.83887\n",
      "[27]\tvalidation_0-auc:0.89594\tvalidation_1-auc:0.83915\n",
      "[28]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.83930\n",
      "[29]\tvalidation_0-auc:0.89750\tvalidation_1-auc:0.83933\n",
      "[30]\tvalidation_0-auc:0.89792\tvalidation_1-auc:0.83945\n",
      "[31]\tvalidation_0-auc:0.89789\tvalidation_1-auc:0.83946\n",
      "[32]\tvalidation_0-auc:0.89859\tvalidation_1-auc:0.83946\n",
      "[33]\tvalidation_0-auc:0.89883\tvalidation_1-auc:0.83897\n",
      "[34]\tvalidation_0-auc:0.90039\tvalidation_1-auc:0.83866\n",
      "[35]\tvalidation_0-auc:0.90115\tvalidation_1-auc:0.83872\n",
      "[36]\tvalidation_0-auc:0.90131\tvalidation_1-auc:0.83882\n",
      "[37]\tvalidation_0-auc:0.90170\tvalidation_1-auc:0.83851\n",
      "[38]\tvalidation_0-auc:0.90184\tvalidation_1-auc:0.83852\n",
      "[39]\tvalidation_0-auc:0.90252\tvalidation_1-auc:0.83894\n",
      "[40]\tvalidation_0-auc:0.90250\tvalidation_1-auc:0.83876\n",
      "[41]\tvalidation_0-auc:0.90246\tvalidation_1-auc:0.83867\n",
      "[42]\tvalidation_0-auc:0.90276\tvalidation_1-auc:0.83834\n",
      "[43]\tvalidation_0-auc:0.90412\tvalidation_1-auc:0.83829\n",
      "[44]\tvalidation_0-auc:0.90517\tvalidation_1-auc:0.83801\n",
      "[45]\tvalidation_0-auc:0.90637\tvalidation_1-auc:0.83805\n",
      "[17:15:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74170\tvalidation_1-auc:0.74442\n",
      "[1]\tvalidation_0-auc:0.76011\tvalidation_1-auc:0.75858\n",
      "[2]\tvalidation_0-auc:0.82732\tvalidation_1-auc:0.81876\n",
      "[3]\tvalidation_0-auc:0.84427\tvalidation_1-auc:0.82935\n",
      "[4]\tvalidation_0-auc:0.85214\tvalidation_1-auc:0.83060\n",
      "[5]\tvalidation_0-auc:0.85657\tvalidation_1-auc:0.83556\n",
      "[6]\tvalidation_0-auc:0.85909\tvalidation_1-auc:0.83134\n",
      "[7]\tvalidation_0-auc:0.86606\tvalidation_1-auc:0.83541\n",
      "[8]\tvalidation_0-auc:0.86594\tvalidation_1-auc:0.83546\n",
      "[9]\tvalidation_0-auc:0.86673\tvalidation_1-auc:0.83266\n",
      "[10]\tvalidation_0-auc:0.87376\tvalidation_1-auc:0.83560\n",
      "[11]\tvalidation_0-auc:0.87956\tvalidation_1-auc:0.83815\n",
      "[12]\tvalidation_0-auc:0.88196\tvalidation_1-auc:0.83886\n",
      "[13]\tvalidation_0-auc:0.88254\tvalidation_1-auc:0.83827\n",
      "[14]\tvalidation_0-auc:0.88466\tvalidation_1-auc:0.83830\n",
      "[15]\tvalidation_0-auc:0.88740\tvalidation_1-auc:0.83917\n",
      "[16]\tvalidation_0-auc:0.88920\tvalidation_1-auc:0.83824\n",
      "[17]\tvalidation_0-auc:0.89106\tvalidation_1-auc:0.83841\n",
      "[18]\tvalidation_0-auc:0.89311\tvalidation_1-auc:0.83897\n",
      "[19]\tvalidation_0-auc:0.89392\tvalidation_1-auc:0.83922\n",
      "[20]\tvalidation_0-auc:0.89484\tvalidation_1-auc:0.83908\n",
      "[21]\tvalidation_0-auc:0.89577\tvalidation_1-auc:0.83940\n",
      "[22]\tvalidation_0-auc:0.89697\tvalidation_1-auc:0.83875\n",
      "[23]\tvalidation_0-auc:0.89748\tvalidation_1-auc:0.83832\n",
      "[24]\tvalidation_0-auc:0.89773\tvalidation_1-auc:0.83822\n",
      "[25]\tvalidation_0-auc:0.89833\tvalidation_1-auc:0.83786\n",
      "[26]\tvalidation_0-auc:0.90031\tvalidation_1-auc:0.83677\n",
      "[27]\tvalidation_0-auc:0.90088\tvalidation_1-auc:0.83669\n",
      "[28]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83673\n",
      "[29]\tvalidation_0-auc:0.90140\tvalidation_1-auc:0.83683\n",
      "[30]\tvalidation_0-auc:0.90238\tvalidation_1-auc:0.83628\n",
      "[31]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.83464\n",
      "[32]\tvalidation_0-auc:0.90340\tvalidation_1-auc:0.83454\n",
      "[33]\tvalidation_0-auc:0.90376\tvalidation_1-auc:0.83447\n",
      "[34]\tvalidation_0-auc:0.90388\tvalidation_1-auc:0.83448\n",
      "[35]\tvalidation_0-auc:0.90583\tvalidation_1-auc:0.83389\n",
      "[36]\tvalidation_0-auc:0.90702\tvalidation_1-auc:0.83291\n",
      "[37]\tvalidation_0-auc:0.90717\tvalidation_1-auc:0.83266\n",
      "[38]\tvalidation_0-auc:0.90729\tvalidation_1-auc:0.83266\n",
      "[39]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.83236\n",
      "[40]\tvalidation_0-auc:0.90853\tvalidation_1-auc:0.83181\n",
      "[41]\tvalidation_0-auc:0.90878\tvalidation_1-auc:0.83203\n",
      "[42]\tvalidation_0-auc:0.90906\tvalidation_1-auc:0.83204\n",
      "[43]\tvalidation_0-auc:0.90912\tvalidation_1-auc:0.83183\n",
      "[44]\tvalidation_0-auc:0.91019\tvalidation_1-auc:0.83078\n",
      "[45]\tvalidation_0-auc:0.91100\tvalidation_1-auc:0.83052\n",
      "[46]\tvalidation_0-auc:0.91182\tvalidation_1-auc:0.83034\n",
      "[47]\tvalidation_0-auc:0.91186\tvalidation_1-auc:0.83041\n",
      "[48]\tvalidation_0-auc:0.91331\tvalidation_1-auc:0.83020\n",
      "[49]\tvalidation_0-auc:0.91375\tvalidation_1-auc:0.82970\n",
      "[50]\tvalidation_0-auc:0.91437\tvalidation_1-auc:0.82931\n",
      "[51]\tvalidation_0-auc:0.91446\tvalidation_1-auc:0.82900\n",
      "[17:15:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.72945\tvalidation_1-auc:0.73177\n",
      "[1]\tvalidation_0-auc:0.76304\tvalidation_1-auc:0.76526\n",
      "[2]\tvalidation_0-auc:0.82730\tvalidation_1-auc:0.82171\n",
      "[3]\tvalidation_0-auc:0.84108\tvalidation_1-auc:0.82989\n",
      "[4]\tvalidation_0-auc:0.84852\tvalidation_1-auc:0.83271\n",
      "[5]\tvalidation_0-auc:0.85415\tvalidation_1-auc:0.83413\n",
      "[6]\tvalidation_0-auc:0.85373\tvalidation_1-auc:0.83068\n",
      "[7]\tvalidation_0-auc:0.86106\tvalidation_1-auc:0.83513\n",
      "[8]\tvalidation_0-auc:0.86111\tvalidation_1-auc:0.83102\n",
      "[9]\tvalidation_0-auc:0.86141\tvalidation_1-auc:0.82917\n",
      "[10]\tvalidation_0-auc:0.86689\tvalidation_1-auc:0.83173\n",
      "[11]\tvalidation_0-auc:0.87141\tvalidation_1-auc:0.83439\n",
      "[12]\tvalidation_0-auc:0.87536\tvalidation_1-auc:0.83569\n",
      "[13]\tvalidation_0-auc:0.87602\tvalidation_1-auc:0.83448\n",
      "[14]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.83496\n",
      "[15]\tvalidation_0-auc:0.88033\tvalidation_1-auc:0.83523\n",
      "[16]\tvalidation_0-auc:0.88104\tvalidation_1-auc:0.83546\n",
      "[17]\tvalidation_0-auc:0.88277\tvalidation_1-auc:0.83589\n",
      "[18]\tvalidation_0-auc:0.88396\tvalidation_1-auc:0.83561\n",
      "[19]\tvalidation_0-auc:0.88461\tvalidation_1-auc:0.83569\n",
      "[20]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.83569\n",
      "[21]\tvalidation_0-auc:0.88629\tvalidation_1-auc:0.83483\n",
      "[22]\tvalidation_0-auc:0.88751\tvalidation_1-auc:0.83376\n",
      "[23]\tvalidation_0-auc:0.88801\tvalidation_1-auc:0.83440\n",
      "[24]\tvalidation_0-auc:0.88815\tvalidation_1-auc:0.83444\n",
      "[25]\tvalidation_0-auc:0.88908\tvalidation_1-auc:0.83356\n",
      "[26]\tvalidation_0-auc:0.89075\tvalidation_1-auc:0.83323\n",
      "[27]\tvalidation_0-auc:0.89181\tvalidation_1-auc:0.83360\n",
      "[28]\tvalidation_0-auc:0.89199\tvalidation_1-auc:0.83352\n",
      "[29]\tvalidation_0-auc:0.89271\tvalidation_1-auc:0.83392\n",
      "[30]\tvalidation_0-auc:0.89281\tvalidation_1-auc:0.83394\n",
      "[31]\tvalidation_0-auc:0.89309\tvalidation_1-auc:0.83376\n",
      "[32]\tvalidation_0-auc:0.89344\tvalidation_1-auc:0.83329\n",
      "[33]\tvalidation_0-auc:0.89406\tvalidation_1-auc:0.83420\n",
      "[34]\tvalidation_0-auc:0.89448\tvalidation_1-auc:0.83401\n",
      "[35]\tvalidation_0-auc:0.89542\tvalidation_1-auc:0.83292\n",
      "[36]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.83301\n",
      "[37]\tvalidation_0-auc:0.89562\tvalidation_1-auc:0.83323\n",
      "[38]\tvalidation_0-auc:0.89586\tvalidation_1-auc:0.83305\n",
      "[39]\tvalidation_0-auc:0.89606\tvalidation_1-auc:0.83254\n",
      "[40]\tvalidation_0-auc:0.89645\tvalidation_1-auc:0.83283\n",
      "[41]\tvalidation_0-auc:0.89780\tvalidation_1-auc:0.83242\n",
      "[42]\tvalidation_0-auc:0.89888\tvalidation_1-auc:0.83301\n",
      "[43]\tvalidation_0-auc:0.89897\tvalidation_1-auc:0.83300\n",
      "[44]\tvalidation_0-auc:0.89938\tvalidation_1-auc:0.83281\n",
      "[45]\tvalidation_0-auc:0.89998\tvalidation_1-auc:0.83247\n",
      "[46]\tvalidation_0-auc:0.90033\tvalidation_1-auc:0.83230\n",
      "[47]\tvalidation_0-auc:0.90092\tvalidation_1-auc:0.83190\n",
      "[17:16:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74057\tvalidation_1-auc:0.74544\n",
      "[1]\tvalidation_0-auc:0.76402\tvalidation_1-auc:0.76500\n",
      "[2]\tvalidation_0-auc:0.82889\tvalidation_1-auc:0.81988\n",
      "[3]\tvalidation_0-auc:0.84350\tvalidation_1-auc:0.83065\n",
      "[4]\tvalidation_0-auc:0.85090\tvalidation_1-auc:0.83319\n",
      "[5]\tvalidation_0-auc:0.85518\tvalidation_1-auc:0.83526\n",
      "[6]\tvalidation_0-auc:0.85583\tvalidation_1-auc:0.83434\n",
      "[7]\tvalidation_0-auc:0.86247\tvalidation_1-auc:0.83747\n",
      "[8]\tvalidation_0-auc:0.86197\tvalidation_1-auc:0.83383\n",
      "[9]\tvalidation_0-auc:0.86211\tvalidation_1-auc:0.83283\n",
      "[10]\tvalidation_0-auc:0.86965\tvalidation_1-auc:0.83597\n",
      "[11]\tvalidation_0-auc:0.87282\tvalidation_1-auc:0.83999\n",
      "[12]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.84029\n",
      "[13]\tvalidation_0-auc:0.87526\tvalidation_1-auc:0.84149\n",
      "[14]\tvalidation_0-auc:0.87908\tvalidation_1-auc:0.84180\n",
      "[15]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.84272\n",
      "[16]\tvalidation_0-auc:0.88207\tvalidation_1-auc:0.84283\n",
      "[17]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.84268\n",
      "[18]\tvalidation_0-auc:0.88421\tvalidation_1-auc:0.84230\n",
      "[19]\tvalidation_0-auc:0.88508\tvalidation_1-auc:0.84198\n",
      "[20]\tvalidation_0-auc:0.88572\tvalidation_1-auc:0.84208\n",
      "[21]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.84105\n",
      "[22]\tvalidation_0-auc:0.88914\tvalidation_1-auc:0.84055\n",
      "[23]\tvalidation_0-auc:0.88967\tvalidation_1-auc:0.84066\n",
      "[24]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.84048\n",
      "[25]\tvalidation_0-auc:0.89069\tvalidation_1-auc:0.83985\n",
      "[26]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83979\n",
      "[27]\tvalidation_0-auc:0.89186\tvalidation_1-auc:0.84009\n",
      "[28]\tvalidation_0-auc:0.89214\tvalidation_1-auc:0.83963\n",
      "[29]\tvalidation_0-auc:0.89245\tvalidation_1-auc:0.83971\n",
      "[30]\tvalidation_0-auc:0.89290\tvalidation_1-auc:0.83983\n",
      "[31]\tvalidation_0-auc:0.89298\tvalidation_1-auc:0.83964\n",
      "[32]\tvalidation_0-auc:0.89422\tvalidation_1-auc:0.83994\n",
      "[33]\tvalidation_0-auc:0.89455\tvalidation_1-auc:0.83961\n",
      "[34]\tvalidation_0-auc:0.89476\tvalidation_1-auc:0.83961\n",
      "[35]\tvalidation_0-auc:0.89494\tvalidation_1-auc:0.83957\n",
      "[36]\tvalidation_0-auc:0.89513\tvalidation_1-auc:0.83932\n",
      "[37]\tvalidation_0-auc:0.89673\tvalidation_1-auc:0.83949\n",
      "[38]\tvalidation_0-auc:0.89727\tvalidation_1-auc:0.83938\n",
      "[39]\tvalidation_0-auc:0.89804\tvalidation_1-auc:0.83936\n",
      "[40]\tvalidation_0-auc:0.89822\tvalidation_1-auc:0.83950\n",
      "[41]\tvalidation_0-auc:0.89830\tvalidation_1-auc:0.83969\n",
      "[42]\tvalidation_0-auc:0.90023\tvalidation_1-auc:0.83915\n",
      "[43]\tvalidation_0-auc:0.90041\tvalidation_1-auc:0.83914\n",
      "[44]\tvalidation_0-auc:0.90065\tvalidation_1-auc:0.83928\n",
      "[45]\tvalidation_0-auc:0.90124\tvalidation_1-auc:0.83924\n",
      "[46]\tvalidation_0-auc:0.90185\tvalidation_1-auc:0.83896\n",
      "[17:16:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74282\tvalidation_1-auc:0.74394\n",
      "[1]\tvalidation_0-auc:0.76645\tvalidation_1-auc:0.76136\n",
      "[2]\tvalidation_0-auc:0.82665\tvalidation_1-auc:0.81799\n",
      "[3]\tvalidation_0-auc:0.84195\tvalidation_1-auc:0.83190\n",
      "[4]\tvalidation_0-auc:0.85094\tvalidation_1-auc:0.83532\n",
      "[5]\tvalidation_0-auc:0.85771\tvalidation_1-auc:0.83846\n",
      "[6]\tvalidation_0-auc:0.85693\tvalidation_1-auc:0.83529\n",
      "[7]\tvalidation_0-auc:0.86248\tvalidation_1-auc:0.83545\n",
      "[8]\tvalidation_0-auc:0.86278\tvalidation_1-auc:0.83502\n",
      "[9]\tvalidation_0-auc:0.86160\tvalidation_1-auc:0.83283\n",
      "[10]\tvalidation_0-auc:0.86793\tvalidation_1-auc:0.83697\n",
      "[11]\tvalidation_0-auc:0.87377\tvalidation_1-auc:0.83896\n",
      "[12]\tvalidation_0-auc:0.87686\tvalidation_1-auc:0.83900\n",
      "[13]\tvalidation_0-auc:0.87796\tvalidation_1-auc:0.83697\n",
      "[14]\tvalidation_0-auc:0.88057\tvalidation_1-auc:0.83806\n",
      "[15]\tvalidation_0-auc:0.88176\tvalidation_1-auc:0.83826\n",
      "[16]\tvalidation_0-auc:0.88289\tvalidation_1-auc:0.83905\n",
      "[17]\tvalidation_0-auc:0.88453\tvalidation_1-auc:0.83927\n",
      "[18]\tvalidation_0-auc:0.88541\tvalidation_1-auc:0.83888\n",
      "[19]\tvalidation_0-auc:0.88594\tvalidation_1-auc:0.83864\n",
      "[20]\tvalidation_0-auc:0.88683\tvalidation_1-auc:0.83924\n",
      "[21]\tvalidation_0-auc:0.88766\tvalidation_1-auc:0.83824\n",
      "[22]\tvalidation_0-auc:0.88839\tvalidation_1-auc:0.83792\n",
      "[23]\tvalidation_0-auc:0.88910\tvalidation_1-auc:0.83774\n",
      "[24]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.83762\n",
      "[25]\tvalidation_0-auc:0.88949\tvalidation_1-auc:0.83763\n",
      "[26]\tvalidation_0-auc:0.89071\tvalidation_1-auc:0.83805\n",
      "[27]\tvalidation_0-auc:0.89094\tvalidation_1-auc:0.83778\n",
      "[28]\tvalidation_0-auc:0.89118\tvalidation_1-auc:0.83786\n",
      "[29]\tvalidation_0-auc:0.89209\tvalidation_1-auc:0.83782\n",
      "[30]\tvalidation_0-auc:0.89223\tvalidation_1-auc:0.83776\n",
      "[31]\tvalidation_0-auc:0.89272\tvalidation_1-auc:0.83804\n",
      "[32]\tvalidation_0-auc:0.89279\tvalidation_1-auc:0.83794\n",
      "[33]\tvalidation_0-auc:0.89389\tvalidation_1-auc:0.83753\n",
      "[34]\tvalidation_0-auc:0.89413\tvalidation_1-auc:0.83729\n",
      "[35]\tvalidation_0-auc:0.89471\tvalidation_1-auc:0.83788\n",
      "[36]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.83754\n",
      "[37]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.83739\n",
      "[38]\tvalidation_0-auc:0.89878\tvalidation_1-auc:0.83712\n",
      "[39]\tvalidation_0-auc:0.89923\tvalidation_1-auc:0.83659\n",
      "[40]\tvalidation_0-auc:0.89931\tvalidation_1-auc:0.83604\n",
      "[41]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.83589\n",
      "[42]\tvalidation_0-auc:0.89982\tvalidation_1-auc:0.83542\n",
      "[43]\tvalidation_0-auc:0.90003\tvalidation_1-auc:0.83535\n",
      "[44]\tvalidation_0-auc:0.90039\tvalidation_1-auc:0.83512\n",
      "[45]\tvalidation_0-auc:0.90054\tvalidation_1-auc:0.83504\n",
      "[46]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.83510\n",
      "[17:17:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71812\tvalidation_1-auc:0.72174\n",
      "[1]\tvalidation_0-auc:0.76005\tvalidation_1-auc:0.76007\n",
      "[2]\tvalidation_0-auc:0.82584\tvalidation_1-auc:0.82290\n",
      "[3]\tvalidation_0-auc:0.84063\tvalidation_1-auc:0.83159\n",
      "[4]\tvalidation_0-auc:0.84895\tvalidation_1-auc:0.83541\n",
      "[5]\tvalidation_0-auc:0.85444\tvalidation_1-auc:0.83781\n",
      "[6]\tvalidation_0-auc:0.85416\tvalidation_1-auc:0.83355\n",
      "[7]\tvalidation_0-auc:0.86015\tvalidation_1-auc:0.83557\n",
      "[8]\tvalidation_0-auc:0.85921\tvalidation_1-auc:0.83193\n",
      "[9]\tvalidation_0-auc:0.85994\tvalidation_1-auc:0.83243\n",
      "[10]\tvalidation_0-auc:0.86689\tvalidation_1-auc:0.83784\n",
      "[11]\tvalidation_0-auc:0.87200\tvalidation_1-auc:0.84035\n",
      "[12]\tvalidation_0-auc:0.87423\tvalidation_1-auc:0.84090\n",
      "[13]\tvalidation_0-auc:0.87586\tvalidation_1-auc:0.84065\n",
      "[14]\tvalidation_0-auc:0.87823\tvalidation_1-auc:0.84343\n",
      "[15]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.84383\n",
      "[16]\tvalidation_0-auc:0.88214\tvalidation_1-auc:0.84310\n",
      "[17]\tvalidation_0-auc:0.88341\tvalidation_1-auc:0.84331\n",
      "[18]\tvalidation_0-auc:0.88445\tvalidation_1-auc:0.84349\n",
      "[19]\tvalidation_0-auc:0.88542\tvalidation_1-auc:0.84364\n",
      "[20]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.84296\n",
      "[21]\tvalidation_0-auc:0.88713\tvalidation_1-auc:0.84231\n",
      "[22]\tvalidation_0-auc:0.88858\tvalidation_1-auc:0.84143\n",
      "[23]\tvalidation_0-auc:0.88907\tvalidation_1-auc:0.84098\n",
      "[24]\tvalidation_0-auc:0.88945\tvalidation_1-auc:0.84124\n",
      "[25]\tvalidation_0-auc:0.88964\tvalidation_1-auc:0.84120\n",
      "[26]\tvalidation_0-auc:0.89004\tvalidation_1-auc:0.84132\n",
      "[27]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.84082\n",
      "[28]\tvalidation_0-auc:0.89240\tvalidation_1-auc:0.84079\n",
      "[29]\tvalidation_0-auc:0.89380\tvalidation_1-auc:0.84058\n",
      "[30]\tvalidation_0-auc:0.89392\tvalidation_1-auc:0.84050\n",
      "[31]\tvalidation_0-auc:0.89400\tvalidation_1-auc:0.84040\n",
      "[32]\tvalidation_0-auc:0.89456\tvalidation_1-auc:0.83988\n",
      "[33]\tvalidation_0-auc:0.89465\tvalidation_1-auc:0.83983\n",
      "[34]\tvalidation_0-auc:0.89501\tvalidation_1-auc:0.83977\n",
      "[35]\tvalidation_0-auc:0.89548\tvalidation_1-auc:0.84011\n",
      "[36]\tvalidation_0-auc:0.89675\tvalidation_1-auc:0.84005\n",
      "[37]\tvalidation_0-auc:0.89682\tvalidation_1-auc:0.84032\n",
      "[38]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.84039\n",
      "[39]\tvalidation_0-auc:0.89719\tvalidation_1-auc:0.83979\n",
      "[40]\tvalidation_0-auc:0.89730\tvalidation_1-auc:0.83941\n",
      "[41]\tvalidation_0-auc:0.89742\tvalidation_1-auc:0.83930\n",
      "[42]\tvalidation_0-auc:0.89765\tvalidation_1-auc:0.83901\n",
      "[43]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.83907\n",
      "[44]\tvalidation_0-auc:0.89799\tvalidation_1-auc:0.83891\n",
      "[45]\tvalidation_0-auc:0.89800\tvalidation_1-auc:0.83908\n",
      "[17:17:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.74297\tvalidation_1-auc:0.74279\n",
      "[1]\tvalidation_0-auc:0.77140\tvalidation_1-auc:0.76569\n",
      "[2]\tvalidation_0-auc:0.83169\tvalidation_1-auc:0.82300\n",
      "[3]\tvalidation_0-auc:0.84447\tvalidation_1-auc:0.83181\n",
      "[4]\tvalidation_0-auc:0.85201\tvalidation_1-auc:0.83455\n",
      "[5]\tvalidation_0-auc:0.85741\tvalidation_1-auc:0.83741\n",
      "[6]\tvalidation_0-auc:0.85867\tvalidation_1-auc:0.83407\n",
      "[7]\tvalidation_0-auc:0.86477\tvalidation_1-auc:0.83832\n",
      "[8]\tvalidation_0-auc:0.86415\tvalidation_1-auc:0.83816\n",
      "[9]\tvalidation_0-auc:0.86395\tvalidation_1-auc:0.83557\n",
      "[10]\tvalidation_0-auc:0.87131\tvalidation_1-auc:0.83781\n",
      "[11]\tvalidation_0-auc:0.87518\tvalidation_1-auc:0.83955\n",
      "[12]\tvalidation_0-auc:0.87709\tvalidation_1-auc:0.84039\n",
      "[13]\tvalidation_0-auc:0.87745\tvalidation_1-auc:0.83987\n",
      "[14]\tvalidation_0-auc:0.87958\tvalidation_1-auc:0.83938\n",
      "[15]\tvalidation_0-auc:0.88072\tvalidation_1-auc:0.84020\n",
      "[16]\tvalidation_0-auc:0.88173\tvalidation_1-auc:0.84027\n",
      "[17]\tvalidation_0-auc:0.88262\tvalidation_1-auc:0.84062\n",
      "[18]\tvalidation_0-auc:0.88404\tvalidation_1-auc:0.84010\n",
      "[19]\tvalidation_0-auc:0.88564\tvalidation_1-auc:0.84012\n",
      "[20]\tvalidation_0-auc:0.88668\tvalidation_1-auc:0.84118\n",
      "[21]\tvalidation_0-auc:0.88744\tvalidation_1-auc:0.84123\n",
      "[22]\tvalidation_0-auc:0.88847\tvalidation_1-auc:0.84126\n",
      "[23]\tvalidation_0-auc:0.88887\tvalidation_1-auc:0.84114\n",
      "[24]\tvalidation_0-auc:0.88919\tvalidation_1-auc:0.84067\n",
      "[25]\tvalidation_0-auc:0.89040\tvalidation_1-auc:0.84046\n",
      "[26]\tvalidation_0-auc:0.89102\tvalidation_1-auc:0.84070\n",
      "[27]\tvalidation_0-auc:0.89190\tvalidation_1-auc:0.84066\n",
      "[28]\tvalidation_0-auc:0.89206\tvalidation_1-auc:0.84051\n",
      "[29]\tvalidation_0-auc:0.89338\tvalidation_1-auc:0.83959\n",
      "[30]\tvalidation_0-auc:0.89350\tvalidation_1-auc:0.83969\n",
      "[31]\tvalidation_0-auc:0.89366\tvalidation_1-auc:0.83966\n",
      "[32]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.83944\n",
      "[33]\tvalidation_0-auc:0.89491\tvalidation_1-auc:0.83915\n",
      "[34]\tvalidation_0-auc:0.89568\tvalidation_1-auc:0.83919\n",
      "[35]\tvalidation_0-auc:0.89582\tvalidation_1-auc:0.83909\n",
      "[36]\tvalidation_0-auc:0.89650\tvalidation_1-auc:0.83951\n",
      "[37]\tvalidation_0-auc:0.89786\tvalidation_1-auc:0.83862\n",
      "[38]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83807\n",
      "[39]\tvalidation_0-auc:0.89956\tvalidation_1-auc:0.83785\n",
      "[40]\tvalidation_0-auc:0.89973\tvalidation_1-auc:0.83750\n",
      "[41]\tvalidation_0-auc:0.90028\tvalidation_1-auc:0.83658\n",
      "[42]\tvalidation_0-auc:0.90041\tvalidation_1-auc:0.83650\n",
      "[43]\tvalidation_0-auc:0.90052\tvalidation_1-auc:0.83640\n",
      "[44]\tvalidation_0-auc:0.90098\tvalidation_1-auc:0.83639\n",
      "[45]\tvalidation_0-auc:0.90126\tvalidation_1-auc:0.83633\n",
      "[46]\tvalidation_0-auc:0.90157\tvalidation_1-auc:0.83593\n",
      "[47]\tvalidation_0-auc:0.90198\tvalidation_1-auc:0.83595\n",
      "[48]\tvalidation_0-auc:0.90208\tvalidation_1-auc:0.83580\n",
      "[49]\tvalidation_0-auc:0.90243\tvalidation_1-auc:0.83534\n",
      "[50]\tvalidation_0-auc:0.90285\tvalidation_1-auc:0.83488\n",
      "[51]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.83461\n",
      "[17:18:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73593\tvalidation_1-auc:0.74368\n",
      "[1]\tvalidation_0-auc:0.75297\tvalidation_1-auc:0.75922\n",
      "[2]\tvalidation_0-auc:0.81826\tvalidation_1-auc:0.81836\n",
      "[3]\tvalidation_0-auc:0.83286\tvalidation_1-auc:0.83119\n",
      "[4]\tvalidation_0-auc:0.84075\tvalidation_1-auc:0.83435\n",
      "[5]\tvalidation_0-auc:0.84300\tvalidation_1-auc:0.83595\n",
      "[6]\tvalidation_0-auc:0.84342\tvalidation_1-auc:0.83341\n",
      "[7]\tvalidation_0-auc:0.84862\tvalidation_1-auc:0.83690\n",
      "[8]\tvalidation_0-auc:0.84932\tvalidation_1-auc:0.83488\n",
      "[9]\tvalidation_0-auc:0.84812\tvalidation_1-auc:0.83459\n",
      "[10]\tvalidation_0-auc:0.85473\tvalidation_1-auc:0.83726\n",
      "[11]\tvalidation_0-auc:0.85874\tvalidation_1-auc:0.84140\n",
      "[12]\tvalidation_0-auc:0.86155\tvalidation_1-auc:0.84268\n",
      "[13]\tvalidation_0-auc:0.86282\tvalidation_1-auc:0.84208\n",
      "[14]\tvalidation_0-auc:0.86577\tvalidation_1-auc:0.84310\n",
      "[15]\tvalidation_0-auc:0.86689\tvalidation_1-auc:0.84319\n",
      "[16]\tvalidation_0-auc:0.86877\tvalidation_1-auc:0.84306\n",
      "[17]\tvalidation_0-auc:0.87009\tvalidation_1-auc:0.84299\n",
      "[18]\tvalidation_0-auc:0.87139\tvalidation_1-auc:0.84242\n",
      "[19]\tvalidation_0-auc:0.87253\tvalidation_1-auc:0.84214\n",
      "[20]\tvalidation_0-auc:0.87360\tvalidation_1-auc:0.84176\n",
      "[21]\tvalidation_0-auc:0.87555\tvalidation_1-auc:0.84094\n",
      "[22]\tvalidation_0-auc:0.87752\tvalidation_1-auc:0.84060\n",
      "[23]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.84078\n",
      "[24]\tvalidation_0-auc:0.87845\tvalidation_1-auc:0.84102\n",
      "[25]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.84125\n",
      "[26]\tvalidation_0-auc:0.88009\tvalidation_1-auc:0.84105\n",
      "[27]\tvalidation_0-auc:0.88040\tvalidation_1-auc:0.84118\n",
      "[28]\tvalidation_0-auc:0.88076\tvalidation_1-auc:0.84081\n",
      "[29]\tvalidation_0-auc:0.88138\tvalidation_1-auc:0.84119\n",
      "[30]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.84070\n",
      "[31]\tvalidation_0-auc:0.88365\tvalidation_1-auc:0.84149\n",
      "[32]\tvalidation_0-auc:0.88453\tvalidation_1-auc:0.84075\n",
      "[33]\tvalidation_0-auc:0.88500\tvalidation_1-auc:0.84067\n",
      "[34]\tvalidation_0-auc:0.88557\tvalidation_1-auc:0.84043\n",
      "[35]\tvalidation_0-auc:0.88581\tvalidation_1-auc:0.84033\n",
      "[36]\tvalidation_0-auc:0.88626\tvalidation_1-auc:0.84026\n",
      "[37]\tvalidation_0-auc:0.88704\tvalidation_1-auc:0.84006\n",
      "[38]\tvalidation_0-auc:0.88788\tvalidation_1-auc:0.84008\n",
      "[39]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.84000\n",
      "[40]\tvalidation_0-auc:0.88888\tvalidation_1-auc:0.83994\n",
      "[41]\tvalidation_0-auc:0.88911\tvalidation_1-auc:0.84000\n",
      "[42]\tvalidation_0-auc:0.88993\tvalidation_1-auc:0.84053\n",
      "[43]\tvalidation_0-auc:0.89047\tvalidation_1-auc:0.84073\n",
      "[44]\tvalidation_0-auc:0.89072\tvalidation_1-auc:0.84068\n",
      "GridSearchCV 최적 파라미터: {'colsample_bytree': 0.75, 'max_depth': 5, 'min_child_weight': 1}\n",
      "ROC AUC : 0.8432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators = 100, silent = 1)\n",
    "\n",
    "params = {'max_depth' : [5,7],\n",
    "         'min_child_weight':[1,3],\n",
    "         'colsample_bytree' : [0.5, 0.75]}\n",
    "\n",
    "gridcv = GridSearchCV(xgb_clf, param_grid = params)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric = 'auc',\n",
    "          eval_set = [(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "print('GridSearchCV 최적 파라미터:', gridcv.best_params_)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:,1], average = 'macro')\n",
    "print('ROC AUC : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators = 1000, random_state = 156, learning_rate = 0.2, \n",
    "                        max_depth = 5, min_child_weight = 1, colsample_bytree = 0.75, verbosity=0, reg_alpha = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.74129\tvalidation_1-auc:0.74595\n",
      "[1]\tvalidation_0-auc:0.81350\tvalidation_1-auc:0.81745\n",
      "[2]\tvalidation_0-auc:0.82928\tvalidation_1-auc:0.82637\n",
      "[3]\tvalidation_0-auc:0.83481\tvalidation_1-auc:0.82899\n",
      "[4]\tvalidation_0-auc:0.83746\tvalidation_1-auc:0.82919\n",
      "[5]\tvalidation_0-auc:0.83851\tvalidation_1-auc:0.82998\n",
      "[6]\tvalidation_0-auc:0.84282\tvalidation_1-auc:0.83262\n",
      "[7]\tvalidation_0-auc:0.84291\tvalidation_1-auc:0.83416\n",
      "[8]\tvalidation_0-auc:0.84503\tvalidation_1-auc:0.83530\n",
      "[9]\tvalidation_0-auc:0.84751\tvalidation_1-auc:0.83785\n",
      "[10]\tvalidation_0-auc:0.84872\tvalidation_1-auc:0.83830\n",
      "[11]\tvalidation_0-auc:0.85021\tvalidation_1-auc:0.83907\n",
      "[12]\tvalidation_0-auc:0.85160\tvalidation_1-auc:0.84062\n",
      "[13]\tvalidation_0-auc:0.85352\tvalidation_1-auc:0.84110\n",
      "[14]\tvalidation_0-auc:0.85458\tvalidation_1-auc:0.84245\n",
      "[15]\tvalidation_0-auc:0.85594\tvalidation_1-auc:0.84277\n",
      "[16]\tvalidation_0-auc:0.85852\tvalidation_1-auc:0.84304\n",
      "[17]\tvalidation_0-auc:0.85954\tvalidation_1-auc:0.84402\n",
      "[18]\tvalidation_0-auc:0.86116\tvalidation_1-auc:0.84442\n",
      "[19]\tvalidation_0-auc:0.86235\tvalidation_1-auc:0.84464\n",
      "[20]\tvalidation_0-auc:0.86336\tvalidation_1-auc:0.84454\n",
      "[21]\tvalidation_0-auc:0.86546\tvalidation_1-auc:0.84438\n",
      "[22]\tvalidation_0-auc:0.86611\tvalidation_1-auc:0.84405\n",
      "[23]\tvalidation_0-auc:0.86687\tvalidation_1-auc:0.84362\n",
      "[24]\tvalidation_0-auc:0.86752\tvalidation_1-auc:0.84384\n",
      "[25]\tvalidation_0-auc:0.86843\tvalidation_1-auc:0.84354\n",
      "[26]\tvalidation_0-auc:0.86952\tvalidation_1-auc:0.84357\n",
      "[27]\tvalidation_0-auc:0.87056\tvalidation_1-auc:0.84299\n",
      "[28]\tvalidation_0-auc:0.87158\tvalidation_1-auc:0.84303\n",
      "[29]\tvalidation_0-auc:0.87261\tvalidation_1-auc:0.84218\n",
      "[30]\tvalidation_0-auc:0.87352\tvalidation_1-auc:0.84239\n",
      "[31]\tvalidation_0-auc:0.87404\tvalidation_1-auc:0.84295\n",
      "[32]\tvalidation_0-auc:0.87446\tvalidation_1-auc:0.84294\n",
      "[33]\tvalidation_0-auc:0.87520\tvalidation_1-auc:0.84323\n",
      "[34]\tvalidation_0-auc:0.87617\tvalidation_1-auc:0.84302\n",
      "[35]\tvalidation_0-auc:0.87641\tvalidation_1-auc:0.84333\n",
      "[36]\tvalidation_0-auc:0.87695\tvalidation_1-auc:0.84322\n",
      "[37]\tvalidation_0-auc:0.87853\tvalidation_1-auc:0.84298\n",
      "[38]\tvalidation_0-auc:0.87900\tvalidation_1-auc:0.84311\n",
      "[39]\tvalidation_0-auc:0.87947\tvalidation_1-auc:0.84316\n",
      "[40]\tvalidation_0-auc:0.87970\tvalidation_1-auc:0.84322\n",
      "[41]\tvalidation_0-auc:0.88007\tvalidation_1-auc:0.84335\n",
      "[42]\tvalidation_0-auc:0.88025\tvalidation_1-auc:0.84334\n",
      "[43]\tvalidation_0-auc:0.88074\tvalidation_1-auc:0.84337\n",
      "[44]\tvalidation_0-auc:0.88144\tvalidation_1-auc:0.84285\n",
      "[45]\tvalidation_0-auc:0.88215\tvalidation_1-auc:0.84337\n",
      "[46]\tvalidation_0-auc:0.88237\tvalidation_1-auc:0.84361\n",
      "[47]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.84328\n",
      "[48]\tvalidation_0-auc:0.88299\tvalidation_1-auc:0.84319\n",
      "[49]\tvalidation_0-auc:0.88328\tvalidation_1-auc:0.84317\n",
      "[50]\tvalidation_0-auc:0.88376\tvalidation_1-auc:0.84296\n",
      "[51]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.84286\n",
      "[52]\tvalidation_0-auc:0.88424\tvalidation_1-auc:0.84290\n",
      "[53]\tvalidation_0-auc:0.88499\tvalidation_1-auc:0.84293\n",
      "[54]\tvalidation_0-auc:0.88604\tvalidation_1-auc:0.84274\n",
      "[55]\tvalidation_0-auc:0.88642\tvalidation_1-auc:0.84284\n",
      "[56]\tvalidation_0-auc:0.88655\tvalidation_1-auc:0.84279\n",
      "[57]\tvalidation_0-auc:0.88683\tvalidation_1-auc:0.84275\n",
      "[58]\tvalidation_0-auc:0.88709\tvalidation_1-auc:0.84252\n",
      "[59]\tvalidation_0-auc:0.88741\tvalidation_1-auc:0.84232\n",
      "[60]\tvalidation_0-auc:0.88782\tvalidation_1-auc:0.84214\n",
      "[61]\tvalidation_0-auc:0.88926\tvalidation_1-auc:0.84233\n",
      "[62]\tvalidation_0-auc:0.89033\tvalidation_1-auc:0.84201\n",
      "[63]\tvalidation_0-auc:0.89115\tvalidation_1-auc:0.84204\n",
      "[64]\tvalidation_0-auc:0.89131\tvalidation_1-auc:0.84199\n",
      "[65]\tvalidation_0-auc:0.89146\tvalidation_1-auc:0.84222\n",
      "[66]\tvalidation_0-auc:0.89162\tvalidation_1-auc:0.84233\n",
      "[67]\tvalidation_0-auc:0.89173\tvalidation_1-auc:0.84241\n",
      "[68]\tvalidation_0-auc:0.89177\tvalidation_1-auc:0.84240\n",
      "[69]\tvalidation_0-auc:0.89198\tvalidation_1-auc:0.84215\n",
      "[70]\tvalidation_0-auc:0.89247\tvalidation_1-auc:0.84186\n",
      "[71]\tvalidation_0-auc:0.89282\tvalidation_1-auc:0.84189\n",
      "[72]\tvalidation_0-auc:0.89354\tvalidation_1-auc:0.84178\n",
      "[73]\tvalidation_0-auc:0.89373\tvalidation_1-auc:0.84198\n",
      "[74]\tvalidation_0-auc:0.89427\tvalidation_1-auc:0.84184\n",
      "[75]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.84170\n",
      "[76]\tvalidation_0-auc:0.89465\tvalidation_1-auc:0.84178\n",
      "[77]\tvalidation_0-auc:0.89489\tvalidation_1-auc:0.84174\n",
      "[78]\tvalidation_0-auc:0.89504\tvalidation_1-auc:0.84163\n",
      "[79]\tvalidation_0-auc:0.89540\tvalidation_1-auc:0.84160\n",
      "[80]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.84160\n",
      "[81]\tvalidation_0-auc:0.89557\tvalidation_1-auc:0.84158\n",
      "[82]\tvalidation_0-auc:0.89574\tvalidation_1-auc:0.84140\n",
      "[83]\tvalidation_0-auc:0.89578\tvalidation_1-auc:0.84147\n",
      "[84]\tvalidation_0-auc:0.89587\tvalidation_1-auc:0.84123\n",
      "[85]\tvalidation_0-auc:0.89599\tvalidation_1-auc:0.84135\n",
      "[86]\tvalidation_0-auc:0.89609\tvalidation_1-auc:0.84132\n",
      "[87]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.84127\n",
      "[88]\tvalidation_0-auc:0.89723\tvalidation_1-auc:0.84088\n",
      "[89]\tvalidation_0-auc:0.89773\tvalidation_1-auc:0.84097\n",
      "[90]\tvalidation_0-auc:0.89855\tvalidation_1-auc:0.84094\n",
      "[91]\tvalidation_0-auc:0.89920\tvalidation_1-auc:0.84052\n",
      "[92]\tvalidation_0-auc:0.89940\tvalidation_1-auc:0.84042\n",
      "[93]\tvalidation_0-auc:0.89993\tvalidation_1-auc:0.84056\n",
      "[94]\tvalidation_0-auc:0.90035\tvalidation_1-auc:0.84046\n",
      "[95]\tvalidation_0-auc:0.90057\tvalidation_1-auc:0.84034\n",
      "[96]\tvalidation_0-auc:0.90112\tvalidation_1-auc:0.84040\n",
      "[97]\tvalidation_0-auc:0.90182\tvalidation_1-auc:0.84064\n",
      "[98]\tvalidation_0-auc:0.90194\tvalidation_1-auc:0.84054\n",
      "[99]\tvalidation_0-auc:0.90204\tvalidation_1-auc:0.84053\n",
      "[100]\tvalidation_0-auc:0.90230\tvalidation_1-auc:0.84032\n",
      "[101]\tvalidation_0-auc:0.90239\tvalidation_1-auc:0.84031\n",
      "[102]\tvalidation_0-auc:0.90271\tvalidation_1-auc:0.84015\n",
      "[103]\tvalidation_0-auc:0.90323\tvalidation_1-auc:0.84012\n",
      "[104]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.84020\n",
      "[105]\tvalidation_0-auc:0.90396\tvalidation_1-auc:0.84024\n",
      "[106]\tvalidation_0-auc:0.90401\tvalidation_1-auc:0.84022\n",
      "[107]\tvalidation_0-auc:0.90421\tvalidation_1-auc:0.84026\n",
      "[108]\tvalidation_0-auc:0.90435\tvalidation_1-auc:0.84025\n",
      "[109]\tvalidation_0-auc:0.90433\tvalidation_1-auc:0.84022\n",
      "[110]\tvalidation_0-auc:0.90449\tvalidation_1-auc:0.84006\n",
      "[111]\tvalidation_0-auc:0.90456\tvalidation_1-auc:0.84004\n",
      "[112]\tvalidation_0-auc:0.90486\tvalidation_1-auc:0.83978\n",
      "[113]\tvalidation_0-auc:0.90491\tvalidation_1-auc:0.83978\n",
      "[114]\tvalidation_0-auc:0.90509\tvalidation_1-auc:0.83995\n",
      "[115]\tvalidation_0-auc:0.90583\tvalidation_1-auc:0.84005\n",
      "[116]\tvalidation_0-auc:0.90606\tvalidation_1-auc:0.84002\n",
      "[117]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.84007\n",
      "[118]\tvalidation_0-auc:0.90687\tvalidation_1-auc:0.84008\n",
      "[119]\tvalidation_0-auc:0.90768\tvalidation_1-auc:0.83979\n",
      "[120]\tvalidation_0-auc:0.90772\tvalidation_1-auc:0.83983\n",
      "[121]\tvalidation_0-auc:0.90779\tvalidation_1-auc:0.83977\n",
      "[122]\tvalidation_0-auc:0.90788\tvalidation_1-auc:0.83966\n",
      "[123]\tvalidation_0-auc:0.90799\tvalidation_1-auc:0.83958\n",
      "[124]\tvalidation_0-auc:0.90806\tvalidation_1-auc:0.83956\n",
      "[125]\tvalidation_0-auc:0.90858\tvalidation_1-auc:0.83947\n",
      "[126]\tvalidation_0-auc:0.90874\tvalidation_1-auc:0.83955\n",
      "[127]\tvalidation_0-auc:0.90934\tvalidation_1-auc:0.83916\n",
      "[128]\tvalidation_0-auc:0.90970\tvalidation_1-auc:0.83881\n",
      "[129]\tvalidation_0-auc:0.90990\tvalidation_1-auc:0.83851\n",
      "[130]\tvalidation_0-auc:0.91010\tvalidation_1-auc:0.83841\n",
      "[131]\tvalidation_0-auc:0.91077\tvalidation_1-auc:0.83863\n",
      "[132]\tvalidation_0-auc:0.91093\tvalidation_1-auc:0.83852\n",
      "[133]\tvalidation_0-auc:0.91109\tvalidation_1-auc:0.83847\n",
      "[134]\tvalidation_0-auc:0.91119\tvalidation_1-auc:0.83852\n",
      "[135]\tvalidation_0-auc:0.91138\tvalidation_1-auc:0.83853\n",
      "[136]\tvalidation_0-auc:0.91155\tvalidation_1-auc:0.83852\n",
      "[137]\tvalidation_0-auc:0.91164\tvalidation_1-auc:0.83825\n",
      "[138]\tvalidation_0-auc:0.91169\tvalidation_1-auc:0.83831\n",
      "[139]\tvalidation_0-auc:0.91222\tvalidation_1-auc:0.83881\n",
      "[140]\tvalidation_0-auc:0.91251\tvalidation_1-auc:0.83850\n",
      "[141]\tvalidation_0-auc:0.91255\tvalidation_1-auc:0.83854\n",
      "[142]\tvalidation_0-auc:0.91269\tvalidation_1-auc:0.83868\n",
      "[143]\tvalidation_0-auc:0.91280\tvalidation_1-auc:0.83863\n",
      "[144]\tvalidation_0-auc:0.91285\tvalidation_1-auc:0.83868\n",
      "[145]\tvalidation_0-auc:0.91291\tvalidation_1-auc:0.83851\n",
      "[146]\tvalidation_0-auc:0.91382\tvalidation_1-auc:0.83920\n",
      "[147]\tvalidation_0-auc:0.91400\tvalidation_1-auc:0.83919\n",
      "[148]\tvalidation_0-auc:0.91405\tvalidation_1-auc:0.83923\n",
      "[149]\tvalidation_0-auc:0.91447\tvalidation_1-auc:0.83915\n",
      "[150]\tvalidation_0-auc:0.91453\tvalidation_1-auc:0.83901\n",
      "[151]\tvalidation_0-auc:0.91455\tvalidation_1-auc:0.83907\n",
      "[152]\tvalidation_0-auc:0.91522\tvalidation_1-auc:0.83871\n",
      "[153]\tvalidation_0-auc:0.91535\tvalidation_1-auc:0.83866\n",
      "[154]\tvalidation_0-auc:0.91539\tvalidation_1-auc:0.83865\n",
      "[155]\tvalidation_0-auc:0.91603\tvalidation_1-auc:0.83860\n",
      "[156]\tvalidation_0-auc:0.91630\tvalidation_1-auc:0.83886\n",
      "[157]\tvalidation_0-auc:0.91657\tvalidation_1-auc:0.83903\n",
      "[158]\tvalidation_0-auc:0.91666\tvalidation_1-auc:0.83881\n",
      "[159]\tvalidation_0-auc:0.91681\tvalidation_1-auc:0.83861\n",
      "[160]\tvalidation_0-auc:0.91695\tvalidation_1-auc:0.83852\n",
      "[161]\tvalidation_0-auc:0.91705\tvalidation_1-auc:0.83829\n",
      "[162]\tvalidation_0-auc:0.91709\tvalidation_1-auc:0.83832\n",
      "[163]\tvalidation_0-auc:0.91738\tvalidation_1-auc:0.83775\n",
      "[164]\tvalidation_0-auc:0.91756\tvalidation_1-auc:0.83786\n",
      "[165]\tvalidation_0-auc:0.91782\tvalidation_1-auc:0.83785\n",
      "[166]\tvalidation_0-auc:0.91807\tvalidation_1-auc:0.83758\n",
      "[167]\tvalidation_0-auc:0.91818\tvalidation_1-auc:0.83765\n",
      "[168]\tvalidation_0-auc:0.91824\tvalidation_1-auc:0.83768\n",
      "[169]\tvalidation_0-auc:0.91826\tvalidation_1-auc:0.83762\n",
      "[170]\tvalidation_0-auc:0.91848\tvalidation_1-auc:0.83764\n",
      "[171]\tvalidation_0-auc:0.91852\tvalidation_1-auc:0.83764\n",
      "[172]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.83769\n",
      "[173]\tvalidation_0-auc:0.91897\tvalidation_1-auc:0.83782\n",
      "[174]\tvalidation_0-auc:0.91912\tvalidation_1-auc:0.83789\n",
      "[175]\tvalidation_0-auc:0.91917\tvalidation_1-auc:0.83790\n",
      "[176]\tvalidation_0-auc:0.91958\tvalidation_1-auc:0.83777\n",
      "[177]\tvalidation_0-auc:0.91984\tvalidation_1-auc:0.83788\n",
      "[178]\tvalidation_0-auc:0.91993\tvalidation_1-auc:0.83779\n",
      "[179]\tvalidation_0-auc:0.92018\tvalidation_1-auc:0.83786\n",
      "[180]\tvalidation_0-auc:0.92029\tvalidation_1-auc:0.83784\n",
      "[181]\tvalidation_0-auc:0.92037\tvalidation_1-auc:0.83765\n",
      "[182]\tvalidation_0-auc:0.92039\tvalidation_1-auc:0.83761\n",
      "[183]\tvalidation_0-auc:0.92050\tvalidation_1-auc:0.83760\n",
      "[184]\tvalidation_0-auc:0.92055\tvalidation_1-auc:0.83754\n",
      "[185]\tvalidation_0-auc:0.92063\tvalidation_1-auc:0.83748\n",
      "[186]\tvalidation_0-auc:0.92070\tvalidation_1-auc:0.83759\n",
      "[187]\tvalidation_0-auc:0.92109\tvalidation_1-auc:0.83779\n",
      "[188]\tvalidation_0-auc:0.92156\tvalidation_1-auc:0.83782\n",
      "[189]\tvalidation_0-auc:0.92163\tvalidation_1-auc:0.83756\n",
      "[190]\tvalidation_0-auc:0.92184\tvalidation_1-auc:0.83735\n",
      "[191]\tvalidation_0-auc:0.92190\tvalidation_1-auc:0.83736\n",
      "[192]\tvalidation_0-auc:0.92232\tvalidation_1-auc:0.83669\n",
      "[193]\tvalidation_0-auc:0.92241\tvalidation_1-auc:0.83660\n",
      "[194]\tvalidation_0-auc:0.92246\tvalidation_1-auc:0.83647\n",
      "[195]\tvalidation_0-auc:0.92256\tvalidation_1-auc:0.83633\n",
      "[196]\tvalidation_0-auc:0.92289\tvalidation_1-auc:0.83638\n",
      "[197]\tvalidation_0-auc:0.92322\tvalidation_1-auc:0.83639\n",
      "[198]\tvalidation_0-auc:0.92326\tvalidation_1-auc:0.83639\n",
      "[199]\tvalidation_0-auc:0.92351\tvalidation_1-auc:0.83646\n",
      "[200]\tvalidation_0-auc:0.92361\tvalidation_1-auc:0.83628\n",
      "[201]\tvalidation_0-auc:0.92363\tvalidation_1-auc:0.83625\n",
      "[202]\tvalidation_0-auc:0.92371\tvalidation_1-auc:0.83634\n",
      "[203]\tvalidation_0-auc:0.92379\tvalidation_1-auc:0.83603\n",
      "[204]\tvalidation_0-auc:0.92394\tvalidation_1-auc:0.83614\n",
      "[205]\tvalidation_0-auc:0.92407\tvalidation_1-auc:0.83587\n",
      "[206]\tvalidation_0-auc:0.92409\tvalidation_1-auc:0.83581\n",
      "[207]\tvalidation_0-auc:0.92414\tvalidation_1-auc:0.83581\n",
      "[208]\tvalidation_0-auc:0.92430\tvalidation_1-auc:0.83554\n",
      "[209]\tvalidation_0-auc:0.92493\tvalidation_1-auc:0.83532\n",
      "[210]\tvalidation_0-auc:0.92549\tvalidation_1-auc:0.83507\n",
      "[211]\tvalidation_0-auc:0.92569\tvalidation_1-auc:0.83495\n",
      "[212]\tvalidation_0-auc:0.92605\tvalidation_1-auc:0.83506\n",
      "[213]\tvalidation_0-auc:0.92607\tvalidation_1-auc:0.83495\n",
      "[214]\tvalidation_0-auc:0.92608\tvalidation_1-auc:0.83490\n",
      "[215]\tvalidation_0-auc:0.92617\tvalidation_1-auc:0.83487\n",
      "[216]\tvalidation_0-auc:0.92642\tvalidation_1-auc:0.83471\n",
      "[217]\tvalidation_0-auc:0.92722\tvalidation_1-auc:0.83434\n",
      "[218]\tvalidation_0-auc:0.92736\tvalidation_1-auc:0.83404\n",
      "[219]\tvalidation_0-auc:0.92741\tvalidation_1-auc:0.83395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=4, num_parallel_tree=1,\n",
       "              random_state=156, reg_alpha=0.03, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train, early_stopping_rounds = 200, \n",
    "           eval_metric = 'auc', eval_set = [(X_train, y_train), (X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC : 0.8446\n"
     ]
    }
   ],
   "source": [
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1], average = 'macro')\n",
    "print('ROC AUC : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe093c375b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance \n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "\n",
    "plot_importance(xgb_clf, ax= ax, max_num_features = 20, height = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 500)\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric ='auc',\n",
    "            eval_set = evals, verbose = True )\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1], average = 'macro')\n",
    "\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823664\tvalid_0's binary_logloss: 0.156198\tvalid_1's auc: 0.821078\tvalid_1's binary_logloss: 0.16488\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.82966\tvalid_0's binary_logloss: 0.150925\tvalid_1's auc: 0.826326\tvalid_1's binary_logloss: 0.159774\n",
      "[3]\tvalid_0's auc: 0.834498\tvalid_0's binary_logloss: 0.147158\tvalid_1's auc: 0.826852\tvalid_1's binary_logloss: 0.156113\n",
      "[4]\tvalid_0's auc: 0.83904\tvalid_0's binary_logloss: 0.144173\tvalid_1's auc: 0.831417\tvalid_1's binary_logloss: 0.153186\n",
      "[5]\tvalid_0's auc: 0.841964\tvalid_0's binary_logloss: 0.141745\tvalid_1's auc: 0.834593\tvalid_1's binary_logloss: 0.150797\n",
      "[6]\tvalid_0's auc: 0.845253\tvalid_0's binary_logloss: 0.139712\tvalid_1's auc: 0.836659\tvalid_1's binary_logloss: 0.149062\n",
      "[7]\tvalid_0's auc: 0.846545\tvalid_0's binary_logloss: 0.138053\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.147537\n",
      "[8]\tvalid_0's auc: 0.848885\tvalid_0's binary_logloss: 0.1366\tvalid_1's auc: 0.838153\tvalid_1's binary_logloss: 0.146268\n",
      "[9]\tvalid_0's auc: 0.850839\tvalid_0's binary_logloss: 0.135205\tvalid_1's auc: 0.839816\tvalid_1's binary_logloss: 0.145097\n",
      "[10]\tvalid_0's auc: 0.851902\tvalid_0's binary_logloss: 0.134136\tvalid_1's auc: 0.839977\tvalid_1's binary_logloss: 0.144182\n",
      "[11]\tvalid_0's auc: 0.853188\tvalid_0's binary_logloss: 0.133195\tvalid_1's auc: 0.840379\tvalid_1's binary_logloss: 0.143374\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[13]\tvalid_0's auc: 0.857693\tvalid_0's binary_logloss: 0.131411\tvalid_1's auc: 0.840669\tvalid_1's binary_logloss: 0.142221\n",
      "[14]\tvalid_0's auc: 0.859427\tvalid_0's binary_logloss: 0.130627\tvalid_1's auc: 0.840024\tvalid_1's binary_logloss: 0.141818\n",
      "[15]\tvalid_0's auc: 0.861064\tvalid_0's binary_logloss: 0.12997\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.141407\n",
      "[16]\tvalid_0's auc: 0.861905\tvalid_0's binary_logloss: 0.12935\tvalid_1's auc: 0.839151\tvalid_1's binary_logloss: 0.141108\n",
      "[17]\tvalid_0's auc: 0.863357\tvalid_0's binary_logloss: 0.128765\tvalid_1's auc: 0.839205\tvalid_1's binary_logloss: 0.14086\n",
      "[18]\tvalid_0's auc: 0.865057\tvalid_0's binary_logloss: 0.128197\tvalid_1's auc: 0.838756\tvalid_1's binary_logloss: 0.140615\n",
      "[19]\tvalid_0's auc: 0.866322\tvalid_0's binary_logloss: 0.127685\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.140439\n",
      "[20]\tvalid_0's auc: 0.867327\tvalid_0's binary_logloss: 0.127201\tvalid_1's auc: 0.838595\tvalid_1's binary_logloss: 0.140208\n",
      "[21]\tvalid_0's auc: 0.868281\tvalid_0's binary_logloss: 0.126821\tvalid_1's auc: 0.83842\tvalid_1's binary_logloss: 0.140081\n",
      "[22]\tvalid_0's auc: 0.869333\tvalid_0's binary_logloss: 0.126397\tvalid_1's auc: 0.838291\tvalid_1's binary_logloss: 0.139941\n",
      "[23]\tvalid_0's auc: 0.870664\tvalid_0's binary_logloss: 0.125953\tvalid_1's auc: 0.837637\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.871541\tvalid_0's binary_logloss: 0.125585\tvalid_1's auc: 0.837144\tvalid_1's binary_logloss: 0.139915\n",
      "[25]\tvalid_0's auc: 0.872827\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837438\tvalid_1's binary_logloss: 0.139775\n",
      "[26]\tvalid_0's auc: 0.873522\tvalid_0's binary_logloss: 0.12487\tvalid_1's auc: 0.83729\tvalid_1's binary_logloss: 0.139751\n",
      "[27]\tvalid_0's auc: 0.874428\tvalid_0's binary_logloss: 0.124521\tvalid_1's auc: 0.837295\tvalid_1's binary_logloss: 0.139667\n",
      "[28]\tvalid_0's auc: 0.875453\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.836916\tvalid_1's binary_logloss: 0.139693\n",
      "[29]\tvalid_0's auc: 0.876968\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.836543\tvalid_1's binary_logloss: 0.139692\n",
      "[30]\tvalid_0's auc: 0.878211\tvalid_0's binary_logloss: 0.123513\tvalid_1's auc: 0.836768\tvalid_1's binary_logloss: 0.139653\n",
      "[31]\tvalid_0's auc: 0.879123\tvalid_0's binary_logloss: 0.123238\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.879609\tvalid_0's binary_logloss: 0.122982\tvalid_1's auc: 0.836481\tvalid_1's binary_logloss: 0.139632\n",
      "[33]\tvalid_0's auc: 0.880297\tvalid_0's binary_logloss: 0.122728\tvalid_1's auc: 0.8369\tvalid_1's binary_logloss: 0.139575\n",
      "[34]\tvalid_0's auc: 0.881002\tvalid_0's binary_logloss: 0.122492\tvalid_1's auc: 0.836762\tvalid_1's binary_logloss: 0.139536\n",
      "[35]\tvalid_0's auc: 0.881621\tvalid_0's binary_logloss: 0.122231\tvalid_1's auc: 0.836948\tvalid_1's binary_logloss: 0.139471\n",
      "[36]\tvalid_0's auc: 0.882178\tvalid_0's binary_logloss: 0.121993\tvalid_1's auc: 0.83713\tvalid_1's binary_logloss: 0.139418\n",
      "[37]\tvalid_0's auc: 0.882783\tvalid_0's binary_logloss: 0.121741\tvalid_1's auc: 0.837135\tvalid_1's binary_logloss: 0.139368\n",
      "[38]\tvalid_0's auc: 0.88336\tvalid_0's binary_logloss: 0.121507\tvalid_1's auc: 0.836861\tvalid_1's binary_logloss: 0.139431\n",
      "[39]\tvalid_0's auc: 0.883753\tvalid_0's binary_logloss: 0.121298\tvalid_1's auc: 0.836288\tvalid_1's binary_logloss: 0.139548\n",
      "[40]\tvalid_0's auc: 0.884325\tvalid_0's binary_logloss: 0.121031\tvalid_1's auc: 0.83612\tvalid_1's binary_logloss: 0.139622\n",
      "[41]\tvalid_0's auc: 0.884814\tvalid_0's binary_logloss: 0.12081\tvalid_1's auc: 0.835963\tvalid_1's binary_logloss: 0.139644\n",
      "[42]\tvalid_0's auc: 0.885392\tvalid_0's binary_logloss: 0.120617\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.139624\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.821268\tvalid_0's binary_logloss: 0.156277\tvalid_1's auc: 0.816814\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.828863\tvalid_0's binary_logloss: 0.151005\tvalid_1's auc: 0.821376\tvalid_1's binary_logloss: 0.159886\n",
      "[3]\tvalid_0's auc: 0.837474\tvalid_0's binary_logloss: 0.147149\tvalid_1's auc: 0.828229\tvalid_1's binary_logloss: 0.156519\n",
      "[4]\tvalid_0's auc: 0.842962\tvalid_0's binary_logloss: 0.144152\tvalid_1's auc: 0.829952\tvalid_1's binary_logloss: 0.153687\n",
      "[5]\tvalid_0's auc: 0.84635\tvalid_0's binary_logloss: 0.141643\tvalid_1's auc: 0.834055\tvalid_1's binary_logloss: 0.15137\n",
      "[6]\tvalid_0's auc: 0.849269\tvalid_0's binary_logloss: 0.139637\tvalid_1's auc: 0.834861\tvalid_1's binary_logloss: 0.149513\n",
      "[7]\tvalid_0's auc: 0.851069\tvalid_0's binary_logloss: 0.137899\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.147828\n",
      "[8]\tvalid_0's auc: 0.852425\tvalid_0's binary_logloss: 0.136444\tvalid_1's auc: 0.837615\tvalid_1's binary_logloss: 0.146566\n",
      "[9]\tvalid_0's auc: 0.853725\tvalid_0's binary_logloss: 0.135223\tvalid_1's auc: 0.838944\tvalid_1's binary_logloss: 0.145455\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[11]\tvalid_0's auc: 0.856642\tvalid_0's binary_logloss: 0.13318\tvalid_1's auc: 0.83836\tvalid_1's binary_logloss: 0.143998\n",
      "[12]\tvalid_0's auc: 0.857381\tvalid_0's binary_logloss: 0.13235\tvalid_1's auc: 0.83849\tvalid_1's binary_logloss: 0.143384\n",
      "[13]\tvalid_0's auc: 0.858555\tvalid_0's binary_logloss: 0.13154\tvalid_1's auc: 0.83788\tvalid_1's binary_logloss: 0.142918\n",
      "[14]\tvalid_0's auc: 0.859092\tvalid_0's binary_logloss: 0.130843\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.142521\n",
      "[15]\tvalid_0's auc: 0.860202\tvalid_0's binary_logloss: 0.130174\tvalid_1's auc: 0.836385\tvalid_1's binary_logloss: 0.142279\n",
      "[16]\tvalid_0's auc: 0.861797\tvalid_0's binary_logloss: 0.129525\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.141987\n",
      "[17]\tvalid_0's auc: 0.863207\tvalid_0's binary_logloss: 0.128978\tvalid_1's auc: 0.835285\tvalid_1's binary_logloss: 0.141713\n",
      "[18]\tvalid_0's auc: 0.864433\tvalid_0's binary_logloss: 0.128402\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.141442\n",
      "[19]\tvalid_0's auc: 0.865245\tvalid_0's binary_logloss: 0.127948\tvalid_1's auc: 0.836123\tvalid_1's binary_logloss: 0.1412\n",
      "[20]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.127497\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.140979\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.12703\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.140825\n",
      "[22]\tvalid_0's auc: 0.86828\tvalid_0's binary_logloss: 0.126598\tvalid_1's auc: 0.836515\tvalid_1's binary_logloss: 0.140741\n",
      "[23]\tvalid_0's auc: 0.869182\tvalid_0's binary_logloss: 0.126269\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.140588\n",
      "[24]\tvalid_0's auc: 0.869979\tvalid_0's binary_logloss: 0.125886\tvalid_1's auc: 0.836766\tvalid_1's binary_logloss: 0.140496\n",
      "[25]\tvalid_0's auc: 0.870956\tvalid_0's binary_logloss: 0.125545\tvalid_1's auc: 0.837001\tvalid_1's binary_logloss: 0.140322\n",
      "[26]\tvalid_0's auc: 0.872886\tvalid_0's binary_logloss: 0.125108\tvalid_1's auc: 0.836911\tvalid_1's binary_logloss: 0.140274\n",
      "[27]\tvalid_0's auc: 0.873971\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.140247\n",
      "[28]\tvalid_0's auc: 0.875129\tvalid_0's binary_logloss: 0.124434\tvalid_1's auc: 0.837012\tvalid_1's binary_logloss: 0.140143\n",
      "[29]\tvalid_0's auc: 0.875873\tvalid_0's binary_logloss: 0.12414\tvalid_1's auc: 0.836866\tvalid_1's binary_logloss: 0.140163\n",
      "[30]\tvalid_0's auc: 0.876465\tvalid_0's binary_logloss: 0.123865\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.140195\n",
      "[31]\tvalid_0's auc: 0.877699\tvalid_0's binary_logloss: 0.123521\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.140186\n",
      "[32]\tvalid_0's auc: 0.878492\tvalid_0's binary_logloss: 0.123253\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.140145\n",
      "[33]\tvalid_0's auc: 0.879281\tvalid_0's binary_logloss: 0.122981\tvalid_1's auc: 0.836061\tvalid_1's binary_logloss: 0.140165\n",
      "[34]\tvalid_0's auc: 0.880016\tvalid_0's binary_logloss: 0.12271\tvalid_1's auc: 0.836238\tvalid_1's binary_logloss: 0.140112\n",
      "[35]\tvalid_0's auc: 0.880929\tvalid_0's binary_logloss: 0.122397\tvalid_1's auc: 0.836618\tvalid_1's binary_logloss: 0.140034\n",
      "[36]\tvalid_0's auc: 0.881746\tvalid_0's binary_logloss: 0.122132\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.140013\n",
      "[37]\tvalid_0's auc: 0.882622\tvalid_0's binary_logloss: 0.121854\tvalid_1's auc: 0.836926\tvalid_1's binary_logloss: 0.139982\n",
      "[38]\tvalid_0's auc: 0.883018\tvalid_0's binary_logloss: 0.121618\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.139968\n",
      "[39]\tvalid_0's auc: 0.883857\tvalid_0's binary_logloss: 0.12136\tvalid_1's auc: 0.837075\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.884437\tvalid_0's binary_logloss: 0.121112\tvalid_1's auc: 0.836834\tvalid_1's binary_logloss: 0.139996\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.825972\tvalid_0's binary_logloss: 0.15626\tvalid_1's auc: 0.817426\tvalid_1's binary_logloss: 0.165002\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830735\tvalid_0's binary_logloss: 0.150869\tvalid_1's auc: 0.821832\tvalid_1's binary_logloss: 0.159685\n",
      "[3]\tvalid_0's auc: 0.836213\tvalid_0's binary_logloss: 0.147022\tvalid_1's auc: 0.825847\tvalid_1's binary_logloss: 0.156023\n",
      "[4]\tvalid_0's auc: 0.839911\tvalid_0's binary_logloss: 0.143985\tvalid_1's auc: 0.830159\tvalid_1's binary_logloss: 0.153298\n",
      "[5]\tvalid_0's auc: 0.842712\tvalid_0's binary_logloss: 0.14152\tvalid_1's auc: 0.831253\tvalid_1's binary_logloss: 0.151107\n",
      "[6]\tvalid_0's auc: 0.84576\tvalid_0's binary_logloss: 0.139503\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.149167\n",
      "[7]\tvalid_0's auc: 0.84864\tvalid_0's binary_logloss: 0.137792\tvalid_1's auc: 0.836612\tvalid_1's binary_logloss: 0.147629\n",
      "[8]\tvalid_0's auc: 0.850006\tvalid_0's binary_logloss: 0.136329\tvalid_1's auc: 0.837077\tvalid_1's binary_logloss: 0.146348\n",
      "[9]\tvalid_0's auc: 0.852085\tvalid_0's binary_logloss: 0.135086\tvalid_1's auc: 0.838711\tvalid_1's binary_logloss: 0.145304\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[11]\tvalid_0's auc: 0.856458\tvalid_0's binary_logloss: 0.132947\tvalid_1's auc: 0.838948\tvalid_1's binary_logloss: 0.143547\n",
      "[12]\tvalid_0's auc: 0.857299\tvalid_0's binary_logloss: 0.132061\tvalid_1's auc: 0.839046\tvalid_1's binary_logloss: 0.142873\n",
      "[13]\tvalid_0's auc: 0.858451\tvalid_0's binary_logloss: 0.131304\tvalid_1's auc: 0.838455\tvalid_1's binary_logloss: 0.142387\n",
      "[14]\tvalid_0's auc: 0.860294\tvalid_0's binary_logloss: 0.130565\tvalid_1's auc: 0.838925\tvalid_1's binary_logloss: 0.141904\n",
      "[15]\tvalid_0's auc: 0.861473\tvalid_0's binary_logloss: 0.129923\tvalid_1's auc: 0.838733\tvalid_1's binary_logloss: 0.141518\n",
      "[16]\tvalid_0's auc: 0.862203\tvalid_0's binary_logloss: 0.129333\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.141178\n",
      "[17]\tvalid_0's auc: 0.863233\tvalid_0's binary_logloss: 0.128766\tvalid_1's auc: 0.838823\tvalid_1's binary_logloss: 0.140886\n",
      "[18]\tvalid_0's auc: 0.86399\tvalid_0's binary_logloss: 0.128208\tvalid_1's auc: 0.838336\tvalid_1's binary_logloss: 0.140669\n",
      "[19]\tvalid_0's auc: 0.864707\tvalid_0's binary_logloss: 0.127724\tvalid_1's auc: 0.83783\tvalid_1's binary_logloss: 0.140495\n",
      "[20]\tvalid_0's auc: 0.865576\tvalid_0's binary_logloss: 0.127256\tvalid_1's auc: 0.838481\tvalid_1's binary_logloss: 0.140248\n",
      "[21]\tvalid_0's auc: 0.866846\tvalid_0's binary_logloss: 0.126797\tvalid_1's auc: 0.838182\tvalid_1's binary_logloss: 0.140129\n",
      "[22]\tvalid_0's auc: 0.86837\tvalid_0's binary_logloss: 0.126354\tvalid_1's auc: 0.838279\tvalid_1's binary_logloss: 0.139978\n",
      "[23]\tvalid_0's auc: 0.869587\tvalid_0's binary_logloss: 0.125905\tvalid_1's auc: 0.83825\tvalid_1's binary_logloss: 0.139909\n",
      "[24]\tvalid_0's auc: 0.870532\tvalid_0's binary_logloss: 0.125527\tvalid_1's auc: 0.838429\tvalid_1's binary_logloss: 0.139818\n",
      "[25]\tvalid_0's auc: 0.871628\tvalid_0's binary_logloss: 0.125118\tvalid_1's auc: 0.837908\tvalid_1's binary_logloss: 0.139768\n",
      "[26]\tvalid_0's auc: 0.872816\tvalid_0's binary_logloss: 0.12478\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139683\n",
      "[27]\tvalid_0's auc: 0.873647\tvalid_0's binary_logloss: 0.124448\tvalid_1's auc: 0.837808\tvalid_1's binary_logloss: 0.139669\n",
      "[28]\tvalid_0's auc: 0.874326\tvalid_0's binary_logloss: 0.124117\tvalid_1's auc: 0.837756\tvalid_1's binary_logloss: 0.139635\n",
      "[29]\tvalid_0's auc: 0.875069\tvalid_0's binary_logloss: 0.123826\tvalid_1's auc: 0.838037\tvalid_1's binary_logloss: 0.139565\n",
      "[30]\tvalid_0's auc: 0.876092\tvalid_0's binary_logloss: 0.123541\tvalid_1's auc: 0.838013\tvalid_1's binary_logloss: 0.139571\n",
      "[31]\tvalid_0's auc: 0.877253\tvalid_0's binary_logloss: 0.123222\tvalid_1's auc: 0.838176\tvalid_1's binary_logloss: 0.139525\n",
      "[32]\tvalid_0's auc: 0.877859\tvalid_0's binary_logloss: 0.122952\tvalid_1's auc: 0.837999\tvalid_1's binary_logloss: 0.139539\n",
      "[33]\tvalid_0's auc: 0.878881\tvalid_0's binary_logloss: 0.122669\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139429\n",
      "[34]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.122378\tvalid_1's auc: 0.838388\tvalid_1's binary_logloss: 0.139425\n",
      "[35]\tvalid_0's auc: 0.880711\tvalid_0's binary_logloss: 0.122133\tvalid_1's auc: 0.838795\tvalid_1's binary_logloss: 0.139306\n",
      "[36]\tvalid_0's auc: 0.881763\tvalid_0's binary_logloss: 0.12187\tvalid_1's auc: 0.83878\tvalid_1's binary_logloss: 0.139315\n",
      "[37]\tvalid_0's auc: 0.882612\tvalid_0's binary_logloss: 0.121565\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139322\n",
      "[38]\tvalid_0's auc: 0.883169\tvalid_0's binary_logloss: 0.121312\tvalid_1's auc: 0.838615\tvalid_1's binary_logloss: 0.139324\n",
      "[39]\tvalid_0's auc: 0.883934\tvalid_0's binary_logloss: 0.12102\tvalid_1's auc: 0.838763\tvalid_1's binary_logloss: 0.139293\n",
      "[40]\tvalid_0's auc: 0.884499\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.838547\tvalid_1's binary_logloss: 0.13931\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823084\tvalid_0's binary_logloss: 0.156066\tvalid_1's auc: 0.821793\tvalid_1's binary_logloss: 0.164822\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.827813\tvalid_0's binary_logloss: 0.150805\tvalid_1's auc: 0.823891\tvalid_1's binary_logloss: 0.159732\n",
      "[3]\tvalid_0's auc: 0.836023\tvalid_0's binary_logloss: 0.147035\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.156124\n",
      "[4]\tvalid_0's auc: 0.842374\tvalid_0's binary_logloss: 0.143993\tvalid_1's auc: 0.832801\tvalid_1's binary_logloss: 0.153225\n",
      "[5]\tvalid_0's auc: 0.845121\tvalid_0's binary_logloss: 0.141663\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.15098\n",
      "[6]\tvalid_0's auc: 0.846404\tvalid_0's binary_logloss: 0.139689\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.14912\n",
      "[7]\tvalid_0's auc: 0.848157\tvalid_0's binary_logloss: 0.137973\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.147706\n",
      "[8]\tvalid_0's auc: 0.84954\tvalid_0's binary_logloss: 0.136555\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.146499\n",
      "[9]\tvalid_0's auc: 0.851438\tvalid_0's binary_logloss: 0.135283\tvalid_1's auc: 0.838446\tvalid_1's binary_logloss: 0.145447\n",
      "[10]\tvalid_0's auc: 0.853323\tvalid_0's binary_logloss: 0.134172\tvalid_1's auc: 0.838164\tvalid_1's binary_logloss: 0.144649\n",
      "[11]\tvalid_0's auc: 0.85454\tvalid_0's binary_logloss: 0.133213\tvalid_1's auc: 0.838387\tvalid_1's binary_logloss: 0.143878\n",
      "[12]\tvalid_0's auc: 0.856731\tvalid_0's binary_logloss: 0.1323\tvalid_1's auc: 0.83958\tvalid_1's binary_logloss: 0.143232\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[14]\tvalid_0's auc: 0.859616\tvalid_0's binary_logloss: 0.130695\tvalid_1's auc: 0.839638\tvalid_1's binary_logloss: 0.142197\n",
      "[15]\tvalid_0's auc: 0.86065\tvalid_0's binary_logloss: 0.130019\tvalid_1's auc: 0.839342\tvalid_1's binary_logloss: 0.141867\n",
      "[16]\tvalid_0's auc: 0.861879\tvalid_0's binary_logloss: 0.129426\tvalid_1's auc: 0.839474\tvalid_1's binary_logloss: 0.141484\n",
      "[17]\tvalid_0's auc: 0.86312\tvalid_0's binary_logloss: 0.128865\tvalid_1's auc: 0.838976\tvalid_1's binary_logloss: 0.141297\n",
      "[18]\tvalid_0's auc: 0.864292\tvalid_0's binary_logloss: 0.128302\tvalid_1's auc: 0.839738\tvalid_1's binary_logloss: 0.140953\n",
      "[19]\tvalid_0's auc: 0.86562\tvalid_0's binary_logloss: 0.12782\tvalid_1's auc: 0.839799\tvalid_1's binary_logloss: 0.140766\n",
      "[20]\tvalid_0's auc: 0.866802\tvalid_0's binary_logloss: 0.127322\tvalid_1's auc: 0.839807\tvalid_1's binary_logloss: 0.140536\n",
      "[21]\tvalid_0's auc: 0.868305\tvalid_0's binary_logloss: 0.126848\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.140335\n",
      "[22]\tvalid_0's auc: 0.869367\tvalid_0's binary_logloss: 0.126428\tvalid_1's auc: 0.839045\tvalid_1's binary_logloss: 0.140242\n",
      "[23]\tvalid_0's auc: 0.870018\tvalid_0's binary_logloss: 0.126051\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.140113\n",
      "[24]\tvalid_0's auc: 0.871076\tvalid_0's binary_logloss: 0.125665\tvalid_1's auc: 0.838918\tvalid_1's binary_logloss: 0.139963\n",
      "[25]\tvalid_0's auc: 0.871808\tvalid_0's binary_logloss: 0.12529\tvalid_1's auc: 0.838876\tvalid_1's binary_logloss: 0.139886\n",
      "[26]\tvalid_0's auc: 0.872679\tvalid_0's binary_logloss: 0.124953\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.139811\n",
      "[27]\tvalid_0's auc: 0.873565\tvalid_0's binary_logloss: 0.124623\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139786\n",
      "[28]\tvalid_0's auc: 0.874397\tvalid_0's binary_logloss: 0.124307\tvalid_1's auc: 0.83805\tvalid_1's binary_logloss: 0.139815\n",
      "[29]\tvalid_0's auc: 0.87544\tvalid_0's binary_logloss: 0.124018\tvalid_1's auc: 0.837719\tvalid_1's binary_logloss: 0.139819\n",
      "[30]\tvalid_0's auc: 0.876222\tvalid_0's binary_logloss: 0.123733\tvalid_1's auc: 0.838003\tvalid_1's binary_logloss: 0.139778\n",
      "[31]\tvalid_0's auc: 0.877142\tvalid_0's binary_logloss: 0.12348\tvalid_1's auc: 0.838078\tvalid_1's binary_logloss: 0.139735\n",
      "[32]\tvalid_0's auc: 0.877956\tvalid_0's binary_logloss: 0.123203\tvalid_1's auc: 0.838002\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878477\tvalid_0's binary_logloss: 0.122964\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139665\n",
      "[34]\tvalid_0's auc: 0.879048\tvalid_0's binary_logloss: 0.122668\tvalid_1's auc: 0.838296\tvalid_1's binary_logloss: 0.139589\n",
      "[35]\tvalid_0's auc: 0.879723\tvalid_0's binary_logloss: 0.122403\tvalid_1's auc: 0.838433\tvalid_1's binary_logloss: 0.139597\n",
      "[36]\tvalid_0's auc: 0.881202\tvalid_0's binary_logloss: 0.122123\tvalid_1's auc: 0.838596\tvalid_1's binary_logloss: 0.139557\n",
      "[37]\tvalid_0's auc: 0.882142\tvalid_0's binary_logloss: 0.121861\tvalid_1's auc: 0.838424\tvalid_1's binary_logloss: 0.139578\n",
      "[38]\tvalid_0's auc: 0.882706\tvalid_0's binary_logloss: 0.121634\tvalid_1's auc: 0.838625\tvalid_1's binary_logloss: 0.139548\n",
      "[39]\tvalid_0's auc: 0.883054\tvalid_0's binary_logloss: 0.121421\tvalid_1's auc: 0.838452\tvalid_1's binary_logloss: 0.139609\n",
      "[40]\tvalid_0's auc: 0.883797\tvalid_0's binary_logloss: 0.121128\tvalid_1's auc: 0.838612\tvalid_1's binary_logloss: 0.139576\n",
      "[41]\tvalid_0's auc: 0.884595\tvalid_0's binary_logloss: 0.120862\tvalid_1's auc: 0.838672\tvalid_1's binary_logloss: 0.139551\n",
      "[42]\tvalid_0's auc: 0.885101\tvalid_0's binary_logloss: 0.120643\tvalid_1's auc: 0.839085\tvalid_1's binary_logloss: 0.139462\n",
      "[43]\tvalid_0's auc: 0.885377\tvalid_0's binary_logloss: 0.120471\tvalid_1's auc: 0.838989\tvalid_1's binary_logloss: 0.13949\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823422\tvalid_0's binary_logloss: 0.156446\tvalid_1's auc: 0.819043\tvalid_1's binary_logloss: 0.165337\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830391\tvalid_0's binary_logloss: 0.151103\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.160151\n",
      "[3]\tvalid_0's auc: 0.836251\tvalid_0's binary_logloss: 0.14724\tvalid_1's auc: 0.829717\tvalid_1's binary_logloss: 0.156452\n",
      "[4]\tvalid_0's auc: 0.842516\tvalid_0's binary_logloss: 0.144162\tvalid_1's auc: 0.832695\tvalid_1's binary_logloss: 0.15358\n",
      "[5]\tvalid_0's auc: 0.846316\tvalid_0's binary_logloss: 0.141636\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.151246\n",
      "[6]\tvalid_0's auc: 0.847998\tvalid_0's binary_logloss: 0.139517\tvalid_1's auc: 0.836546\tvalid_1's binary_logloss: 0.149374\n",
      "[7]\tvalid_0's auc: 0.849074\tvalid_0's binary_logloss: 0.13782\tvalid_1's auc: 0.838333\tvalid_1's binary_logloss: 0.147794\n",
      "[8]\tvalid_0's auc: 0.85\tvalid_0's binary_logloss: 0.136391\tvalid_1's auc: 0.838986\tvalid_1's binary_logloss: 0.146497\n",
      "[9]\tvalid_0's auc: 0.851546\tvalid_0's binary_logloss: 0.135138\tvalid_1's auc: 0.839435\tvalid_1's binary_logloss: 0.145445\n",
      "[10]\tvalid_0's auc: 0.852573\tvalid_0's binary_logloss: 0.134059\tvalid_1's auc: 0.839729\tvalid_1's binary_logloss: 0.144614\n",
      "[11]\tvalid_0's auc: 0.854408\tvalid_0's binary_logloss: 0.133048\tvalid_1's auc: 0.840015\tvalid_1's binary_logloss: 0.143842\n",
      "[12]\tvalid_0's auc: 0.857486\tvalid_0's binary_logloss: 0.132117\tvalid_1's auc: 0.83955\tvalid_1's binary_logloss: 0.143278\n",
      "[13]\tvalid_0's auc: 0.859425\tvalid_0's binary_logloss: 0.131314\tvalid_1's auc: 0.840426\tvalid_1's binary_logloss: 0.142719\n",
      "[14]\tvalid_0's auc: 0.861454\tvalid_0's binary_logloss: 0.130495\tvalid_1's auc: 0.840751\tvalid_1's binary_logloss: 0.14226\n",
      "[15]\tvalid_0's auc: 0.862973\tvalid_0's binary_logloss: 0.12978\tvalid_1's auc: 0.840328\tvalid_1's binary_logloss: 0.14183\n",
      "[16]\tvalid_0's auc: 0.864608\tvalid_0's binary_logloss: 0.129092\tvalid_1's auc: 0.839958\tvalid_1's binary_logloss: 0.14153\n",
      "[17]\tvalid_0's auc: 0.865394\tvalid_0's binary_logloss: 0.128538\tvalid_1's auc: 0.840045\tvalid_1's binary_logloss: 0.141215\n",
      "[18]\tvalid_0's auc: 0.867204\tvalid_0's binary_logloss: 0.127947\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.1409\n",
      "[19]\tvalid_0's auc: 0.868095\tvalid_0's binary_logloss: 0.127461\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.14074\n",
      "[20]\tvalid_0's auc: 0.86902\tvalid_0's binary_logloss: 0.126956\tvalid_1's auc: 0.840596\tvalid_1's binary_logloss: 0.140606\n",
      "[21]\tvalid_0's auc: 0.869954\tvalid_0's binary_logloss: 0.126491\tvalid_1's auc: 0.840559\tvalid_1's binary_logloss: 0.140425\n",
      "[22]\tvalid_0's auc: 0.870971\tvalid_0's binary_logloss: 0.126075\tvalid_1's auc: 0.840789\tvalid_1's binary_logloss: 0.140251\n",
      "[23]\tvalid_0's auc: 0.872384\tvalid_0's binary_logloss: 0.125599\tvalid_1's auc: 0.840267\tvalid_1's binary_logloss: 0.14022\n",
      "[24]\tvalid_0's auc: 0.873433\tvalid_0's binary_logloss: 0.125215\tvalid_1's auc: 0.840763\tvalid_1's binary_logloss: 0.140023\n",
      "[25]\tvalid_0's auc: 0.874094\tvalid_0's binary_logloss: 0.124834\tvalid_1's auc: 0.840782\tvalid_1's binary_logloss: 0.139927\n",
      "[26]\tvalid_0's auc: 0.875299\tvalid_0's binary_logloss: 0.12446\tvalid_1's auc: 0.840852\tvalid_1's binary_logloss: 0.139864\n",
      "[27]\tvalid_0's auc: 0.875863\tvalid_0's binary_logloss: 0.124178\tvalid_1's auc: 0.840905\tvalid_1's binary_logloss: 0.139751\n",
      "[28]\tvalid_0's auc: 0.876477\tvalid_0's binary_logloss: 0.123899\tvalid_1's auc: 0.840828\tvalid_1's binary_logloss: 0.139688\n",
      "[29]\tvalid_0's auc: 0.877436\tvalid_0's binary_logloss: 0.123585\tvalid_1's auc: 0.840653\tvalid_1's binary_logloss: 0.139596\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[31]\tvalid_0's auc: 0.879246\tvalid_0's binary_logloss: 0.122979\tvalid_1's auc: 0.840819\tvalid_1's binary_logloss: 0.139442\n",
      "[32]\tvalid_0's auc: 0.880496\tvalid_0's binary_logloss: 0.122664\tvalid_1's auc: 0.840531\tvalid_1's binary_logloss: 0.139452\n",
      "[33]\tvalid_0's auc: 0.881439\tvalid_0's binary_logloss: 0.122371\tvalid_1's auc: 0.840279\tvalid_1's binary_logloss: 0.139455\n",
      "[34]\tvalid_0's auc: 0.882347\tvalid_0's binary_logloss: 0.122119\tvalid_1's auc: 0.840374\tvalid_1's binary_logloss: 0.139423\n",
      "[35]\tvalid_0's auc: 0.883154\tvalid_0's binary_logloss: 0.121847\tvalid_1's auc: 0.840528\tvalid_1's binary_logloss: 0.139369\n",
      "[36]\tvalid_0's auc: 0.883941\tvalid_0's binary_logloss: 0.121532\tvalid_1's auc: 0.840858\tvalid_1's binary_logloss: 0.139284\n",
      "[37]\tvalid_0's auc: 0.884407\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.840641\tvalid_1's binary_logloss: 0.139325\n",
      "[38]\tvalid_0's auc: 0.885324\tvalid_0's binary_logloss: 0.121016\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.13934\n",
      "[39]\tvalid_0's auc: 0.885824\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.840244\tvalid_1's binary_logloss: 0.139346\n",
      "[40]\tvalid_0's auc: 0.886492\tvalid_0's binary_logloss: 0.120515\tvalid_1's auc: 0.84003\tvalid_1's binary_logloss: 0.139395\n",
      "[41]\tvalid_0's auc: 0.887212\tvalid_0's binary_logloss: 0.120235\tvalid_1's auc: 0.839933\tvalid_1's binary_logloss: 0.139397\n",
      "[42]\tvalid_0's auc: 0.887679\tvalid_0's binary_logloss: 0.120004\tvalid_1's auc: 0.839795\tvalid_1's binary_logloss: 0.139391\n",
      "[43]\tvalid_0's auc: 0.88855\tvalid_0's binary_logloss: 0.119787\tvalid_1's auc: 0.839567\tvalid_1's binary_logloss: 0.139426\n",
      "[44]\tvalid_0's auc: 0.888918\tvalid_0's binary_logloss: 0.119598\tvalid_1's auc: 0.839591\tvalid_1's binary_logloss: 0.139427\n",
      "[45]\tvalid_0's auc: 0.889615\tvalid_0's binary_logloss: 0.119335\tvalid_1's auc: 0.839609\tvalid_1's binary_logloss: 0.139412\n",
      "[46]\tvalid_0's auc: 0.890166\tvalid_0's binary_logloss: 0.119099\tvalid_1's auc: 0.839346\tvalid_1's binary_logloss: 0.139475\n",
      "[47]\tvalid_0's auc: 0.890678\tvalid_0's binary_logloss: 0.118869\tvalid_1's auc: 0.839761\tvalid_1's binary_logloss: 0.1394\n",
      "[48]\tvalid_0's auc: 0.891058\tvalid_0's binary_logloss: 0.118665\tvalid_1's auc: 0.839755\tvalid_1's binary_logloss: 0.139409\n",
      "[49]\tvalid_0's auc: 0.891635\tvalid_0's binary_logloss: 0.118425\tvalid_1's auc: 0.839754\tvalid_1's binary_logloss: 0.139428\n",
      "[50]\tvalid_0's auc: 0.892346\tvalid_0's binary_logloss: 0.118168\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.139501\n",
      "[51]\tvalid_0's auc: 0.892736\tvalid_0's binary_logloss: 0.117984\tvalid_1's auc: 0.839121\tvalid_1's binary_logloss: 0.139524\n",
      "[52]\tvalid_0's auc: 0.893171\tvalid_0's binary_logloss: 0.117764\tvalid_1's auc: 0.838794\tvalid_1's binary_logloss: 0.139586\n",
      "[53]\tvalid_0's auc: 0.893573\tvalid_0's binary_logloss: 0.117568\tvalid_1's auc: 0.838694\tvalid_1's binary_logloss: 0.139581\n",
      "[54]\tvalid_0's auc: 0.894147\tvalid_0's binary_logloss: 0.117322\tvalid_1's auc: 0.838487\tvalid_1's binary_logloss: 0.139606\n",
      "[55]\tvalid_0's auc: 0.894518\tvalid_0's binary_logloss: 0.117157\tvalid_1's auc: 0.838831\tvalid_1's binary_logloss: 0.139538\n",
      "[56]\tvalid_0's auc: 0.894919\tvalid_0's binary_logloss: 0.116983\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139562\n",
      "[57]\tvalid_0's auc: 0.895096\tvalid_0's binary_logloss: 0.116832\tvalid_1's auc: 0.838982\tvalid_1's binary_logloss: 0.139544\n",
      "[58]\tvalid_0's auc: 0.895448\tvalid_0's binary_logloss: 0.116643\tvalid_1's auc: 0.839062\tvalid_1's binary_logloss: 0.139518\n",
      "[59]\tvalid_0's auc: 0.895699\tvalid_0's binary_logloss: 0.116514\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.139543\n",
      "[60]\tvalid_0's auc: 0.896178\tvalid_0's binary_logloss: 0.116313\tvalid_1's auc: 0.838833\tvalid_1's binary_logloss: 0.1396\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823664\tvalid_0's binary_logloss: 0.156198\tvalid_1's auc: 0.821078\tvalid_1's binary_logloss: 0.16488\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.82966\tvalid_0's binary_logloss: 0.150925\tvalid_1's auc: 0.826326\tvalid_1's binary_logloss: 0.159774\n",
      "[3]\tvalid_0's auc: 0.834498\tvalid_0's binary_logloss: 0.147158\tvalid_1's auc: 0.826852\tvalid_1's binary_logloss: 0.156113\n",
      "[4]\tvalid_0's auc: 0.83904\tvalid_0's binary_logloss: 0.144173\tvalid_1's auc: 0.831417\tvalid_1's binary_logloss: 0.153186\n",
      "[5]\tvalid_0's auc: 0.841964\tvalid_0's binary_logloss: 0.141745\tvalid_1's auc: 0.834593\tvalid_1's binary_logloss: 0.150797\n",
      "[6]\tvalid_0's auc: 0.845253\tvalid_0's binary_logloss: 0.139712\tvalid_1's auc: 0.836659\tvalid_1's binary_logloss: 0.149062\n",
      "[7]\tvalid_0's auc: 0.846545\tvalid_0's binary_logloss: 0.138053\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.147537\n",
      "[8]\tvalid_0's auc: 0.848885\tvalid_0's binary_logloss: 0.1366\tvalid_1's auc: 0.838153\tvalid_1's binary_logloss: 0.146268\n",
      "[9]\tvalid_0's auc: 0.850839\tvalid_0's binary_logloss: 0.135205\tvalid_1's auc: 0.839816\tvalid_1's binary_logloss: 0.145097\n",
      "[10]\tvalid_0's auc: 0.851902\tvalid_0's binary_logloss: 0.134136\tvalid_1's auc: 0.839977\tvalid_1's binary_logloss: 0.144182\n",
      "[11]\tvalid_0's auc: 0.853188\tvalid_0's binary_logloss: 0.133195\tvalid_1's auc: 0.840379\tvalid_1's binary_logloss: 0.143374\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[13]\tvalid_0's auc: 0.857693\tvalid_0's binary_logloss: 0.131411\tvalid_1's auc: 0.840669\tvalid_1's binary_logloss: 0.142221\n",
      "[14]\tvalid_0's auc: 0.859427\tvalid_0's binary_logloss: 0.130627\tvalid_1's auc: 0.840024\tvalid_1's binary_logloss: 0.141818\n",
      "[15]\tvalid_0's auc: 0.861064\tvalid_0's binary_logloss: 0.12997\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.141407\n",
      "[16]\tvalid_0's auc: 0.861905\tvalid_0's binary_logloss: 0.12935\tvalid_1's auc: 0.839151\tvalid_1's binary_logloss: 0.141108\n",
      "[17]\tvalid_0's auc: 0.863357\tvalid_0's binary_logloss: 0.128765\tvalid_1's auc: 0.839205\tvalid_1's binary_logloss: 0.14086\n",
      "[18]\tvalid_0's auc: 0.865057\tvalid_0's binary_logloss: 0.128197\tvalid_1's auc: 0.838756\tvalid_1's binary_logloss: 0.140615\n",
      "[19]\tvalid_0's auc: 0.866322\tvalid_0's binary_logloss: 0.127685\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.140439\n",
      "[20]\tvalid_0's auc: 0.867327\tvalid_0's binary_logloss: 0.127201\tvalid_1's auc: 0.838595\tvalid_1's binary_logloss: 0.140208\n",
      "[21]\tvalid_0's auc: 0.868281\tvalid_0's binary_logloss: 0.126821\tvalid_1's auc: 0.83842\tvalid_1's binary_logloss: 0.140081\n",
      "[22]\tvalid_0's auc: 0.869333\tvalid_0's binary_logloss: 0.126397\tvalid_1's auc: 0.838291\tvalid_1's binary_logloss: 0.139941\n",
      "[23]\tvalid_0's auc: 0.870664\tvalid_0's binary_logloss: 0.125953\tvalid_1's auc: 0.837637\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.871541\tvalid_0's binary_logloss: 0.125585\tvalid_1's auc: 0.837144\tvalid_1's binary_logloss: 0.139915\n",
      "[25]\tvalid_0's auc: 0.872827\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837438\tvalid_1's binary_logloss: 0.139775\n",
      "[26]\tvalid_0's auc: 0.873522\tvalid_0's binary_logloss: 0.12487\tvalid_1's auc: 0.83729\tvalid_1's binary_logloss: 0.139751\n",
      "[27]\tvalid_0's auc: 0.874428\tvalid_0's binary_logloss: 0.124521\tvalid_1's auc: 0.837295\tvalid_1's binary_logloss: 0.139667\n",
      "[28]\tvalid_0's auc: 0.875453\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.836916\tvalid_1's binary_logloss: 0.139693\n",
      "[29]\tvalid_0's auc: 0.876968\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.836543\tvalid_1's binary_logloss: 0.139692\n",
      "[30]\tvalid_0's auc: 0.878211\tvalid_0's binary_logloss: 0.123513\tvalid_1's auc: 0.836768\tvalid_1's binary_logloss: 0.139653\n",
      "[31]\tvalid_0's auc: 0.879123\tvalid_0's binary_logloss: 0.123238\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.879609\tvalid_0's binary_logloss: 0.122982\tvalid_1's auc: 0.836481\tvalid_1's binary_logloss: 0.139632\n",
      "[33]\tvalid_0's auc: 0.880297\tvalid_0's binary_logloss: 0.122728\tvalid_1's auc: 0.8369\tvalid_1's binary_logloss: 0.139575\n",
      "[34]\tvalid_0's auc: 0.881002\tvalid_0's binary_logloss: 0.122492\tvalid_1's auc: 0.836762\tvalid_1's binary_logloss: 0.139536\n",
      "[35]\tvalid_0's auc: 0.881621\tvalid_0's binary_logloss: 0.122231\tvalid_1's auc: 0.836948\tvalid_1's binary_logloss: 0.139471\n",
      "[36]\tvalid_0's auc: 0.882178\tvalid_0's binary_logloss: 0.121993\tvalid_1's auc: 0.83713\tvalid_1's binary_logloss: 0.139418\n",
      "[37]\tvalid_0's auc: 0.882783\tvalid_0's binary_logloss: 0.121741\tvalid_1's auc: 0.837135\tvalid_1's binary_logloss: 0.139368\n",
      "[38]\tvalid_0's auc: 0.88336\tvalid_0's binary_logloss: 0.121507\tvalid_1's auc: 0.836861\tvalid_1's binary_logloss: 0.139431\n",
      "[39]\tvalid_0's auc: 0.883753\tvalid_0's binary_logloss: 0.121298\tvalid_1's auc: 0.836288\tvalid_1's binary_logloss: 0.139548\n",
      "[40]\tvalid_0's auc: 0.884325\tvalid_0's binary_logloss: 0.121031\tvalid_1's auc: 0.83612\tvalid_1's binary_logloss: 0.139622\n",
      "[41]\tvalid_0's auc: 0.884814\tvalid_0's binary_logloss: 0.12081\tvalid_1's auc: 0.835963\tvalid_1's binary_logloss: 0.139644\n",
      "[42]\tvalid_0's auc: 0.885392\tvalid_0's binary_logloss: 0.120617\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.139624\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.821268\tvalid_0's binary_logloss: 0.156277\tvalid_1's auc: 0.816814\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.828863\tvalid_0's binary_logloss: 0.151005\tvalid_1's auc: 0.821376\tvalid_1's binary_logloss: 0.159886\n",
      "[3]\tvalid_0's auc: 0.837474\tvalid_0's binary_logloss: 0.147149\tvalid_1's auc: 0.828229\tvalid_1's binary_logloss: 0.156519\n",
      "[4]\tvalid_0's auc: 0.842962\tvalid_0's binary_logloss: 0.144152\tvalid_1's auc: 0.829952\tvalid_1's binary_logloss: 0.153687\n",
      "[5]\tvalid_0's auc: 0.84635\tvalid_0's binary_logloss: 0.141643\tvalid_1's auc: 0.834055\tvalid_1's binary_logloss: 0.15137\n",
      "[6]\tvalid_0's auc: 0.849269\tvalid_0's binary_logloss: 0.139637\tvalid_1's auc: 0.834861\tvalid_1's binary_logloss: 0.149513\n",
      "[7]\tvalid_0's auc: 0.851069\tvalid_0's binary_logloss: 0.137899\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.147828\n",
      "[8]\tvalid_0's auc: 0.852425\tvalid_0's binary_logloss: 0.136444\tvalid_1's auc: 0.837615\tvalid_1's binary_logloss: 0.146566\n",
      "[9]\tvalid_0's auc: 0.853725\tvalid_0's binary_logloss: 0.135223\tvalid_1's auc: 0.838944\tvalid_1's binary_logloss: 0.145455\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[11]\tvalid_0's auc: 0.856642\tvalid_0's binary_logloss: 0.13318\tvalid_1's auc: 0.83836\tvalid_1's binary_logloss: 0.143998\n",
      "[12]\tvalid_0's auc: 0.857381\tvalid_0's binary_logloss: 0.13235\tvalid_1's auc: 0.83849\tvalid_1's binary_logloss: 0.143384\n",
      "[13]\tvalid_0's auc: 0.858555\tvalid_0's binary_logloss: 0.13154\tvalid_1's auc: 0.83788\tvalid_1's binary_logloss: 0.142918\n",
      "[14]\tvalid_0's auc: 0.859092\tvalid_0's binary_logloss: 0.130843\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.142521\n",
      "[15]\tvalid_0's auc: 0.860202\tvalid_0's binary_logloss: 0.130174\tvalid_1's auc: 0.836385\tvalid_1's binary_logloss: 0.142279\n",
      "[16]\tvalid_0's auc: 0.861797\tvalid_0's binary_logloss: 0.129525\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.141987\n",
      "[17]\tvalid_0's auc: 0.863207\tvalid_0's binary_logloss: 0.128978\tvalid_1's auc: 0.835285\tvalid_1's binary_logloss: 0.141713\n",
      "[18]\tvalid_0's auc: 0.864433\tvalid_0's binary_logloss: 0.128402\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.141442\n",
      "[19]\tvalid_0's auc: 0.865245\tvalid_0's binary_logloss: 0.127948\tvalid_1's auc: 0.836123\tvalid_1's binary_logloss: 0.1412\n",
      "[20]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.127497\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.140979\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.12703\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.140825\n",
      "[22]\tvalid_0's auc: 0.86828\tvalid_0's binary_logloss: 0.126598\tvalid_1's auc: 0.836515\tvalid_1's binary_logloss: 0.140741\n",
      "[23]\tvalid_0's auc: 0.869182\tvalid_0's binary_logloss: 0.126269\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.140588\n",
      "[24]\tvalid_0's auc: 0.869979\tvalid_0's binary_logloss: 0.125886\tvalid_1's auc: 0.836766\tvalid_1's binary_logloss: 0.140496\n",
      "[25]\tvalid_0's auc: 0.870956\tvalid_0's binary_logloss: 0.125545\tvalid_1's auc: 0.837001\tvalid_1's binary_logloss: 0.140322\n",
      "[26]\tvalid_0's auc: 0.872886\tvalid_0's binary_logloss: 0.125108\tvalid_1's auc: 0.836911\tvalid_1's binary_logloss: 0.140274\n",
      "[27]\tvalid_0's auc: 0.873971\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.140247\n",
      "[28]\tvalid_0's auc: 0.875129\tvalid_0's binary_logloss: 0.124434\tvalid_1's auc: 0.837012\tvalid_1's binary_logloss: 0.140143\n",
      "[29]\tvalid_0's auc: 0.875873\tvalid_0's binary_logloss: 0.12414\tvalid_1's auc: 0.836866\tvalid_1's binary_logloss: 0.140163\n",
      "[30]\tvalid_0's auc: 0.876465\tvalid_0's binary_logloss: 0.123865\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.140195\n",
      "[31]\tvalid_0's auc: 0.877699\tvalid_0's binary_logloss: 0.123521\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.140186\n",
      "[32]\tvalid_0's auc: 0.878492\tvalid_0's binary_logloss: 0.123253\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.140145\n",
      "[33]\tvalid_0's auc: 0.879281\tvalid_0's binary_logloss: 0.122981\tvalid_1's auc: 0.836061\tvalid_1's binary_logloss: 0.140165\n",
      "[34]\tvalid_0's auc: 0.880016\tvalid_0's binary_logloss: 0.12271\tvalid_1's auc: 0.836238\tvalid_1's binary_logloss: 0.140112\n",
      "[35]\tvalid_0's auc: 0.880929\tvalid_0's binary_logloss: 0.122397\tvalid_1's auc: 0.836618\tvalid_1's binary_logloss: 0.140034\n",
      "[36]\tvalid_0's auc: 0.881746\tvalid_0's binary_logloss: 0.122132\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.140013\n",
      "[37]\tvalid_0's auc: 0.882622\tvalid_0's binary_logloss: 0.121854\tvalid_1's auc: 0.836926\tvalid_1's binary_logloss: 0.139982\n",
      "[38]\tvalid_0's auc: 0.883018\tvalid_0's binary_logloss: 0.121618\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.139968\n",
      "[39]\tvalid_0's auc: 0.883857\tvalid_0's binary_logloss: 0.12136\tvalid_1's auc: 0.837075\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.884437\tvalid_0's binary_logloss: 0.121112\tvalid_1's auc: 0.836834\tvalid_1's binary_logloss: 0.139996\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.825972\tvalid_0's binary_logloss: 0.15626\tvalid_1's auc: 0.817426\tvalid_1's binary_logloss: 0.165002\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830735\tvalid_0's binary_logloss: 0.150869\tvalid_1's auc: 0.821832\tvalid_1's binary_logloss: 0.159685\n",
      "[3]\tvalid_0's auc: 0.836213\tvalid_0's binary_logloss: 0.147022\tvalid_1's auc: 0.825847\tvalid_1's binary_logloss: 0.156023\n",
      "[4]\tvalid_0's auc: 0.839911\tvalid_0's binary_logloss: 0.143985\tvalid_1's auc: 0.830159\tvalid_1's binary_logloss: 0.153298\n",
      "[5]\tvalid_0's auc: 0.842712\tvalid_0's binary_logloss: 0.14152\tvalid_1's auc: 0.831253\tvalid_1's binary_logloss: 0.151107\n",
      "[6]\tvalid_0's auc: 0.84576\tvalid_0's binary_logloss: 0.139503\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.149167\n",
      "[7]\tvalid_0's auc: 0.84864\tvalid_0's binary_logloss: 0.137792\tvalid_1's auc: 0.836612\tvalid_1's binary_logloss: 0.147629\n",
      "[8]\tvalid_0's auc: 0.850006\tvalid_0's binary_logloss: 0.136329\tvalid_1's auc: 0.837077\tvalid_1's binary_logloss: 0.146348\n",
      "[9]\tvalid_0's auc: 0.852085\tvalid_0's binary_logloss: 0.135086\tvalid_1's auc: 0.838711\tvalid_1's binary_logloss: 0.145304\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[11]\tvalid_0's auc: 0.856458\tvalid_0's binary_logloss: 0.132947\tvalid_1's auc: 0.838948\tvalid_1's binary_logloss: 0.143547\n",
      "[12]\tvalid_0's auc: 0.857299\tvalid_0's binary_logloss: 0.132061\tvalid_1's auc: 0.839046\tvalid_1's binary_logloss: 0.142873\n",
      "[13]\tvalid_0's auc: 0.858451\tvalid_0's binary_logloss: 0.131304\tvalid_1's auc: 0.838455\tvalid_1's binary_logloss: 0.142387\n",
      "[14]\tvalid_0's auc: 0.860294\tvalid_0's binary_logloss: 0.130565\tvalid_1's auc: 0.838925\tvalid_1's binary_logloss: 0.141904\n",
      "[15]\tvalid_0's auc: 0.861473\tvalid_0's binary_logloss: 0.129923\tvalid_1's auc: 0.838733\tvalid_1's binary_logloss: 0.141518\n",
      "[16]\tvalid_0's auc: 0.862203\tvalid_0's binary_logloss: 0.129333\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.141178\n",
      "[17]\tvalid_0's auc: 0.863233\tvalid_0's binary_logloss: 0.128766\tvalid_1's auc: 0.838823\tvalid_1's binary_logloss: 0.140886\n",
      "[18]\tvalid_0's auc: 0.86399\tvalid_0's binary_logloss: 0.128208\tvalid_1's auc: 0.838336\tvalid_1's binary_logloss: 0.140669\n",
      "[19]\tvalid_0's auc: 0.864707\tvalid_0's binary_logloss: 0.127724\tvalid_1's auc: 0.83783\tvalid_1's binary_logloss: 0.140495\n",
      "[20]\tvalid_0's auc: 0.865576\tvalid_0's binary_logloss: 0.127256\tvalid_1's auc: 0.838481\tvalid_1's binary_logloss: 0.140248\n",
      "[21]\tvalid_0's auc: 0.866846\tvalid_0's binary_logloss: 0.126797\tvalid_1's auc: 0.838182\tvalid_1's binary_logloss: 0.140129\n",
      "[22]\tvalid_0's auc: 0.86837\tvalid_0's binary_logloss: 0.126354\tvalid_1's auc: 0.838279\tvalid_1's binary_logloss: 0.139978\n",
      "[23]\tvalid_0's auc: 0.869587\tvalid_0's binary_logloss: 0.125905\tvalid_1's auc: 0.83825\tvalid_1's binary_logloss: 0.139909\n",
      "[24]\tvalid_0's auc: 0.870532\tvalid_0's binary_logloss: 0.125527\tvalid_1's auc: 0.838429\tvalid_1's binary_logloss: 0.139818\n",
      "[25]\tvalid_0's auc: 0.871628\tvalid_0's binary_logloss: 0.125118\tvalid_1's auc: 0.837908\tvalid_1's binary_logloss: 0.139768\n",
      "[26]\tvalid_0's auc: 0.872816\tvalid_0's binary_logloss: 0.12478\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139683\n",
      "[27]\tvalid_0's auc: 0.873647\tvalid_0's binary_logloss: 0.124448\tvalid_1's auc: 0.837808\tvalid_1's binary_logloss: 0.139669\n",
      "[28]\tvalid_0's auc: 0.874326\tvalid_0's binary_logloss: 0.124117\tvalid_1's auc: 0.837756\tvalid_1's binary_logloss: 0.139635\n",
      "[29]\tvalid_0's auc: 0.875069\tvalid_0's binary_logloss: 0.123826\tvalid_1's auc: 0.838037\tvalid_1's binary_logloss: 0.139565\n",
      "[30]\tvalid_0's auc: 0.876092\tvalid_0's binary_logloss: 0.123541\tvalid_1's auc: 0.838013\tvalid_1's binary_logloss: 0.139571\n",
      "[31]\tvalid_0's auc: 0.877253\tvalid_0's binary_logloss: 0.123222\tvalid_1's auc: 0.838176\tvalid_1's binary_logloss: 0.139525\n",
      "[32]\tvalid_0's auc: 0.877859\tvalid_0's binary_logloss: 0.122952\tvalid_1's auc: 0.837999\tvalid_1's binary_logloss: 0.139539\n",
      "[33]\tvalid_0's auc: 0.878881\tvalid_0's binary_logloss: 0.122669\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139429\n",
      "[34]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.122378\tvalid_1's auc: 0.838388\tvalid_1's binary_logloss: 0.139425\n",
      "[35]\tvalid_0's auc: 0.880711\tvalid_0's binary_logloss: 0.122133\tvalid_1's auc: 0.838795\tvalid_1's binary_logloss: 0.139306\n",
      "[36]\tvalid_0's auc: 0.881763\tvalid_0's binary_logloss: 0.12187\tvalid_1's auc: 0.83878\tvalid_1's binary_logloss: 0.139315\n",
      "[37]\tvalid_0's auc: 0.882612\tvalid_0's binary_logloss: 0.121565\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139322\n",
      "[38]\tvalid_0's auc: 0.883169\tvalid_0's binary_logloss: 0.121312\tvalid_1's auc: 0.838615\tvalid_1's binary_logloss: 0.139324\n",
      "[39]\tvalid_0's auc: 0.883934\tvalid_0's binary_logloss: 0.12102\tvalid_1's auc: 0.838763\tvalid_1's binary_logloss: 0.139293\n",
      "[40]\tvalid_0's auc: 0.884499\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.838547\tvalid_1's binary_logloss: 0.13931\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823084\tvalid_0's binary_logloss: 0.156066\tvalid_1's auc: 0.821793\tvalid_1's binary_logloss: 0.164822\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.827813\tvalid_0's binary_logloss: 0.150805\tvalid_1's auc: 0.823891\tvalid_1's binary_logloss: 0.159732\n",
      "[3]\tvalid_0's auc: 0.836023\tvalid_0's binary_logloss: 0.147035\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.156124\n",
      "[4]\tvalid_0's auc: 0.842374\tvalid_0's binary_logloss: 0.143993\tvalid_1's auc: 0.832801\tvalid_1's binary_logloss: 0.153225\n",
      "[5]\tvalid_0's auc: 0.845121\tvalid_0's binary_logloss: 0.141663\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.15098\n",
      "[6]\tvalid_0's auc: 0.846404\tvalid_0's binary_logloss: 0.139689\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.14912\n",
      "[7]\tvalid_0's auc: 0.848157\tvalid_0's binary_logloss: 0.137973\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.147706\n",
      "[8]\tvalid_0's auc: 0.84954\tvalid_0's binary_logloss: 0.136555\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.146499\n",
      "[9]\tvalid_0's auc: 0.851438\tvalid_0's binary_logloss: 0.135283\tvalid_1's auc: 0.838446\tvalid_1's binary_logloss: 0.145447\n",
      "[10]\tvalid_0's auc: 0.853323\tvalid_0's binary_logloss: 0.134172\tvalid_1's auc: 0.838164\tvalid_1's binary_logloss: 0.144649\n",
      "[11]\tvalid_0's auc: 0.85454\tvalid_0's binary_logloss: 0.133213\tvalid_1's auc: 0.838387\tvalid_1's binary_logloss: 0.143878\n",
      "[12]\tvalid_0's auc: 0.856731\tvalid_0's binary_logloss: 0.1323\tvalid_1's auc: 0.83958\tvalid_1's binary_logloss: 0.143232\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[14]\tvalid_0's auc: 0.859616\tvalid_0's binary_logloss: 0.130695\tvalid_1's auc: 0.839638\tvalid_1's binary_logloss: 0.142197\n",
      "[15]\tvalid_0's auc: 0.86065\tvalid_0's binary_logloss: 0.130019\tvalid_1's auc: 0.839342\tvalid_1's binary_logloss: 0.141867\n",
      "[16]\tvalid_0's auc: 0.861879\tvalid_0's binary_logloss: 0.129426\tvalid_1's auc: 0.839474\tvalid_1's binary_logloss: 0.141484\n",
      "[17]\tvalid_0's auc: 0.86312\tvalid_0's binary_logloss: 0.128865\tvalid_1's auc: 0.838976\tvalid_1's binary_logloss: 0.141297\n",
      "[18]\tvalid_0's auc: 0.864292\tvalid_0's binary_logloss: 0.128302\tvalid_1's auc: 0.839738\tvalid_1's binary_logloss: 0.140953\n",
      "[19]\tvalid_0's auc: 0.86562\tvalid_0's binary_logloss: 0.12782\tvalid_1's auc: 0.839799\tvalid_1's binary_logloss: 0.140766\n",
      "[20]\tvalid_0's auc: 0.866802\tvalid_0's binary_logloss: 0.127322\tvalid_1's auc: 0.839807\tvalid_1's binary_logloss: 0.140536\n",
      "[21]\tvalid_0's auc: 0.868305\tvalid_0's binary_logloss: 0.126848\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.140335\n",
      "[22]\tvalid_0's auc: 0.869367\tvalid_0's binary_logloss: 0.126428\tvalid_1's auc: 0.839045\tvalid_1's binary_logloss: 0.140242\n",
      "[23]\tvalid_0's auc: 0.870018\tvalid_0's binary_logloss: 0.126051\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.140113\n",
      "[24]\tvalid_0's auc: 0.871076\tvalid_0's binary_logloss: 0.125665\tvalid_1's auc: 0.838918\tvalid_1's binary_logloss: 0.139963\n",
      "[25]\tvalid_0's auc: 0.871808\tvalid_0's binary_logloss: 0.12529\tvalid_1's auc: 0.838876\tvalid_1's binary_logloss: 0.139886\n",
      "[26]\tvalid_0's auc: 0.872679\tvalid_0's binary_logloss: 0.124953\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.139811\n",
      "[27]\tvalid_0's auc: 0.873565\tvalid_0's binary_logloss: 0.124623\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139786\n",
      "[28]\tvalid_0's auc: 0.874397\tvalid_0's binary_logloss: 0.124307\tvalid_1's auc: 0.83805\tvalid_1's binary_logloss: 0.139815\n",
      "[29]\tvalid_0's auc: 0.87544\tvalid_0's binary_logloss: 0.124018\tvalid_1's auc: 0.837719\tvalid_1's binary_logloss: 0.139819\n",
      "[30]\tvalid_0's auc: 0.876222\tvalid_0's binary_logloss: 0.123733\tvalid_1's auc: 0.838003\tvalid_1's binary_logloss: 0.139778\n",
      "[31]\tvalid_0's auc: 0.877142\tvalid_0's binary_logloss: 0.12348\tvalid_1's auc: 0.838078\tvalid_1's binary_logloss: 0.139735\n",
      "[32]\tvalid_0's auc: 0.877956\tvalid_0's binary_logloss: 0.123203\tvalid_1's auc: 0.838002\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878477\tvalid_0's binary_logloss: 0.122964\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139665\n",
      "[34]\tvalid_0's auc: 0.879048\tvalid_0's binary_logloss: 0.122668\tvalid_1's auc: 0.838296\tvalid_1's binary_logloss: 0.139589\n",
      "[35]\tvalid_0's auc: 0.879723\tvalid_0's binary_logloss: 0.122403\tvalid_1's auc: 0.838433\tvalid_1's binary_logloss: 0.139597\n",
      "[36]\tvalid_0's auc: 0.881202\tvalid_0's binary_logloss: 0.122123\tvalid_1's auc: 0.838596\tvalid_1's binary_logloss: 0.139557\n",
      "[37]\tvalid_0's auc: 0.882142\tvalid_0's binary_logloss: 0.121861\tvalid_1's auc: 0.838424\tvalid_1's binary_logloss: 0.139578\n",
      "[38]\tvalid_0's auc: 0.882706\tvalid_0's binary_logloss: 0.121634\tvalid_1's auc: 0.838625\tvalid_1's binary_logloss: 0.139548\n",
      "[39]\tvalid_0's auc: 0.883054\tvalid_0's binary_logloss: 0.121421\tvalid_1's auc: 0.838452\tvalid_1's binary_logloss: 0.139609\n",
      "[40]\tvalid_0's auc: 0.883797\tvalid_0's binary_logloss: 0.121128\tvalid_1's auc: 0.838612\tvalid_1's binary_logloss: 0.139576\n",
      "[41]\tvalid_0's auc: 0.884595\tvalid_0's binary_logloss: 0.120862\tvalid_1's auc: 0.838672\tvalid_1's binary_logloss: 0.139551\n",
      "[42]\tvalid_0's auc: 0.885101\tvalid_0's binary_logloss: 0.120643\tvalid_1's auc: 0.839085\tvalid_1's binary_logloss: 0.139462\n",
      "[43]\tvalid_0's auc: 0.885377\tvalid_0's binary_logloss: 0.120471\tvalid_1's auc: 0.838989\tvalid_1's binary_logloss: 0.13949\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823422\tvalid_0's binary_logloss: 0.156446\tvalid_1's auc: 0.819043\tvalid_1's binary_logloss: 0.165337\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830391\tvalid_0's binary_logloss: 0.151103\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.160151\n",
      "[3]\tvalid_0's auc: 0.836251\tvalid_0's binary_logloss: 0.14724\tvalid_1's auc: 0.829717\tvalid_1's binary_logloss: 0.156452\n",
      "[4]\tvalid_0's auc: 0.842516\tvalid_0's binary_logloss: 0.144162\tvalid_1's auc: 0.832695\tvalid_1's binary_logloss: 0.15358\n",
      "[5]\tvalid_0's auc: 0.846316\tvalid_0's binary_logloss: 0.141636\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.151246\n",
      "[6]\tvalid_0's auc: 0.847998\tvalid_0's binary_logloss: 0.139517\tvalid_1's auc: 0.836546\tvalid_1's binary_logloss: 0.149374\n",
      "[7]\tvalid_0's auc: 0.849074\tvalid_0's binary_logloss: 0.13782\tvalid_1's auc: 0.838333\tvalid_1's binary_logloss: 0.147794\n",
      "[8]\tvalid_0's auc: 0.85\tvalid_0's binary_logloss: 0.136391\tvalid_1's auc: 0.838986\tvalid_1's binary_logloss: 0.146497\n",
      "[9]\tvalid_0's auc: 0.851546\tvalid_0's binary_logloss: 0.135138\tvalid_1's auc: 0.839435\tvalid_1's binary_logloss: 0.145445\n",
      "[10]\tvalid_0's auc: 0.852573\tvalid_0's binary_logloss: 0.134059\tvalid_1's auc: 0.839729\tvalid_1's binary_logloss: 0.144614\n",
      "[11]\tvalid_0's auc: 0.854408\tvalid_0's binary_logloss: 0.133048\tvalid_1's auc: 0.840015\tvalid_1's binary_logloss: 0.143842\n",
      "[12]\tvalid_0's auc: 0.857486\tvalid_0's binary_logloss: 0.132117\tvalid_1's auc: 0.83955\tvalid_1's binary_logloss: 0.143278\n",
      "[13]\tvalid_0's auc: 0.859425\tvalid_0's binary_logloss: 0.131314\tvalid_1's auc: 0.840426\tvalid_1's binary_logloss: 0.142719\n",
      "[14]\tvalid_0's auc: 0.861454\tvalid_0's binary_logloss: 0.130495\tvalid_1's auc: 0.840751\tvalid_1's binary_logloss: 0.14226\n",
      "[15]\tvalid_0's auc: 0.862973\tvalid_0's binary_logloss: 0.12978\tvalid_1's auc: 0.840328\tvalid_1's binary_logloss: 0.14183\n",
      "[16]\tvalid_0's auc: 0.864608\tvalid_0's binary_logloss: 0.129092\tvalid_1's auc: 0.839958\tvalid_1's binary_logloss: 0.14153\n",
      "[17]\tvalid_0's auc: 0.865394\tvalid_0's binary_logloss: 0.128538\tvalid_1's auc: 0.840045\tvalid_1's binary_logloss: 0.141215\n",
      "[18]\tvalid_0's auc: 0.867204\tvalid_0's binary_logloss: 0.127947\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.1409\n",
      "[19]\tvalid_0's auc: 0.868095\tvalid_0's binary_logloss: 0.127461\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.14074\n",
      "[20]\tvalid_0's auc: 0.86902\tvalid_0's binary_logloss: 0.126956\tvalid_1's auc: 0.840596\tvalid_1's binary_logloss: 0.140606\n",
      "[21]\tvalid_0's auc: 0.869954\tvalid_0's binary_logloss: 0.126491\tvalid_1's auc: 0.840559\tvalid_1's binary_logloss: 0.140425\n",
      "[22]\tvalid_0's auc: 0.870971\tvalid_0's binary_logloss: 0.126075\tvalid_1's auc: 0.840789\tvalid_1's binary_logloss: 0.140251\n",
      "[23]\tvalid_0's auc: 0.872384\tvalid_0's binary_logloss: 0.125599\tvalid_1's auc: 0.840267\tvalid_1's binary_logloss: 0.14022\n",
      "[24]\tvalid_0's auc: 0.873433\tvalid_0's binary_logloss: 0.125215\tvalid_1's auc: 0.840763\tvalid_1's binary_logloss: 0.140023\n",
      "[25]\tvalid_0's auc: 0.874094\tvalid_0's binary_logloss: 0.124834\tvalid_1's auc: 0.840782\tvalid_1's binary_logloss: 0.139927\n",
      "[26]\tvalid_0's auc: 0.875299\tvalid_0's binary_logloss: 0.12446\tvalid_1's auc: 0.840852\tvalid_1's binary_logloss: 0.139864\n",
      "[27]\tvalid_0's auc: 0.875863\tvalid_0's binary_logloss: 0.124178\tvalid_1's auc: 0.840905\tvalid_1's binary_logloss: 0.139751\n",
      "[28]\tvalid_0's auc: 0.876477\tvalid_0's binary_logloss: 0.123899\tvalid_1's auc: 0.840828\tvalid_1's binary_logloss: 0.139688\n",
      "[29]\tvalid_0's auc: 0.877436\tvalid_0's binary_logloss: 0.123585\tvalid_1's auc: 0.840653\tvalid_1's binary_logloss: 0.139596\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[31]\tvalid_0's auc: 0.879246\tvalid_0's binary_logloss: 0.122979\tvalid_1's auc: 0.840819\tvalid_1's binary_logloss: 0.139442\n",
      "[32]\tvalid_0's auc: 0.880496\tvalid_0's binary_logloss: 0.122664\tvalid_1's auc: 0.840531\tvalid_1's binary_logloss: 0.139452\n",
      "[33]\tvalid_0's auc: 0.881439\tvalid_0's binary_logloss: 0.122371\tvalid_1's auc: 0.840279\tvalid_1's binary_logloss: 0.139455\n",
      "[34]\tvalid_0's auc: 0.882347\tvalid_0's binary_logloss: 0.122119\tvalid_1's auc: 0.840374\tvalid_1's binary_logloss: 0.139423\n",
      "[35]\tvalid_0's auc: 0.883154\tvalid_0's binary_logloss: 0.121847\tvalid_1's auc: 0.840528\tvalid_1's binary_logloss: 0.139369\n",
      "[36]\tvalid_0's auc: 0.883941\tvalid_0's binary_logloss: 0.121532\tvalid_1's auc: 0.840858\tvalid_1's binary_logloss: 0.139284\n",
      "[37]\tvalid_0's auc: 0.884407\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.840641\tvalid_1's binary_logloss: 0.139325\n",
      "[38]\tvalid_0's auc: 0.885324\tvalid_0's binary_logloss: 0.121016\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.13934\n",
      "[39]\tvalid_0's auc: 0.885824\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.840244\tvalid_1's binary_logloss: 0.139346\n",
      "[40]\tvalid_0's auc: 0.886492\tvalid_0's binary_logloss: 0.120515\tvalid_1's auc: 0.84003\tvalid_1's binary_logloss: 0.139395\n",
      "[41]\tvalid_0's auc: 0.887212\tvalid_0's binary_logloss: 0.120235\tvalid_1's auc: 0.839933\tvalid_1's binary_logloss: 0.139397\n",
      "[42]\tvalid_0's auc: 0.887679\tvalid_0's binary_logloss: 0.120004\tvalid_1's auc: 0.839795\tvalid_1's binary_logloss: 0.139391\n",
      "[43]\tvalid_0's auc: 0.88855\tvalid_0's binary_logloss: 0.119787\tvalid_1's auc: 0.839567\tvalid_1's binary_logloss: 0.139426\n",
      "[44]\tvalid_0's auc: 0.888918\tvalid_0's binary_logloss: 0.119598\tvalid_1's auc: 0.839591\tvalid_1's binary_logloss: 0.139427\n",
      "[45]\tvalid_0's auc: 0.889615\tvalid_0's binary_logloss: 0.119335\tvalid_1's auc: 0.839609\tvalid_1's binary_logloss: 0.139412\n",
      "[46]\tvalid_0's auc: 0.890166\tvalid_0's binary_logloss: 0.119099\tvalid_1's auc: 0.839346\tvalid_1's binary_logloss: 0.139475\n",
      "[47]\tvalid_0's auc: 0.890678\tvalid_0's binary_logloss: 0.118869\tvalid_1's auc: 0.839761\tvalid_1's binary_logloss: 0.1394\n",
      "[48]\tvalid_0's auc: 0.891058\tvalid_0's binary_logloss: 0.118665\tvalid_1's auc: 0.839755\tvalid_1's binary_logloss: 0.139409\n",
      "[49]\tvalid_0's auc: 0.891635\tvalid_0's binary_logloss: 0.118425\tvalid_1's auc: 0.839754\tvalid_1's binary_logloss: 0.139428\n",
      "[50]\tvalid_0's auc: 0.892346\tvalid_0's binary_logloss: 0.118168\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.139501\n",
      "[51]\tvalid_0's auc: 0.892736\tvalid_0's binary_logloss: 0.117984\tvalid_1's auc: 0.839121\tvalid_1's binary_logloss: 0.139524\n",
      "[52]\tvalid_0's auc: 0.893171\tvalid_0's binary_logloss: 0.117764\tvalid_1's auc: 0.838794\tvalid_1's binary_logloss: 0.139586\n",
      "[53]\tvalid_0's auc: 0.893573\tvalid_0's binary_logloss: 0.117568\tvalid_1's auc: 0.838694\tvalid_1's binary_logloss: 0.139581\n",
      "[54]\tvalid_0's auc: 0.894147\tvalid_0's binary_logloss: 0.117322\tvalid_1's auc: 0.838487\tvalid_1's binary_logloss: 0.139606\n",
      "[55]\tvalid_0's auc: 0.894518\tvalid_0's binary_logloss: 0.117157\tvalid_1's auc: 0.838831\tvalid_1's binary_logloss: 0.139538\n",
      "[56]\tvalid_0's auc: 0.894919\tvalid_0's binary_logloss: 0.116983\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139562\n",
      "[57]\tvalid_0's auc: 0.895096\tvalid_0's binary_logloss: 0.116832\tvalid_1's auc: 0.838982\tvalid_1's binary_logloss: 0.139544\n",
      "[58]\tvalid_0's auc: 0.895448\tvalid_0's binary_logloss: 0.116643\tvalid_1's auc: 0.839062\tvalid_1's binary_logloss: 0.139518\n",
      "[59]\tvalid_0's auc: 0.895699\tvalid_0's binary_logloss: 0.116514\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.139543\n",
      "[60]\tvalid_0's auc: 0.896178\tvalid_0's binary_logloss: 0.116313\tvalid_1's auc: 0.838833\tvalid_1's binary_logloss: 0.1396\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.832025\tvalid_0's binary_logloss: 0.155465\tvalid_1's auc: 0.820076\tvalid_1's binary_logloss: 0.164546\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.844878\tvalid_0's binary_logloss: 0.14969\tvalid_1's auc: 0.828857\tvalid_1's binary_logloss: 0.159283\n",
      "[3]\tvalid_0's auc: 0.848608\tvalid_0's binary_logloss: 0.145495\tvalid_1's auc: 0.831668\tvalid_1's binary_logloss: 0.155726\n",
      "[4]\tvalid_0's auc: 0.85412\tvalid_0's binary_logloss: 0.142244\tvalid_1's auc: 0.832954\tvalid_1's binary_logloss: 0.153013\n",
      "[5]\tvalid_0's auc: 0.856985\tvalid_0's binary_logloss: 0.139541\tvalid_1's auc: 0.834294\tvalid_1's binary_logloss: 0.150762\n",
      "[6]\tvalid_0's auc: 0.860318\tvalid_0's binary_logloss: 0.137315\tvalid_1's auc: 0.834439\tvalid_1's binary_logloss: 0.148891\n",
      "[7]\tvalid_0's auc: 0.862354\tvalid_0's binary_logloss: 0.135314\tvalid_1's auc: 0.835254\tvalid_1's binary_logloss: 0.147306\n",
      "[8]\tvalid_0's auc: 0.864507\tvalid_0's binary_logloss: 0.133588\tvalid_1's auc: 0.834413\tvalid_1's binary_logloss: 0.146246\n",
      "[9]\tvalid_0's auc: 0.866506\tvalid_0's binary_logloss: 0.132094\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.14517\n",
      "[10]\tvalid_0's auc: 0.867622\tvalid_0's binary_logloss: 0.130807\tvalid_1's auc: 0.835059\tvalid_1's binary_logloss: 0.144333\n",
      "[11]\tvalid_0's auc: 0.869595\tvalid_0's binary_logloss: 0.12963\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.143624\n",
      "[12]\tvalid_0's auc: 0.871732\tvalid_0's binary_logloss: 0.128488\tvalid_1's auc: 0.837004\tvalid_1's binary_logloss: 0.142969\n",
      "[13]\tvalid_0's auc: 0.874689\tvalid_0's binary_logloss: 0.127457\tvalid_1's auc: 0.837217\tvalid_1's binary_logloss: 0.142409\n",
      "[14]\tvalid_0's auc: 0.876111\tvalid_0's binary_logloss: 0.126511\tvalid_1's auc: 0.837232\tvalid_1's binary_logloss: 0.141993\n",
      "[15]\tvalid_0's auc: 0.87877\tvalid_0's binary_logloss: 0.12553\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.141557\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[17]\tvalid_0's auc: 0.881444\tvalid_0's binary_logloss: 0.123911\tvalid_1's auc: 0.836877\tvalid_1's binary_logloss: 0.141158\n",
      "[18]\tvalid_0's auc: 0.882597\tvalid_0's binary_logloss: 0.123216\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.140956\n",
      "[19]\tvalid_0's auc: 0.884069\tvalid_0's binary_logloss: 0.1225\tvalid_1's auc: 0.836798\tvalid_1's binary_logloss: 0.140747\n",
      "[20]\tvalid_0's auc: 0.885553\tvalid_0's binary_logloss: 0.121835\tvalid_1's auc: 0.837335\tvalid_1's binary_logloss: 0.140578\n",
      "[21]\tvalid_0's auc: 0.886758\tvalid_0's binary_logloss: 0.121199\tvalid_1's auc: 0.837053\tvalid_1's binary_logloss: 0.1405\n",
      "[22]\tvalid_0's auc: 0.888245\tvalid_0's binary_logloss: 0.120566\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.140423\n",
      "[23]\tvalid_0's auc: 0.889287\tvalid_0's binary_logloss: 0.119999\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.140319\n",
      "[24]\tvalid_0's auc: 0.890242\tvalid_0's binary_logloss: 0.119535\tvalid_1's auc: 0.837226\tvalid_1's binary_logloss: 0.140192\n",
      "[25]\tvalid_0's auc: 0.89128\tvalid_0's binary_logloss: 0.119025\tvalid_1's auc: 0.836975\tvalid_1's binary_logloss: 0.140152\n",
      "[26]\tvalid_0's auc: 0.892936\tvalid_0's binary_logloss: 0.118515\tvalid_1's auc: 0.836466\tvalid_1's binary_logloss: 0.14011\n",
      "[27]\tvalid_0's auc: 0.894014\tvalid_0's binary_logloss: 0.118046\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140163\n",
      "[28]\tvalid_0's auc: 0.895806\tvalid_0's binary_logloss: 0.1175\tvalid_1's auc: 0.835987\tvalid_1's binary_logloss: 0.1401\n",
      "[29]\tvalid_0's auc: 0.896704\tvalid_0's binary_logloss: 0.117069\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140035\n",
      "[30]\tvalid_0's auc: 0.897739\tvalid_0's binary_logloss: 0.116577\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.139877\n",
      "[31]\tvalid_0's auc: 0.898365\tvalid_0's binary_logloss: 0.116187\tvalid_1's auc: 0.836258\tvalid_1's binary_logloss: 0.139893\n",
      "[32]\tvalid_0's auc: 0.899428\tvalid_0's binary_logloss: 0.115755\tvalid_1's auc: 0.836228\tvalid_1's binary_logloss: 0.139825\n",
      "[33]\tvalid_0's auc: 0.900129\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836132\tvalid_1's binary_logloss: 0.139815\n",
      "[34]\tvalid_0's auc: 0.900819\tvalid_0's binary_logloss: 0.115047\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.139786\n",
      "[35]\tvalid_0's auc: 0.901929\tvalid_0's binary_logloss: 0.114682\tvalid_1's auc: 0.836241\tvalid_1's binary_logloss: 0.139758\n",
      "[36]\tvalid_0's auc: 0.902923\tvalid_0's binary_logloss: 0.114287\tvalid_1's auc: 0.836594\tvalid_1's binary_logloss: 0.139739\n",
      "[37]\tvalid_0's auc: 0.903583\tvalid_0's binary_logloss: 0.113893\tvalid_1's auc: 0.836319\tvalid_1's binary_logloss: 0.139831\n",
      "[38]\tvalid_0's auc: 0.904289\tvalid_0's binary_logloss: 0.113536\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.139874\n",
      "[39]\tvalid_0's auc: 0.904948\tvalid_0's binary_logloss: 0.113207\tvalid_1's auc: 0.835797\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.905808\tvalid_0's binary_logloss: 0.112811\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.139967\n",
      "[41]\tvalid_0's auc: 0.906507\tvalid_0's binary_logloss: 0.112548\tvalid_1's auc: 0.835793\tvalid_1's binary_logloss: 0.139996\n",
      "[42]\tvalid_0's auc: 0.907263\tvalid_0's binary_logloss: 0.112199\tvalid_1's auc: 0.835583\tvalid_1's binary_logloss: 0.140069\n",
      "[43]\tvalid_0's auc: 0.907622\tvalid_0's binary_logloss: 0.111883\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.140122\n",
      "[44]\tvalid_0's auc: 0.908342\tvalid_0's binary_logloss: 0.111608\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.140227\n",
      "[45]\tvalid_0's auc: 0.908935\tvalid_0's binary_logloss: 0.111287\tvalid_1's auc: 0.834854\tvalid_1's binary_logloss: 0.140271\n",
      "[46]\tvalid_0's auc: 0.910346\tvalid_0's binary_logloss: 0.110886\tvalid_1's auc: 0.834699\tvalid_1's binary_logloss: 0.140295\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.832082\tvalid_0's binary_logloss: 0.155469\tvalid_1's auc: 0.814834\tvalid_1's binary_logloss: 0.164811\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840358\tvalid_0's binary_logloss: 0.149705\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.159739\n",
      "[3]\tvalid_0's auc: 0.846958\tvalid_0's binary_logloss: 0.145462\tvalid_1's auc: 0.829037\tvalid_1's binary_logloss: 0.155963\n",
      "[4]\tvalid_0's auc: 0.850608\tvalid_0's binary_logloss: 0.142192\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.153305\n",
      "[5]\tvalid_0's auc: 0.857054\tvalid_0's binary_logloss: 0.139496\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.150999\n",
      "[6]\tvalid_0's auc: 0.860917\tvalid_0's binary_logloss: 0.137183\tvalid_1's auc: 0.837251\tvalid_1's binary_logloss: 0.149102\n",
      "[7]\tvalid_0's auc: 0.862765\tvalid_0's binary_logloss: 0.135234\tvalid_1's auc: 0.838397\tvalid_1's binary_logloss: 0.14754\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[9]\tvalid_0's auc: 0.866709\tvalid_0's binary_logloss: 0.132066\tvalid_1's auc: 0.838734\tvalid_1's binary_logloss: 0.145324\n",
      "[10]\tvalid_0's auc: 0.868899\tvalid_0's binary_logloss: 0.130682\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.144425\n",
      "[11]\tvalid_0's auc: 0.87095\tvalid_0's binary_logloss: 0.129509\tvalid_1's auc: 0.837304\tvalid_1's binary_logloss: 0.143844\n",
      "[12]\tvalid_0's auc: 0.872258\tvalid_0's binary_logloss: 0.128409\tvalid_1's auc: 0.83669\tvalid_1's binary_logloss: 0.143316\n",
      "[13]\tvalid_0's auc: 0.874037\tvalid_0's binary_logloss: 0.127397\tvalid_1's auc: 0.835346\tvalid_1's binary_logloss: 0.142981\n",
      "[14]\tvalid_0's auc: 0.875949\tvalid_0's binary_logloss: 0.126455\tvalid_1's auc: 0.835276\tvalid_1's binary_logloss: 0.142607\n",
      "[15]\tvalid_0's auc: 0.877382\tvalid_0's binary_logloss: 0.125645\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.142362\n",
      "[16]\tvalid_0's auc: 0.878987\tvalid_0's binary_logloss: 0.124805\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.142102\n",
      "[17]\tvalid_0's auc: 0.880532\tvalid_0's binary_logloss: 0.124054\tvalid_1's auc: 0.833893\tvalid_1's binary_logloss: 0.141884\n",
      "[18]\tvalid_0's auc: 0.882045\tvalid_0's binary_logloss: 0.123344\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.141697\n",
      "[19]\tvalid_0's auc: 0.883566\tvalid_0's binary_logloss: 0.122594\tvalid_1's auc: 0.832707\tvalid_1's binary_logloss: 0.141615\n",
      "[20]\tvalid_0's auc: 0.885585\tvalid_0's binary_logloss: 0.121869\tvalid_1's auc: 0.833151\tvalid_1's binary_logloss: 0.141426\n",
      "[21]\tvalid_0's auc: 0.887553\tvalid_0's binary_logloss: 0.121164\tvalid_1's auc: 0.834052\tvalid_1's binary_logloss: 0.141225\n",
      "[22]\tvalid_0's auc: 0.88866\tvalid_0's binary_logloss: 0.120577\tvalid_1's auc: 0.834098\tvalid_1's binary_logloss: 0.141029\n",
      "[23]\tvalid_0's auc: 0.889845\tvalid_0's binary_logloss: 0.11997\tvalid_1's auc: 0.833894\tvalid_1's binary_logloss: 0.140951\n",
      "[24]\tvalid_0's auc: 0.890796\tvalid_0's binary_logloss: 0.119485\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.140844\n",
      "[25]\tvalid_0's auc: 0.89199\tvalid_0's binary_logloss: 0.118928\tvalid_1's auc: 0.833906\tvalid_1's binary_logloss: 0.140917\n",
      "[26]\tvalid_0's auc: 0.893398\tvalid_0's binary_logloss: 0.118364\tvalid_1's auc: 0.834288\tvalid_1's binary_logloss: 0.140784\n",
      "[27]\tvalid_0's auc: 0.894509\tvalid_0's binary_logloss: 0.117887\tvalid_1's auc: 0.834364\tvalid_1's binary_logloss: 0.140677\n",
      "[28]\tvalid_0's auc: 0.895524\tvalid_0's binary_logloss: 0.117424\tvalid_1's auc: 0.834009\tvalid_1's binary_logloss: 0.140715\n",
      "[29]\tvalid_0's auc: 0.896654\tvalid_0's binary_logloss: 0.116949\tvalid_1's auc: 0.833704\tvalid_1's binary_logloss: 0.140719\n",
      "[30]\tvalid_0's auc: 0.897948\tvalid_0's binary_logloss: 0.116488\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140635\n",
      "[31]\tvalid_0's auc: 0.898781\tvalid_0's binary_logloss: 0.116069\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140671\n",
      "[32]\tvalid_0's auc: 0.90009\tvalid_0's binary_logloss: 0.115625\tvalid_1's auc: 0.83384\tvalid_1's binary_logloss: 0.140667\n",
      "[33]\tvalid_0's auc: 0.901073\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.833911\tvalid_1's binary_logloss: 0.140619\n",
      "[34]\tvalid_0's auc: 0.902228\tvalid_0's binary_logloss: 0.114803\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.140595\n",
      "[35]\tvalid_0's auc: 0.902949\tvalid_0's binary_logloss: 0.114411\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.140641\n",
      "[36]\tvalid_0's auc: 0.90428\tvalid_0's binary_logloss: 0.114027\tvalid_1's auc: 0.833146\tvalid_1's binary_logloss: 0.140714\n",
      "[37]\tvalid_0's auc: 0.90518\tvalid_0's binary_logloss: 0.113632\tvalid_1's auc: 0.833423\tvalid_1's binary_logloss: 0.140663\n",
      "[38]\tvalid_0's auc: 0.905995\tvalid_0's binary_logloss: 0.113243\tvalid_1's auc: 0.83347\tvalid_1's binary_logloss: 0.140755\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833919\tvalid_0's binary_logloss: 0.155512\tvalid_1's auc: 0.820637\tvalid_1's binary_logloss: 0.164643\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842002\tvalid_0's binary_logloss: 0.149635\tvalid_1's auc: 0.827273\tvalid_1's binary_logloss: 0.15926\n",
      "[3]\tvalid_0's auc: 0.844839\tvalid_0's binary_logloss: 0.145363\tvalid_1's auc: 0.829328\tvalid_1's binary_logloss: 0.155446\n",
      "[4]\tvalid_0's auc: 0.851547\tvalid_0's binary_logloss: 0.142092\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.152516\n",
      "[5]\tvalid_0's auc: 0.85629\tvalid_0's binary_logloss: 0.139314\tvalid_1's auc: 0.837608\tvalid_1's binary_logloss: 0.150218\n",
      "[6]\tvalid_0's auc: 0.860698\tvalid_0's binary_logloss: 0.137026\tvalid_1's auc: 0.837977\tvalid_1's binary_logloss: 0.148376\n",
      "[7]\tvalid_0's auc: 0.863515\tvalid_0's binary_logloss: 0.135113\tvalid_1's auc: 0.838443\tvalid_1's binary_logloss: 0.146922\n",
      "[8]\tvalid_0's auc: 0.864625\tvalid_0's binary_logloss: 0.133401\tvalid_1's auc: 0.838988\tvalid_1's binary_logloss: 0.145624\n",
      "[9]\tvalid_0's auc: 0.866831\tvalid_0's binary_logloss: 0.131907\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.14464\n",
      "[10]\tvalid_0's auc: 0.868953\tvalid_0's binary_logloss: 0.130539\tvalid_1's auc: 0.83779\tvalid_1's binary_logloss: 0.143795\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[12]\tvalid_0's auc: 0.872964\tvalid_0's binary_logloss: 0.128158\tvalid_1's auc: 0.838184\tvalid_1's binary_logloss: 0.142277\n",
      "[13]\tvalid_0's auc: 0.874758\tvalid_0's binary_logloss: 0.127141\tvalid_1's auc: 0.837972\tvalid_1's binary_logloss: 0.141744\n",
      "[14]\tvalid_0's auc: 0.876311\tvalid_0's binary_logloss: 0.126137\tvalid_1's auc: 0.837484\tvalid_1's binary_logloss: 0.141408\n",
      "[15]\tvalid_0's auc: 0.877968\tvalid_0's binary_logloss: 0.12525\tvalid_1's auc: 0.836581\tvalid_1's binary_logloss: 0.141099\n",
      "[16]\tvalid_0's auc: 0.87963\tvalid_0's binary_logloss: 0.124439\tvalid_1's auc: 0.836006\tvalid_1's binary_logloss: 0.140886\n",
      "[17]\tvalid_0's auc: 0.881659\tvalid_0's binary_logloss: 0.123628\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.140605\n",
      "[18]\tvalid_0's auc: 0.882607\tvalid_0's binary_logloss: 0.122935\tvalid_1's auc: 0.836156\tvalid_1's binary_logloss: 0.140354\n",
      "[19]\tvalid_0's auc: 0.884204\tvalid_0's binary_logloss: 0.122205\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.140094\n",
      "[20]\tvalid_0's auc: 0.88564\tvalid_0's binary_logloss: 0.121562\tvalid_1's auc: 0.836976\tvalid_1's binary_logloss: 0.139982\n",
      "[21]\tvalid_0's auc: 0.886788\tvalid_0's binary_logloss: 0.120948\tvalid_1's auc: 0.83734\tvalid_1's binary_logloss: 0.139793\n",
      "[22]\tvalid_0's auc: 0.888424\tvalid_0's binary_logloss: 0.120314\tvalid_1's auc: 0.83802\tvalid_1's binary_logloss: 0.139623\n",
      "[23]\tvalid_0's auc: 0.889756\tvalid_0's binary_logloss: 0.119797\tvalid_1's auc: 0.837015\tvalid_1's binary_logloss: 0.139653\n",
      "[24]\tvalid_0's auc: 0.891304\tvalid_0's binary_logloss: 0.119202\tvalid_1's auc: 0.837202\tvalid_1's binary_logloss: 0.139584\n",
      "[25]\tvalid_0's auc: 0.892545\tvalid_0's binary_logloss: 0.118664\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.1395\n",
      "[26]\tvalid_0's auc: 0.893944\tvalid_0's binary_logloss: 0.118169\tvalid_1's auc: 0.837371\tvalid_1's binary_logloss: 0.139458\n",
      "[27]\tvalid_0's auc: 0.894982\tvalid_0's binary_logloss: 0.117651\tvalid_1's auc: 0.836907\tvalid_1's binary_logloss: 0.139528\n",
      "[28]\tvalid_0's auc: 0.896304\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837127\tvalid_1's binary_logloss: 0.139491\n",
      "[29]\tvalid_0's auc: 0.89754\tvalid_0's binary_logloss: 0.116665\tvalid_1's auc: 0.837063\tvalid_1's binary_logloss: 0.139497\n",
      "[30]\tvalid_0's auc: 0.898907\tvalid_0's binary_logloss: 0.116238\tvalid_1's auc: 0.836952\tvalid_1's binary_logloss: 0.139457\n",
      "[31]\tvalid_0's auc: 0.89958\tvalid_0's binary_logloss: 0.115802\tvalid_1's auc: 0.837327\tvalid_1's binary_logloss: 0.139384\n",
      "[32]\tvalid_0's auc: 0.900529\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836541\tvalid_1's binary_logloss: 0.139496\n",
      "[33]\tvalid_0's auc: 0.90188\tvalid_0's binary_logloss: 0.114972\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.139413\n",
      "[34]\tvalid_0's auc: 0.902879\tvalid_0's binary_logloss: 0.114528\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.13943\n",
      "[35]\tvalid_0's auc: 0.903932\tvalid_0's binary_logloss: 0.114157\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.139458\n",
      "[36]\tvalid_0's auc: 0.904707\tvalid_0's binary_logloss: 0.113777\tvalid_1's auc: 0.836824\tvalid_1's binary_logloss: 0.139459\n",
      "[37]\tvalid_0's auc: 0.905376\tvalid_0's binary_logloss: 0.113446\tvalid_1's auc: 0.836614\tvalid_1's binary_logloss: 0.139503\n",
      "[38]\tvalid_0's auc: 0.906535\tvalid_0's binary_logloss: 0.11295\tvalid_1's auc: 0.836328\tvalid_1's binary_logloss: 0.139575\n",
      "[39]\tvalid_0's auc: 0.907125\tvalid_0's binary_logloss: 0.112599\tvalid_1's auc: 0.83631\tvalid_1's binary_logloss: 0.139598\n",
      "[40]\tvalid_0's auc: 0.908267\tvalid_0's binary_logloss: 0.112224\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.139675\n",
      "[41]\tvalid_0's auc: 0.908916\tvalid_0's binary_logloss: 0.111848\tvalid_1's auc: 0.835954\tvalid_1's binary_logloss: 0.139752\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.830163\tvalid_0's binary_logloss: 0.155383\tvalid_1's auc: 0.817444\tvalid_1's binary_logloss: 0.164924\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840688\tvalid_0's binary_logloss: 0.14972\tvalid_1's auc: 0.825893\tvalid_1's binary_logloss: 0.159538\n",
      "[3]\tvalid_0's auc: 0.847811\tvalid_0's binary_logloss: 0.145576\tvalid_1's auc: 0.832086\tvalid_1's binary_logloss: 0.155889\n",
      "[4]\tvalid_0's auc: 0.85262\tvalid_0's binary_logloss: 0.142266\tvalid_1's auc: 0.83348\tvalid_1's binary_logloss: 0.153059\n",
      "[5]\tvalid_0's auc: 0.856853\tvalid_0's binary_logloss: 0.139575\tvalid_1's auc: 0.837158\tvalid_1's binary_logloss: 0.150847\n",
      "[6]\tvalid_0's auc: 0.859779\tvalid_0's binary_logloss: 0.13732\tvalid_1's auc: 0.839471\tvalid_1's binary_logloss: 0.148924\n",
      "[7]\tvalid_0's auc: 0.861819\tvalid_0's binary_logloss: 0.135402\tvalid_1's auc: 0.838324\tvalid_1's binary_logloss: 0.147505\n",
      "[8]\tvalid_0's auc: 0.863714\tvalid_0's binary_logloss: 0.133757\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.146279\n",
      "[9]\tvalid_0's auc: 0.864749\tvalid_0's binary_logloss: 0.132364\tvalid_1's auc: 0.838331\tvalid_1's binary_logloss: 0.14529\n",
      "[10]\tvalid_0's auc: 0.866663\tvalid_0's binary_logloss: 0.131026\tvalid_1's auc: 0.837673\tvalid_1's binary_logloss: 0.144419\n",
      "[11]\tvalid_0's auc: 0.868726\tvalid_0's binary_logloss: 0.12984\tvalid_1's auc: 0.838501\tvalid_1's binary_logloss: 0.143675\n",
      "[12]\tvalid_0's auc: 0.871558\tvalid_0's binary_logloss: 0.128733\tvalid_1's auc: 0.838492\tvalid_1's binary_logloss: 0.143092\n",
      "[13]\tvalid_0's auc: 0.873442\tvalid_0's binary_logloss: 0.127675\tvalid_1's auc: 0.839717\tvalid_1's binary_logloss: 0.142342\n",
      "[14]\tvalid_0's auc: 0.875241\tvalid_0's binary_logloss: 0.126727\tvalid_1's auc: 0.839554\tvalid_1's binary_logloss: 0.141894\n",
      "[15]\tvalid_0's auc: 0.877606\tvalid_0's binary_logloss: 0.125834\tvalid_1's auc: 0.839663\tvalid_1's binary_logloss: 0.141484\n",
      "[16]\tvalid_0's auc: 0.878882\tvalid_0's binary_logloss: 0.125061\tvalid_1's auc: 0.840269\tvalid_1's binary_logloss: 0.141121\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[18]\tvalid_0's auc: 0.881171\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.839956\tvalid_1's binary_logloss: 0.14074\n",
      "[19]\tvalid_0's auc: 0.882715\tvalid_0's binary_logloss: 0.12297\tvalid_1's auc: 0.839997\tvalid_1's binary_logloss: 0.140537\n",
      "[20]\tvalid_0's auc: 0.884031\tvalid_0's binary_logloss: 0.122325\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.140381\n",
      "[21]\tvalid_0's auc: 0.885764\tvalid_0's binary_logloss: 0.121625\tvalid_1's auc: 0.839843\tvalid_1's binary_logloss: 0.140197\n",
      "[22]\tvalid_0's auc: 0.887281\tvalid_0's binary_logloss: 0.120983\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140102\n",
      "[23]\tvalid_0's auc: 0.888433\tvalid_0's binary_logloss: 0.120453\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.140039\n",
      "[24]\tvalid_0's auc: 0.890216\tvalid_0's binary_logloss: 0.119857\tvalid_1's auc: 0.839006\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.891521\tvalid_0's binary_logloss: 0.119298\tvalid_1's auc: 0.83887\tvalid_1's binary_logloss: 0.139884\n",
      "[26]\tvalid_0's auc: 0.892429\tvalid_0's binary_logloss: 0.118862\tvalid_1's auc: 0.838468\tvalid_1's binary_logloss: 0.139871\n",
      "[27]\tvalid_0's auc: 0.893299\tvalid_0's binary_logloss: 0.11838\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139845\n",
      "[28]\tvalid_0's auc: 0.894251\tvalid_0's binary_logloss: 0.117957\tvalid_1's auc: 0.837679\tvalid_1's binary_logloss: 0.139855\n",
      "[29]\tvalid_0's auc: 0.895243\tvalid_0's binary_logloss: 0.117508\tvalid_1's auc: 0.837735\tvalid_1's binary_logloss: 0.139821\n",
      "[30]\tvalid_0's auc: 0.896095\tvalid_0's binary_logloss: 0.117089\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139898\n",
      "[31]\tvalid_0's auc: 0.897359\tvalid_0's binary_logloss: 0.116601\tvalid_1's auc: 0.837136\tvalid_1's binary_logloss: 0.139894\n",
      "[32]\tvalid_0's auc: 0.898643\tvalid_0's binary_logloss: 0.11607\tvalid_1's auc: 0.836864\tvalid_1's binary_logloss: 0.139923\n",
      "[33]\tvalid_0's auc: 0.89992\tvalid_0's binary_logloss: 0.115645\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139915\n",
      "[34]\tvalid_0's auc: 0.900901\tvalid_0's binary_logloss: 0.115264\tvalid_1's auc: 0.836791\tvalid_1's binary_logloss: 0.139982\n",
      "[35]\tvalid_0's auc: 0.901751\tvalid_0's binary_logloss: 0.114906\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.139951\n",
      "[36]\tvalid_0's auc: 0.903021\tvalid_0's binary_logloss: 0.114415\tvalid_1's auc: 0.836623\tvalid_1's binary_logloss: 0.139976\n",
      "[37]\tvalid_0's auc: 0.904251\tvalid_0's binary_logloss: 0.114061\tvalid_1's auc: 0.836728\tvalid_1's binary_logloss: 0.139975\n",
      "[38]\tvalid_0's auc: 0.90516\tvalid_0's binary_logloss: 0.113675\tvalid_1's auc: 0.837\tvalid_1's binary_logloss: 0.139923\n",
      "[39]\tvalid_0's auc: 0.90596\tvalid_0's binary_logloss: 0.113263\tvalid_1's auc: 0.837387\tvalid_1's binary_logloss: 0.13986\n",
      "[40]\tvalid_0's auc: 0.906683\tvalid_0's binary_logloss: 0.112912\tvalid_1's auc: 0.837328\tvalid_1's binary_logloss: 0.139857\n",
      "[41]\tvalid_0's auc: 0.907126\tvalid_0's binary_logloss: 0.112589\tvalid_1's auc: 0.836763\tvalid_1's binary_logloss: 0.139978\n",
      "[42]\tvalid_0's auc: 0.907766\tvalid_0's binary_logloss: 0.112228\tvalid_1's auc: 0.836668\tvalid_1's binary_logloss: 0.140037\n",
      "[43]\tvalid_0's auc: 0.908476\tvalid_0's binary_logloss: 0.111878\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.140074\n",
      "[44]\tvalid_0's auc: 0.908965\tvalid_0's binary_logloss: 0.111555\tvalid_1's auc: 0.836825\tvalid_1's binary_logloss: 0.140052\n",
      "[45]\tvalid_0's auc: 0.90954\tvalid_0's binary_logloss: 0.111283\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.140134\n",
      "[46]\tvalid_0's auc: 0.910195\tvalid_0's binary_logloss: 0.111029\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.140137\n",
      "[47]\tvalid_0's auc: 0.910771\tvalid_0's binary_logloss: 0.110662\tvalid_1's auc: 0.836357\tvalid_1's binary_logloss: 0.140222\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833594\tvalid_0's binary_logloss: 0.155635\tvalid_1's auc: 0.820913\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.846048\tvalid_0's binary_logloss: 0.149713\tvalid_1's auc: 0.830646\tvalid_1's binary_logloss: 0.159607\n",
      "[3]\tvalid_0's auc: 0.849539\tvalid_0's binary_logloss: 0.145369\tvalid_1's auc: 0.833531\tvalid_1's binary_logloss: 0.155847\n",
      "[4]\tvalid_0's auc: 0.8529\tvalid_0's binary_logloss: 0.142095\tvalid_1's auc: 0.832813\tvalid_1's binary_logloss: 0.15325\n",
      "[5]\tvalid_0's auc: 0.855497\tvalid_0's binary_logloss: 0.13934\tvalid_1's auc: 0.833555\tvalid_1's binary_logloss: 0.150958\n",
      "[6]\tvalid_0's auc: 0.860603\tvalid_0's binary_logloss: 0.13707\tvalid_1's auc: 0.836476\tvalid_1's binary_logloss: 0.149037\n",
      "[7]\tvalid_0's auc: 0.86401\tvalid_0's binary_logloss: 0.13507\tvalid_1's auc: 0.838639\tvalid_1's binary_logloss: 0.147363\n",
      "[8]\tvalid_0's auc: 0.866327\tvalid_0's binary_logloss: 0.133353\tvalid_1's auc: 0.83917\tvalid_1's binary_logloss: 0.146142\n",
      "[9]\tvalid_0's auc: 0.868666\tvalid_0's binary_logloss: 0.131872\tvalid_1's auc: 0.839119\tvalid_1's binary_logloss: 0.145095\n",
      "[10]\tvalid_0's auc: 0.870055\tvalid_0's binary_logloss: 0.130535\tvalid_1's auc: 0.839769\tvalid_1's binary_logloss: 0.144187\n",
      "[11]\tvalid_0's auc: 0.871923\tvalid_0's binary_logloss: 0.129272\tvalid_1's auc: 0.840793\tvalid_1's binary_logloss: 0.143281\n",
      "[12]\tvalid_0's auc: 0.87487\tvalid_0's binary_logloss: 0.128204\tvalid_1's auc: 0.841107\tvalid_1's binary_logloss: 0.142593\n",
      "[13]\tvalid_0's auc: 0.87716\tvalid_0's binary_logloss: 0.127155\tvalid_1's auc: 0.840555\tvalid_1's binary_logloss: 0.142065\n",
      "[14]\tvalid_0's auc: 0.879344\tvalid_0's binary_logloss: 0.126173\tvalid_1's auc: 0.841197\tvalid_1's binary_logloss: 0.141536\n",
      "[15]\tvalid_0's auc: 0.880521\tvalid_0's binary_logloss: 0.125283\tvalid_1's auc: 0.841423\tvalid_1's binary_logloss: 0.141157\n",
      "[16]\tvalid_0's auc: 0.882066\tvalid_0's binary_logloss: 0.1244\tvalid_1's auc: 0.841461\tvalid_1's binary_logloss: 0.140813\n",
      "[17]\tvalid_0's auc: 0.883582\tvalid_0's binary_logloss: 0.123652\tvalid_1's auc: 0.841626\tvalid_1's binary_logloss: 0.1405\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[19]\tvalid_0's auc: 0.885618\tvalid_0's binary_logloss: 0.122288\tvalid_1's auc: 0.841595\tvalid_1's binary_logloss: 0.140038\n",
      "[20]\tvalid_0's auc: 0.887262\tvalid_0's binary_logloss: 0.12156\tvalid_1's auc: 0.841475\tvalid_1's binary_logloss: 0.13984\n",
      "[21]\tvalid_0's auc: 0.888549\tvalid_0's binary_logloss: 0.120864\tvalid_1's auc: 0.841698\tvalid_1's binary_logloss: 0.139644\n",
      "[22]\tvalid_0's auc: 0.889783\tvalid_0's binary_logloss: 0.120226\tvalid_1's auc: 0.841265\tvalid_1's binary_logloss: 0.139524\n",
      "[23]\tvalid_0's auc: 0.891007\tvalid_0's binary_logloss: 0.119647\tvalid_1's auc: 0.840909\tvalid_1's binary_logloss: 0.139463\n",
      "[24]\tvalid_0's auc: 0.892111\tvalid_0's binary_logloss: 0.11912\tvalid_1's auc: 0.840884\tvalid_1's binary_logloss: 0.13939\n",
      "[25]\tvalid_0's auc: 0.892959\tvalid_0's binary_logloss: 0.118644\tvalid_1's auc: 0.840779\tvalid_1's binary_logloss: 0.139336\n",
      "[26]\tvalid_0's auc: 0.894356\tvalid_0's binary_logloss: 0.118128\tvalid_1's auc: 0.841299\tvalid_1's binary_logloss: 0.139198\n",
      "[27]\tvalid_0's auc: 0.895981\tvalid_0's binary_logloss: 0.117575\tvalid_1's auc: 0.8407\tvalid_1's binary_logloss: 0.139192\n",
      "[28]\tvalid_0's auc: 0.896969\tvalid_0's binary_logloss: 0.11709\tvalid_1's auc: 0.840437\tvalid_1's binary_logloss: 0.139222\n",
      "[29]\tvalid_0's auc: 0.898028\tvalid_0's binary_logloss: 0.116618\tvalid_1's auc: 0.840857\tvalid_1's binary_logloss: 0.139136\n",
      "[30]\tvalid_0's auc: 0.89908\tvalid_0's binary_logloss: 0.116142\tvalid_1's auc: 0.840827\tvalid_1's binary_logloss: 0.139074\n",
      "[31]\tvalid_0's auc: 0.900145\tvalid_0's binary_logloss: 0.115699\tvalid_1's auc: 0.840974\tvalid_1's binary_logloss: 0.138987\n",
      "[32]\tvalid_0's auc: 0.90112\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.840942\tvalid_1's binary_logloss: 0.139024\n",
      "[33]\tvalid_0's auc: 0.901846\tvalid_0's binary_logloss: 0.114793\tvalid_1's auc: 0.840933\tvalid_1's binary_logloss: 0.13904\n",
      "[34]\tvalid_0's auc: 0.902883\tvalid_0's binary_logloss: 0.114387\tvalid_1's auc: 0.840844\tvalid_1's binary_logloss: 0.139066\n",
      "[35]\tvalid_0's auc: 0.903648\tvalid_0's binary_logloss: 0.113998\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.13901\n",
      "[36]\tvalid_0's auc: 0.905129\tvalid_0's binary_logloss: 0.113587\tvalid_1's auc: 0.840769\tvalid_1's binary_logloss: 0.139037\n",
      "[37]\tvalid_0's auc: 0.906133\tvalid_0's binary_logloss: 0.113131\tvalid_1's auc: 0.84035\tvalid_1's binary_logloss: 0.139137\n",
      "[38]\tvalid_0's auc: 0.907\tvalid_0's binary_logloss: 0.112813\tvalid_1's auc: 0.840254\tvalid_1's binary_logloss: 0.139186\n",
      "[39]\tvalid_0's auc: 0.907829\tvalid_0's binary_logloss: 0.112418\tvalid_1's auc: 0.84009\tvalid_1's binary_logloss: 0.139236\n",
      "[40]\tvalid_0's auc: 0.908551\tvalid_0's binary_logloss: 0.112078\tvalid_1's auc: 0.839874\tvalid_1's binary_logloss: 0.139313\n",
      "[41]\tvalid_0's auc: 0.909258\tvalid_0's binary_logloss: 0.111745\tvalid_1's auc: 0.839426\tvalid_1's binary_logloss: 0.139447\n",
      "[42]\tvalid_0's auc: 0.909875\tvalid_0's binary_logloss: 0.111354\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139428\n",
      "[43]\tvalid_0's auc: 0.910434\tvalid_0's binary_logloss: 0.111052\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.139483\n",
      "[44]\tvalid_0's auc: 0.911375\tvalid_0's binary_logloss: 0.110624\tvalid_1's auc: 0.839582\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.912055\tvalid_0's binary_logloss: 0.110372\tvalid_1's auc: 0.839536\tvalid_1's binary_logloss: 0.139546\n",
      "[46]\tvalid_0's auc: 0.912574\tvalid_0's binary_logloss: 0.110057\tvalid_1's auc: 0.83948\tvalid_1's binary_logloss: 0.139584\n",
      "[47]\tvalid_0's auc: 0.91302\tvalid_0's binary_logloss: 0.109723\tvalid_1's auc: 0.839228\tvalid_1's binary_logloss: 0.139685\n",
      "[48]\tvalid_0's auc: 0.913378\tvalid_0's binary_logloss: 0.109457\tvalid_1's auc: 0.839315\tvalid_1's binary_logloss: 0.139695\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.832025\tvalid_0's binary_logloss: 0.155465\tvalid_1's auc: 0.820076\tvalid_1's binary_logloss: 0.164546\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.844878\tvalid_0's binary_logloss: 0.14969\tvalid_1's auc: 0.828857\tvalid_1's binary_logloss: 0.159283\n",
      "[3]\tvalid_0's auc: 0.848608\tvalid_0's binary_logloss: 0.145495\tvalid_1's auc: 0.831668\tvalid_1's binary_logloss: 0.155726\n",
      "[4]\tvalid_0's auc: 0.85412\tvalid_0's binary_logloss: 0.142244\tvalid_1's auc: 0.832954\tvalid_1's binary_logloss: 0.153013\n",
      "[5]\tvalid_0's auc: 0.856985\tvalid_0's binary_logloss: 0.139541\tvalid_1's auc: 0.834294\tvalid_1's binary_logloss: 0.150762\n",
      "[6]\tvalid_0's auc: 0.860318\tvalid_0's binary_logloss: 0.137315\tvalid_1's auc: 0.834439\tvalid_1's binary_logloss: 0.148891\n",
      "[7]\tvalid_0's auc: 0.862354\tvalid_0's binary_logloss: 0.135314\tvalid_1's auc: 0.835254\tvalid_1's binary_logloss: 0.147306\n",
      "[8]\tvalid_0's auc: 0.864507\tvalid_0's binary_logloss: 0.133588\tvalid_1's auc: 0.834413\tvalid_1's binary_logloss: 0.146246\n",
      "[9]\tvalid_0's auc: 0.866506\tvalid_0's binary_logloss: 0.132094\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.14517\n",
      "[10]\tvalid_0's auc: 0.867622\tvalid_0's binary_logloss: 0.130807\tvalid_1's auc: 0.835059\tvalid_1's binary_logloss: 0.144333\n",
      "[11]\tvalid_0's auc: 0.869595\tvalid_0's binary_logloss: 0.12963\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.143624\n",
      "[12]\tvalid_0's auc: 0.871732\tvalid_0's binary_logloss: 0.128488\tvalid_1's auc: 0.837004\tvalid_1's binary_logloss: 0.142969\n",
      "[13]\tvalid_0's auc: 0.874689\tvalid_0's binary_logloss: 0.127457\tvalid_1's auc: 0.837217\tvalid_1's binary_logloss: 0.142409\n",
      "[14]\tvalid_0's auc: 0.876111\tvalid_0's binary_logloss: 0.126511\tvalid_1's auc: 0.837232\tvalid_1's binary_logloss: 0.141993\n",
      "[15]\tvalid_0's auc: 0.87877\tvalid_0's binary_logloss: 0.12553\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.141557\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[17]\tvalid_0's auc: 0.881444\tvalid_0's binary_logloss: 0.123911\tvalid_1's auc: 0.836877\tvalid_1's binary_logloss: 0.141158\n",
      "[18]\tvalid_0's auc: 0.882597\tvalid_0's binary_logloss: 0.123216\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.140956\n",
      "[19]\tvalid_0's auc: 0.884069\tvalid_0's binary_logloss: 0.1225\tvalid_1's auc: 0.836798\tvalid_1's binary_logloss: 0.140747\n",
      "[20]\tvalid_0's auc: 0.885553\tvalid_0's binary_logloss: 0.121835\tvalid_1's auc: 0.837335\tvalid_1's binary_logloss: 0.140578\n",
      "[21]\tvalid_0's auc: 0.886758\tvalid_0's binary_logloss: 0.121199\tvalid_1's auc: 0.837053\tvalid_1's binary_logloss: 0.1405\n",
      "[22]\tvalid_0's auc: 0.888245\tvalid_0's binary_logloss: 0.120566\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.140423\n",
      "[23]\tvalid_0's auc: 0.889287\tvalid_0's binary_logloss: 0.119999\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.140319\n",
      "[24]\tvalid_0's auc: 0.890242\tvalid_0's binary_logloss: 0.119535\tvalid_1's auc: 0.837226\tvalid_1's binary_logloss: 0.140192\n",
      "[25]\tvalid_0's auc: 0.89128\tvalid_0's binary_logloss: 0.119025\tvalid_1's auc: 0.836975\tvalid_1's binary_logloss: 0.140152\n",
      "[26]\tvalid_0's auc: 0.892936\tvalid_0's binary_logloss: 0.118515\tvalid_1's auc: 0.836466\tvalid_1's binary_logloss: 0.14011\n",
      "[27]\tvalid_0's auc: 0.894014\tvalid_0's binary_logloss: 0.118046\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140163\n",
      "[28]\tvalid_0's auc: 0.895806\tvalid_0's binary_logloss: 0.1175\tvalid_1's auc: 0.835987\tvalid_1's binary_logloss: 0.1401\n",
      "[29]\tvalid_0's auc: 0.896704\tvalid_0's binary_logloss: 0.117069\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140035\n",
      "[30]\tvalid_0's auc: 0.897739\tvalid_0's binary_logloss: 0.116577\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.139877\n",
      "[31]\tvalid_0's auc: 0.898365\tvalid_0's binary_logloss: 0.116187\tvalid_1's auc: 0.836258\tvalid_1's binary_logloss: 0.139893\n",
      "[32]\tvalid_0's auc: 0.899428\tvalid_0's binary_logloss: 0.115755\tvalid_1's auc: 0.836228\tvalid_1's binary_logloss: 0.139825\n",
      "[33]\tvalid_0's auc: 0.900129\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836132\tvalid_1's binary_logloss: 0.139815\n",
      "[34]\tvalid_0's auc: 0.900819\tvalid_0's binary_logloss: 0.115047\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.139786\n",
      "[35]\tvalid_0's auc: 0.901929\tvalid_0's binary_logloss: 0.114682\tvalid_1's auc: 0.836241\tvalid_1's binary_logloss: 0.139758\n",
      "[36]\tvalid_0's auc: 0.902923\tvalid_0's binary_logloss: 0.114287\tvalid_1's auc: 0.836594\tvalid_1's binary_logloss: 0.139739\n",
      "[37]\tvalid_0's auc: 0.903583\tvalid_0's binary_logloss: 0.113893\tvalid_1's auc: 0.836319\tvalid_1's binary_logloss: 0.139831\n",
      "[38]\tvalid_0's auc: 0.904289\tvalid_0's binary_logloss: 0.113536\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.139874\n",
      "[39]\tvalid_0's auc: 0.904948\tvalid_0's binary_logloss: 0.113207\tvalid_1's auc: 0.835797\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.905808\tvalid_0's binary_logloss: 0.112811\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.139967\n",
      "[41]\tvalid_0's auc: 0.906507\tvalid_0's binary_logloss: 0.112548\tvalid_1's auc: 0.835793\tvalid_1's binary_logloss: 0.139996\n",
      "[42]\tvalid_0's auc: 0.907263\tvalid_0's binary_logloss: 0.112199\tvalid_1's auc: 0.835583\tvalid_1's binary_logloss: 0.140069\n",
      "[43]\tvalid_0's auc: 0.907622\tvalid_0's binary_logloss: 0.111883\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.140122\n",
      "[44]\tvalid_0's auc: 0.908342\tvalid_0's binary_logloss: 0.111608\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.140227\n",
      "[45]\tvalid_0's auc: 0.908935\tvalid_0's binary_logloss: 0.111287\tvalid_1's auc: 0.834854\tvalid_1's binary_logloss: 0.140271\n",
      "[46]\tvalid_0's auc: 0.910346\tvalid_0's binary_logloss: 0.110886\tvalid_1's auc: 0.834699\tvalid_1's binary_logloss: 0.140295\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.832082\tvalid_0's binary_logloss: 0.155469\tvalid_1's auc: 0.814834\tvalid_1's binary_logloss: 0.164811\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840358\tvalid_0's binary_logloss: 0.149705\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.159739\n",
      "[3]\tvalid_0's auc: 0.846958\tvalid_0's binary_logloss: 0.145462\tvalid_1's auc: 0.829037\tvalid_1's binary_logloss: 0.155963\n",
      "[4]\tvalid_0's auc: 0.850608\tvalid_0's binary_logloss: 0.142192\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.153305\n",
      "[5]\tvalid_0's auc: 0.857054\tvalid_0's binary_logloss: 0.139496\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.150999\n",
      "[6]\tvalid_0's auc: 0.860917\tvalid_0's binary_logloss: 0.137183\tvalid_1's auc: 0.837251\tvalid_1's binary_logloss: 0.149102\n",
      "[7]\tvalid_0's auc: 0.862765\tvalid_0's binary_logloss: 0.135234\tvalid_1's auc: 0.838397\tvalid_1's binary_logloss: 0.14754\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[9]\tvalid_0's auc: 0.866709\tvalid_0's binary_logloss: 0.132066\tvalid_1's auc: 0.838734\tvalid_1's binary_logloss: 0.145324\n",
      "[10]\tvalid_0's auc: 0.868899\tvalid_0's binary_logloss: 0.130682\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.144425\n",
      "[11]\tvalid_0's auc: 0.87095\tvalid_0's binary_logloss: 0.129509\tvalid_1's auc: 0.837304\tvalid_1's binary_logloss: 0.143844\n",
      "[12]\tvalid_0's auc: 0.872258\tvalid_0's binary_logloss: 0.128409\tvalid_1's auc: 0.83669\tvalid_1's binary_logloss: 0.143316\n",
      "[13]\tvalid_0's auc: 0.874037\tvalid_0's binary_logloss: 0.127397\tvalid_1's auc: 0.835346\tvalid_1's binary_logloss: 0.142981\n",
      "[14]\tvalid_0's auc: 0.875949\tvalid_0's binary_logloss: 0.126455\tvalid_1's auc: 0.835276\tvalid_1's binary_logloss: 0.142607\n",
      "[15]\tvalid_0's auc: 0.877382\tvalid_0's binary_logloss: 0.125645\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.142362\n",
      "[16]\tvalid_0's auc: 0.878987\tvalid_0's binary_logloss: 0.124805\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.142102\n",
      "[17]\tvalid_0's auc: 0.880532\tvalid_0's binary_logloss: 0.124054\tvalid_1's auc: 0.833893\tvalid_1's binary_logloss: 0.141884\n",
      "[18]\tvalid_0's auc: 0.882045\tvalid_0's binary_logloss: 0.123344\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.141697\n",
      "[19]\tvalid_0's auc: 0.883566\tvalid_0's binary_logloss: 0.122594\tvalid_1's auc: 0.832707\tvalid_1's binary_logloss: 0.141615\n",
      "[20]\tvalid_0's auc: 0.885585\tvalid_0's binary_logloss: 0.121869\tvalid_1's auc: 0.833151\tvalid_1's binary_logloss: 0.141426\n",
      "[21]\tvalid_0's auc: 0.887553\tvalid_0's binary_logloss: 0.121164\tvalid_1's auc: 0.834052\tvalid_1's binary_logloss: 0.141225\n",
      "[22]\tvalid_0's auc: 0.88866\tvalid_0's binary_logloss: 0.120577\tvalid_1's auc: 0.834098\tvalid_1's binary_logloss: 0.141029\n",
      "[23]\tvalid_0's auc: 0.889845\tvalid_0's binary_logloss: 0.11997\tvalid_1's auc: 0.833894\tvalid_1's binary_logloss: 0.140951\n",
      "[24]\tvalid_0's auc: 0.890796\tvalid_0's binary_logloss: 0.119485\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.140844\n",
      "[25]\tvalid_0's auc: 0.89199\tvalid_0's binary_logloss: 0.118928\tvalid_1's auc: 0.833906\tvalid_1's binary_logloss: 0.140917\n",
      "[26]\tvalid_0's auc: 0.893398\tvalid_0's binary_logloss: 0.118364\tvalid_1's auc: 0.834288\tvalid_1's binary_logloss: 0.140784\n",
      "[27]\tvalid_0's auc: 0.894509\tvalid_0's binary_logloss: 0.117887\tvalid_1's auc: 0.834364\tvalid_1's binary_logloss: 0.140677\n",
      "[28]\tvalid_0's auc: 0.895524\tvalid_0's binary_logloss: 0.117424\tvalid_1's auc: 0.834009\tvalid_1's binary_logloss: 0.140715\n",
      "[29]\tvalid_0's auc: 0.896654\tvalid_0's binary_logloss: 0.116949\tvalid_1's auc: 0.833704\tvalid_1's binary_logloss: 0.140719\n",
      "[30]\tvalid_0's auc: 0.897948\tvalid_0's binary_logloss: 0.116488\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140635\n",
      "[31]\tvalid_0's auc: 0.898781\tvalid_0's binary_logloss: 0.116069\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140671\n",
      "[32]\tvalid_0's auc: 0.90009\tvalid_0's binary_logloss: 0.115625\tvalid_1's auc: 0.83384\tvalid_1's binary_logloss: 0.140667\n",
      "[33]\tvalid_0's auc: 0.901073\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.833911\tvalid_1's binary_logloss: 0.140619\n",
      "[34]\tvalid_0's auc: 0.902228\tvalid_0's binary_logloss: 0.114803\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.140595\n",
      "[35]\tvalid_0's auc: 0.902949\tvalid_0's binary_logloss: 0.114411\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.140641\n",
      "[36]\tvalid_0's auc: 0.90428\tvalid_0's binary_logloss: 0.114027\tvalid_1's auc: 0.833146\tvalid_1's binary_logloss: 0.140714\n",
      "[37]\tvalid_0's auc: 0.90518\tvalid_0's binary_logloss: 0.113632\tvalid_1's auc: 0.833423\tvalid_1's binary_logloss: 0.140663\n",
      "[38]\tvalid_0's auc: 0.905995\tvalid_0's binary_logloss: 0.113243\tvalid_1's auc: 0.83347\tvalid_1's binary_logloss: 0.140755\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833919\tvalid_0's binary_logloss: 0.155512\tvalid_1's auc: 0.820637\tvalid_1's binary_logloss: 0.164643\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842002\tvalid_0's binary_logloss: 0.149635\tvalid_1's auc: 0.827273\tvalid_1's binary_logloss: 0.15926\n",
      "[3]\tvalid_0's auc: 0.844839\tvalid_0's binary_logloss: 0.145363\tvalid_1's auc: 0.829328\tvalid_1's binary_logloss: 0.155446\n",
      "[4]\tvalid_0's auc: 0.851547\tvalid_0's binary_logloss: 0.142092\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.152516\n",
      "[5]\tvalid_0's auc: 0.85629\tvalid_0's binary_logloss: 0.139314\tvalid_1's auc: 0.837608\tvalid_1's binary_logloss: 0.150218\n",
      "[6]\tvalid_0's auc: 0.860698\tvalid_0's binary_logloss: 0.137026\tvalid_1's auc: 0.837977\tvalid_1's binary_logloss: 0.148376\n",
      "[7]\tvalid_0's auc: 0.863515\tvalid_0's binary_logloss: 0.135113\tvalid_1's auc: 0.838443\tvalid_1's binary_logloss: 0.146922\n",
      "[8]\tvalid_0's auc: 0.864625\tvalid_0's binary_logloss: 0.133401\tvalid_1's auc: 0.838988\tvalid_1's binary_logloss: 0.145624\n",
      "[9]\tvalid_0's auc: 0.866831\tvalid_0's binary_logloss: 0.131907\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.14464\n",
      "[10]\tvalid_0's auc: 0.868953\tvalid_0's binary_logloss: 0.130539\tvalid_1's auc: 0.83779\tvalid_1's binary_logloss: 0.143795\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[12]\tvalid_0's auc: 0.872964\tvalid_0's binary_logloss: 0.128158\tvalid_1's auc: 0.838184\tvalid_1's binary_logloss: 0.142277\n",
      "[13]\tvalid_0's auc: 0.874758\tvalid_0's binary_logloss: 0.127141\tvalid_1's auc: 0.837972\tvalid_1's binary_logloss: 0.141744\n",
      "[14]\tvalid_0's auc: 0.876311\tvalid_0's binary_logloss: 0.126137\tvalid_1's auc: 0.837484\tvalid_1's binary_logloss: 0.141408\n",
      "[15]\tvalid_0's auc: 0.877968\tvalid_0's binary_logloss: 0.12525\tvalid_1's auc: 0.836581\tvalid_1's binary_logloss: 0.141099\n",
      "[16]\tvalid_0's auc: 0.87963\tvalid_0's binary_logloss: 0.124439\tvalid_1's auc: 0.836006\tvalid_1's binary_logloss: 0.140886\n",
      "[17]\tvalid_0's auc: 0.881659\tvalid_0's binary_logloss: 0.123628\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.140605\n",
      "[18]\tvalid_0's auc: 0.882607\tvalid_0's binary_logloss: 0.122935\tvalid_1's auc: 0.836156\tvalid_1's binary_logloss: 0.140354\n",
      "[19]\tvalid_0's auc: 0.884204\tvalid_0's binary_logloss: 0.122205\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.140094\n",
      "[20]\tvalid_0's auc: 0.88564\tvalid_0's binary_logloss: 0.121562\tvalid_1's auc: 0.836976\tvalid_1's binary_logloss: 0.139982\n",
      "[21]\tvalid_0's auc: 0.886788\tvalid_0's binary_logloss: 0.120948\tvalid_1's auc: 0.83734\tvalid_1's binary_logloss: 0.139793\n",
      "[22]\tvalid_0's auc: 0.888424\tvalid_0's binary_logloss: 0.120314\tvalid_1's auc: 0.83802\tvalid_1's binary_logloss: 0.139623\n",
      "[23]\tvalid_0's auc: 0.889756\tvalid_0's binary_logloss: 0.119797\tvalid_1's auc: 0.837015\tvalid_1's binary_logloss: 0.139653\n",
      "[24]\tvalid_0's auc: 0.891304\tvalid_0's binary_logloss: 0.119202\tvalid_1's auc: 0.837202\tvalid_1's binary_logloss: 0.139584\n",
      "[25]\tvalid_0's auc: 0.892545\tvalid_0's binary_logloss: 0.118664\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.1395\n",
      "[26]\tvalid_0's auc: 0.893944\tvalid_0's binary_logloss: 0.118169\tvalid_1's auc: 0.837371\tvalid_1's binary_logloss: 0.139458\n",
      "[27]\tvalid_0's auc: 0.894982\tvalid_0's binary_logloss: 0.117651\tvalid_1's auc: 0.836907\tvalid_1's binary_logloss: 0.139528\n",
      "[28]\tvalid_0's auc: 0.896304\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837127\tvalid_1's binary_logloss: 0.139491\n",
      "[29]\tvalid_0's auc: 0.89754\tvalid_0's binary_logloss: 0.116665\tvalid_1's auc: 0.837063\tvalid_1's binary_logloss: 0.139497\n",
      "[30]\tvalid_0's auc: 0.898907\tvalid_0's binary_logloss: 0.116238\tvalid_1's auc: 0.836952\tvalid_1's binary_logloss: 0.139457\n",
      "[31]\tvalid_0's auc: 0.89958\tvalid_0's binary_logloss: 0.115802\tvalid_1's auc: 0.837327\tvalid_1's binary_logloss: 0.139384\n",
      "[32]\tvalid_0's auc: 0.900529\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836541\tvalid_1's binary_logloss: 0.139496\n",
      "[33]\tvalid_0's auc: 0.90188\tvalid_0's binary_logloss: 0.114972\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.139413\n",
      "[34]\tvalid_0's auc: 0.902879\tvalid_0's binary_logloss: 0.114528\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.13943\n",
      "[35]\tvalid_0's auc: 0.903932\tvalid_0's binary_logloss: 0.114157\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.139458\n",
      "[36]\tvalid_0's auc: 0.904707\tvalid_0's binary_logloss: 0.113777\tvalid_1's auc: 0.836824\tvalid_1's binary_logloss: 0.139459\n",
      "[37]\tvalid_0's auc: 0.905376\tvalid_0's binary_logloss: 0.113446\tvalid_1's auc: 0.836614\tvalid_1's binary_logloss: 0.139503\n",
      "[38]\tvalid_0's auc: 0.906535\tvalid_0's binary_logloss: 0.11295\tvalid_1's auc: 0.836328\tvalid_1's binary_logloss: 0.139575\n",
      "[39]\tvalid_0's auc: 0.907125\tvalid_0's binary_logloss: 0.112599\tvalid_1's auc: 0.83631\tvalid_1's binary_logloss: 0.139598\n",
      "[40]\tvalid_0's auc: 0.908267\tvalid_0's binary_logloss: 0.112224\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.139675\n",
      "[41]\tvalid_0's auc: 0.908916\tvalid_0's binary_logloss: 0.111848\tvalid_1's auc: 0.835954\tvalid_1's binary_logloss: 0.139752\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.830163\tvalid_0's binary_logloss: 0.155383\tvalid_1's auc: 0.817444\tvalid_1's binary_logloss: 0.164924\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840688\tvalid_0's binary_logloss: 0.14972\tvalid_1's auc: 0.825893\tvalid_1's binary_logloss: 0.159538\n",
      "[3]\tvalid_0's auc: 0.847811\tvalid_0's binary_logloss: 0.145576\tvalid_1's auc: 0.832086\tvalid_1's binary_logloss: 0.155889\n",
      "[4]\tvalid_0's auc: 0.85262\tvalid_0's binary_logloss: 0.142266\tvalid_1's auc: 0.83348\tvalid_1's binary_logloss: 0.153059\n",
      "[5]\tvalid_0's auc: 0.856853\tvalid_0's binary_logloss: 0.139575\tvalid_1's auc: 0.837158\tvalid_1's binary_logloss: 0.150847\n",
      "[6]\tvalid_0's auc: 0.859779\tvalid_0's binary_logloss: 0.13732\tvalid_1's auc: 0.839471\tvalid_1's binary_logloss: 0.148924\n",
      "[7]\tvalid_0's auc: 0.861819\tvalid_0's binary_logloss: 0.135402\tvalid_1's auc: 0.838324\tvalid_1's binary_logloss: 0.147505\n",
      "[8]\tvalid_0's auc: 0.863714\tvalid_0's binary_logloss: 0.133757\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.146279\n",
      "[9]\tvalid_0's auc: 0.864749\tvalid_0's binary_logloss: 0.132364\tvalid_1's auc: 0.838331\tvalid_1's binary_logloss: 0.14529\n",
      "[10]\tvalid_0's auc: 0.866663\tvalid_0's binary_logloss: 0.131026\tvalid_1's auc: 0.837673\tvalid_1's binary_logloss: 0.144419\n",
      "[11]\tvalid_0's auc: 0.868726\tvalid_0's binary_logloss: 0.12984\tvalid_1's auc: 0.838501\tvalid_1's binary_logloss: 0.143675\n",
      "[12]\tvalid_0's auc: 0.871558\tvalid_0's binary_logloss: 0.128733\tvalid_1's auc: 0.838492\tvalid_1's binary_logloss: 0.143092\n",
      "[13]\tvalid_0's auc: 0.873442\tvalid_0's binary_logloss: 0.127675\tvalid_1's auc: 0.839717\tvalid_1's binary_logloss: 0.142342\n",
      "[14]\tvalid_0's auc: 0.875241\tvalid_0's binary_logloss: 0.126727\tvalid_1's auc: 0.839554\tvalid_1's binary_logloss: 0.141894\n",
      "[15]\tvalid_0's auc: 0.877606\tvalid_0's binary_logloss: 0.125834\tvalid_1's auc: 0.839663\tvalid_1's binary_logloss: 0.141484\n",
      "[16]\tvalid_0's auc: 0.878882\tvalid_0's binary_logloss: 0.125061\tvalid_1's auc: 0.840269\tvalid_1's binary_logloss: 0.141121\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[18]\tvalid_0's auc: 0.881171\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.839956\tvalid_1's binary_logloss: 0.14074\n",
      "[19]\tvalid_0's auc: 0.882715\tvalid_0's binary_logloss: 0.12297\tvalid_1's auc: 0.839997\tvalid_1's binary_logloss: 0.140537\n",
      "[20]\tvalid_0's auc: 0.884031\tvalid_0's binary_logloss: 0.122325\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.140381\n",
      "[21]\tvalid_0's auc: 0.885764\tvalid_0's binary_logloss: 0.121625\tvalid_1's auc: 0.839843\tvalid_1's binary_logloss: 0.140197\n",
      "[22]\tvalid_0's auc: 0.887281\tvalid_0's binary_logloss: 0.120983\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140102\n",
      "[23]\tvalid_0's auc: 0.888433\tvalid_0's binary_logloss: 0.120453\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.140039\n",
      "[24]\tvalid_0's auc: 0.890216\tvalid_0's binary_logloss: 0.119857\tvalid_1's auc: 0.839006\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.891521\tvalid_0's binary_logloss: 0.119298\tvalid_1's auc: 0.83887\tvalid_1's binary_logloss: 0.139884\n",
      "[26]\tvalid_0's auc: 0.892429\tvalid_0's binary_logloss: 0.118862\tvalid_1's auc: 0.838468\tvalid_1's binary_logloss: 0.139871\n",
      "[27]\tvalid_0's auc: 0.893299\tvalid_0's binary_logloss: 0.11838\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139845\n",
      "[28]\tvalid_0's auc: 0.894251\tvalid_0's binary_logloss: 0.117957\tvalid_1's auc: 0.837679\tvalid_1's binary_logloss: 0.139855\n",
      "[29]\tvalid_0's auc: 0.895243\tvalid_0's binary_logloss: 0.117508\tvalid_1's auc: 0.837735\tvalid_1's binary_logloss: 0.139821\n",
      "[30]\tvalid_0's auc: 0.896095\tvalid_0's binary_logloss: 0.117089\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139898\n",
      "[31]\tvalid_0's auc: 0.897359\tvalid_0's binary_logloss: 0.116601\tvalid_1's auc: 0.837136\tvalid_1's binary_logloss: 0.139894\n",
      "[32]\tvalid_0's auc: 0.898643\tvalid_0's binary_logloss: 0.11607\tvalid_1's auc: 0.836864\tvalid_1's binary_logloss: 0.139923\n",
      "[33]\tvalid_0's auc: 0.89992\tvalid_0's binary_logloss: 0.115645\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139915\n",
      "[34]\tvalid_0's auc: 0.900901\tvalid_0's binary_logloss: 0.115264\tvalid_1's auc: 0.836791\tvalid_1's binary_logloss: 0.139982\n",
      "[35]\tvalid_0's auc: 0.901751\tvalid_0's binary_logloss: 0.114906\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.139951\n",
      "[36]\tvalid_0's auc: 0.903021\tvalid_0's binary_logloss: 0.114415\tvalid_1's auc: 0.836623\tvalid_1's binary_logloss: 0.139976\n",
      "[37]\tvalid_0's auc: 0.904251\tvalid_0's binary_logloss: 0.114061\tvalid_1's auc: 0.836728\tvalid_1's binary_logloss: 0.139975\n",
      "[38]\tvalid_0's auc: 0.90516\tvalid_0's binary_logloss: 0.113675\tvalid_1's auc: 0.837\tvalid_1's binary_logloss: 0.139923\n",
      "[39]\tvalid_0's auc: 0.90596\tvalid_0's binary_logloss: 0.113263\tvalid_1's auc: 0.837387\tvalid_1's binary_logloss: 0.13986\n",
      "[40]\tvalid_0's auc: 0.906683\tvalid_0's binary_logloss: 0.112912\tvalid_1's auc: 0.837328\tvalid_1's binary_logloss: 0.139857\n",
      "[41]\tvalid_0's auc: 0.907126\tvalid_0's binary_logloss: 0.112589\tvalid_1's auc: 0.836763\tvalid_1's binary_logloss: 0.139978\n",
      "[42]\tvalid_0's auc: 0.907766\tvalid_0's binary_logloss: 0.112228\tvalid_1's auc: 0.836668\tvalid_1's binary_logloss: 0.140037\n",
      "[43]\tvalid_0's auc: 0.908476\tvalid_0's binary_logloss: 0.111878\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.140074\n",
      "[44]\tvalid_0's auc: 0.908965\tvalid_0's binary_logloss: 0.111555\tvalid_1's auc: 0.836825\tvalid_1's binary_logloss: 0.140052\n",
      "[45]\tvalid_0's auc: 0.90954\tvalid_0's binary_logloss: 0.111283\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.140134\n",
      "[46]\tvalid_0's auc: 0.910195\tvalid_0's binary_logloss: 0.111029\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.140137\n",
      "[47]\tvalid_0's auc: 0.910771\tvalid_0's binary_logloss: 0.110662\tvalid_1's auc: 0.836357\tvalid_1's binary_logloss: 0.140222\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833594\tvalid_0's binary_logloss: 0.155635\tvalid_1's auc: 0.820913\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.846048\tvalid_0's binary_logloss: 0.149713\tvalid_1's auc: 0.830646\tvalid_1's binary_logloss: 0.159607\n",
      "[3]\tvalid_0's auc: 0.849539\tvalid_0's binary_logloss: 0.145369\tvalid_1's auc: 0.833531\tvalid_1's binary_logloss: 0.155847\n",
      "[4]\tvalid_0's auc: 0.8529\tvalid_0's binary_logloss: 0.142095\tvalid_1's auc: 0.832813\tvalid_1's binary_logloss: 0.15325\n",
      "[5]\tvalid_0's auc: 0.855497\tvalid_0's binary_logloss: 0.13934\tvalid_1's auc: 0.833555\tvalid_1's binary_logloss: 0.150958\n",
      "[6]\tvalid_0's auc: 0.860603\tvalid_0's binary_logloss: 0.13707\tvalid_1's auc: 0.836476\tvalid_1's binary_logloss: 0.149037\n",
      "[7]\tvalid_0's auc: 0.86401\tvalid_0's binary_logloss: 0.13507\tvalid_1's auc: 0.838639\tvalid_1's binary_logloss: 0.147363\n",
      "[8]\tvalid_0's auc: 0.866327\tvalid_0's binary_logloss: 0.133353\tvalid_1's auc: 0.83917\tvalid_1's binary_logloss: 0.146142\n",
      "[9]\tvalid_0's auc: 0.868666\tvalid_0's binary_logloss: 0.131872\tvalid_1's auc: 0.839119\tvalid_1's binary_logloss: 0.145095\n",
      "[10]\tvalid_0's auc: 0.870055\tvalid_0's binary_logloss: 0.130535\tvalid_1's auc: 0.839769\tvalid_1's binary_logloss: 0.144187\n",
      "[11]\tvalid_0's auc: 0.871923\tvalid_0's binary_logloss: 0.129272\tvalid_1's auc: 0.840793\tvalid_1's binary_logloss: 0.143281\n",
      "[12]\tvalid_0's auc: 0.87487\tvalid_0's binary_logloss: 0.128204\tvalid_1's auc: 0.841107\tvalid_1's binary_logloss: 0.142593\n",
      "[13]\tvalid_0's auc: 0.87716\tvalid_0's binary_logloss: 0.127155\tvalid_1's auc: 0.840555\tvalid_1's binary_logloss: 0.142065\n",
      "[14]\tvalid_0's auc: 0.879344\tvalid_0's binary_logloss: 0.126173\tvalid_1's auc: 0.841197\tvalid_1's binary_logloss: 0.141536\n",
      "[15]\tvalid_0's auc: 0.880521\tvalid_0's binary_logloss: 0.125283\tvalid_1's auc: 0.841423\tvalid_1's binary_logloss: 0.141157\n",
      "[16]\tvalid_0's auc: 0.882066\tvalid_0's binary_logloss: 0.1244\tvalid_1's auc: 0.841461\tvalid_1's binary_logloss: 0.140813\n",
      "[17]\tvalid_0's auc: 0.883582\tvalid_0's binary_logloss: 0.123652\tvalid_1's auc: 0.841626\tvalid_1's binary_logloss: 0.1405\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[19]\tvalid_0's auc: 0.885618\tvalid_0's binary_logloss: 0.122288\tvalid_1's auc: 0.841595\tvalid_1's binary_logloss: 0.140038\n",
      "[20]\tvalid_0's auc: 0.887262\tvalid_0's binary_logloss: 0.12156\tvalid_1's auc: 0.841475\tvalid_1's binary_logloss: 0.13984\n",
      "[21]\tvalid_0's auc: 0.888549\tvalid_0's binary_logloss: 0.120864\tvalid_1's auc: 0.841698\tvalid_1's binary_logloss: 0.139644\n",
      "[22]\tvalid_0's auc: 0.889783\tvalid_0's binary_logloss: 0.120226\tvalid_1's auc: 0.841265\tvalid_1's binary_logloss: 0.139524\n",
      "[23]\tvalid_0's auc: 0.891007\tvalid_0's binary_logloss: 0.119647\tvalid_1's auc: 0.840909\tvalid_1's binary_logloss: 0.139463\n",
      "[24]\tvalid_0's auc: 0.892111\tvalid_0's binary_logloss: 0.11912\tvalid_1's auc: 0.840884\tvalid_1's binary_logloss: 0.13939\n",
      "[25]\tvalid_0's auc: 0.892959\tvalid_0's binary_logloss: 0.118644\tvalid_1's auc: 0.840779\tvalid_1's binary_logloss: 0.139336\n",
      "[26]\tvalid_0's auc: 0.894356\tvalid_0's binary_logloss: 0.118128\tvalid_1's auc: 0.841299\tvalid_1's binary_logloss: 0.139198\n",
      "[27]\tvalid_0's auc: 0.895981\tvalid_0's binary_logloss: 0.117575\tvalid_1's auc: 0.8407\tvalid_1's binary_logloss: 0.139192\n",
      "[28]\tvalid_0's auc: 0.896969\tvalid_0's binary_logloss: 0.11709\tvalid_1's auc: 0.840437\tvalid_1's binary_logloss: 0.139222\n",
      "[29]\tvalid_0's auc: 0.898028\tvalid_0's binary_logloss: 0.116618\tvalid_1's auc: 0.840857\tvalid_1's binary_logloss: 0.139136\n",
      "[30]\tvalid_0's auc: 0.89908\tvalid_0's binary_logloss: 0.116142\tvalid_1's auc: 0.840827\tvalid_1's binary_logloss: 0.139074\n",
      "[31]\tvalid_0's auc: 0.900145\tvalid_0's binary_logloss: 0.115699\tvalid_1's auc: 0.840974\tvalid_1's binary_logloss: 0.138987\n",
      "[32]\tvalid_0's auc: 0.90112\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.840942\tvalid_1's binary_logloss: 0.139024\n",
      "[33]\tvalid_0's auc: 0.901846\tvalid_0's binary_logloss: 0.114793\tvalid_1's auc: 0.840933\tvalid_1's binary_logloss: 0.13904\n",
      "[34]\tvalid_0's auc: 0.902883\tvalid_0's binary_logloss: 0.114387\tvalid_1's auc: 0.840844\tvalid_1's binary_logloss: 0.139066\n",
      "[35]\tvalid_0's auc: 0.903648\tvalid_0's binary_logloss: 0.113998\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.13901\n",
      "[36]\tvalid_0's auc: 0.905129\tvalid_0's binary_logloss: 0.113587\tvalid_1's auc: 0.840769\tvalid_1's binary_logloss: 0.139037\n",
      "[37]\tvalid_0's auc: 0.906133\tvalid_0's binary_logloss: 0.113131\tvalid_1's auc: 0.84035\tvalid_1's binary_logloss: 0.139137\n",
      "[38]\tvalid_0's auc: 0.907\tvalid_0's binary_logloss: 0.112813\tvalid_1's auc: 0.840254\tvalid_1's binary_logloss: 0.139186\n",
      "[39]\tvalid_0's auc: 0.907829\tvalid_0's binary_logloss: 0.112418\tvalid_1's auc: 0.84009\tvalid_1's binary_logloss: 0.139236\n",
      "[40]\tvalid_0's auc: 0.908551\tvalid_0's binary_logloss: 0.112078\tvalid_1's auc: 0.839874\tvalid_1's binary_logloss: 0.139313\n",
      "[41]\tvalid_0's auc: 0.909258\tvalid_0's binary_logloss: 0.111745\tvalid_1's auc: 0.839426\tvalid_1's binary_logloss: 0.139447\n",
      "[42]\tvalid_0's auc: 0.909875\tvalid_0's binary_logloss: 0.111354\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139428\n",
      "[43]\tvalid_0's auc: 0.910434\tvalid_0's binary_logloss: 0.111052\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.139483\n",
      "[44]\tvalid_0's auc: 0.911375\tvalid_0's binary_logloss: 0.110624\tvalid_1's auc: 0.839582\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.912055\tvalid_0's binary_logloss: 0.110372\tvalid_1's auc: 0.839536\tvalid_1's binary_logloss: 0.139546\n",
      "[46]\tvalid_0's auc: 0.912574\tvalid_0's binary_logloss: 0.110057\tvalid_1's auc: 0.83948\tvalid_1's binary_logloss: 0.139584\n",
      "[47]\tvalid_0's auc: 0.91302\tvalid_0's binary_logloss: 0.109723\tvalid_1's auc: 0.839228\tvalid_1's binary_logloss: 0.139685\n",
      "[48]\tvalid_0's auc: 0.913378\tvalid_0's binary_logloss: 0.109457\tvalid_1's auc: 0.839315\tvalid_1's binary_logloss: 0.139695\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823879\tvalid_0's binary_logloss: 0.156213\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.16489\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829817\tvalid_0's binary_logloss: 0.151021\tvalid_1's auc: 0.825621\tvalid_1's binary_logloss: 0.159697\n",
      "[3]\tvalid_0's auc: 0.835232\tvalid_0's binary_logloss: 0.147177\tvalid_1's auc: 0.827536\tvalid_1's binary_logloss: 0.156048\n",
      "[4]\tvalid_0's auc: 0.83968\tvalid_0's binary_logloss: 0.144169\tvalid_1's auc: 0.829988\tvalid_1's binary_logloss: 0.15317\n",
      "[5]\tvalid_0's auc: 0.842369\tvalid_0's binary_logloss: 0.141776\tvalid_1's auc: 0.832821\tvalid_1's binary_logloss: 0.150835\n",
      "[6]\tvalid_0's auc: 0.845358\tvalid_0's binary_logloss: 0.13981\tvalid_1's auc: 0.835915\tvalid_1's binary_logloss: 0.148944\n",
      "[7]\tvalid_0's auc: 0.847188\tvalid_0's binary_logloss: 0.13809\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.147409\n",
      "[8]\tvalid_0's auc: 0.850075\tvalid_0's binary_logloss: 0.136655\tvalid_1's auc: 0.838523\tvalid_1's binary_logloss: 0.146144\n",
      "[9]\tvalid_0's auc: 0.851721\tvalid_0's binary_logloss: 0.135431\tvalid_1's auc: 0.839526\tvalid_1's binary_logloss: 0.14501\n",
      "[10]\tvalid_0's auc: 0.852681\tvalid_0's binary_logloss: 0.134272\tvalid_1's auc: 0.839568\tvalid_1's binary_logloss: 0.144144\n",
      "[11]\tvalid_0's auc: 0.853905\tvalid_0's binary_logloss: 0.133325\tvalid_1's auc: 0.839485\tvalid_1's binary_logloss: 0.143444\n",
      "[12]\tvalid_0's auc: 0.854971\tvalid_0's binary_logloss: 0.132446\tvalid_1's auc: 0.839402\tvalid_1's binary_logloss: 0.142813\n",
      "[13]\tvalid_0's auc: 0.857695\tvalid_0's binary_logloss: 0.131634\tvalid_1's auc: 0.839553\tvalid_1's binary_logloss: 0.142327\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[15]\tvalid_0's auc: 0.860717\tvalid_0's binary_logloss: 0.130253\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.141526\n",
      "[16]\tvalid_0's auc: 0.861684\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.839477\tvalid_1's binary_logloss: 0.141164\n",
      "[17]\tvalid_0's auc: 0.863005\tvalid_0's binary_logloss: 0.129116\tvalid_1's auc: 0.839652\tvalid_1's binary_logloss: 0.140811\n",
      "[18]\tvalid_0's auc: 0.864178\tvalid_0's binary_logloss: 0.128588\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140551\n",
      "[19]\tvalid_0's auc: 0.865462\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.838928\tvalid_1's binary_logloss: 0.140383\n",
      "[20]\tvalid_0's auc: 0.86641\tvalid_0's binary_logloss: 0.127645\tvalid_1's auc: 0.838283\tvalid_1's binary_logloss: 0.140237\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.127271\tvalid_1's auc: 0.838068\tvalid_1's binary_logloss: 0.140114\n",
      "[22]\tvalid_0's auc: 0.868689\tvalid_0's binary_logloss: 0.126832\tvalid_1's auc: 0.837975\tvalid_1's binary_logloss: 0.139969\n",
      "[23]\tvalid_0's auc: 0.869773\tvalid_0's binary_logloss: 0.126451\tvalid_1's auc: 0.837722\tvalid_1's binary_logloss: 0.139931\n",
      "[24]\tvalid_0's auc: 0.871205\tvalid_0's binary_logloss: 0.12605\tvalid_1's auc: 0.837453\tvalid_1's binary_logloss: 0.139824\n",
      "[25]\tvalid_0's auc: 0.871806\tvalid_0's binary_logloss: 0.125728\tvalid_1's auc: 0.837283\tvalid_1's binary_logloss: 0.13976\n",
      "[26]\tvalid_0's auc: 0.873412\tvalid_0's binary_logloss: 0.125313\tvalid_1's auc: 0.836946\tvalid_1's binary_logloss: 0.139742\n",
      "[27]\tvalid_0's auc: 0.874137\tvalid_0's binary_logloss: 0.124988\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.139799\n",
      "[28]\tvalid_0's auc: 0.874911\tvalid_0's binary_logloss: 0.124675\tvalid_1's auc: 0.836489\tvalid_1's binary_logloss: 0.139742\n",
      "[29]\tvalid_0's auc: 0.875538\tvalid_0's binary_logloss: 0.124397\tvalid_1's auc: 0.836554\tvalid_1's binary_logloss: 0.139712\n",
      "[30]\tvalid_0's auc: 0.876317\tvalid_0's binary_logloss: 0.124137\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.139716\n",
      "[31]\tvalid_0's auc: 0.87724\tvalid_0's binary_logloss: 0.123841\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.139683\n",
      "[32]\tvalid_0's auc: 0.877783\tvalid_0's binary_logloss: 0.123594\tvalid_1's auc: 0.835851\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878348\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.139824\n",
      "[34]\tvalid_0's auc: 0.878909\tvalid_0's binary_logloss: 0.123136\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.139745\n",
      "[35]\tvalid_0's auc: 0.879757\tvalid_0's binary_logloss: 0.122828\tvalid_1's auc: 0.835337\tvalid_1's binary_logloss: 0.139761\n",
      "[36]\tvalid_0's auc: 0.880504\tvalid_0's binary_logloss: 0.122572\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.139792\n",
      "[37]\tvalid_0's auc: 0.881015\tvalid_0's binary_logloss: 0.122349\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.139809\n",
      "[38]\tvalid_0's auc: 0.881565\tvalid_0's binary_logloss: 0.122148\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.139772\n",
      "[39]\tvalid_0's auc: 0.882176\tvalid_0's binary_logloss: 0.121925\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.13977\n",
      "[40]\tvalid_0's auc: 0.882818\tvalid_0's binary_logloss: 0.121683\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.139736\n",
      "[41]\tvalid_0's auc: 0.883353\tvalid_0's binary_logloss: 0.121428\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.139663\n",
      "[42]\tvalid_0's auc: 0.884062\tvalid_0's binary_logloss: 0.121195\tvalid_1's auc: 0.835313\tvalid_1's binary_logloss: 0.139727\n",
      "[43]\tvalid_0's auc: 0.884607\tvalid_0's binary_logloss: 0.120984\tvalid_1's auc: 0.835083\tvalid_1's binary_logloss: 0.139745\n",
      "[44]\tvalid_0's auc: 0.885155\tvalid_0's binary_logloss: 0.120752\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.139761\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.822096\tvalid_0's binary_logloss: 0.15642\tvalid_1's auc: 0.814231\tvalid_1's binary_logloss: 0.165423\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830899\tvalid_0's binary_logloss: 0.151112\tvalid_1's auc: 0.821277\tvalid_1's binary_logloss: 0.160161\n",
      "[3]\tvalid_0's auc: 0.83949\tvalid_0's binary_logloss: 0.147196\tvalid_1's auc: 0.828421\tvalid_1's binary_logloss: 0.156499\n",
      "[4]\tvalid_0's auc: 0.84292\tvalid_0's binary_logloss: 0.14418\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.153682\n",
      "[5]\tvalid_0's auc: 0.846745\tvalid_0's binary_logloss: 0.141793\tvalid_1's auc: 0.836391\tvalid_1's binary_logloss: 0.151366\n",
      "[6]\tvalid_0's auc: 0.849204\tvalid_0's binary_logloss: 0.139816\tvalid_1's auc: 0.838385\tvalid_1's binary_logloss: 0.149412\n",
      "[7]\tvalid_0's auc: 0.850163\tvalid_0's binary_logloss: 0.138129\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.147877\n",
      "[8]\tvalid_0's auc: 0.852051\tvalid_0's binary_logloss: 0.136672\tvalid_1's auc: 0.838308\tvalid_1's binary_logloss: 0.146579\n",
      "[9]\tvalid_0's auc: 0.853307\tvalid_0's binary_logloss: 0.13545\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.145501\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[11]\tvalid_0's auc: 0.855751\tvalid_0's binary_logloss: 0.133459\tvalid_1's auc: 0.839746\tvalid_1's binary_logloss: 0.143859\n",
      "[12]\tvalid_0's auc: 0.856423\tvalid_0's binary_logloss: 0.132613\tvalid_1's auc: 0.838761\tvalid_1's binary_logloss: 0.143262\n",
      "[13]\tvalid_0's auc: 0.857763\tvalid_0's binary_logloss: 0.131837\tvalid_1's auc: 0.838486\tvalid_1's binary_logloss: 0.142774\n",
      "[14]\tvalid_0's auc: 0.858818\tvalid_0's binary_logloss: 0.131136\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.142334\n",
      "[15]\tvalid_0's auc: 0.859873\tvalid_0's binary_logloss: 0.130476\tvalid_1's auc: 0.83747\tvalid_1's binary_logloss: 0.14209\n",
      "[16]\tvalid_0's auc: 0.86059\tvalid_0's binary_logloss: 0.129898\tvalid_1's auc: 0.837199\tvalid_1's binary_logloss: 0.141785\n",
      "[17]\tvalid_0's auc: 0.861469\tvalid_0's binary_logloss: 0.129391\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.141489\n",
      "[18]\tvalid_0's auc: 0.8626\tvalid_0's binary_logloss: 0.128887\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.141321\n",
      "[19]\tvalid_0's auc: 0.863942\tvalid_0's binary_logloss: 0.128362\tvalid_1's auc: 0.837273\tvalid_1's binary_logloss: 0.14108\n",
      "[20]\tvalid_0's auc: 0.865345\tvalid_0's binary_logloss: 0.12787\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.140905\n",
      "[21]\tvalid_0's auc: 0.866373\tvalid_0's binary_logloss: 0.127496\tvalid_1's auc: 0.838239\tvalid_1's binary_logloss: 0.140637\n",
      "[22]\tvalid_0's auc: 0.867435\tvalid_0's binary_logloss: 0.12708\tvalid_1's auc: 0.837639\tvalid_1's binary_logloss: 0.1406\n",
      "[23]\tvalid_0's auc: 0.868304\tvalid_0's binary_logloss: 0.12669\tvalid_1's auc: 0.837619\tvalid_1's binary_logloss: 0.140434\n",
      "[24]\tvalid_0's auc: 0.869271\tvalid_0's binary_logloss: 0.126307\tvalid_1's auc: 0.838019\tvalid_1's binary_logloss: 0.140281\n",
      "[25]\tvalid_0's auc: 0.870212\tvalid_0's binary_logloss: 0.125949\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.14025\n",
      "[26]\tvalid_0's auc: 0.871023\tvalid_0's binary_logloss: 0.125636\tvalid_1's auc: 0.837504\tvalid_1's binary_logloss: 0.140165\n",
      "[27]\tvalid_0's auc: 0.872756\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837762\tvalid_1's binary_logloss: 0.140044\n",
      "[28]\tvalid_0's auc: 0.874041\tvalid_0's binary_logloss: 0.124866\tvalid_1's auc: 0.837513\tvalid_1's binary_logloss: 0.14003\n",
      "[29]\tvalid_0's auc: 0.875088\tvalid_0's binary_logloss: 0.12452\tvalid_1's auc: 0.837397\tvalid_1's binary_logloss: 0.140013\n",
      "[30]\tvalid_0's auc: 0.876006\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.140044\n",
      "[31]\tvalid_0's auc: 0.876443\tvalid_0's binary_logloss: 0.123946\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.139984\n",
      "[32]\tvalid_0's auc: 0.877157\tvalid_0's binary_logloss: 0.123679\tvalid_1's auc: 0.837186\tvalid_1's binary_logloss: 0.139974\n",
      "[33]\tvalid_0's auc: 0.877846\tvalid_0's binary_logloss: 0.123426\tvalid_1's auc: 0.836741\tvalid_1's binary_logloss: 0.140021\n",
      "[34]\tvalid_0's auc: 0.879036\tvalid_0's binary_logloss: 0.123124\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.140057\n",
      "[35]\tvalid_0's auc: 0.879941\tvalid_0's binary_logloss: 0.12285\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.140035\n",
      "[36]\tvalid_0's auc: 0.880696\tvalid_0's binary_logloss: 0.122577\tvalid_1's auc: 0.836552\tvalid_1's binary_logloss: 0.140011\n",
      "[37]\tvalid_0's auc: 0.881398\tvalid_0's binary_logloss: 0.122348\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140062\n",
      "[38]\tvalid_0's auc: 0.882135\tvalid_0's binary_logloss: 0.122135\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.14006\n",
      "[39]\tvalid_0's auc: 0.882826\tvalid_0's binary_logloss: 0.121918\tvalid_1's auc: 0.836302\tvalid_1's binary_logloss: 0.140015\n",
      "[40]\tvalid_0's auc: 0.883347\tvalid_0's binary_logloss: 0.121692\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.139995\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.826319\tvalid_0's binary_logloss: 0.156309\tvalid_1's auc: 0.814027\tvalid_1's binary_logloss: 0.16516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.832276\tvalid_0's binary_logloss: 0.151075\tvalid_1's auc: 0.819879\tvalid_1's binary_logloss: 0.160057\n",
      "[3]\tvalid_0's auc: 0.836968\tvalid_0's binary_logloss: 0.147259\tvalid_1's auc: 0.825144\tvalid_1's binary_logloss: 0.156367\n",
      "[4]\tvalid_0's auc: 0.840937\tvalid_0's binary_logloss: 0.144237\tvalid_1's auc: 0.830372\tvalid_1's binary_logloss: 0.153364\n",
      "[5]\tvalid_0's auc: 0.845178\tvalid_0's binary_logloss: 0.141851\tvalid_1's auc: 0.835122\tvalid_1's binary_logloss: 0.151017\n",
      "[6]\tvalid_0's auc: 0.846202\tvalid_0's binary_logloss: 0.139881\tvalid_1's auc: 0.835139\tvalid_1's binary_logloss: 0.149202\n",
      "[7]\tvalid_0's auc: 0.849501\tvalid_0's binary_logloss: 0.13816\tvalid_1's auc: 0.838439\tvalid_1's binary_logloss: 0.147646\n",
      "[8]\tvalid_0's auc: 0.850898\tvalid_0's binary_logloss: 0.136639\tvalid_1's auc: 0.838862\tvalid_1's binary_logloss: 0.146267\n",
      "[9]\tvalid_0's auc: 0.85237\tvalid_0's binary_logloss: 0.135394\tvalid_1's auc: 0.838585\tvalid_1's binary_logloss: 0.145261\n",
      "[10]\tvalid_0's auc: 0.855108\tvalid_0's binary_logloss: 0.134315\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.144377\n",
      "[11]\tvalid_0's auc: 0.856895\tvalid_0's binary_logloss: 0.133347\tvalid_1's auc: 0.837858\tvalid_1's binary_logloss: 0.143552\n",
      "[12]\tvalid_0's auc: 0.857593\tvalid_0's binary_logloss: 0.132493\tvalid_1's auc: 0.837734\tvalid_1's binary_logloss: 0.14288\n",
      "[13]\tvalid_0's auc: 0.85875\tvalid_0's binary_logloss: 0.131727\tvalid_1's auc: 0.838214\tvalid_1's binary_logloss: 0.142368\n",
      "[14]\tvalid_0's auc: 0.859561\tvalid_0's binary_logloss: 0.131032\tvalid_1's auc: 0.837766\tvalid_1's binary_logloss: 0.14195\n",
      "[15]\tvalid_0's auc: 0.860666\tvalid_0's binary_logloss: 0.130386\tvalid_1's auc: 0.837751\tvalid_1's binary_logloss: 0.141607\n",
      "[16]\tvalid_0's auc: 0.861555\tvalid_0's binary_logloss: 0.129851\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.14128\n",
      "[17]\tvalid_0's auc: 0.863042\tvalid_0's binary_logloss: 0.129232\tvalid_1's auc: 0.83902\tvalid_1's binary_logloss: 0.141008\n",
      "[18]\tvalid_0's auc: 0.864262\tvalid_0's binary_logloss: 0.128631\tvalid_1's auc: 0.839058\tvalid_1's binary_logloss: 0.140747\n",
      "[19]\tvalid_0's auc: 0.86545\tvalid_0's binary_logloss: 0.128138\tvalid_1's auc: 0.838753\tvalid_1's binary_logloss: 0.140544\n",
      "[20]\tvalid_0's auc: 0.8663\tvalid_0's binary_logloss: 0.12769\tvalid_1's auc: 0.83863\tvalid_1's binary_logloss: 0.140304\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[22]\tvalid_0's auc: 0.868709\tvalid_0's binary_logloss: 0.126813\tvalid_1's auc: 0.839171\tvalid_1's binary_logloss: 0.14001\n",
      "[23]\tvalid_0's auc: 0.869543\tvalid_0's binary_logloss: 0.126412\tvalid_1's auc: 0.839032\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.870296\tvalid_0's binary_logloss: 0.126025\tvalid_1's auc: 0.839048\tvalid_1's binary_logloss: 0.139785\n",
      "[25]\tvalid_0's auc: 0.871119\tvalid_0's binary_logloss: 0.125654\tvalid_1's auc: 0.83856\tvalid_1's binary_logloss: 0.139743\n",
      "[26]\tvalid_0's auc: 0.871934\tvalid_0's binary_logloss: 0.12537\tvalid_1's auc: 0.838594\tvalid_1's binary_logloss: 0.139669\n",
      "[27]\tvalid_0's auc: 0.873048\tvalid_0's binary_logloss: 0.125049\tvalid_1's auc: 0.83847\tvalid_1's binary_logloss: 0.139655\n",
      "[28]\tvalid_0's auc: 0.873824\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.838229\tvalid_1's binary_logloss: 0.139655\n",
      "[29]\tvalid_0's auc: 0.874662\tvalid_0's binary_logloss: 0.124467\tvalid_1's auc: 0.838445\tvalid_1's binary_logloss: 0.139579\n",
      "[30]\tvalid_0's auc: 0.87542\tvalid_0's binary_logloss: 0.124168\tvalid_1's auc: 0.838156\tvalid_1's binary_logloss: 0.139548\n",
      "[31]\tvalid_0's auc: 0.876207\tvalid_0's binary_logloss: 0.123915\tvalid_1's auc: 0.838237\tvalid_1's binary_logloss: 0.139538\n",
      "[32]\tvalid_0's auc: 0.877156\tvalid_0's binary_logloss: 0.123623\tvalid_1's auc: 0.838271\tvalid_1's binary_logloss: 0.13947\n",
      "[33]\tvalid_0's auc: 0.87768\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.838713\tvalid_1's binary_logloss: 0.139346\n",
      "[34]\tvalid_0's auc: 0.87849\tvalid_0's binary_logloss: 0.123137\tvalid_1's auc: 0.838649\tvalid_1's binary_logloss: 0.139374\n",
      "[35]\tvalid_0's auc: 0.879407\tvalid_0's binary_logloss: 0.122839\tvalid_1's auc: 0.838892\tvalid_1's binary_logloss: 0.139274\n",
      "[36]\tvalid_0's auc: 0.879965\tvalid_0's binary_logloss: 0.122622\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.139304\n",
      "[37]\tvalid_0's auc: 0.880613\tvalid_0's binary_logloss: 0.122331\tvalid_1's auc: 0.839029\tvalid_1's binary_logloss: 0.139242\n",
      "[38]\tvalid_0's auc: 0.881276\tvalid_0's binary_logloss: 0.122084\tvalid_1's auc: 0.838779\tvalid_1's binary_logloss: 0.139277\n",
      "[39]\tvalid_0's auc: 0.881947\tvalid_0's binary_logloss: 0.121841\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139295\n",
      "[40]\tvalid_0's auc: 0.882617\tvalid_0's binary_logloss: 0.121559\tvalid_1's auc: 0.838919\tvalid_1's binary_logloss: 0.13924\n",
      "[41]\tvalid_0's auc: 0.883227\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.838817\tvalid_1's binary_logloss: 0.13925\n",
      "[42]\tvalid_0's auc: 0.883844\tvalid_0's binary_logloss: 0.121097\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.139244\n",
      "[43]\tvalid_0's auc: 0.884188\tvalid_0's binary_logloss: 0.12095\tvalid_1's auc: 0.838842\tvalid_1's binary_logloss: 0.139242\n",
      "[44]\tvalid_0's auc: 0.884844\tvalid_0's binary_logloss: 0.120718\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.139282\n",
      "[45]\tvalid_0's auc: 0.885417\tvalid_0's binary_logloss: 0.120493\tvalid_1's auc: 0.838678\tvalid_1's binary_logloss: 0.139288\n",
      "[46]\tvalid_0's auc: 0.885803\tvalid_0's binary_logloss: 0.120327\tvalid_1's auc: 0.838716\tvalid_1's binary_logloss: 0.139279\n",
      "[47]\tvalid_0's auc: 0.886486\tvalid_0's binary_logloss: 0.120099\tvalid_1's auc: 0.838668\tvalid_1's binary_logloss: 0.139274\n",
      "[48]\tvalid_0's auc: 0.887253\tvalid_0's binary_logloss: 0.119903\tvalid_1's auc: 0.838451\tvalid_1's binary_logloss: 0.139321\n",
      "[49]\tvalid_0's auc: 0.887742\tvalid_0's binary_logloss: 0.11971\tvalid_1's auc: 0.838484\tvalid_1's binary_logloss: 0.139332\n",
      "[50]\tvalid_0's auc: 0.888224\tvalid_0's binary_logloss: 0.119543\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139353\n",
      "[51]\tvalid_0's auc: 0.888667\tvalid_0's binary_logloss: 0.11938\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.1394\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823467\tvalid_0's binary_logloss: 0.156234\tvalid_1's auc: 0.818359\tvalid_1's binary_logloss: 0.165045\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.831432\tvalid_0's binary_logloss: 0.151096\tvalid_1's auc: 0.822806\tvalid_1's binary_logloss: 0.160035\n",
      "[3]\tvalid_0's auc: 0.837942\tvalid_0's binary_logloss: 0.147265\tvalid_1's auc: 0.827733\tvalid_1's binary_logloss: 0.156278\n",
      "[4]\tvalid_0's auc: 0.842228\tvalid_0's binary_logloss: 0.144266\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.153439\n",
      "[5]\tvalid_0's auc: 0.845913\tvalid_0's binary_logloss: 0.141908\tvalid_1's auc: 0.836078\tvalid_1's binary_logloss: 0.151112\n",
      "[6]\tvalid_0's auc: 0.847301\tvalid_0's binary_logloss: 0.139924\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.149212\n",
      "[7]\tvalid_0's auc: 0.848494\tvalid_0's binary_logloss: 0.138267\tvalid_1's auc: 0.837664\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.849608\tvalid_0's binary_logloss: 0.136839\tvalid_1's auc: 0.839054\tvalid_1's binary_logloss: 0.146332\n",
      "[9]\tvalid_0's auc: 0.851401\tvalid_0's binary_logloss: 0.135609\tvalid_1's auc: 0.839453\tvalid_1's binary_logloss: 0.145351\n",
      "[10]\tvalid_0's auc: 0.852795\tvalid_0's binary_logloss: 0.134534\tvalid_1's auc: 0.840274\tvalid_1's binary_logloss: 0.144391\n",
      "[11]\tvalid_0's auc: 0.853993\tvalid_0's binary_logloss: 0.133621\tvalid_1's auc: 0.840484\tvalid_1's binary_logloss: 0.143622\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[13]\tvalid_0's auc: 0.857408\tvalid_0's binary_logloss: 0.131982\tvalid_1's auc: 0.840313\tvalid_1's binary_logloss: 0.142428\n",
      "[14]\tvalid_0's auc: 0.858394\tvalid_0's binary_logloss: 0.131254\tvalid_1's auc: 0.840441\tvalid_1's binary_logloss: 0.141892\n",
      "[15]\tvalid_0's auc: 0.859543\tvalid_0's binary_logloss: 0.130617\tvalid_1's auc: 0.840527\tvalid_1's binary_logloss: 0.141536\n",
      "[16]\tvalid_0's auc: 0.860896\tvalid_0's binary_logloss: 0.130045\tvalid_1's auc: 0.839976\tvalid_1's binary_logloss: 0.141199\n",
      "[17]\tvalid_0's auc: 0.862165\tvalid_0's binary_logloss: 0.129495\tvalid_1's auc: 0.840423\tvalid_1's binary_logloss: 0.140913\n",
      "[18]\tvalid_0's auc: 0.863167\tvalid_0's binary_logloss: 0.128982\tvalid_1's auc: 0.840347\tvalid_1's binary_logloss: 0.140622\n",
      "[19]\tvalid_0's auc: 0.864691\tvalid_0's binary_logloss: 0.128474\tvalid_1's auc: 0.840438\tvalid_1's binary_logloss: 0.140372\n",
      "[20]\tvalid_0's auc: 0.865493\tvalid_0's binary_logloss: 0.128073\tvalid_1's auc: 0.840373\tvalid_1's binary_logloss: 0.140128\n",
      "[21]\tvalid_0's auc: 0.866463\tvalid_0's binary_logloss: 0.127636\tvalid_1's auc: 0.840418\tvalid_1's binary_logloss: 0.139909\n",
      "[22]\tvalid_0's auc: 0.867081\tvalid_0's binary_logloss: 0.12726\tvalid_1's auc: 0.840315\tvalid_1's binary_logloss: 0.139758\n",
      "[23]\tvalid_0's auc: 0.867656\tvalid_0's binary_logloss: 0.126888\tvalid_1's auc: 0.839878\tvalid_1's binary_logloss: 0.139751\n",
      "[24]\tvalid_0's auc: 0.868511\tvalid_0's binary_logloss: 0.12652\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.13964\n",
      "[25]\tvalid_0's auc: 0.869233\tvalid_0's binary_logloss: 0.126158\tvalid_1's auc: 0.840131\tvalid_1's binary_logloss: 0.139495\n",
      "[26]\tvalid_0's auc: 0.870146\tvalid_0's binary_logloss: 0.12583\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139487\n",
      "[27]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.125495\tvalid_1's auc: 0.83977\tvalid_1's binary_logloss: 0.139452\n",
      "[28]\tvalid_0's auc: 0.872449\tvalid_0's binary_logloss: 0.125203\tvalid_1's auc: 0.839707\tvalid_1's binary_logloss: 0.139417\n",
      "[29]\tvalid_0's auc: 0.87307\tvalid_0's binary_logloss: 0.124902\tvalid_1's auc: 0.840062\tvalid_1's binary_logloss: 0.13934\n",
      "[30]\tvalid_0's auc: 0.874009\tvalid_0's binary_logloss: 0.124599\tvalid_1's auc: 0.839797\tvalid_1's binary_logloss: 0.139335\n",
      "[31]\tvalid_0's auc: 0.874961\tvalid_0's binary_logloss: 0.124243\tvalid_1's auc: 0.839401\tvalid_1's binary_logloss: 0.139341\n",
      "[32]\tvalid_0's auc: 0.875534\tvalid_0's binary_logloss: 0.12399\tvalid_1's auc: 0.839344\tvalid_1's binary_logloss: 0.139318\n",
      "[33]\tvalid_0's auc: 0.876073\tvalid_0's binary_logloss: 0.12375\tvalid_1's auc: 0.839413\tvalid_1's binary_logloss: 0.139291\n",
      "[34]\tvalid_0's auc: 0.876721\tvalid_0's binary_logloss: 0.123522\tvalid_1's auc: 0.839706\tvalid_1's binary_logloss: 0.139235\n",
      "[35]\tvalid_0's auc: 0.877275\tvalid_0's binary_logloss: 0.123252\tvalid_1's auc: 0.840335\tvalid_1's binary_logloss: 0.139044\n",
      "[36]\tvalid_0's auc: 0.877922\tvalid_0's binary_logloss: 0.123055\tvalid_1's auc: 0.840293\tvalid_1's binary_logloss: 0.13902\n",
      "[37]\tvalid_0's auc: 0.878499\tvalid_0's binary_logloss: 0.122801\tvalid_1's auc: 0.840333\tvalid_1's binary_logloss: 0.138988\n",
      "[38]\tvalid_0's auc: 0.879297\tvalid_0's binary_logloss: 0.122522\tvalid_1's auc: 0.840156\tvalid_1's binary_logloss: 0.139034\n",
      "[39]\tvalid_0's auc: 0.880019\tvalid_0's binary_logloss: 0.122297\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.138997\n",
      "[40]\tvalid_0's auc: 0.88064\tvalid_0's binary_logloss: 0.122051\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.139001\n",
      "[41]\tvalid_0's auc: 0.88151\tvalid_0's binary_logloss: 0.121784\tvalid_1's auc: 0.839739\tvalid_1's binary_logloss: 0.13906\n",
      "[42]\tvalid_0's auc: 0.882288\tvalid_0's binary_logloss: 0.121573\tvalid_1's auc: 0.839558\tvalid_1's binary_logloss: 0.139089\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.822477\tvalid_0's binary_logloss: 0.156615\tvalid_1's auc: 0.818936\tvalid_1's binary_logloss: 0.16507\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829931\tvalid_0's binary_logloss: 0.151227\tvalid_1's auc: 0.824213\tvalid_1's binary_logloss: 0.159973\n",
      "[3]\tvalid_0's auc: 0.835788\tvalid_0's binary_logloss: 0.147372\tvalid_1's auc: 0.829555\tvalid_1's binary_logloss: 0.156407\n",
      "[4]\tvalid_0's auc: 0.842398\tvalid_0's binary_logloss: 0.14436\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.153426\n",
      "[5]\tvalid_0's auc: 0.84472\tvalid_0's binary_logloss: 0.141969\tvalid_1's auc: 0.835438\tvalid_1's binary_logloss: 0.15118\n",
      "[6]\tvalid_0's auc: 0.846873\tvalid_0's binary_logloss: 0.13984\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.149232\n",
      "[7]\tvalid_0's auc: 0.849397\tvalid_0's binary_logloss: 0.138081\tvalid_1's auc: 0.838165\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.850636\tvalid_0's binary_logloss: 0.136651\tvalid_1's auc: 0.839203\tvalid_1's binary_logloss: 0.146397\n",
      "[9]\tvalid_0's auc: 0.852058\tvalid_0's binary_logloss: 0.135397\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.145335\n",
      "[10]\tvalid_0's auc: 0.853752\tvalid_0's binary_logloss: 0.134296\tvalid_1's auc: 0.840124\tvalid_1's binary_logloss: 0.144474\n",
      "[11]\tvalid_0's auc: 0.855331\tvalid_0's binary_logloss: 0.133348\tvalid_1's auc: 0.839897\tvalid_1's binary_logloss: 0.143725\n",
      "[12]\tvalid_0's auc: 0.857453\tvalid_0's binary_logloss: 0.13245\tvalid_1's auc: 0.84039\tvalid_1's binary_logloss: 0.143067\n",
      "[13]\tvalid_0's auc: 0.858781\tvalid_0's binary_logloss: 0.131689\tvalid_1's auc: 0.840851\tvalid_1's binary_logloss: 0.14244\n",
      "[14]\tvalid_0's auc: 0.860635\tvalid_0's binary_logloss: 0.130982\tvalid_1's auc: 0.840623\tvalid_1's binary_logloss: 0.141945\n",
      "[15]\tvalid_0's auc: 0.861771\tvalid_0's binary_logloss: 0.130283\tvalid_1's auc: 0.84085\tvalid_1's binary_logloss: 0.141501\n",
      "[16]\tvalid_0's auc: 0.863226\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.840816\tvalid_1's binary_logloss: 0.14118\n",
      "[17]\tvalid_0's auc: 0.864022\tvalid_0's binary_logloss: 0.129132\tvalid_1's auc: 0.841034\tvalid_1's binary_logloss: 0.140867\n",
      "[18]\tvalid_0's auc: 0.865122\tvalid_0's binary_logloss: 0.128586\tvalid_1's auc: 0.841066\tvalid_1's binary_logloss: 0.140645\n",
      "[19]\tvalid_0's auc: 0.866114\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.841164\tvalid_1's binary_logloss: 0.140459\n",
      "[20]\tvalid_0's auc: 0.86733\tvalid_0's binary_logloss: 0.127618\tvalid_1's auc: 0.841078\tvalid_1's binary_logloss: 0.140192\n",
      "[21]\tvalid_0's auc: 0.86847\tvalid_0's binary_logloss: 0.12718\tvalid_1's auc: 0.842056\tvalid_1's binary_logloss: 0.139899\n",
      "[22]\tvalid_0's auc: 0.86912\tvalid_0's binary_logloss: 0.126786\tvalid_1's auc: 0.842604\tvalid_1's binary_logloss: 0.139581\n",
      "[23]\tvalid_0's auc: 0.8702\tvalid_0's binary_logloss: 0.1264\tvalid_1's auc: 0.842923\tvalid_1's binary_logloss: 0.13938\n",
      "[24]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.126012\tvalid_1's auc: 0.842853\tvalid_1's binary_logloss: 0.139199\n",
      "[25]\tvalid_0's auc: 0.871861\tvalid_0's binary_logloss: 0.125716\tvalid_1's auc: 0.842924\tvalid_1's binary_logloss: 0.139114\n",
      "[26]\tvalid_0's auc: 0.872932\tvalid_0's binary_logloss: 0.125379\tvalid_1's auc: 0.842821\tvalid_1's binary_logloss: 0.139002\n",
      "[27]\tvalid_0's auc: 0.873488\tvalid_0's binary_logloss: 0.125055\tvalid_1's auc: 0.842803\tvalid_1's binary_logloss: 0.138866\n",
      "[28]\tvalid_0's auc: 0.874282\tvalid_0's binary_logloss: 0.124763\tvalid_1's auc: 0.842697\tvalid_1's binary_logloss: 0.138796\n",
      "[29]\tvalid_0's auc: 0.875185\tvalid_0's binary_logloss: 0.124481\tvalid_1's auc: 0.843506\tvalid_1's binary_logloss: 0.138625\n",
      "[30]\tvalid_0's auc: 0.875805\tvalid_0's binary_logloss: 0.124216\tvalid_1's auc: 0.843564\tvalid_1's binary_logloss: 0.138532\n",
      "[31]\tvalid_0's auc: 0.877289\tvalid_0's binary_logloss: 0.123898\tvalid_1's auc: 0.84385\tvalid_1's binary_logloss: 0.138455\n",
      "[32]\tvalid_0's auc: 0.878137\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.843943\tvalid_1's binary_logloss: 0.138401\n",
      "[33]\tvalid_0's auc: 0.879141\tvalid_0's binary_logloss: 0.123349\tvalid_1's auc: 0.843945\tvalid_1's binary_logloss: 0.13837\n",
      "[34]\tvalid_0's auc: 0.879829\tvalid_0's binary_logloss: 0.123074\tvalid_1's auc: 0.844035\tvalid_1's binary_logloss: 0.13828\n",
      "[35]\tvalid_0's auc: 0.880826\tvalid_0's binary_logloss: 0.122813\tvalid_1's auc: 0.844275\tvalid_1's binary_logloss: 0.138226\n",
      "[36]\tvalid_0's auc: 0.881493\tvalid_0's binary_logloss: 0.122554\tvalid_1's auc: 0.844344\tvalid_1's binary_logloss: 0.138161\n",
      "[37]\tvalid_0's auc: 0.882368\tvalid_0's binary_logloss: 0.122305\tvalid_1's auc: 0.844143\tvalid_1's binary_logloss: 0.138162\n",
      "[38]\tvalid_0's auc: 0.882945\tvalid_0's binary_logloss: 0.122019\tvalid_1's auc: 0.844149\tvalid_1's binary_logloss: 0.13813\n",
      "[39]\tvalid_0's auc: 0.883584\tvalid_0's binary_logloss: 0.121799\tvalid_1's auc: 0.843977\tvalid_1's binary_logloss: 0.138149\n",
      "[40]\tvalid_0's auc: 0.88416\tvalid_0's binary_logloss: 0.121576\tvalid_1's auc: 0.844146\tvalid_1's binary_logloss: 0.138147\n",
      "[41]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.12135\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138128\n",
      "[42]\tvalid_0's auc: 0.885638\tvalid_0's binary_logloss: 0.121096\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138106\n",
      "[43]\tvalid_0's auc: 0.886395\tvalid_0's binary_logloss: 0.120905\tvalid_1's auc: 0.844184\tvalid_1's binary_logloss: 0.138052\n",
      "[44]\tvalid_0's auc: 0.887071\tvalid_0's binary_logloss: 0.120678\tvalid_1's auc: 0.844103\tvalid_1's binary_logloss: 0.138065\n",
      "[45]\tvalid_0's auc: 0.887784\tvalid_0's binary_logloss: 0.120428\tvalid_1's auc: 0.844152\tvalid_1's binary_logloss: 0.138057\n",
      "[46]\tvalid_0's auc: 0.888342\tvalid_0's binary_logloss: 0.120223\tvalid_1's auc: 0.844297\tvalid_1's binary_logloss: 0.138025\n",
      "[47]\tvalid_0's auc: 0.888722\tvalid_0's binary_logloss: 0.119986\tvalid_1's auc: 0.844276\tvalid_1's binary_logloss: 0.138002\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[49]\tvalid_0's auc: 0.889545\tvalid_0's binary_logloss: 0.119601\tvalid_1's auc: 0.844447\tvalid_1's binary_logloss: 0.138002\n",
      "[50]\tvalid_0's auc: 0.89018\tvalid_0's binary_logloss: 0.119358\tvalid_1's auc: 0.844336\tvalid_1's binary_logloss: 0.138021\n",
      "[51]\tvalid_0's auc: 0.890603\tvalid_0's binary_logloss: 0.119182\tvalid_1's auc: 0.84438\tvalid_1's binary_logloss: 0.138019\n",
      "[52]\tvalid_0's auc: 0.891517\tvalid_0's binary_logloss: 0.118924\tvalid_1's auc: 0.844393\tvalid_1's binary_logloss: 0.13803\n",
      "[53]\tvalid_0's auc: 0.891938\tvalid_0's binary_logloss: 0.118749\tvalid_1's auc: 0.844183\tvalid_1's binary_logloss: 0.138086\n",
      "[54]\tvalid_0's auc: 0.892252\tvalid_0's binary_logloss: 0.118601\tvalid_1's auc: 0.844352\tvalid_1's binary_logloss: 0.138077\n",
      "[55]\tvalid_0's auc: 0.892749\tvalid_0's binary_logloss: 0.118391\tvalid_1's auc: 0.84432\tvalid_1's binary_logloss: 0.138057\n",
      "[56]\tvalid_0's auc: 0.893267\tvalid_0's binary_logloss: 0.118246\tvalid_1's auc: 0.844305\tvalid_1's binary_logloss: 0.138061\n",
      "[57]\tvalid_0's auc: 0.893589\tvalid_0's binary_logloss: 0.118094\tvalid_1's auc: 0.844225\tvalid_1's binary_logloss: 0.138064\n",
      "[58]\tvalid_0's auc: 0.89387\tvalid_0's binary_logloss: 0.117959\tvalid_1's auc: 0.844327\tvalid_1's binary_logloss: 0.138044\n",
      "[59]\tvalid_0's auc: 0.894196\tvalid_0's binary_logloss: 0.117784\tvalid_1's auc: 0.844144\tvalid_1's binary_logloss: 0.138088\n",
      "[60]\tvalid_0's auc: 0.894754\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.843942\tvalid_1's binary_logloss: 0.138136\n",
      "[61]\tvalid_0's auc: 0.895224\tvalid_0's binary_logloss: 0.117358\tvalid_1's auc: 0.844107\tvalid_1's binary_logloss: 0.138135\n",
      "[62]\tvalid_0's auc: 0.895747\tvalid_0's binary_logloss: 0.117116\tvalid_1's auc: 0.844033\tvalid_1's binary_logloss: 0.138143\n",
      "[63]\tvalid_0's auc: 0.896042\tvalid_0's binary_logloss: 0.116934\tvalid_1's auc: 0.844057\tvalid_1's binary_logloss: 0.138188\n",
      "[64]\tvalid_0's auc: 0.89648\tvalid_0's binary_logloss: 0.116742\tvalid_1's auc: 0.843882\tvalid_1's binary_logloss: 0.138258\n",
      "[65]\tvalid_0's auc: 0.8968\tvalid_0's binary_logloss: 0.116596\tvalid_1's auc: 0.843553\tvalid_1's binary_logloss: 0.138317\n",
      "[66]\tvalid_0's auc: 0.89727\tvalid_0's binary_logloss: 0.116455\tvalid_1's auc: 0.843435\tvalid_1's binary_logloss: 0.138362\n",
      "[67]\tvalid_0's auc: 0.897643\tvalid_0's binary_logloss: 0.11627\tvalid_1's auc: 0.843148\tvalid_1's binary_logloss: 0.138424\n",
      "[68]\tvalid_0's auc: 0.898008\tvalid_0's binary_logloss: 0.116079\tvalid_1's auc: 0.843355\tvalid_1's binary_logloss: 0.138452\n",
      "[69]\tvalid_0's auc: 0.898293\tvalid_0's binary_logloss: 0.115943\tvalid_1's auc: 0.843203\tvalid_1's binary_logloss: 0.138515\n",
      "[70]\tvalid_0's auc: 0.898585\tvalid_0's binary_logloss: 0.115794\tvalid_1's auc: 0.84311\tvalid_1's binary_logloss: 0.138551\n",
      "[71]\tvalid_0's auc: 0.898878\tvalid_0's binary_logloss: 0.115634\tvalid_1's auc: 0.843163\tvalid_1's binary_logloss: 0.138557\n",
      "[72]\tvalid_0's auc: 0.89933\tvalid_0's binary_logloss: 0.11544\tvalid_1's auc: 0.843123\tvalid_1's binary_logloss: 0.138587\n",
      "[73]\tvalid_0's auc: 0.899665\tvalid_0's binary_logloss: 0.115279\tvalid_1's auc: 0.843158\tvalid_1's binary_logloss: 0.138606\n",
      "[74]\tvalid_0's auc: 0.899872\tvalid_0's binary_logloss: 0.115145\tvalid_1's auc: 0.843153\tvalid_1's binary_logloss: 0.138622\n",
      "[75]\tvalid_0's auc: 0.900318\tvalid_0's binary_logloss: 0.115012\tvalid_1's auc: 0.8431\tvalid_1's binary_logloss: 0.138652\n",
      "[76]\tvalid_0's auc: 0.900838\tvalid_0's binary_logloss: 0.114797\tvalid_1's auc: 0.843128\tvalid_1's binary_logloss: 0.138654\n",
      "[77]\tvalid_0's auc: 0.901053\tvalid_0's binary_logloss: 0.11465\tvalid_1's auc: 0.843183\tvalid_1's binary_logloss: 0.138667\n",
      "[78]\tvalid_0's auc: 0.901334\tvalid_0's binary_logloss: 0.114492\tvalid_1's auc: 0.843036\tvalid_1's binary_logloss: 0.138728\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823879\tvalid_0's binary_logloss: 0.156213\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.16489\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829817\tvalid_0's binary_logloss: 0.151021\tvalid_1's auc: 0.825621\tvalid_1's binary_logloss: 0.159697\n",
      "[3]\tvalid_0's auc: 0.835232\tvalid_0's binary_logloss: 0.147177\tvalid_1's auc: 0.827536\tvalid_1's binary_logloss: 0.156048\n",
      "[4]\tvalid_0's auc: 0.83968\tvalid_0's binary_logloss: 0.144169\tvalid_1's auc: 0.829988\tvalid_1's binary_logloss: 0.15317\n",
      "[5]\tvalid_0's auc: 0.842369\tvalid_0's binary_logloss: 0.141776\tvalid_1's auc: 0.832821\tvalid_1's binary_logloss: 0.150835\n",
      "[6]\tvalid_0's auc: 0.845358\tvalid_0's binary_logloss: 0.13981\tvalid_1's auc: 0.835915\tvalid_1's binary_logloss: 0.148944\n",
      "[7]\tvalid_0's auc: 0.847188\tvalid_0's binary_logloss: 0.13809\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.147409\n",
      "[8]\tvalid_0's auc: 0.850075\tvalid_0's binary_logloss: 0.136655\tvalid_1's auc: 0.838523\tvalid_1's binary_logloss: 0.146144\n",
      "[9]\tvalid_0's auc: 0.851721\tvalid_0's binary_logloss: 0.135431\tvalid_1's auc: 0.839526\tvalid_1's binary_logloss: 0.14501\n",
      "[10]\tvalid_0's auc: 0.852681\tvalid_0's binary_logloss: 0.134272\tvalid_1's auc: 0.839568\tvalid_1's binary_logloss: 0.144144\n",
      "[11]\tvalid_0's auc: 0.853905\tvalid_0's binary_logloss: 0.133325\tvalid_1's auc: 0.839485\tvalid_1's binary_logloss: 0.143444\n",
      "[12]\tvalid_0's auc: 0.854971\tvalid_0's binary_logloss: 0.132446\tvalid_1's auc: 0.839402\tvalid_1's binary_logloss: 0.142813\n",
      "[13]\tvalid_0's auc: 0.857695\tvalid_0's binary_logloss: 0.131634\tvalid_1's auc: 0.839553\tvalid_1's binary_logloss: 0.142327\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[15]\tvalid_0's auc: 0.860717\tvalid_0's binary_logloss: 0.130253\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.141526\n",
      "[16]\tvalid_0's auc: 0.861684\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.839477\tvalid_1's binary_logloss: 0.141164\n",
      "[17]\tvalid_0's auc: 0.863005\tvalid_0's binary_logloss: 0.129116\tvalid_1's auc: 0.839652\tvalid_1's binary_logloss: 0.140811\n",
      "[18]\tvalid_0's auc: 0.864178\tvalid_0's binary_logloss: 0.128588\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140551\n",
      "[19]\tvalid_0's auc: 0.865462\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.838928\tvalid_1's binary_logloss: 0.140383\n",
      "[20]\tvalid_0's auc: 0.86641\tvalid_0's binary_logloss: 0.127645\tvalid_1's auc: 0.838283\tvalid_1's binary_logloss: 0.140237\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.127271\tvalid_1's auc: 0.838068\tvalid_1's binary_logloss: 0.140114\n",
      "[22]\tvalid_0's auc: 0.868689\tvalid_0's binary_logloss: 0.126832\tvalid_1's auc: 0.837975\tvalid_1's binary_logloss: 0.139969\n",
      "[23]\tvalid_0's auc: 0.869773\tvalid_0's binary_logloss: 0.126451\tvalid_1's auc: 0.837722\tvalid_1's binary_logloss: 0.139931\n",
      "[24]\tvalid_0's auc: 0.871205\tvalid_0's binary_logloss: 0.12605\tvalid_1's auc: 0.837453\tvalid_1's binary_logloss: 0.139824\n",
      "[25]\tvalid_0's auc: 0.871806\tvalid_0's binary_logloss: 0.125728\tvalid_1's auc: 0.837283\tvalid_1's binary_logloss: 0.13976\n",
      "[26]\tvalid_0's auc: 0.873412\tvalid_0's binary_logloss: 0.125313\tvalid_1's auc: 0.836946\tvalid_1's binary_logloss: 0.139742\n",
      "[27]\tvalid_0's auc: 0.874137\tvalid_0's binary_logloss: 0.124988\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.139799\n",
      "[28]\tvalid_0's auc: 0.874911\tvalid_0's binary_logloss: 0.124675\tvalid_1's auc: 0.836489\tvalid_1's binary_logloss: 0.139742\n",
      "[29]\tvalid_0's auc: 0.875538\tvalid_0's binary_logloss: 0.124397\tvalid_1's auc: 0.836554\tvalid_1's binary_logloss: 0.139712\n",
      "[30]\tvalid_0's auc: 0.876317\tvalid_0's binary_logloss: 0.124137\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.139716\n",
      "[31]\tvalid_0's auc: 0.87724\tvalid_0's binary_logloss: 0.123841\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.139683\n",
      "[32]\tvalid_0's auc: 0.877783\tvalid_0's binary_logloss: 0.123594\tvalid_1's auc: 0.835851\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878348\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.139824\n",
      "[34]\tvalid_0's auc: 0.878909\tvalid_0's binary_logloss: 0.123136\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.139745\n",
      "[35]\tvalid_0's auc: 0.879757\tvalid_0's binary_logloss: 0.122828\tvalid_1's auc: 0.835337\tvalid_1's binary_logloss: 0.139761\n",
      "[36]\tvalid_0's auc: 0.880504\tvalid_0's binary_logloss: 0.122572\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.139792\n",
      "[37]\tvalid_0's auc: 0.881015\tvalid_0's binary_logloss: 0.122349\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.139809\n",
      "[38]\tvalid_0's auc: 0.881565\tvalid_0's binary_logloss: 0.122148\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.139772\n",
      "[39]\tvalid_0's auc: 0.882176\tvalid_0's binary_logloss: 0.121925\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.13977\n",
      "[40]\tvalid_0's auc: 0.882818\tvalid_0's binary_logloss: 0.121683\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.139736\n",
      "[41]\tvalid_0's auc: 0.883353\tvalid_0's binary_logloss: 0.121428\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.139663\n",
      "[42]\tvalid_0's auc: 0.884062\tvalid_0's binary_logloss: 0.121195\tvalid_1's auc: 0.835313\tvalid_1's binary_logloss: 0.139727\n",
      "[43]\tvalid_0's auc: 0.884607\tvalid_0's binary_logloss: 0.120984\tvalid_1's auc: 0.835083\tvalid_1's binary_logloss: 0.139745\n",
      "[44]\tvalid_0's auc: 0.885155\tvalid_0's binary_logloss: 0.120752\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.139761\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.822096\tvalid_0's binary_logloss: 0.15642\tvalid_1's auc: 0.814231\tvalid_1's binary_logloss: 0.165423\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830899\tvalid_0's binary_logloss: 0.151112\tvalid_1's auc: 0.821277\tvalid_1's binary_logloss: 0.160161\n",
      "[3]\tvalid_0's auc: 0.83949\tvalid_0's binary_logloss: 0.147196\tvalid_1's auc: 0.828421\tvalid_1's binary_logloss: 0.156499\n",
      "[4]\tvalid_0's auc: 0.84292\tvalid_0's binary_logloss: 0.14418\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.153682\n",
      "[5]\tvalid_0's auc: 0.846745\tvalid_0's binary_logloss: 0.141793\tvalid_1's auc: 0.836391\tvalid_1's binary_logloss: 0.151366\n",
      "[6]\tvalid_0's auc: 0.849204\tvalid_0's binary_logloss: 0.139816\tvalid_1's auc: 0.838385\tvalid_1's binary_logloss: 0.149412\n",
      "[7]\tvalid_0's auc: 0.850163\tvalid_0's binary_logloss: 0.138129\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.147877\n",
      "[8]\tvalid_0's auc: 0.852051\tvalid_0's binary_logloss: 0.136672\tvalid_1's auc: 0.838308\tvalid_1's binary_logloss: 0.146579\n",
      "[9]\tvalid_0's auc: 0.853307\tvalid_0's binary_logloss: 0.13545\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.145501\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[11]\tvalid_0's auc: 0.855751\tvalid_0's binary_logloss: 0.133459\tvalid_1's auc: 0.839746\tvalid_1's binary_logloss: 0.143859\n",
      "[12]\tvalid_0's auc: 0.856423\tvalid_0's binary_logloss: 0.132613\tvalid_1's auc: 0.838761\tvalid_1's binary_logloss: 0.143262\n",
      "[13]\tvalid_0's auc: 0.857763\tvalid_0's binary_logloss: 0.131837\tvalid_1's auc: 0.838486\tvalid_1's binary_logloss: 0.142774\n",
      "[14]\tvalid_0's auc: 0.858818\tvalid_0's binary_logloss: 0.131136\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.142334\n",
      "[15]\tvalid_0's auc: 0.859873\tvalid_0's binary_logloss: 0.130476\tvalid_1's auc: 0.83747\tvalid_1's binary_logloss: 0.14209\n",
      "[16]\tvalid_0's auc: 0.86059\tvalid_0's binary_logloss: 0.129898\tvalid_1's auc: 0.837199\tvalid_1's binary_logloss: 0.141785\n",
      "[17]\tvalid_0's auc: 0.861469\tvalid_0's binary_logloss: 0.129391\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.141489\n",
      "[18]\tvalid_0's auc: 0.8626\tvalid_0's binary_logloss: 0.128887\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.141321\n",
      "[19]\tvalid_0's auc: 0.863942\tvalid_0's binary_logloss: 0.128362\tvalid_1's auc: 0.837273\tvalid_1's binary_logloss: 0.14108\n",
      "[20]\tvalid_0's auc: 0.865345\tvalid_0's binary_logloss: 0.12787\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.140905\n",
      "[21]\tvalid_0's auc: 0.866373\tvalid_0's binary_logloss: 0.127496\tvalid_1's auc: 0.838239\tvalid_1's binary_logloss: 0.140637\n",
      "[22]\tvalid_0's auc: 0.867435\tvalid_0's binary_logloss: 0.12708\tvalid_1's auc: 0.837639\tvalid_1's binary_logloss: 0.1406\n",
      "[23]\tvalid_0's auc: 0.868304\tvalid_0's binary_logloss: 0.12669\tvalid_1's auc: 0.837619\tvalid_1's binary_logloss: 0.140434\n",
      "[24]\tvalid_0's auc: 0.869271\tvalid_0's binary_logloss: 0.126307\tvalid_1's auc: 0.838019\tvalid_1's binary_logloss: 0.140281\n",
      "[25]\tvalid_0's auc: 0.870212\tvalid_0's binary_logloss: 0.125949\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.14025\n",
      "[26]\tvalid_0's auc: 0.871023\tvalid_0's binary_logloss: 0.125636\tvalid_1's auc: 0.837504\tvalid_1's binary_logloss: 0.140165\n",
      "[27]\tvalid_0's auc: 0.872756\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837762\tvalid_1's binary_logloss: 0.140044\n",
      "[28]\tvalid_0's auc: 0.874041\tvalid_0's binary_logloss: 0.124866\tvalid_1's auc: 0.837513\tvalid_1's binary_logloss: 0.14003\n",
      "[29]\tvalid_0's auc: 0.875088\tvalid_0's binary_logloss: 0.12452\tvalid_1's auc: 0.837397\tvalid_1's binary_logloss: 0.140013\n",
      "[30]\tvalid_0's auc: 0.876006\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.140044\n",
      "[31]\tvalid_0's auc: 0.876443\tvalid_0's binary_logloss: 0.123946\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.139984\n",
      "[32]\tvalid_0's auc: 0.877157\tvalid_0's binary_logloss: 0.123679\tvalid_1's auc: 0.837186\tvalid_1's binary_logloss: 0.139974\n",
      "[33]\tvalid_0's auc: 0.877846\tvalid_0's binary_logloss: 0.123426\tvalid_1's auc: 0.836741\tvalid_1's binary_logloss: 0.140021\n",
      "[34]\tvalid_0's auc: 0.879036\tvalid_0's binary_logloss: 0.123124\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.140057\n",
      "[35]\tvalid_0's auc: 0.879941\tvalid_0's binary_logloss: 0.12285\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.140035\n",
      "[36]\tvalid_0's auc: 0.880696\tvalid_0's binary_logloss: 0.122577\tvalid_1's auc: 0.836552\tvalid_1's binary_logloss: 0.140011\n",
      "[37]\tvalid_0's auc: 0.881398\tvalid_0's binary_logloss: 0.122348\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140062\n",
      "[38]\tvalid_0's auc: 0.882135\tvalid_0's binary_logloss: 0.122135\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.14006\n",
      "[39]\tvalid_0's auc: 0.882826\tvalid_0's binary_logloss: 0.121918\tvalid_1's auc: 0.836302\tvalid_1's binary_logloss: 0.140015\n",
      "[40]\tvalid_0's auc: 0.883347\tvalid_0's binary_logloss: 0.121692\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.139995\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.826319\tvalid_0's binary_logloss: 0.156309\tvalid_1's auc: 0.814027\tvalid_1's binary_logloss: 0.16516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.832276\tvalid_0's binary_logloss: 0.151075\tvalid_1's auc: 0.819879\tvalid_1's binary_logloss: 0.160057\n",
      "[3]\tvalid_0's auc: 0.836968\tvalid_0's binary_logloss: 0.147259\tvalid_1's auc: 0.825144\tvalid_1's binary_logloss: 0.156367\n",
      "[4]\tvalid_0's auc: 0.840937\tvalid_0's binary_logloss: 0.144237\tvalid_1's auc: 0.830372\tvalid_1's binary_logloss: 0.153364\n",
      "[5]\tvalid_0's auc: 0.845178\tvalid_0's binary_logloss: 0.141851\tvalid_1's auc: 0.835122\tvalid_1's binary_logloss: 0.151017\n",
      "[6]\tvalid_0's auc: 0.846202\tvalid_0's binary_logloss: 0.139881\tvalid_1's auc: 0.835139\tvalid_1's binary_logloss: 0.149202\n",
      "[7]\tvalid_0's auc: 0.849501\tvalid_0's binary_logloss: 0.13816\tvalid_1's auc: 0.838439\tvalid_1's binary_logloss: 0.147646\n",
      "[8]\tvalid_0's auc: 0.850898\tvalid_0's binary_logloss: 0.136639\tvalid_1's auc: 0.838862\tvalid_1's binary_logloss: 0.146267\n",
      "[9]\tvalid_0's auc: 0.85237\tvalid_0's binary_logloss: 0.135394\tvalid_1's auc: 0.838585\tvalid_1's binary_logloss: 0.145261\n",
      "[10]\tvalid_0's auc: 0.855108\tvalid_0's binary_logloss: 0.134315\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.144377\n",
      "[11]\tvalid_0's auc: 0.856895\tvalid_0's binary_logloss: 0.133347\tvalid_1's auc: 0.837858\tvalid_1's binary_logloss: 0.143552\n",
      "[12]\tvalid_0's auc: 0.857593\tvalid_0's binary_logloss: 0.132493\tvalid_1's auc: 0.837734\tvalid_1's binary_logloss: 0.14288\n",
      "[13]\tvalid_0's auc: 0.85875\tvalid_0's binary_logloss: 0.131727\tvalid_1's auc: 0.838214\tvalid_1's binary_logloss: 0.142368\n",
      "[14]\tvalid_0's auc: 0.859561\tvalid_0's binary_logloss: 0.131032\tvalid_1's auc: 0.837766\tvalid_1's binary_logloss: 0.14195\n",
      "[15]\tvalid_0's auc: 0.860666\tvalid_0's binary_logloss: 0.130386\tvalid_1's auc: 0.837751\tvalid_1's binary_logloss: 0.141607\n",
      "[16]\tvalid_0's auc: 0.861555\tvalid_0's binary_logloss: 0.129851\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.14128\n",
      "[17]\tvalid_0's auc: 0.863042\tvalid_0's binary_logloss: 0.129232\tvalid_1's auc: 0.83902\tvalid_1's binary_logloss: 0.141008\n",
      "[18]\tvalid_0's auc: 0.864262\tvalid_0's binary_logloss: 0.128631\tvalid_1's auc: 0.839058\tvalid_1's binary_logloss: 0.140747\n",
      "[19]\tvalid_0's auc: 0.86545\tvalid_0's binary_logloss: 0.128138\tvalid_1's auc: 0.838753\tvalid_1's binary_logloss: 0.140544\n",
      "[20]\tvalid_0's auc: 0.8663\tvalid_0's binary_logloss: 0.12769\tvalid_1's auc: 0.83863\tvalid_1's binary_logloss: 0.140304\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[22]\tvalid_0's auc: 0.868709\tvalid_0's binary_logloss: 0.126813\tvalid_1's auc: 0.839171\tvalid_1's binary_logloss: 0.14001\n",
      "[23]\tvalid_0's auc: 0.869543\tvalid_0's binary_logloss: 0.126412\tvalid_1's auc: 0.839032\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.870296\tvalid_0's binary_logloss: 0.126025\tvalid_1's auc: 0.839048\tvalid_1's binary_logloss: 0.139785\n",
      "[25]\tvalid_0's auc: 0.871119\tvalid_0's binary_logloss: 0.125654\tvalid_1's auc: 0.83856\tvalid_1's binary_logloss: 0.139743\n",
      "[26]\tvalid_0's auc: 0.871934\tvalid_0's binary_logloss: 0.12537\tvalid_1's auc: 0.838594\tvalid_1's binary_logloss: 0.139669\n",
      "[27]\tvalid_0's auc: 0.873048\tvalid_0's binary_logloss: 0.125049\tvalid_1's auc: 0.83847\tvalid_1's binary_logloss: 0.139655\n",
      "[28]\tvalid_0's auc: 0.873824\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.838229\tvalid_1's binary_logloss: 0.139655\n",
      "[29]\tvalid_0's auc: 0.874662\tvalid_0's binary_logloss: 0.124467\tvalid_1's auc: 0.838445\tvalid_1's binary_logloss: 0.139579\n",
      "[30]\tvalid_0's auc: 0.87542\tvalid_0's binary_logloss: 0.124168\tvalid_1's auc: 0.838156\tvalid_1's binary_logloss: 0.139548\n",
      "[31]\tvalid_0's auc: 0.876207\tvalid_0's binary_logloss: 0.123915\tvalid_1's auc: 0.838237\tvalid_1's binary_logloss: 0.139538\n",
      "[32]\tvalid_0's auc: 0.877156\tvalid_0's binary_logloss: 0.123623\tvalid_1's auc: 0.838271\tvalid_1's binary_logloss: 0.13947\n",
      "[33]\tvalid_0's auc: 0.87768\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.838713\tvalid_1's binary_logloss: 0.139346\n",
      "[34]\tvalid_0's auc: 0.87849\tvalid_0's binary_logloss: 0.123137\tvalid_1's auc: 0.838649\tvalid_1's binary_logloss: 0.139374\n",
      "[35]\tvalid_0's auc: 0.879407\tvalid_0's binary_logloss: 0.122839\tvalid_1's auc: 0.838892\tvalid_1's binary_logloss: 0.139274\n",
      "[36]\tvalid_0's auc: 0.879965\tvalid_0's binary_logloss: 0.122622\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.139304\n",
      "[37]\tvalid_0's auc: 0.880613\tvalid_0's binary_logloss: 0.122331\tvalid_1's auc: 0.839029\tvalid_1's binary_logloss: 0.139242\n",
      "[38]\tvalid_0's auc: 0.881276\tvalid_0's binary_logloss: 0.122084\tvalid_1's auc: 0.838779\tvalid_1's binary_logloss: 0.139277\n",
      "[39]\tvalid_0's auc: 0.881947\tvalid_0's binary_logloss: 0.121841\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139295\n",
      "[40]\tvalid_0's auc: 0.882617\tvalid_0's binary_logloss: 0.121559\tvalid_1's auc: 0.838919\tvalid_1's binary_logloss: 0.13924\n",
      "[41]\tvalid_0's auc: 0.883227\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.838817\tvalid_1's binary_logloss: 0.13925\n",
      "[42]\tvalid_0's auc: 0.883844\tvalid_0's binary_logloss: 0.121097\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.139244\n",
      "[43]\tvalid_0's auc: 0.884188\tvalid_0's binary_logloss: 0.12095\tvalid_1's auc: 0.838842\tvalid_1's binary_logloss: 0.139242\n",
      "[44]\tvalid_0's auc: 0.884844\tvalid_0's binary_logloss: 0.120718\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.139282\n",
      "[45]\tvalid_0's auc: 0.885417\tvalid_0's binary_logloss: 0.120493\tvalid_1's auc: 0.838678\tvalid_1's binary_logloss: 0.139288\n",
      "[46]\tvalid_0's auc: 0.885803\tvalid_0's binary_logloss: 0.120327\tvalid_1's auc: 0.838716\tvalid_1's binary_logloss: 0.139279\n",
      "[47]\tvalid_0's auc: 0.886486\tvalid_0's binary_logloss: 0.120099\tvalid_1's auc: 0.838668\tvalid_1's binary_logloss: 0.139274\n",
      "[48]\tvalid_0's auc: 0.887253\tvalid_0's binary_logloss: 0.119903\tvalid_1's auc: 0.838451\tvalid_1's binary_logloss: 0.139321\n",
      "[49]\tvalid_0's auc: 0.887742\tvalid_0's binary_logloss: 0.11971\tvalid_1's auc: 0.838484\tvalid_1's binary_logloss: 0.139332\n",
      "[50]\tvalid_0's auc: 0.888224\tvalid_0's binary_logloss: 0.119543\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139353\n",
      "[51]\tvalid_0's auc: 0.888667\tvalid_0's binary_logloss: 0.11938\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.1394\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823467\tvalid_0's binary_logloss: 0.156234\tvalid_1's auc: 0.818359\tvalid_1's binary_logloss: 0.165045\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.831432\tvalid_0's binary_logloss: 0.151096\tvalid_1's auc: 0.822806\tvalid_1's binary_logloss: 0.160035\n",
      "[3]\tvalid_0's auc: 0.837942\tvalid_0's binary_logloss: 0.147265\tvalid_1's auc: 0.827733\tvalid_1's binary_logloss: 0.156278\n",
      "[4]\tvalid_0's auc: 0.842228\tvalid_0's binary_logloss: 0.144266\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.153439\n",
      "[5]\tvalid_0's auc: 0.845913\tvalid_0's binary_logloss: 0.141908\tvalid_1's auc: 0.836078\tvalid_1's binary_logloss: 0.151112\n",
      "[6]\tvalid_0's auc: 0.847301\tvalid_0's binary_logloss: 0.139924\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.149212\n",
      "[7]\tvalid_0's auc: 0.848494\tvalid_0's binary_logloss: 0.138267\tvalid_1's auc: 0.837664\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.849608\tvalid_0's binary_logloss: 0.136839\tvalid_1's auc: 0.839054\tvalid_1's binary_logloss: 0.146332\n",
      "[9]\tvalid_0's auc: 0.851401\tvalid_0's binary_logloss: 0.135609\tvalid_1's auc: 0.839453\tvalid_1's binary_logloss: 0.145351\n",
      "[10]\tvalid_0's auc: 0.852795\tvalid_0's binary_logloss: 0.134534\tvalid_1's auc: 0.840274\tvalid_1's binary_logloss: 0.144391\n",
      "[11]\tvalid_0's auc: 0.853993\tvalid_0's binary_logloss: 0.133621\tvalid_1's auc: 0.840484\tvalid_1's binary_logloss: 0.143622\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[13]\tvalid_0's auc: 0.857408\tvalid_0's binary_logloss: 0.131982\tvalid_1's auc: 0.840313\tvalid_1's binary_logloss: 0.142428\n",
      "[14]\tvalid_0's auc: 0.858394\tvalid_0's binary_logloss: 0.131254\tvalid_1's auc: 0.840441\tvalid_1's binary_logloss: 0.141892\n",
      "[15]\tvalid_0's auc: 0.859543\tvalid_0's binary_logloss: 0.130617\tvalid_1's auc: 0.840527\tvalid_1's binary_logloss: 0.141536\n",
      "[16]\tvalid_0's auc: 0.860896\tvalid_0's binary_logloss: 0.130045\tvalid_1's auc: 0.839976\tvalid_1's binary_logloss: 0.141199\n",
      "[17]\tvalid_0's auc: 0.862165\tvalid_0's binary_logloss: 0.129495\tvalid_1's auc: 0.840423\tvalid_1's binary_logloss: 0.140913\n",
      "[18]\tvalid_0's auc: 0.863167\tvalid_0's binary_logloss: 0.128982\tvalid_1's auc: 0.840347\tvalid_1's binary_logloss: 0.140622\n",
      "[19]\tvalid_0's auc: 0.864691\tvalid_0's binary_logloss: 0.128474\tvalid_1's auc: 0.840438\tvalid_1's binary_logloss: 0.140372\n",
      "[20]\tvalid_0's auc: 0.865493\tvalid_0's binary_logloss: 0.128073\tvalid_1's auc: 0.840373\tvalid_1's binary_logloss: 0.140128\n",
      "[21]\tvalid_0's auc: 0.866463\tvalid_0's binary_logloss: 0.127636\tvalid_1's auc: 0.840418\tvalid_1's binary_logloss: 0.139909\n",
      "[22]\tvalid_0's auc: 0.867081\tvalid_0's binary_logloss: 0.12726\tvalid_1's auc: 0.840315\tvalid_1's binary_logloss: 0.139758\n",
      "[23]\tvalid_0's auc: 0.867656\tvalid_0's binary_logloss: 0.126888\tvalid_1's auc: 0.839878\tvalid_1's binary_logloss: 0.139751\n",
      "[24]\tvalid_0's auc: 0.868511\tvalid_0's binary_logloss: 0.12652\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.13964\n",
      "[25]\tvalid_0's auc: 0.869233\tvalid_0's binary_logloss: 0.126158\tvalid_1's auc: 0.840131\tvalid_1's binary_logloss: 0.139495\n",
      "[26]\tvalid_0's auc: 0.870146\tvalid_0's binary_logloss: 0.12583\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139487\n",
      "[27]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.125495\tvalid_1's auc: 0.83977\tvalid_1's binary_logloss: 0.139452\n",
      "[28]\tvalid_0's auc: 0.872449\tvalid_0's binary_logloss: 0.125203\tvalid_1's auc: 0.839707\tvalid_1's binary_logloss: 0.139417\n",
      "[29]\tvalid_0's auc: 0.87307\tvalid_0's binary_logloss: 0.124902\tvalid_1's auc: 0.840062\tvalid_1's binary_logloss: 0.13934\n",
      "[30]\tvalid_0's auc: 0.874009\tvalid_0's binary_logloss: 0.124599\tvalid_1's auc: 0.839797\tvalid_1's binary_logloss: 0.139335\n",
      "[31]\tvalid_0's auc: 0.874961\tvalid_0's binary_logloss: 0.124243\tvalid_1's auc: 0.839401\tvalid_1's binary_logloss: 0.139341\n",
      "[32]\tvalid_0's auc: 0.875534\tvalid_0's binary_logloss: 0.12399\tvalid_1's auc: 0.839344\tvalid_1's binary_logloss: 0.139318\n",
      "[33]\tvalid_0's auc: 0.876073\tvalid_0's binary_logloss: 0.12375\tvalid_1's auc: 0.839413\tvalid_1's binary_logloss: 0.139291\n",
      "[34]\tvalid_0's auc: 0.876721\tvalid_0's binary_logloss: 0.123522\tvalid_1's auc: 0.839706\tvalid_1's binary_logloss: 0.139235\n",
      "[35]\tvalid_0's auc: 0.877275\tvalid_0's binary_logloss: 0.123252\tvalid_1's auc: 0.840335\tvalid_1's binary_logloss: 0.139044\n",
      "[36]\tvalid_0's auc: 0.877922\tvalid_0's binary_logloss: 0.123055\tvalid_1's auc: 0.840293\tvalid_1's binary_logloss: 0.13902\n",
      "[37]\tvalid_0's auc: 0.878499\tvalid_0's binary_logloss: 0.122801\tvalid_1's auc: 0.840333\tvalid_1's binary_logloss: 0.138988\n",
      "[38]\tvalid_0's auc: 0.879297\tvalid_0's binary_logloss: 0.122522\tvalid_1's auc: 0.840156\tvalid_1's binary_logloss: 0.139034\n",
      "[39]\tvalid_0's auc: 0.880019\tvalid_0's binary_logloss: 0.122297\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.138997\n",
      "[40]\tvalid_0's auc: 0.88064\tvalid_0's binary_logloss: 0.122051\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.139001\n",
      "[41]\tvalid_0's auc: 0.88151\tvalid_0's binary_logloss: 0.121784\tvalid_1's auc: 0.839739\tvalid_1's binary_logloss: 0.13906\n",
      "[42]\tvalid_0's auc: 0.882288\tvalid_0's binary_logloss: 0.121573\tvalid_1's auc: 0.839558\tvalid_1's binary_logloss: 0.139089\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.822477\tvalid_0's binary_logloss: 0.156615\tvalid_1's auc: 0.818936\tvalid_1's binary_logloss: 0.16507\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829931\tvalid_0's binary_logloss: 0.151227\tvalid_1's auc: 0.824213\tvalid_1's binary_logloss: 0.159973\n",
      "[3]\tvalid_0's auc: 0.835788\tvalid_0's binary_logloss: 0.147372\tvalid_1's auc: 0.829555\tvalid_1's binary_logloss: 0.156407\n",
      "[4]\tvalid_0's auc: 0.842398\tvalid_0's binary_logloss: 0.14436\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.153426\n",
      "[5]\tvalid_0's auc: 0.84472\tvalid_0's binary_logloss: 0.141969\tvalid_1's auc: 0.835438\tvalid_1's binary_logloss: 0.15118\n",
      "[6]\tvalid_0's auc: 0.846873\tvalid_0's binary_logloss: 0.13984\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.149232\n",
      "[7]\tvalid_0's auc: 0.849397\tvalid_0's binary_logloss: 0.138081\tvalid_1's auc: 0.838165\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.850636\tvalid_0's binary_logloss: 0.136651\tvalid_1's auc: 0.839203\tvalid_1's binary_logloss: 0.146397\n",
      "[9]\tvalid_0's auc: 0.852058\tvalid_0's binary_logloss: 0.135397\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.145335\n",
      "[10]\tvalid_0's auc: 0.853752\tvalid_0's binary_logloss: 0.134296\tvalid_1's auc: 0.840124\tvalid_1's binary_logloss: 0.144474\n",
      "[11]\tvalid_0's auc: 0.855331\tvalid_0's binary_logloss: 0.133348\tvalid_1's auc: 0.839897\tvalid_1's binary_logloss: 0.143725\n",
      "[12]\tvalid_0's auc: 0.857453\tvalid_0's binary_logloss: 0.13245\tvalid_1's auc: 0.84039\tvalid_1's binary_logloss: 0.143067\n",
      "[13]\tvalid_0's auc: 0.858781\tvalid_0's binary_logloss: 0.131689\tvalid_1's auc: 0.840851\tvalid_1's binary_logloss: 0.14244\n",
      "[14]\tvalid_0's auc: 0.860635\tvalid_0's binary_logloss: 0.130982\tvalid_1's auc: 0.840623\tvalid_1's binary_logloss: 0.141945\n",
      "[15]\tvalid_0's auc: 0.861771\tvalid_0's binary_logloss: 0.130283\tvalid_1's auc: 0.84085\tvalid_1's binary_logloss: 0.141501\n",
      "[16]\tvalid_0's auc: 0.863226\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.840816\tvalid_1's binary_logloss: 0.14118\n",
      "[17]\tvalid_0's auc: 0.864022\tvalid_0's binary_logloss: 0.129132\tvalid_1's auc: 0.841034\tvalid_1's binary_logloss: 0.140867\n",
      "[18]\tvalid_0's auc: 0.865122\tvalid_0's binary_logloss: 0.128586\tvalid_1's auc: 0.841066\tvalid_1's binary_logloss: 0.140645\n",
      "[19]\tvalid_0's auc: 0.866114\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.841164\tvalid_1's binary_logloss: 0.140459\n",
      "[20]\tvalid_0's auc: 0.86733\tvalid_0's binary_logloss: 0.127618\tvalid_1's auc: 0.841078\tvalid_1's binary_logloss: 0.140192\n",
      "[21]\tvalid_0's auc: 0.86847\tvalid_0's binary_logloss: 0.12718\tvalid_1's auc: 0.842056\tvalid_1's binary_logloss: 0.139899\n",
      "[22]\tvalid_0's auc: 0.86912\tvalid_0's binary_logloss: 0.126786\tvalid_1's auc: 0.842604\tvalid_1's binary_logloss: 0.139581\n",
      "[23]\tvalid_0's auc: 0.8702\tvalid_0's binary_logloss: 0.1264\tvalid_1's auc: 0.842923\tvalid_1's binary_logloss: 0.13938\n",
      "[24]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.126012\tvalid_1's auc: 0.842853\tvalid_1's binary_logloss: 0.139199\n",
      "[25]\tvalid_0's auc: 0.871861\tvalid_0's binary_logloss: 0.125716\tvalid_1's auc: 0.842924\tvalid_1's binary_logloss: 0.139114\n",
      "[26]\tvalid_0's auc: 0.872932\tvalid_0's binary_logloss: 0.125379\tvalid_1's auc: 0.842821\tvalid_1's binary_logloss: 0.139002\n",
      "[27]\tvalid_0's auc: 0.873488\tvalid_0's binary_logloss: 0.125055\tvalid_1's auc: 0.842803\tvalid_1's binary_logloss: 0.138866\n",
      "[28]\tvalid_0's auc: 0.874282\tvalid_0's binary_logloss: 0.124763\tvalid_1's auc: 0.842697\tvalid_1's binary_logloss: 0.138796\n",
      "[29]\tvalid_0's auc: 0.875185\tvalid_0's binary_logloss: 0.124481\tvalid_1's auc: 0.843506\tvalid_1's binary_logloss: 0.138625\n",
      "[30]\tvalid_0's auc: 0.875805\tvalid_0's binary_logloss: 0.124216\tvalid_1's auc: 0.843564\tvalid_1's binary_logloss: 0.138532\n",
      "[31]\tvalid_0's auc: 0.877289\tvalid_0's binary_logloss: 0.123898\tvalid_1's auc: 0.84385\tvalid_1's binary_logloss: 0.138455\n",
      "[32]\tvalid_0's auc: 0.878137\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.843943\tvalid_1's binary_logloss: 0.138401\n",
      "[33]\tvalid_0's auc: 0.879141\tvalid_0's binary_logloss: 0.123349\tvalid_1's auc: 0.843945\tvalid_1's binary_logloss: 0.13837\n",
      "[34]\tvalid_0's auc: 0.879829\tvalid_0's binary_logloss: 0.123074\tvalid_1's auc: 0.844035\tvalid_1's binary_logloss: 0.13828\n",
      "[35]\tvalid_0's auc: 0.880826\tvalid_0's binary_logloss: 0.122813\tvalid_1's auc: 0.844275\tvalid_1's binary_logloss: 0.138226\n",
      "[36]\tvalid_0's auc: 0.881493\tvalid_0's binary_logloss: 0.122554\tvalid_1's auc: 0.844344\tvalid_1's binary_logloss: 0.138161\n",
      "[37]\tvalid_0's auc: 0.882368\tvalid_0's binary_logloss: 0.122305\tvalid_1's auc: 0.844143\tvalid_1's binary_logloss: 0.138162\n",
      "[38]\tvalid_0's auc: 0.882945\tvalid_0's binary_logloss: 0.122019\tvalid_1's auc: 0.844149\tvalid_1's binary_logloss: 0.13813\n",
      "[39]\tvalid_0's auc: 0.883584\tvalid_0's binary_logloss: 0.121799\tvalid_1's auc: 0.843977\tvalid_1's binary_logloss: 0.138149\n",
      "[40]\tvalid_0's auc: 0.88416\tvalid_0's binary_logloss: 0.121576\tvalid_1's auc: 0.844146\tvalid_1's binary_logloss: 0.138147\n",
      "[41]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.12135\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138128\n",
      "[42]\tvalid_0's auc: 0.885638\tvalid_0's binary_logloss: 0.121096\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138106\n",
      "[43]\tvalid_0's auc: 0.886395\tvalid_0's binary_logloss: 0.120905\tvalid_1's auc: 0.844184\tvalid_1's binary_logloss: 0.138052\n",
      "[44]\tvalid_0's auc: 0.887071\tvalid_0's binary_logloss: 0.120678\tvalid_1's auc: 0.844103\tvalid_1's binary_logloss: 0.138065\n",
      "[45]\tvalid_0's auc: 0.887784\tvalid_0's binary_logloss: 0.120428\tvalid_1's auc: 0.844152\tvalid_1's binary_logloss: 0.138057\n",
      "[46]\tvalid_0's auc: 0.888342\tvalid_0's binary_logloss: 0.120223\tvalid_1's auc: 0.844297\tvalid_1's binary_logloss: 0.138025\n",
      "[47]\tvalid_0's auc: 0.888722\tvalid_0's binary_logloss: 0.119986\tvalid_1's auc: 0.844276\tvalid_1's binary_logloss: 0.138002\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[49]\tvalid_0's auc: 0.889545\tvalid_0's binary_logloss: 0.119601\tvalid_1's auc: 0.844447\tvalid_1's binary_logloss: 0.138002\n",
      "[50]\tvalid_0's auc: 0.89018\tvalid_0's binary_logloss: 0.119358\tvalid_1's auc: 0.844336\tvalid_1's binary_logloss: 0.138021\n",
      "[51]\tvalid_0's auc: 0.890603\tvalid_0's binary_logloss: 0.119182\tvalid_1's auc: 0.84438\tvalid_1's binary_logloss: 0.138019\n",
      "[52]\tvalid_0's auc: 0.891517\tvalid_0's binary_logloss: 0.118924\tvalid_1's auc: 0.844393\tvalid_1's binary_logloss: 0.13803\n",
      "[53]\tvalid_0's auc: 0.891938\tvalid_0's binary_logloss: 0.118749\tvalid_1's auc: 0.844183\tvalid_1's binary_logloss: 0.138086\n",
      "[54]\tvalid_0's auc: 0.892252\tvalid_0's binary_logloss: 0.118601\tvalid_1's auc: 0.844352\tvalid_1's binary_logloss: 0.138077\n",
      "[55]\tvalid_0's auc: 0.892749\tvalid_0's binary_logloss: 0.118391\tvalid_1's auc: 0.84432\tvalid_1's binary_logloss: 0.138057\n",
      "[56]\tvalid_0's auc: 0.893267\tvalid_0's binary_logloss: 0.118246\tvalid_1's auc: 0.844305\tvalid_1's binary_logloss: 0.138061\n",
      "[57]\tvalid_0's auc: 0.893589\tvalid_0's binary_logloss: 0.118094\tvalid_1's auc: 0.844225\tvalid_1's binary_logloss: 0.138064\n",
      "[58]\tvalid_0's auc: 0.89387\tvalid_0's binary_logloss: 0.117959\tvalid_1's auc: 0.844327\tvalid_1's binary_logloss: 0.138044\n",
      "[59]\tvalid_0's auc: 0.894196\tvalid_0's binary_logloss: 0.117784\tvalid_1's auc: 0.844144\tvalid_1's binary_logloss: 0.138088\n",
      "[60]\tvalid_0's auc: 0.894754\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.843942\tvalid_1's binary_logloss: 0.138136\n",
      "[61]\tvalid_0's auc: 0.895224\tvalid_0's binary_logloss: 0.117358\tvalid_1's auc: 0.844107\tvalid_1's binary_logloss: 0.138135\n",
      "[62]\tvalid_0's auc: 0.895747\tvalid_0's binary_logloss: 0.117116\tvalid_1's auc: 0.844033\tvalid_1's binary_logloss: 0.138143\n",
      "[63]\tvalid_0's auc: 0.896042\tvalid_0's binary_logloss: 0.116934\tvalid_1's auc: 0.844057\tvalid_1's binary_logloss: 0.138188\n",
      "[64]\tvalid_0's auc: 0.89648\tvalid_0's binary_logloss: 0.116742\tvalid_1's auc: 0.843882\tvalid_1's binary_logloss: 0.138258\n",
      "[65]\tvalid_0's auc: 0.8968\tvalid_0's binary_logloss: 0.116596\tvalid_1's auc: 0.843553\tvalid_1's binary_logloss: 0.138317\n",
      "[66]\tvalid_0's auc: 0.89727\tvalid_0's binary_logloss: 0.116455\tvalid_1's auc: 0.843435\tvalid_1's binary_logloss: 0.138362\n",
      "[67]\tvalid_0's auc: 0.897643\tvalid_0's binary_logloss: 0.11627\tvalid_1's auc: 0.843148\tvalid_1's binary_logloss: 0.138424\n",
      "[68]\tvalid_0's auc: 0.898008\tvalid_0's binary_logloss: 0.116079\tvalid_1's auc: 0.843355\tvalid_1's binary_logloss: 0.138452\n",
      "[69]\tvalid_0's auc: 0.898293\tvalid_0's binary_logloss: 0.115943\tvalid_1's auc: 0.843203\tvalid_1's binary_logloss: 0.138515\n",
      "[70]\tvalid_0's auc: 0.898585\tvalid_0's binary_logloss: 0.115794\tvalid_1's auc: 0.84311\tvalid_1's binary_logloss: 0.138551\n",
      "[71]\tvalid_0's auc: 0.898878\tvalid_0's binary_logloss: 0.115634\tvalid_1's auc: 0.843163\tvalid_1's binary_logloss: 0.138557\n",
      "[72]\tvalid_0's auc: 0.89933\tvalid_0's binary_logloss: 0.11544\tvalid_1's auc: 0.843123\tvalid_1's binary_logloss: 0.138587\n",
      "[73]\tvalid_0's auc: 0.899665\tvalid_0's binary_logloss: 0.115279\tvalid_1's auc: 0.843158\tvalid_1's binary_logloss: 0.138606\n",
      "[74]\tvalid_0's auc: 0.899872\tvalid_0's binary_logloss: 0.115145\tvalid_1's auc: 0.843153\tvalid_1's binary_logloss: 0.138622\n",
      "[75]\tvalid_0's auc: 0.900318\tvalid_0's binary_logloss: 0.115012\tvalid_1's auc: 0.8431\tvalid_1's binary_logloss: 0.138652\n",
      "[76]\tvalid_0's auc: 0.900838\tvalid_0's binary_logloss: 0.114797\tvalid_1's auc: 0.843128\tvalid_1's binary_logloss: 0.138654\n",
      "[77]\tvalid_0's auc: 0.901053\tvalid_0's binary_logloss: 0.11465\tvalid_1's auc: 0.843183\tvalid_1's binary_logloss: 0.138667\n",
      "[78]\tvalid_0's auc: 0.901334\tvalid_0's binary_logloss: 0.114492\tvalid_1's auc: 0.843036\tvalid_1's binary_logloss: 0.138728\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.833136\tvalid_0's binary_logloss: 0.155618\tvalid_1's auc: 0.823516\tvalid_1's binary_logloss: 0.164757\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842036\tvalid_0's binary_logloss: 0.149972\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.159717\n",
      "[3]\tvalid_0's auc: 0.847172\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.830898\tvalid_1's binary_logloss: 0.156155\n",
      "[4]\tvalid_0's auc: 0.854159\tvalid_0's binary_logloss: 0.142767\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.153226\n",
      "[5]\tvalid_0's auc: 0.857704\tvalid_0's binary_logloss: 0.140143\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.15094\n",
      "[6]\tvalid_0's auc: 0.860316\tvalid_0's binary_logloss: 0.137951\tvalid_1's auc: 0.836175\tvalid_1's binary_logloss: 0.149162\n",
      "[7]\tvalid_0's auc: 0.862439\tvalid_0's binary_logloss: 0.136077\tvalid_1's auc: 0.835532\tvalid_1's binary_logloss: 0.147649\n",
      "[8]\tvalid_0's auc: 0.864272\tvalid_0's binary_logloss: 0.134388\tvalid_1's auc: 0.83563\tvalid_1's binary_logloss: 0.146354\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[10]\tvalid_0's auc: 0.867535\tvalid_0's binary_logloss: 0.13164\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.144361\n",
      "[11]\tvalid_0's auc: 0.869515\tvalid_0's binary_logloss: 0.130402\tvalid_1's auc: 0.83647\tvalid_1's binary_logloss: 0.143633\n",
      "[12]\tvalid_0's auc: 0.870746\tvalid_0's binary_logloss: 0.129418\tvalid_1's auc: 0.836512\tvalid_1's binary_logloss: 0.14302\n",
      "[13]\tvalid_0's auc: 0.872719\tvalid_0's binary_logloss: 0.12844\tvalid_1's auc: 0.836236\tvalid_1's binary_logloss: 0.142554\n",
      "[14]\tvalid_0's auc: 0.874567\tvalid_0's binary_logloss: 0.127509\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.142114\n",
      "[15]\tvalid_0's auc: 0.876764\tvalid_0's binary_logloss: 0.126626\tvalid_1's auc: 0.836237\tvalid_1's binary_logloss: 0.141748\n",
      "[16]\tvalid_0's auc: 0.87792\tvalid_0's binary_logloss: 0.125854\tvalid_1's auc: 0.836368\tvalid_1's binary_logloss: 0.141474\n",
      "[17]\tvalid_0's auc: 0.879062\tvalid_0's binary_logloss: 0.125102\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.14123\n",
      "[18]\tvalid_0's auc: 0.880333\tvalid_0's binary_logloss: 0.12445\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.14109\n",
      "[19]\tvalid_0's auc: 0.881986\tvalid_0's binary_logloss: 0.123735\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.140974\n",
      "[20]\tvalid_0's auc: 0.883497\tvalid_0's binary_logloss: 0.123057\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.140833\n",
      "[21]\tvalid_0's auc: 0.88477\tvalid_0's binary_logloss: 0.122502\tvalid_1's auc: 0.83413\tvalid_1's binary_logloss: 0.140756\n",
      "[22]\tvalid_0's auc: 0.886052\tvalid_0's binary_logloss: 0.121963\tvalid_1's auc: 0.833448\tvalid_1's binary_logloss: 0.140744\n",
      "[23]\tvalid_0's auc: 0.88729\tvalid_0's binary_logloss: 0.121374\tvalid_1's auc: 0.832949\tvalid_1's binary_logloss: 0.140705\n",
      "[24]\tvalid_0's auc: 0.888202\tvalid_0's binary_logloss: 0.120845\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.140716\n",
      "[25]\tvalid_0's auc: 0.889261\tvalid_0's binary_logloss: 0.120276\tvalid_1's auc: 0.832717\tvalid_1's binary_logloss: 0.140524\n",
      "[26]\tvalid_0's auc: 0.89008\tvalid_0's binary_logloss: 0.119792\tvalid_1's auc: 0.832126\tvalid_1's binary_logloss: 0.140541\n",
      "[27]\tvalid_0's auc: 0.891071\tvalid_0's binary_logloss: 0.119365\tvalid_1's auc: 0.832245\tvalid_1's binary_logloss: 0.140458\n",
      "[28]\tvalid_0's auc: 0.891965\tvalid_0's binary_logloss: 0.118917\tvalid_1's auc: 0.832098\tvalid_1's binary_logloss: 0.140348\n",
      "[29]\tvalid_0's auc: 0.893292\tvalid_0's binary_logloss: 0.118413\tvalid_1's auc: 0.832091\tvalid_1's binary_logloss: 0.140371\n",
      "[30]\tvalid_0's auc: 0.894193\tvalid_0's binary_logloss: 0.118022\tvalid_1's auc: 0.831601\tvalid_1's binary_logloss: 0.140412\n",
      "[31]\tvalid_0's auc: 0.894983\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.140402\n",
      "[32]\tvalid_0's auc: 0.896347\tvalid_0's binary_logloss: 0.117114\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.14049\n",
      "[33]\tvalid_0's auc: 0.897531\tvalid_0's binary_logloss: 0.116696\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.140462\n",
      "[34]\tvalid_0's auc: 0.898503\tvalid_0's binary_logloss: 0.116337\tvalid_1's auc: 0.831998\tvalid_1's binary_logloss: 0.140436\n",
      "[35]\tvalid_0's auc: 0.899431\tvalid_0's binary_logloss: 0.115966\tvalid_1's auc: 0.832323\tvalid_1's binary_logloss: 0.140357\n",
      "[36]\tvalid_0's auc: 0.900259\tvalid_0's binary_logloss: 0.115619\tvalid_1's auc: 0.832052\tvalid_1's binary_logloss: 0.140411\n",
      "[37]\tvalid_0's auc: 0.901414\tvalid_0's binary_logloss: 0.115269\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.14042\n",
      "[38]\tvalid_0's auc: 0.902365\tvalid_0's binary_logloss: 0.114862\tvalid_1's auc: 0.832015\tvalid_1's binary_logloss: 0.140464\n",
      "[39]\tvalid_0's auc: 0.90309\tvalid_0's binary_logloss: 0.114499\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.140399\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.833297\tvalid_0's binary_logloss: 0.155798\tvalid_1's auc: 0.814648\tvalid_1's binary_logloss: 0.165178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.84496\tvalid_0's binary_logloss: 0.150106\tvalid_1's auc: 0.825101\tvalid_1's binary_logloss: 0.159672\n",
      "[3]\tvalid_0's auc: 0.848339\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.829756\tvalid_1's binary_logloss: 0.156122\n",
      "[4]\tvalid_0's auc: 0.852327\tvalid_0's binary_logloss: 0.142785\tvalid_1's auc: 0.83262\tvalid_1's binary_logloss: 0.153215\n",
      "[5]\tvalid_0's auc: 0.856991\tvalid_0's binary_logloss: 0.140075\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.150936\n",
      "[6]\tvalid_0's auc: 0.860123\tvalid_0's binary_logloss: 0.13786\tvalid_1's auc: 0.837776\tvalid_1's binary_logloss: 0.149015\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[8]\tvalid_0's auc: 0.863556\tvalid_0's binary_logloss: 0.134329\tvalid_1's auc: 0.837522\tvalid_1's binary_logloss: 0.146495\n",
      "[9]\tvalid_0's auc: 0.865702\tvalid_0's binary_logloss: 0.132867\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.145505\n",
      "[10]\tvalid_0's auc: 0.867419\tvalid_0's binary_logloss: 0.131589\tvalid_1's auc: 0.83738\tvalid_1's binary_logloss: 0.144639\n",
      "[11]\tvalid_0's auc: 0.869474\tvalid_0's binary_logloss: 0.130487\tvalid_1's auc: 0.837061\tvalid_1's binary_logloss: 0.143902\n",
      "[12]\tvalid_0's auc: 0.871188\tvalid_0's binary_logloss: 0.12944\tvalid_1's auc: 0.83674\tvalid_1's binary_logloss: 0.14338\n",
      "[13]\tvalid_0's auc: 0.873292\tvalid_0's binary_logloss: 0.128408\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.142955\n",
      "[14]\tvalid_0's auc: 0.875272\tvalid_0's binary_logloss: 0.127498\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.142577\n",
      "[15]\tvalid_0's auc: 0.876333\tvalid_0's binary_logloss: 0.126687\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.142233\n",
      "[16]\tvalid_0's auc: 0.878172\tvalid_0's binary_logloss: 0.125868\tvalid_1's auc: 0.835135\tvalid_1's binary_logloss: 0.141915\n",
      "[17]\tvalid_0's auc: 0.879493\tvalid_0's binary_logloss: 0.125166\tvalid_1's auc: 0.834462\tvalid_1's binary_logloss: 0.141684\n",
      "[18]\tvalid_0's auc: 0.880697\tvalid_0's binary_logloss: 0.124485\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.141381\n",
      "[19]\tvalid_0's auc: 0.881751\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.141089\n",
      "[20]\tvalid_0's auc: 0.883208\tvalid_0's binary_logloss: 0.123231\tvalid_1's auc: 0.834617\tvalid_1's binary_logloss: 0.141074\n",
      "[21]\tvalid_0's auc: 0.884441\tvalid_0's binary_logloss: 0.122672\tvalid_1's auc: 0.835086\tvalid_1's binary_logloss: 0.140871\n",
      "[22]\tvalid_0's auc: 0.885795\tvalid_0's binary_logloss: 0.122047\tvalid_1's auc: 0.834691\tvalid_1's binary_logloss: 0.140833\n",
      "[23]\tvalid_0's auc: 0.88703\tvalid_0's binary_logloss: 0.121437\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.14067\n",
      "[24]\tvalid_0's auc: 0.888628\tvalid_0's binary_logloss: 0.120866\tvalid_1's auc: 0.834703\tvalid_1's binary_logloss: 0.140607\n",
      "[25]\tvalid_0's auc: 0.889539\tvalid_0's binary_logloss: 0.120354\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.140572\n",
      "[26]\tvalid_0's auc: 0.890707\tvalid_0's binary_logloss: 0.119835\tvalid_1's auc: 0.834353\tvalid_1's binary_logloss: 0.140508\n",
      "[27]\tvalid_0's auc: 0.89189\tvalid_0's binary_logloss: 0.119344\tvalid_1's auc: 0.833736\tvalid_1's binary_logloss: 0.14057\n",
      "[28]\tvalid_0's auc: 0.892973\tvalid_0's binary_logloss: 0.118875\tvalid_1's auc: 0.83339\tvalid_1's binary_logloss: 0.140614\n",
      "[29]\tvalid_0's auc: 0.894538\tvalid_0's binary_logloss: 0.118402\tvalid_1's auc: 0.833262\tvalid_1's binary_logloss: 0.140617\n",
      "[30]\tvalid_0's auc: 0.895805\tvalid_0's binary_logloss: 0.117902\tvalid_1's auc: 0.832581\tvalid_1's binary_logloss: 0.140733\n",
      "[31]\tvalid_0's auc: 0.897165\tvalid_0's binary_logloss: 0.117449\tvalid_1's auc: 0.832965\tvalid_1's binary_logloss: 0.14067\n",
      "[32]\tvalid_0's auc: 0.898106\tvalid_0's binary_logloss: 0.117027\tvalid_1's auc: 0.832548\tvalid_1's binary_logloss: 0.140717\n",
      "[33]\tvalid_0's auc: 0.898897\tvalid_0's binary_logloss: 0.116646\tvalid_1's auc: 0.832294\tvalid_1's binary_logloss: 0.140755\n",
      "[34]\tvalid_0's auc: 0.899579\tvalid_0's binary_logloss: 0.11632\tvalid_1's auc: 0.832478\tvalid_1's binary_logloss: 0.14074\n",
      "[35]\tvalid_0's auc: 0.900941\tvalid_0's binary_logloss: 0.115884\tvalid_1's auc: 0.83257\tvalid_1's binary_logloss: 0.140703\n",
      "[36]\tvalid_0's auc: 0.902074\tvalid_0's binary_logloss: 0.115452\tvalid_1's auc: 0.832369\tvalid_1's binary_logloss: 0.140774\n",
      "[37]\tvalid_0's auc: 0.902849\tvalid_0's binary_logloss: 0.115101\tvalid_1's auc: 0.832046\tvalid_1's binary_logloss: 0.140792\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.834438\tvalid_0's binary_logloss: 0.155707\tvalid_1's auc: 0.821419\tvalid_1's binary_logloss: 0.164715\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845934\tvalid_0's binary_logloss: 0.150048\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.159506\n",
      "[3]\tvalid_0's auc: 0.849836\tvalid_0's binary_logloss: 0.145927\tvalid_1's auc: 0.831719\tvalid_1's binary_logloss: 0.155735\n",
      "[4]\tvalid_0's auc: 0.854642\tvalid_0's binary_logloss: 0.142686\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.152919\n",
      "[5]\tvalid_0's auc: 0.856628\tvalid_0's binary_logloss: 0.139976\tvalid_1's auc: 0.83701\tvalid_1's binary_logloss: 0.15048\n",
      "[6]\tvalid_0's auc: 0.859766\tvalid_0's binary_logloss: 0.137707\tvalid_1's auc: 0.83737\tvalid_1's binary_logloss: 0.148709\n",
      "[7]\tvalid_0's auc: 0.861667\tvalid_0's binary_logloss: 0.13588\tvalid_1's auc: 0.837028\tvalid_1's binary_logloss: 0.147239\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[9]\tvalid_0's auc: 0.866131\tvalid_0's binary_logloss: 0.132702\tvalid_1's auc: 0.837967\tvalid_1's binary_logloss: 0.144848\n",
      "[10]\tvalid_0's auc: 0.867742\tvalid_0's binary_logloss: 0.1314\tvalid_1's auc: 0.837692\tvalid_1's binary_logloss: 0.143974\n",
      "[11]\tvalid_0's auc: 0.869179\tvalid_0's binary_logloss: 0.130269\tvalid_1's auc: 0.837036\tvalid_1's binary_logloss: 0.143346\n",
      "[12]\tvalid_0's auc: 0.870565\tvalid_0's binary_logloss: 0.129231\tvalid_1's auc: 0.836722\tvalid_1's binary_logloss: 0.14276\n",
      "[13]\tvalid_0's auc: 0.871715\tvalid_0's binary_logloss: 0.128325\tvalid_1's auc: 0.836964\tvalid_1's binary_logloss: 0.14221\n",
      "[14]\tvalid_0's auc: 0.873118\tvalid_0's binary_logloss: 0.127433\tvalid_1's auc: 0.836616\tvalid_1's binary_logloss: 0.141769\n",
      "[15]\tvalid_0's auc: 0.874777\tvalid_0's binary_logloss: 0.126525\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.141352\n",
      "[16]\tvalid_0's auc: 0.876077\tvalid_0's binary_logloss: 0.125761\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.141109\n",
      "[17]\tvalid_0's auc: 0.87775\tvalid_0's binary_logloss: 0.125008\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.140988\n",
      "[18]\tvalid_0's auc: 0.879171\tvalid_0's binary_logloss: 0.124326\tvalid_1's auc: 0.837265\tvalid_1's binary_logloss: 0.140636\n",
      "[19]\tvalid_0's auc: 0.880771\tvalid_0's binary_logloss: 0.123637\tvalid_1's auc: 0.836922\tvalid_1's binary_logloss: 0.140454\n",
      "[20]\tvalid_0's auc: 0.882476\tvalid_0's binary_logloss: 0.123001\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.140307\n",
      "[21]\tvalid_0's auc: 0.883998\tvalid_0's binary_logloss: 0.122399\tvalid_1's auc: 0.83698\tvalid_1's binary_logloss: 0.140209\n",
      "[22]\tvalid_0's auc: 0.885371\tvalid_0's binary_logloss: 0.121789\tvalid_1's auc: 0.836641\tvalid_1's binary_logloss: 0.140165\n",
      "[23]\tvalid_0's auc: 0.886707\tvalid_0's binary_logloss: 0.121228\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.140035\n",
      "[24]\tvalid_0's auc: 0.887902\tvalid_0's binary_logloss: 0.120685\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.139977\n",
      "[25]\tvalid_0's auc: 0.889092\tvalid_0's binary_logloss: 0.12018\tvalid_1's auc: 0.83633\tvalid_1's binary_logloss: 0.139976\n",
      "[26]\tvalid_0's auc: 0.890287\tvalid_0's binary_logloss: 0.119694\tvalid_1's auc: 0.836088\tvalid_1's binary_logloss: 0.13994\n",
      "[27]\tvalid_0's auc: 0.891557\tvalid_0's binary_logloss: 0.11921\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.139925\n",
      "[28]\tvalid_0's auc: 0.892479\tvalid_0's binary_logloss: 0.118767\tvalid_1's auc: 0.836047\tvalid_1's binary_logloss: 0.139873\n",
      "[29]\tvalid_0's auc: 0.893752\tvalid_0's binary_logloss: 0.118311\tvalid_1's auc: 0.836111\tvalid_1's binary_logloss: 0.139884\n",
      "[30]\tvalid_0's auc: 0.894906\tvalid_0's binary_logloss: 0.117808\tvalid_1's auc: 0.836072\tvalid_1's binary_logloss: 0.139896\n",
      "[31]\tvalid_0's auc: 0.895735\tvalid_0's binary_logloss: 0.117395\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.139865\n",
      "[32]\tvalid_0's auc: 0.896982\tvalid_0's binary_logloss: 0.116948\tvalid_1's auc: 0.836178\tvalid_1's binary_logloss: 0.139866\n",
      "[33]\tvalid_0's auc: 0.898332\tvalid_0's binary_logloss: 0.116584\tvalid_1's auc: 0.836498\tvalid_1's binary_logloss: 0.139828\n",
      "[34]\tvalid_0's auc: 0.899324\tvalid_0's binary_logloss: 0.116129\tvalid_1's auc: 0.836499\tvalid_1's binary_logloss: 0.139874\n",
      "[35]\tvalid_0's auc: 0.900175\tvalid_0's binary_logloss: 0.11578\tvalid_1's auc: 0.836226\tvalid_1's binary_logloss: 0.139924\n",
      "[36]\tvalid_0's auc: 0.901261\tvalid_0's binary_logloss: 0.115448\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.13999\n",
      "[37]\tvalid_0's auc: 0.901964\tvalid_0's binary_logloss: 0.115083\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.14012\n",
      "[38]\tvalid_0's auc: 0.902511\tvalid_0's binary_logloss: 0.114769\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.140207\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.831709\tvalid_0's binary_logloss: 0.155602\tvalid_1's auc: 0.817142\tvalid_1's binary_logloss: 0.164826\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845013\tvalid_0's binary_logloss: 0.15006\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.159674\n",
      "[3]\tvalid_0's auc: 0.847843\tvalid_0's binary_logloss: 0.145936\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.155788\n",
      "[4]\tvalid_0's auc: 0.853126\tvalid_0's binary_logloss: 0.142751\tvalid_1's auc: 0.836086\tvalid_1's binary_logloss: 0.152883\n",
      "[5]\tvalid_0's auc: 0.855373\tvalid_0's binary_logloss: 0.140124\tvalid_1's auc: 0.836802\tvalid_1's binary_logloss: 0.150648\n",
      "[6]\tvalid_0's auc: 0.858982\tvalid_0's binary_logloss: 0.137929\tvalid_1's auc: 0.837196\tvalid_1's binary_logloss: 0.148838\n",
      "[7]\tvalid_0's auc: 0.860432\tvalid_0's binary_logloss: 0.136116\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.147355\n",
      "[8]\tvalid_0's auc: 0.86237\tvalid_0's binary_logloss: 0.134493\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.146137\n",
      "[9]\tvalid_0's auc: 0.864538\tvalid_0's binary_logloss: 0.133112\tvalid_1's auc: 0.837924\tvalid_1's binary_logloss: 0.145039\n",
      "[10]\tvalid_0's auc: 0.866285\tvalid_0's binary_logloss: 0.131888\tvalid_1's auc: 0.837794\tvalid_1's binary_logloss: 0.14412\n",
      "[11]\tvalid_0's auc: 0.867679\tvalid_0's binary_logloss: 0.130774\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.143337\n",
      "[12]\tvalid_0's auc: 0.869423\tvalid_0's binary_logloss: 0.129754\tvalid_1's auc: 0.839862\tvalid_1's binary_logloss: 0.142609\n",
      "[13]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.128815\tvalid_1's auc: 0.838873\tvalid_1's binary_logloss: 0.142215\n",
      "[14]\tvalid_0's auc: 0.871813\tvalid_0's binary_logloss: 0.128007\tvalid_1's auc: 0.83922\tvalid_1's binary_logloss: 0.141872\n",
      "[15]\tvalid_0's auc: 0.873349\tvalid_0's binary_logloss: 0.127226\tvalid_1's auc: 0.838558\tvalid_1's binary_logloss: 0.141577\n",
      "[16]\tvalid_0's auc: 0.875071\tvalid_0's binary_logloss: 0.126463\tvalid_1's auc: 0.838328\tvalid_1's binary_logloss: 0.141336\n",
      "[17]\tvalid_0's auc: 0.87671\tvalid_0's binary_logloss: 0.125734\tvalid_1's auc: 0.838859\tvalid_1's binary_logloss: 0.140993\n",
      "[18]\tvalid_0's auc: 0.877745\tvalid_0's binary_logloss: 0.12506\tvalid_1's auc: 0.838826\tvalid_1's binary_logloss: 0.140774\n",
      "[19]\tvalid_0's auc: 0.87955\tvalid_0's binary_logloss: 0.124346\tvalid_1's auc: 0.838685\tvalid_1's binary_logloss: 0.14062\n",
      "[20]\tvalid_0's auc: 0.88095\tvalid_0's binary_logloss: 0.123758\tvalid_1's auc: 0.839472\tvalid_1's binary_logloss: 0.140278\n",
      "[21]\tvalid_0's auc: 0.882333\tvalid_0's binary_logloss: 0.123172\tvalid_1's auc: 0.839953\tvalid_1's binary_logloss: 0.139987\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[23]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.122106\tvalid_1's auc: 0.840085\tvalid_1's binary_logloss: 0.139652\n",
      "[24]\tvalid_0's auc: 0.886267\tvalid_0's binary_logloss: 0.121544\tvalid_1's auc: 0.839519\tvalid_1's binary_logloss: 0.13967\n",
      "[25]\tvalid_0's auc: 0.887231\tvalid_0's binary_logloss: 0.12107\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.139554\n",
      "[26]\tvalid_0's auc: 0.888362\tvalid_0's binary_logloss: 0.120592\tvalid_1's auc: 0.839436\tvalid_1's binary_logloss: 0.139477\n",
      "[27]\tvalid_0's auc: 0.889402\tvalid_0's binary_logloss: 0.12012\tvalid_1's auc: 0.839576\tvalid_1's binary_logloss: 0.139364\n",
      "[28]\tvalid_0's auc: 0.890567\tvalid_0's binary_logloss: 0.119695\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.139379\n",
      "[29]\tvalid_0's auc: 0.891561\tvalid_0's binary_logloss: 0.119229\tvalid_1's auc: 0.838494\tvalid_1's binary_logloss: 0.139484\n",
      "[30]\tvalid_0's auc: 0.892335\tvalid_0's binary_logloss: 0.118804\tvalid_1's auc: 0.838442\tvalid_1's binary_logloss: 0.139471\n",
      "[31]\tvalid_0's auc: 0.893386\tvalid_0's binary_logloss: 0.118372\tvalid_1's auc: 0.838123\tvalid_1's binary_logloss: 0.139487\n",
      "[32]\tvalid_0's auc: 0.894414\tvalid_0's binary_logloss: 0.117941\tvalid_1's auc: 0.838093\tvalid_1's binary_logloss: 0.139521\n",
      "[33]\tvalid_0's auc: 0.895465\tvalid_0's binary_logloss: 0.117514\tvalid_1's auc: 0.837947\tvalid_1's binary_logloss: 0.139537\n",
      "[34]\tvalid_0's auc: 0.896166\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837807\tvalid_1's binary_logloss: 0.139577\n",
      "[35]\tvalid_0's auc: 0.896684\tvalid_0's binary_logloss: 0.116863\tvalid_1's auc: 0.837668\tvalid_1's binary_logloss: 0.139588\n",
      "[36]\tvalid_0's auc: 0.897535\tvalid_0's binary_logloss: 0.116484\tvalid_1's auc: 0.837261\tvalid_1's binary_logloss: 0.139733\n",
      "[37]\tvalid_0's auc: 0.898253\tvalid_0's binary_logloss: 0.116123\tvalid_1's auc: 0.837235\tvalid_1's binary_logloss: 0.139781\n",
      "[38]\tvalid_0's auc: 0.898964\tvalid_0's binary_logloss: 0.115828\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.139841\n",
      "[39]\tvalid_0's auc: 0.89972\tvalid_0's binary_logloss: 0.115476\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.13991\n",
      "[40]\tvalid_0's auc: 0.900293\tvalid_0's binary_logloss: 0.115122\tvalid_1's auc: 0.837147\tvalid_1's binary_logloss: 0.139846\n",
      "[41]\tvalid_0's auc: 0.900934\tvalid_0's binary_logloss: 0.114813\tvalid_1's auc: 0.836986\tvalid_1's binary_logloss: 0.139923\n",
      "[42]\tvalid_0's auc: 0.901636\tvalid_0's binary_logloss: 0.114489\tvalid_1's auc: 0.836537\tvalid_1's binary_logloss: 0.140017\n",
      "[43]\tvalid_0's auc: 0.90272\tvalid_0's binary_logloss: 0.114161\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.140025\n",
      "[44]\tvalid_0's auc: 0.903084\tvalid_0's binary_logloss: 0.113909\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.140037\n",
      "[45]\tvalid_0's auc: 0.903622\tvalid_0's binary_logloss: 0.113641\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.140106\n",
      "[46]\tvalid_0's auc: 0.904201\tvalid_0's binary_logloss: 0.113301\tvalid_1's auc: 0.83619\tvalid_1's binary_logloss: 0.140186\n",
      "[47]\tvalid_0's auc: 0.904762\tvalid_0's binary_logloss: 0.112961\tvalid_1's auc: 0.836219\tvalid_1's binary_logloss: 0.14019\n",
      "[48]\tvalid_0's auc: 0.905387\tvalid_0's binary_logloss: 0.11272\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.140252\n",
      "[49]\tvalid_0's auc: 0.90574\tvalid_0's binary_logloss: 0.112462\tvalid_1's auc: 0.835874\tvalid_1's binary_logloss: 0.140337\n",
      "[50]\tvalid_0's auc: 0.906329\tvalid_0's binary_logloss: 0.112158\tvalid_1's auc: 0.835754\tvalid_1's binary_logloss: 0.140395\n",
      "[51]\tvalid_0's auc: 0.906807\tvalid_0's binary_logloss: 0.111885\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140381\n",
      "[52]\tvalid_0's auc: 0.907054\tvalid_0's binary_logloss: 0.111647\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.14054\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.832354\tvalid_0's binary_logloss: 0.156011\tvalid_1's auc: 0.824432\tvalid_1's binary_logloss: 0.164746\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845573\tvalid_0's binary_logloss: 0.150188\tvalid_1's auc: 0.832252\tvalid_1's binary_logloss: 0.159476\n",
      "[3]\tvalid_0's auc: 0.848609\tvalid_0's binary_logloss: 0.145958\tvalid_1's auc: 0.834138\tvalid_1's binary_logloss: 0.155738\n",
      "[4]\tvalid_0's auc: 0.851924\tvalid_0's binary_logloss: 0.142678\tvalid_1's auc: 0.834388\tvalid_1's binary_logloss: 0.152853\n",
      "[5]\tvalid_0's auc: 0.854459\tvalid_0's binary_logloss: 0.140096\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.150614\n",
      "[6]\tvalid_0's auc: 0.860195\tvalid_0's binary_logloss: 0.137818\tvalid_1's auc: 0.837402\tvalid_1's binary_logloss: 0.148623\n",
      "[7]\tvalid_0's auc: 0.861877\tvalid_0's binary_logloss: 0.135948\tvalid_1's auc: 0.837505\tvalid_1's binary_logloss: 0.14706\n",
      "[8]\tvalid_0's auc: 0.863997\tvalid_0's binary_logloss: 0.134369\tvalid_1's auc: 0.837955\tvalid_1's binary_logloss: 0.145859\n",
      "[9]\tvalid_0's auc: 0.866333\tvalid_0's binary_logloss: 0.132937\tvalid_1's auc: 0.839366\tvalid_1's binary_logloss: 0.144812\n",
      "[10]\tvalid_0's auc: 0.867965\tvalid_0's binary_logloss: 0.131647\tvalid_1's auc: 0.839399\tvalid_1's binary_logloss: 0.143987\n",
      "[11]\tvalid_0's auc: 0.869851\tvalid_0's binary_logloss: 0.130406\tvalid_1's auc: 0.839421\tvalid_1's binary_logloss: 0.14329\n",
      "[12]\tvalid_0's auc: 0.872223\tvalid_0's binary_logloss: 0.129323\tvalid_1's auc: 0.839253\tvalid_1's binary_logloss: 0.142712\n",
      "[13]\tvalid_0's auc: 0.873776\tvalid_0's binary_logloss: 0.12837\tvalid_1's auc: 0.838607\tvalid_1's binary_logloss: 0.142208\n",
      "[14]\tvalid_0's auc: 0.875666\tvalid_0's binary_logloss: 0.127409\tvalid_1's auc: 0.839513\tvalid_1's binary_logloss: 0.141711\n",
      "[15]\tvalid_0's auc: 0.876977\tvalid_0's binary_logloss: 0.126591\tvalid_1's auc: 0.839539\tvalid_1's binary_logloss: 0.141288\n",
      "[16]\tvalid_0's auc: 0.878097\tvalid_0's binary_logloss: 0.125796\tvalid_1's auc: 0.839021\tvalid_1's binary_logloss: 0.141036\n",
      "[17]\tvalid_0's auc: 0.879098\tvalid_0's binary_logloss: 0.125088\tvalid_1's auc: 0.837465\tvalid_1's binary_logloss: 0.1409\n",
      "[18]\tvalid_0's auc: 0.880601\tvalid_0's binary_logloss: 0.124364\tvalid_1's auc: 0.837466\tvalid_1's binary_logloss: 0.140701\n",
      "[19]\tvalid_0's auc: 0.88248\tvalid_0's binary_logloss: 0.123621\tvalid_1's auc: 0.838247\tvalid_1's binary_logloss: 0.140429\n",
      "[20]\tvalid_0's auc: 0.883936\tvalid_0's binary_logloss: 0.122911\tvalid_1's auc: 0.83793\tvalid_1's binary_logloss: 0.140317\n",
      "[21]\tvalid_0's auc: 0.88529\tvalid_0's binary_logloss: 0.122327\tvalid_1's auc: 0.838792\tvalid_1's binary_logloss: 0.140098\n",
      "[22]\tvalid_0's auc: 0.88648\tvalid_0's binary_logloss: 0.121732\tvalid_1's auc: 0.838403\tvalid_1's binary_logloss: 0.139974\n",
      "[23]\tvalid_0's auc: 0.887765\tvalid_0's binary_logloss: 0.121176\tvalid_1's auc: 0.838404\tvalid_1's binary_logloss: 0.139891\n",
      "[24]\tvalid_0's auc: 0.888887\tvalid_0's binary_logloss: 0.120591\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.890044\tvalid_0's binary_logloss: 0.120074\tvalid_1's auc: 0.838114\tvalid_1's binary_logloss: 0.139883\n",
      "[26]\tvalid_0's auc: 0.891051\tvalid_0's binary_logloss: 0.119588\tvalid_1's auc: 0.838544\tvalid_1's binary_logloss: 0.139784\n",
      "[27]\tvalid_0's auc: 0.892157\tvalid_0's binary_logloss: 0.119094\tvalid_1's auc: 0.838348\tvalid_1's binary_logloss: 0.139788\n",
      "[28]\tvalid_0's auc: 0.893116\tvalid_0's binary_logloss: 0.118639\tvalid_1's auc: 0.838654\tvalid_1's binary_logloss: 0.139723\n",
      "[29]\tvalid_0's auc: 0.894065\tvalid_0's binary_logloss: 0.118191\tvalid_1's auc: 0.83815\tvalid_1's binary_logloss: 0.13979\n",
      "[30]\tvalid_0's auc: 0.895189\tvalid_0's binary_logloss: 0.117742\tvalid_1's auc: 0.838393\tvalid_1's binary_logloss: 0.139755\n",
      "[31]\tvalid_0's auc: 0.896336\tvalid_0's binary_logloss: 0.117289\tvalid_1's auc: 0.838384\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.897473\tvalid_0's binary_logloss: 0.116901\tvalid_1's auc: 0.838447\tvalid_1's binary_logloss: 0.139683\n",
      "[33]\tvalid_0's auc: 0.898375\tvalid_0's binary_logloss: 0.116464\tvalid_1's auc: 0.838512\tvalid_1's binary_logloss: 0.139636\n",
      "[34]\tvalid_0's auc: 0.899242\tvalid_0's binary_logloss: 0.116054\tvalid_1's auc: 0.838475\tvalid_1's binary_logloss: 0.139614\n",
      "[35]\tvalid_0's auc: 0.900316\tvalid_0's binary_logloss: 0.115653\tvalid_1's auc: 0.838522\tvalid_1's binary_logloss: 0.13957\n",
      "[36]\tvalid_0's auc: 0.901114\tvalid_0's binary_logloss: 0.11531\tvalid_1's auc: 0.838721\tvalid_1's binary_logloss: 0.139537\n",
      "[37]\tvalid_0's auc: 0.901919\tvalid_0's binary_logloss: 0.114911\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.139581\n",
      "[38]\tvalid_0's auc: 0.902827\tvalid_0's binary_logloss: 0.114566\tvalid_1's auc: 0.839027\tvalid_1's binary_logloss: 0.139517\n",
      "[39]\tvalid_0's auc: 0.903647\tvalid_0's binary_logloss: 0.114176\tvalid_1's auc: 0.839264\tvalid_1's binary_logloss: 0.13948\n",
      "[40]\tvalid_0's auc: 0.904461\tvalid_0's binary_logloss: 0.11382\tvalid_1's auc: 0.839535\tvalid_1's binary_logloss: 0.13945\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[42]\tvalid_0's auc: 0.90573\tvalid_0's binary_logloss: 0.11309\tvalid_1's auc: 0.839177\tvalid_1's binary_logloss: 0.139527\n",
      "[43]\tvalid_0's auc: 0.906484\tvalid_0's binary_logloss: 0.112737\tvalid_1's auc: 0.839561\tvalid_1's binary_logloss: 0.139494\n",
      "[44]\tvalid_0's auc: 0.907269\tvalid_0's binary_logloss: 0.112432\tvalid_1's auc: 0.839357\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.907761\tvalid_0's binary_logloss: 0.112094\tvalid_1's auc: 0.839145\tvalid_1's binary_logloss: 0.139503\n",
      "[46]\tvalid_0's auc: 0.908229\tvalid_0's binary_logloss: 0.111774\tvalid_1's auc: 0.839064\tvalid_1's binary_logloss: 0.139515\n",
      "[47]\tvalid_0's auc: 0.908961\tvalid_0's binary_logloss: 0.111399\tvalid_1's auc: 0.838752\tvalid_1's binary_logloss: 0.139561\n",
      "[48]\tvalid_0's auc: 0.909623\tvalid_0's binary_logloss: 0.111156\tvalid_1's auc: 0.838658\tvalid_1's binary_logloss: 0.139589\n",
      "[49]\tvalid_0's auc: 0.910075\tvalid_0's binary_logloss: 0.110845\tvalid_1's auc: 0.838588\tvalid_1's binary_logloss: 0.13959\n",
      "[50]\tvalid_0's auc: 0.910737\tvalid_0's binary_logloss: 0.110566\tvalid_1's auc: 0.838609\tvalid_1's binary_logloss: 0.139608\n",
      "[51]\tvalid_0's auc: 0.911115\tvalid_0's binary_logloss: 0.110282\tvalid_1's auc: 0.838459\tvalid_1's binary_logloss: 0.139669\n",
      "[52]\tvalid_0's auc: 0.911601\tvalid_0's binary_logloss: 0.10999\tvalid_1's auc: 0.838303\tvalid_1's binary_logloss: 0.139708\n",
      "[53]\tvalid_0's auc: 0.911908\tvalid_0's binary_logloss: 0.109751\tvalid_1's auc: 0.838117\tvalid_1's binary_logloss: 0.13975\n",
      "[54]\tvalid_0's auc: 0.912261\tvalid_0's binary_logloss: 0.109498\tvalid_1's auc: 0.838252\tvalid_1's binary_logloss: 0.139711\n",
      "[55]\tvalid_0's auc: 0.912616\tvalid_0's binary_logloss: 0.109226\tvalid_1's auc: 0.837936\tvalid_1's binary_logloss: 0.13983\n",
      "[56]\tvalid_0's auc: 0.913202\tvalid_0's binary_logloss: 0.108936\tvalid_1's auc: 0.83804\tvalid_1's binary_logloss: 0.13983\n",
      "[57]\tvalid_0's auc: 0.913592\tvalid_0's binary_logloss: 0.10867\tvalid_1's auc: 0.838083\tvalid_1's binary_logloss: 0.139818\n",
      "[58]\tvalid_0's auc: 0.913818\tvalid_0's binary_logloss: 0.108421\tvalid_1's auc: 0.837716\tvalid_1's binary_logloss: 0.139971\n",
      "[59]\tvalid_0's auc: 0.914378\tvalid_0's binary_logloss: 0.108194\tvalid_1's auc: 0.837836\tvalid_1's binary_logloss: 0.139971\n",
      "[60]\tvalid_0's auc: 0.91493\tvalid_0's binary_logloss: 0.107966\tvalid_1's auc: 0.837549\tvalid_1's binary_logloss: 0.140068\n",
      "[61]\tvalid_0's auc: 0.915354\tvalid_0's binary_logloss: 0.107682\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.140197\n",
      "[62]\tvalid_0's auc: 0.915606\tvalid_0's binary_logloss: 0.107477\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.140336\n",
      "[63]\tvalid_0's auc: 0.916315\tvalid_0's binary_logloss: 0.107178\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.140384\n",
      "[64]\tvalid_0's auc: 0.916522\tvalid_0's binary_logloss: 0.10698\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.140446\n",
      "[65]\tvalid_0's auc: 0.917048\tvalid_0's binary_logloss: 0.106704\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.140528\n",
      "[66]\tvalid_0's auc: 0.917714\tvalid_0's binary_logloss: 0.1065\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.140589\n",
      "[67]\tvalid_0's auc: 0.918245\tvalid_0's binary_logloss: 0.106235\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.140673\n",
      "[68]\tvalid_0's auc: 0.918757\tvalid_0's binary_logloss: 0.105956\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.140696\n",
      "[69]\tvalid_0's auc: 0.919319\tvalid_0's binary_logloss: 0.105704\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.140788\n",
      "[70]\tvalid_0's auc: 0.919498\tvalid_0's binary_logloss: 0.105505\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.140912\n",
      "[71]\tvalid_0's auc: 0.919774\tvalid_0's binary_logloss: 0.105296\tvalid_1's auc: 0.834571\tvalid_1's binary_logloss: 0.141016\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.833136\tvalid_0's binary_logloss: 0.155618\tvalid_1's auc: 0.823516\tvalid_1's binary_logloss: 0.164757\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842036\tvalid_0's binary_logloss: 0.149972\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.159717\n",
      "[3]\tvalid_0's auc: 0.847172\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.830898\tvalid_1's binary_logloss: 0.156155\n",
      "[4]\tvalid_0's auc: 0.854159\tvalid_0's binary_logloss: 0.142767\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.153226\n",
      "[5]\tvalid_0's auc: 0.857704\tvalid_0's binary_logloss: 0.140143\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.15094\n",
      "[6]\tvalid_0's auc: 0.860316\tvalid_0's binary_logloss: 0.137951\tvalid_1's auc: 0.836175\tvalid_1's binary_logloss: 0.149162\n",
      "[7]\tvalid_0's auc: 0.862439\tvalid_0's binary_logloss: 0.136077\tvalid_1's auc: 0.835532\tvalid_1's binary_logloss: 0.147649\n",
      "[8]\tvalid_0's auc: 0.864272\tvalid_0's binary_logloss: 0.134388\tvalid_1's auc: 0.83563\tvalid_1's binary_logloss: 0.146354\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[10]\tvalid_0's auc: 0.867535\tvalid_0's binary_logloss: 0.13164\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.144361\n",
      "[11]\tvalid_0's auc: 0.869515\tvalid_0's binary_logloss: 0.130402\tvalid_1's auc: 0.83647\tvalid_1's binary_logloss: 0.143633\n",
      "[12]\tvalid_0's auc: 0.870746\tvalid_0's binary_logloss: 0.129418\tvalid_1's auc: 0.836512\tvalid_1's binary_logloss: 0.14302\n",
      "[13]\tvalid_0's auc: 0.872719\tvalid_0's binary_logloss: 0.12844\tvalid_1's auc: 0.836236\tvalid_1's binary_logloss: 0.142554\n",
      "[14]\tvalid_0's auc: 0.874567\tvalid_0's binary_logloss: 0.127509\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.142114\n",
      "[15]\tvalid_0's auc: 0.876764\tvalid_0's binary_logloss: 0.126626\tvalid_1's auc: 0.836237\tvalid_1's binary_logloss: 0.141748\n",
      "[16]\tvalid_0's auc: 0.87792\tvalid_0's binary_logloss: 0.125854\tvalid_1's auc: 0.836368\tvalid_1's binary_logloss: 0.141474\n",
      "[17]\tvalid_0's auc: 0.879062\tvalid_0's binary_logloss: 0.125102\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.14123\n",
      "[18]\tvalid_0's auc: 0.880333\tvalid_0's binary_logloss: 0.12445\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.14109\n",
      "[19]\tvalid_0's auc: 0.881986\tvalid_0's binary_logloss: 0.123735\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.140974\n",
      "[20]\tvalid_0's auc: 0.883497\tvalid_0's binary_logloss: 0.123057\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.140833\n",
      "[21]\tvalid_0's auc: 0.88477\tvalid_0's binary_logloss: 0.122502\tvalid_1's auc: 0.83413\tvalid_1's binary_logloss: 0.140756\n",
      "[22]\tvalid_0's auc: 0.886052\tvalid_0's binary_logloss: 0.121963\tvalid_1's auc: 0.833448\tvalid_1's binary_logloss: 0.140744\n",
      "[23]\tvalid_0's auc: 0.88729\tvalid_0's binary_logloss: 0.121374\tvalid_1's auc: 0.832949\tvalid_1's binary_logloss: 0.140705\n",
      "[24]\tvalid_0's auc: 0.888202\tvalid_0's binary_logloss: 0.120845\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.140716\n",
      "[25]\tvalid_0's auc: 0.889261\tvalid_0's binary_logloss: 0.120276\tvalid_1's auc: 0.832717\tvalid_1's binary_logloss: 0.140524\n",
      "[26]\tvalid_0's auc: 0.89008\tvalid_0's binary_logloss: 0.119792\tvalid_1's auc: 0.832126\tvalid_1's binary_logloss: 0.140541\n",
      "[27]\tvalid_0's auc: 0.891071\tvalid_0's binary_logloss: 0.119365\tvalid_1's auc: 0.832245\tvalid_1's binary_logloss: 0.140458\n",
      "[28]\tvalid_0's auc: 0.891965\tvalid_0's binary_logloss: 0.118917\tvalid_1's auc: 0.832098\tvalid_1's binary_logloss: 0.140348\n",
      "[29]\tvalid_0's auc: 0.893292\tvalid_0's binary_logloss: 0.118413\tvalid_1's auc: 0.832091\tvalid_1's binary_logloss: 0.140371\n",
      "[30]\tvalid_0's auc: 0.894193\tvalid_0's binary_logloss: 0.118022\tvalid_1's auc: 0.831601\tvalid_1's binary_logloss: 0.140412\n",
      "[31]\tvalid_0's auc: 0.894983\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.140402\n",
      "[32]\tvalid_0's auc: 0.896347\tvalid_0's binary_logloss: 0.117114\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.14049\n",
      "[33]\tvalid_0's auc: 0.897531\tvalid_0's binary_logloss: 0.116696\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.140462\n",
      "[34]\tvalid_0's auc: 0.898503\tvalid_0's binary_logloss: 0.116337\tvalid_1's auc: 0.831998\tvalid_1's binary_logloss: 0.140436\n",
      "[35]\tvalid_0's auc: 0.899431\tvalid_0's binary_logloss: 0.115966\tvalid_1's auc: 0.832323\tvalid_1's binary_logloss: 0.140357\n",
      "[36]\tvalid_0's auc: 0.900259\tvalid_0's binary_logloss: 0.115619\tvalid_1's auc: 0.832052\tvalid_1's binary_logloss: 0.140411\n",
      "[37]\tvalid_0's auc: 0.901414\tvalid_0's binary_logloss: 0.115269\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.14042\n",
      "[38]\tvalid_0's auc: 0.902365\tvalid_0's binary_logloss: 0.114862\tvalid_1's auc: 0.832015\tvalid_1's binary_logloss: 0.140464\n",
      "[39]\tvalid_0's auc: 0.90309\tvalid_0's binary_logloss: 0.114499\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.140399\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.833297\tvalid_0's binary_logloss: 0.155798\tvalid_1's auc: 0.814648\tvalid_1's binary_logloss: 0.165178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.84496\tvalid_0's binary_logloss: 0.150106\tvalid_1's auc: 0.825101\tvalid_1's binary_logloss: 0.159672\n",
      "[3]\tvalid_0's auc: 0.848339\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.829756\tvalid_1's binary_logloss: 0.156122\n",
      "[4]\tvalid_0's auc: 0.852327\tvalid_0's binary_logloss: 0.142785\tvalid_1's auc: 0.83262\tvalid_1's binary_logloss: 0.153215\n",
      "[5]\tvalid_0's auc: 0.856991\tvalid_0's binary_logloss: 0.140075\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.150936\n",
      "[6]\tvalid_0's auc: 0.860123\tvalid_0's binary_logloss: 0.13786\tvalid_1's auc: 0.837776\tvalid_1's binary_logloss: 0.149015\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[8]\tvalid_0's auc: 0.863556\tvalid_0's binary_logloss: 0.134329\tvalid_1's auc: 0.837522\tvalid_1's binary_logloss: 0.146495\n",
      "[9]\tvalid_0's auc: 0.865702\tvalid_0's binary_logloss: 0.132867\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.145505\n",
      "[10]\tvalid_0's auc: 0.867419\tvalid_0's binary_logloss: 0.131589\tvalid_1's auc: 0.83738\tvalid_1's binary_logloss: 0.144639\n",
      "[11]\tvalid_0's auc: 0.869474\tvalid_0's binary_logloss: 0.130487\tvalid_1's auc: 0.837061\tvalid_1's binary_logloss: 0.143902\n",
      "[12]\tvalid_0's auc: 0.871188\tvalid_0's binary_logloss: 0.12944\tvalid_1's auc: 0.83674\tvalid_1's binary_logloss: 0.14338\n",
      "[13]\tvalid_0's auc: 0.873292\tvalid_0's binary_logloss: 0.128408\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.142955\n",
      "[14]\tvalid_0's auc: 0.875272\tvalid_0's binary_logloss: 0.127498\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.142577\n",
      "[15]\tvalid_0's auc: 0.876333\tvalid_0's binary_logloss: 0.126687\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.142233\n",
      "[16]\tvalid_0's auc: 0.878172\tvalid_0's binary_logloss: 0.125868\tvalid_1's auc: 0.835135\tvalid_1's binary_logloss: 0.141915\n",
      "[17]\tvalid_0's auc: 0.879493\tvalid_0's binary_logloss: 0.125166\tvalid_1's auc: 0.834462\tvalid_1's binary_logloss: 0.141684\n",
      "[18]\tvalid_0's auc: 0.880697\tvalid_0's binary_logloss: 0.124485\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.141381\n",
      "[19]\tvalid_0's auc: 0.881751\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.141089\n",
      "[20]\tvalid_0's auc: 0.883208\tvalid_0's binary_logloss: 0.123231\tvalid_1's auc: 0.834617\tvalid_1's binary_logloss: 0.141074\n",
      "[21]\tvalid_0's auc: 0.884441\tvalid_0's binary_logloss: 0.122672\tvalid_1's auc: 0.835086\tvalid_1's binary_logloss: 0.140871\n",
      "[22]\tvalid_0's auc: 0.885795\tvalid_0's binary_logloss: 0.122047\tvalid_1's auc: 0.834691\tvalid_1's binary_logloss: 0.140833\n",
      "[23]\tvalid_0's auc: 0.88703\tvalid_0's binary_logloss: 0.121437\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.14067\n",
      "[24]\tvalid_0's auc: 0.888628\tvalid_0's binary_logloss: 0.120866\tvalid_1's auc: 0.834703\tvalid_1's binary_logloss: 0.140607\n",
      "[25]\tvalid_0's auc: 0.889539\tvalid_0's binary_logloss: 0.120354\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.140572\n",
      "[26]\tvalid_0's auc: 0.890707\tvalid_0's binary_logloss: 0.119835\tvalid_1's auc: 0.834353\tvalid_1's binary_logloss: 0.140508\n",
      "[27]\tvalid_0's auc: 0.89189\tvalid_0's binary_logloss: 0.119344\tvalid_1's auc: 0.833736\tvalid_1's binary_logloss: 0.14057\n",
      "[28]\tvalid_0's auc: 0.892973\tvalid_0's binary_logloss: 0.118875\tvalid_1's auc: 0.83339\tvalid_1's binary_logloss: 0.140614\n",
      "[29]\tvalid_0's auc: 0.894538\tvalid_0's binary_logloss: 0.118402\tvalid_1's auc: 0.833262\tvalid_1's binary_logloss: 0.140617\n",
      "[30]\tvalid_0's auc: 0.895805\tvalid_0's binary_logloss: 0.117902\tvalid_1's auc: 0.832581\tvalid_1's binary_logloss: 0.140733\n",
      "[31]\tvalid_0's auc: 0.897165\tvalid_0's binary_logloss: 0.117449\tvalid_1's auc: 0.832965\tvalid_1's binary_logloss: 0.14067\n",
      "[32]\tvalid_0's auc: 0.898106\tvalid_0's binary_logloss: 0.117027\tvalid_1's auc: 0.832548\tvalid_1's binary_logloss: 0.140717\n",
      "[33]\tvalid_0's auc: 0.898897\tvalid_0's binary_logloss: 0.116646\tvalid_1's auc: 0.832294\tvalid_1's binary_logloss: 0.140755\n",
      "[34]\tvalid_0's auc: 0.899579\tvalid_0's binary_logloss: 0.11632\tvalid_1's auc: 0.832478\tvalid_1's binary_logloss: 0.14074\n",
      "[35]\tvalid_0's auc: 0.900941\tvalid_0's binary_logloss: 0.115884\tvalid_1's auc: 0.83257\tvalid_1's binary_logloss: 0.140703\n",
      "[36]\tvalid_0's auc: 0.902074\tvalid_0's binary_logloss: 0.115452\tvalid_1's auc: 0.832369\tvalid_1's binary_logloss: 0.140774\n",
      "[37]\tvalid_0's auc: 0.902849\tvalid_0's binary_logloss: 0.115101\tvalid_1's auc: 0.832046\tvalid_1's binary_logloss: 0.140792\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.834438\tvalid_0's binary_logloss: 0.155707\tvalid_1's auc: 0.821419\tvalid_1's binary_logloss: 0.164715\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845934\tvalid_0's binary_logloss: 0.150048\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.159506\n",
      "[3]\tvalid_0's auc: 0.849836\tvalid_0's binary_logloss: 0.145927\tvalid_1's auc: 0.831719\tvalid_1's binary_logloss: 0.155735\n",
      "[4]\tvalid_0's auc: 0.854642\tvalid_0's binary_logloss: 0.142686\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.152919\n",
      "[5]\tvalid_0's auc: 0.856628\tvalid_0's binary_logloss: 0.139976\tvalid_1's auc: 0.83701\tvalid_1's binary_logloss: 0.15048\n",
      "[6]\tvalid_0's auc: 0.859766\tvalid_0's binary_logloss: 0.137707\tvalid_1's auc: 0.83737\tvalid_1's binary_logloss: 0.148709\n",
      "[7]\tvalid_0's auc: 0.861667\tvalid_0's binary_logloss: 0.13588\tvalid_1's auc: 0.837028\tvalid_1's binary_logloss: 0.147239\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[9]\tvalid_0's auc: 0.866131\tvalid_0's binary_logloss: 0.132702\tvalid_1's auc: 0.837967\tvalid_1's binary_logloss: 0.144848\n",
      "[10]\tvalid_0's auc: 0.867742\tvalid_0's binary_logloss: 0.1314\tvalid_1's auc: 0.837692\tvalid_1's binary_logloss: 0.143974\n",
      "[11]\tvalid_0's auc: 0.869179\tvalid_0's binary_logloss: 0.130269\tvalid_1's auc: 0.837036\tvalid_1's binary_logloss: 0.143346\n",
      "[12]\tvalid_0's auc: 0.870565\tvalid_0's binary_logloss: 0.129231\tvalid_1's auc: 0.836722\tvalid_1's binary_logloss: 0.14276\n",
      "[13]\tvalid_0's auc: 0.871715\tvalid_0's binary_logloss: 0.128325\tvalid_1's auc: 0.836964\tvalid_1's binary_logloss: 0.14221\n",
      "[14]\tvalid_0's auc: 0.873118\tvalid_0's binary_logloss: 0.127433\tvalid_1's auc: 0.836616\tvalid_1's binary_logloss: 0.141769\n",
      "[15]\tvalid_0's auc: 0.874777\tvalid_0's binary_logloss: 0.126525\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.141352\n",
      "[16]\tvalid_0's auc: 0.876077\tvalid_0's binary_logloss: 0.125761\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.141109\n",
      "[17]\tvalid_0's auc: 0.87775\tvalid_0's binary_logloss: 0.125008\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.140988\n",
      "[18]\tvalid_0's auc: 0.879171\tvalid_0's binary_logloss: 0.124326\tvalid_1's auc: 0.837265\tvalid_1's binary_logloss: 0.140636\n",
      "[19]\tvalid_0's auc: 0.880771\tvalid_0's binary_logloss: 0.123637\tvalid_1's auc: 0.836922\tvalid_1's binary_logloss: 0.140454\n",
      "[20]\tvalid_0's auc: 0.882476\tvalid_0's binary_logloss: 0.123001\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.140307\n",
      "[21]\tvalid_0's auc: 0.883998\tvalid_0's binary_logloss: 0.122399\tvalid_1's auc: 0.83698\tvalid_1's binary_logloss: 0.140209\n",
      "[22]\tvalid_0's auc: 0.885371\tvalid_0's binary_logloss: 0.121789\tvalid_1's auc: 0.836641\tvalid_1's binary_logloss: 0.140165\n",
      "[23]\tvalid_0's auc: 0.886707\tvalid_0's binary_logloss: 0.121228\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.140035\n",
      "[24]\tvalid_0's auc: 0.887902\tvalid_0's binary_logloss: 0.120685\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.139977\n",
      "[25]\tvalid_0's auc: 0.889092\tvalid_0's binary_logloss: 0.12018\tvalid_1's auc: 0.83633\tvalid_1's binary_logloss: 0.139976\n",
      "[26]\tvalid_0's auc: 0.890287\tvalid_0's binary_logloss: 0.119694\tvalid_1's auc: 0.836088\tvalid_1's binary_logloss: 0.13994\n",
      "[27]\tvalid_0's auc: 0.891557\tvalid_0's binary_logloss: 0.11921\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.139925\n",
      "[28]\tvalid_0's auc: 0.892479\tvalid_0's binary_logloss: 0.118767\tvalid_1's auc: 0.836047\tvalid_1's binary_logloss: 0.139873\n",
      "[29]\tvalid_0's auc: 0.893752\tvalid_0's binary_logloss: 0.118311\tvalid_1's auc: 0.836111\tvalid_1's binary_logloss: 0.139884\n",
      "[30]\tvalid_0's auc: 0.894906\tvalid_0's binary_logloss: 0.117808\tvalid_1's auc: 0.836072\tvalid_1's binary_logloss: 0.139896\n",
      "[31]\tvalid_0's auc: 0.895735\tvalid_0's binary_logloss: 0.117395\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.139865\n",
      "[32]\tvalid_0's auc: 0.896982\tvalid_0's binary_logloss: 0.116948\tvalid_1's auc: 0.836178\tvalid_1's binary_logloss: 0.139866\n",
      "[33]\tvalid_0's auc: 0.898332\tvalid_0's binary_logloss: 0.116584\tvalid_1's auc: 0.836498\tvalid_1's binary_logloss: 0.139828\n",
      "[34]\tvalid_0's auc: 0.899324\tvalid_0's binary_logloss: 0.116129\tvalid_1's auc: 0.836499\tvalid_1's binary_logloss: 0.139874\n",
      "[35]\tvalid_0's auc: 0.900175\tvalid_0's binary_logloss: 0.11578\tvalid_1's auc: 0.836226\tvalid_1's binary_logloss: 0.139924\n",
      "[36]\tvalid_0's auc: 0.901261\tvalid_0's binary_logloss: 0.115448\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.13999\n",
      "[37]\tvalid_0's auc: 0.901964\tvalid_0's binary_logloss: 0.115083\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.14012\n",
      "[38]\tvalid_0's auc: 0.902511\tvalid_0's binary_logloss: 0.114769\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.140207\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.831709\tvalid_0's binary_logloss: 0.155602\tvalid_1's auc: 0.817142\tvalid_1's binary_logloss: 0.164826\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845013\tvalid_0's binary_logloss: 0.15006\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.159674\n",
      "[3]\tvalid_0's auc: 0.847843\tvalid_0's binary_logloss: 0.145936\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.155788\n",
      "[4]\tvalid_0's auc: 0.853126\tvalid_0's binary_logloss: 0.142751\tvalid_1's auc: 0.836086\tvalid_1's binary_logloss: 0.152883\n",
      "[5]\tvalid_0's auc: 0.855373\tvalid_0's binary_logloss: 0.140124\tvalid_1's auc: 0.836802\tvalid_1's binary_logloss: 0.150648\n",
      "[6]\tvalid_0's auc: 0.858982\tvalid_0's binary_logloss: 0.137929\tvalid_1's auc: 0.837196\tvalid_1's binary_logloss: 0.148838\n",
      "[7]\tvalid_0's auc: 0.860432\tvalid_0's binary_logloss: 0.136116\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.147355\n",
      "[8]\tvalid_0's auc: 0.86237\tvalid_0's binary_logloss: 0.134493\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.146137\n",
      "[9]\tvalid_0's auc: 0.864538\tvalid_0's binary_logloss: 0.133112\tvalid_1's auc: 0.837924\tvalid_1's binary_logloss: 0.145039\n",
      "[10]\tvalid_0's auc: 0.866285\tvalid_0's binary_logloss: 0.131888\tvalid_1's auc: 0.837794\tvalid_1's binary_logloss: 0.14412\n",
      "[11]\tvalid_0's auc: 0.867679\tvalid_0's binary_logloss: 0.130774\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.143337\n",
      "[12]\tvalid_0's auc: 0.869423\tvalid_0's binary_logloss: 0.129754\tvalid_1's auc: 0.839862\tvalid_1's binary_logloss: 0.142609\n",
      "[13]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.128815\tvalid_1's auc: 0.838873\tvalid_1's binary_logloss: 0.142215\n",
      "[14]\tvalid_0's auc: 0.871813\tvalid_0's binary_logloss: 0.128007\tvalid_1's auc: 0.83922\tvalid_1's binary_logloss: 0.141872\n",
      "[15]\tvalid_0's auc: 0.873349\tvalid_0's binary_logloss: 0.127226\tvalid_1's auc: 0.838558\tvalid_1's binary_logloss: 0.141577\n",
      "[16]\tvalid_0's auc: 0.875071\tvalid_0's binary_logloss: 0.126463\tvalid_1's auc: 0.838328\tvalid_1's binary_logloss: 0.141336\n",
      "[17]\tvalid_0's auc: 0.87671\tvalid_0's binary_logloss: 0.125734\tvalid_1's auc: 0.838859\tvalid_1's binary_logloss: 0.140993\n",
      "[18]\tvalid_0's auc: 0.877745\tvalid_0's binary_logloss: 0.12506\tvalid_1's auc: 0.838826\tvalid_1's binary_logloss: 0.140774\n",
      "[19]\tvalid_0's auc: 0.87955\tvalid_0's binary_logloss: 0.124346\tvalid_1's auc: 0.838685\tvalid_1's binary_logloss: 0.14062\n",
      "[20]\tvalid_0's auc: 0.88095\tvalid_0's binary_logloss: 0.123758\tvalid_1's auc: 0.839472\tvalid_1's binary_logloss: 0.140278\n",
      "[21]\tvalid_0's auc: 0.882333\tvalid_0's binary_logloss: 0.123172\tvalid_1's auc: 0.839953\tvalid_1's binary_logloss: 0.139987\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[23]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.122106\tvalid_1's auc: 0.840085\tvalid_1's binary_logloss: 0.139652\n",
      "[24]\tvalid_0's auc: 0.886267\tvalid_0's binary_logloss: 0.121544\tvalid_1's auc: 0.839519\tvalid_1's binary_logloss: 0.13967\n",
      "[25]\tvalid_0's auc: 0.887231\tvalid_0's binary_logloss: 0.12107\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.139554\n",
      "[26]\tvalid_0's auc: 0.888362\tvalid_0's binary_logloss: 0.120592\tvalid_1's auc: 0.839436\tvalid_1's binary_logloss: 0.139477\n",
      "[27]\tvalid_0's auc: 0.889402\tvalid_0's binary_logloss: 0.12012\tvalid_1's auc: 0.839576\tvalid_1's binary_logloss: 0.139364\n",
      "[28]\tvalid_0's auc: 0.890567\tvalid_0's binary_logloss: 0.119695\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.139379\n",
      "[29]\tvalid_0's auc: 0.891561\tvalid_0's binary_logloss: 0.119229\tvalid_1's auc: 0.838494\tvalid_1's binary_logloss: 0.139484\n",
      "[30]\tvalid_0's auc: 0.892335\tvalid_0's binary_logloss: 0.118804\tvalid_1's auc: 0.838442\tvalid_1's binary_logloss: 0.139471\n",
      "[31]\tvalid_0's auc: 0.893386\tvalid_0's binary_logloss: 0.118372\tvalid_1's auc: 0.838123\tvalid_1's binary_logloss: 0.139487\n",
      "[32]\tvalid_0's auc: 0.894414\tvalid_0's binary_logloss: 0.117941\tvalid_1's auc: 0.838093\tvalid_1's binary_logloss: 0.139521\n",
      "[33]\tvalid_0's auc: 0.895465\tvalid_0's binary_logloss: 0.117514\tvalid_1's auc: 0.837947\tvalid_1's binary_logloss: 0.139537\n",
      "[34]\tvalid_0's auc: 0.896166\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837807\tvalid_1's binary_logloss: 0.139577\n",
      "[35]\tvalid_0's auc: 0.896684\tvalid_0's binary_logloss: 0.116863\tvalid_1's auc: 0.837668\tvalid_1's binary_logloss: 0.139588\n",
      "[36]\tvalid_0's auc: 0.897535\tvalid_0's binary_logloss: 0.116484\tvalid_1's auc: 0.837261\tvalid_1's binary_logloss: 0.139733\n",
      "[37]\tvalid_0's auc: 0.898253\tvalid_0's binary_logloss: 0.116123\tvalid_1's auc: 0.837235\tvalid_1's binary_logloss: 0.139781\n",
      "[38]\tvalid_0's auc: 0.898964\tvalid_0's binary_logloss: 0.115828\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.139841\n",
      "[39]\tvalid_0's auc: 0.89972\tvalid_0's binary_logloss: 0.115476\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.13991\n",
      "[40]\tvalid_0's auc: 0.900293\tvalid_0's binary_logloss: 0.115122\tvalid_1's auc: 0.837147\tvalid_1's binary_logloss: 0.139846\n",
      "[41]\tvalid_0's auc: 0.900934\tvalid_0's binary_logloss: 0.114813\tvalid_1's auc: 0.836986\tvalid_1's binary_logloss: 0.139923\n",
      "[42]\tvalid_0's auc: 0.901636\tvalid_0's binary_logloss: 0.114489\tvalid_1's auc: 0.836537\tvalid_1's binary_logloss: 0.140017\n",
      "[43]\tvalid_0's auc: 0.90272\tvalid_0's binary_logloss: 0.114161\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.140025\n",
      "[44]\tvalid_0's auc: 0.903084\tvalid_0's binary_logloss: 0.113909\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.140037\n",
      "[45]\tvalid_0's auc: 0.903622\tvalid_0's binary_logloss: 0.113641\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.140106\n",
      "[46]\tvalid_0's auc: 0.904201\tvalid_0's binary_logloss: 0.113301\tvalid_1's auc: 0.83619\tvalid_1's binary_logloss: 0.140186\n",
      "[47]\tvalid_0's auc: 0.904762\tvalid_0's binary_logloss: 0.112961\tvalid_1's auc: 0.836219\tvalid_1's binary_logloss: 0.14019\n",
      "[48]\tvalid_0's auc: 0.905387\tvalid_0's binary_logloss: 0.11272\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.140252\n",
      "[49]\tvalid_0's auc: 0.90574\tvalid_0's binary_logloss: 0.112462\tvalid_1's auc: 0.835874\tvalid_1's binary_logloss: 0.140337\n",
      "[50]\tvalid_0's auc: 0.906329\tvalid_0's binary_logloss: 0.112158\tvalid_1's auc: 0.835754\tvalid_1's binary_logloss: 0.140395\n",
      "[51]\tvalid_0's auc: 0.906807\tvalid_0's binary_logloss: 0.111885\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140381\n",
      "[52]\tvalid_0's auc: 0.907054\tvalid_0's binary_logloss: 0.111647\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.14054\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.832354\tvalid_0's binary_logloss: 0.156011\tvalid_1's auc: 0.824432\tvalid_1's binary_logloss: 0.164746\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845573\tvalid_0's binary_logloss: 0.150188\tvalid_1's auc: 0.832252\tvalid_1's binary_logloss: 0.159476\n",
      "[3]\tvalid_0's auc: 0.848609\tvalid_0's binary_logloss: 0.145958\tvalid_1's auc: 0.834138\tvalid_1's binary_logloss: 0.155738\n",
      "[4]\tvalid_0's auc: 0.851924\tvalid_0's binary_logloss: 0.142678\tvalid_1's auc: 0.834388\tvalid_1's binary_logloss: 0.152853\n",
      "[5]\tvalid_0's auc: 0.854459\tvalid_0's binary_logloss: 0.140096\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.150614\n",
      "[6]\tvalid_0's auc: 0.860195\tvalid_0's binary_logloss: 0.137818\tvalid_1's auc: 0.837402\tvalid_1's binary_logloss: 0.148623\n",
      "[7]\tvalid_0's auc: 0.861877\tvalid_0's binary_logloss: 0.135948\tvalid_1's auc: 0.837505\tvalid_1's binary_logloss: 0.14706\n",
      "[8]\tvalid_0's auc: 0.863997\tvalid_0's binary_logloss: 0.134369\tvalid_1's auc: 0.837955\tvalid_1's binary_logloss: 0.145859\n",
      "[9]\tvalid_0's auc: 0.866333\tvalid_0's binary_logloss: 0.132937\tvalid_1's auc: 0.839366\tvalid_1's binary_logloss: 0.144812\n",
      "[10]\tvalid_0's auc: 0.867965\tvalid_0's binary_logloss: 0.131647\tvalid_1's auc: 0.839399\tvalid_1's binary_logloss: 0.143987\n",
      "[11]\tvalid_0's auc: 0.869851\tvalid_0's binary_logloss: 0.130406\tvalid_1's auc: 0.839421\tvalid_1's binary_logloss: 0.14329\n",
      "[12]\tvalid_0's auc: 0.872223\tvalid_0's binary_logloss: 0.129323\tvalid_1's auc: 0.839253\tvalid_1's binary_logloss: 0.142712\n",
      "[13]\tvalid_0's auc: 0.873776\tvalid_0's binary_logloss: 0.12837\tvalid_1's auc: 0.838607\tvalid_1's binary_logloss: 0.142208\n",
      "[14]\tvalid_0's auc: 0.875666\tvalid_0's binary_logloss: 0.127409\tvalid_1's auc: 0.839513\tvalid_1's binary_logloss: 0.141711\n",
      "[15]\tvalid_0's auc: 0.876977\tvalid_0's binary_logloss: 0.126591\tvalid_1's auc: 0.839539\tvalid_1's binary_logloss: 0.141288\n",
      "[16]\tvalid_0's auc: 0.878097\tvalid_0's binary_logloss: 0.125796\tvalid_1's auc: 0.839021\tvalid_1's binary_logloss: 0.141036\n",
      "[17]\tvalid_0's auc: 0.879098\tvalid_0's binary_logloss: 0.125088\tvalid_1's auc: 0.837465\tvalid_1's binary_logloss: 0.1409\n",
      "[18]\tvalid_0's auc: 0.880601\tvalid_0's binary_logloss: 0.124364\tvalid_1's auc: 0.837466\tvalid_1's binary_logloss: 0.140701\n",
      "[19]\tvalid_0's auc: 0.88248\tvalid_0's binary_logloss: 0.123621\tvalid_1's auc: 0.838247\tvalid_1's binary_logloss: 0.140429\n",
      "[20]\tvalid_0's auc: 0.883936\tvalid_0's binary_logloss: 0.122911\tvalid_1's auc: 0.83793\tvalid_1's binary_logloss: 0.140317\n",
      "[21]\tvalid_0's auc: 0.88529\tvalid_0's binary_logloss: 0.122327\tvalid_1's auc: 0.838792\tvalid_1's binary_logloss: 0.140098\n",
      "[22]\tvalid_0's auc: 0.88648\tvalid_0's binary_logloss: 0.121732\tvalid_1's auc: 0.838403\tvalid_1's binary_logloss: 0.139974\n",
      "[23]\tvalid_0's auc: 0.887765\tvalid_0's binary_logloss: 0.121176\tvalid_1's auc: 0.838404\tvalid_1's binary_logloss: 0.139891\n",
      "[24]\tvalid_0's auc: 0.888887\tvalid_0's binary_logloss: 0.120591\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.890044\tvalid_0's binary_logloss: 0.120074\tvalid_1's auc: 0.838114\tvalid_1's binary_logloss: 0.139883\n",
      "[26]\tvalid_0's auc: 0.891051\tvalid_0's binary_logloss: 0.119588\tvalid_1's auc: 0.838544\tvalid_1's binary_logloss: 0.139784\n",
      "[27]\tvalid_0's auc: 0.892157\tvalid_0's binary_logloss: 0.119094\tvalid_1's auc: 0.838348\tvalid_1's binary_logloss: 0.139788\n",
      "[28]\tvalid_0's auc: 0.893116\tvalid_0's binary_logloss: 0.118639\tvalid_1's auc: 0.838654\tvalid_1's binary_logloss: 0.139723\n",
      "[29]\tvalid_0's auc: 0.894065\tvalid_0's binary_logloss: 0.118191\tvalid_1's auc: 0.83815\tvalid_1's binary_logloss: 0.13979\n",
      "[30]\tvalid_0's auc: 0.895189\tvalid_0's binary_logloss: 0.117742\tvalid_1's auc: 0.838393\tvalid_1's binary_logloss: 0.139755\n",
      "[31]\tvalid_0's auc: 0.896336\tvalid_0's binary_logloss: 0.117289\tvalid_1's auc: 0.838384\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.897473\tvalid_0's binary_logloss: 0.116901\tvalid_1's auc: 0.838447\tvalid_1's binary_logloss: 0.139683\n",
      "[33]\tvalid_0's auc: 0.898375\tvalid_0's binary_logloss: 0.116464\tvalid_1's auc: 0.838512\tvalid_1's binary_logloss: 0.139636\n",
      "[34]\tvalid_0's auc: 0.899242\tvalid_0's binary_logloss: 0.116054\tvalid_1's auc: 0.838475\tvalid_1's binary_logloss: 0.139614\n",
      "[35]\tvalid_0's auc: 0.900316\tvalid_0's binary_logloss: 0.115653\tvalid_1's auc: 0.838522\tvalid_1's binary_logloss: 0.13957\n",
      "[36]\tvalid_0's auc: 0.901114\tvalid_0's binary_logloss: 0.11531\tvalid_1's auc: 0.838721\tvalid_1's binary_logloss: 0.139537\n",
      "[37]\tvalid_0's auc: 0.901919\tvalid_0's binary_logloss: 0.114911\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.139581\n",
      "[38]\tvalid_0's auc: 0.902827\tvalid_0's binary_logloss: 0.114566\tvalid_1's auc: 0.839027\tvalid_1's binary_logloss: 0.139517\n",
      "[39]\tvalid_0's auc: 0.903647\tvalid_0's binary_logloss: 0.114176\tvalid_1's auc: 0.839264\tvalid_1's binary_logloss: 0.13948\n",
      "[40]\tvalid_0's auc: 0.904461\tvalid_0's binary_logloss: 0.11382\tvalid_1's auc: 0.839535\tvalid_1's binary_logloss: 0.13945\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[42]\tvalid_0's auc: 0.90573\tvalid_0's binary_logloss: 0.11309\tvalid_1's auc: 0.839177\tvalid_1's binary_logloss: 0.139527\n",
      "[43]\tvalid_0's auc: 0.906484\tvalid_0's binary_logloss: 0.112737\tvalid_1's auc: 0.839561\tvalid_1's binary_logloss: 0.139494\n",
      "[44]\tvalid_0's auc: 0.907269\tvalid_0's binary_logloss: 0.112432\tvalid_1's auc: 0.839357\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.907761\tvalid_0's binary_logloss: 0.112094\tvalid_1's auc: 0.839145\tvalid_1's binary_logloss: 0.139503\n",
      "[46]\tvalid_0's auc: 0.908229\tvalid_0's binary_logloss: 0.111774\tvalid_1's auc: 0.839064\tvalid_1's binary_logloss: 0.139515\n",
      "[47]\tvalid_0's auc: 0.908961\tvalid_0's binary_logloss: 0.111399\tvalid_1's auc: 0.838752\tvalid_1's binary_logloss: 0.139561\n",
      "[48]\tvalid_0's auc: 0.909623\tvalid_0's binary_logloss: 0.111156\tvalid_1's auc: 0.838658\tvalid_1's binary_logloss: 0.139589\n",
      "[49]\tvalid_0's auc: 0.910075\tvalid_0's binary_logloss: 0.110845\tvalid_1's auc: 0.838588\tvalid_1's binary_logloss: 0.13959\n",
      "[50]\tvalid_0's auc: 0.910737\tvalid_0's binary_logloss: 0.110566\tvalid_1's auc: 0.838609\tvalid_1's binary_logloss: 0.139608\n",
      "[51]\tvalid_0's auc: 0.911115\tvalid_0's binary_logloss: 0.110282\tvalid_1's auc: 0.838459\tvalid_1's binary_logloss: 0.139669\n",
      "[52]\tvalid_0's auc: 0.911601\tvalid_0's binary_logloss: 0.10999\tvalid_1's auc: 0.838303\tvalid_1's binary_logloss: 0.139708\n",
      "[53]\tvalid_0's auc: 0.911908\tvalid_0's binary_logloss: 0.109751\tvalid_1's auc: 0.838117\tvalid_1's binary_logloss: 0.13975\n",
      "[54]\tvalid_0's auc: 0.912261\tvalid_0's binary_logloss: 0.109498\tvalid_1's auc: 0.838252\tvalid_1's binary_logloss: 0.139711\n",
      "[55]\tvalid_0's auc: 0.912616\tvalid_0's binary_logloss: 0.109226\tvalid_1's auc: 0.837936\tvalid_1's binary_logloss: 0.13983\n",
      "[56]\tvalid_0's auc: 0.913202\tvalid_0's binary_logloss: 0.108936\tvalid_1's auc: 0.83804\tvalid_1's binary_logloss: 0.13983\n",
      "[57]\tvalid_0's auc: 0.913592\tvalid_0's binary_logloss: 0.10867\tvalid_1's auc: 0.838083\tvalid_1's binary_logloss: 0.139818\n",
      "[58]\tvalid_0's auc: 0.913818\tvalid_0's binary_logloss: 0.108421\tvalid_1's auc: 0.837716\tvalid_1's binary_logloss: 0.139971\n",
      "[59]\tvalid_0's auc: 0.914378\tvalid_0's binary_logloss: 0.108194\tvalid_1's auc: 0.837836\tvalid_1's binary_logloss: 0.139971\n",
      "[60]\tvalid_0's auc: 0.91493\tvalid_0's binary_logloss: 0.107966\tvalid_1's auc: 0.837549\tvalid_1's binary_logloss: 0.140068\n",
      "[61]\tvalid_0's auc: 0.915354\tvalid_0's binary_logloss: 0.107682\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.140197\n",
      "[62]\tvalid_0's auc: 0.915606\tvalid_0's binary_logloss: 0.107477\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.140336\n",
      "[63]\tvalid_0's auc: 0.916315\tvalid_0's binary_logloss: 0.107178\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.140384\n",
      "[64]\tvalid_0's auc: 0.916522\tvalid_0's binary_logloss: 0.10698\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.140446\n",
      "[65]\tvalid_0's auc: 0.917048\tvalid_0's binary_logloss: 0.106704\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.140528\n",
      "[66]\tvalid_0's auc: 0.917714\tvalid_0's binary_logloss: 0.1065\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.140589\n",
      "[67]\tvalid_0's auc: 0.918245\tvalid_0's binary_logloss: 0.106235\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.140673\n",
      "[68]\tvalid_0's auc: 0.918757\tvalid_0's binary_logloss: 0.105956\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.140696\n",
      "[69]\tvalid_0's auc: 0.919319\tvalid_0's binary_logloss: 0.105704\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.140788\n",
      "[70]\tvalid_0's auc: 0.919498\tvalid_0's binary_logloss: 0.105505\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.140912\n",
      "[71]\tvalid_0's auc: 0.919774\tvalid_0's binary_logloss: 0.105296\tvalid_1's auc: 0.834571\tvalid_1's binary_logloss: 0.141016\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823664\tvalid_0's binary_logloss: 0.156198\tvalid_1's auc: 0.821078\tvalid_1's binary_logloss: 0.16488\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.82966\tvalid_0's binary_logloss: 0.150925\tvalid_1's auc: 0.826326\tvalid_1's binary_logloss: 0.159774\n",
      "[3]\tvalid_0's auc: 0.834498\tvalid_0's binary_logloss: 0.147158\tvalid_1's auc: 0.826852\tvalid_1's binary_logloss: 0.156113\n",
      "[4]\tvalid_0's auc: 0.83904\tvalid_0's binary_logloss: 0.144173\tvalid_1's auc: 0.831417\tvalid_1's binary_logloss: 0.153186\n",
      "[5]\tvalid_0's auc: 0.841964\tvalid_0's binary_logloss: 0.141745\tvalid_1's auc: 0.834593\tvalid_1's binary_logloss: 0.150797\n",
      "[6]\tvalid_0's auc: 0.845253\tvalid_0's binary_logloss: 0.139712\tvalid_1's auc: 0.836659\tvalid_1's binary_logloss: 0.149062\n",
      "[7]\tvalid_0's auc: 0.846545\tvalid_0's binary_logloss: 0.138053\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.147537\n",
      "[8]\tvalid_0's auc: 0.848885\tvalid_0's binary_logloss: 0.1366\tvalid_1's auc: 0.838153\tvalid_1's binary_logloss: 0.146268\n",
      "[9]\tvalid_0's auc: 0.850839\tvalid_0's binary_logloss: 0.135205\tvalid_1's auc: 0.839816\tvalid_1's binary_logloss: 0.145097\n",
      "[10]\tvalid_0's auc: 0.851902\tvalid_0's binary_logloss: 0.134136\tvalid_1's auc: 0.839977\tvalid_1's binary_logloss: 0.144182\n",
      "[11]\tvalid_0's auc: 0.853188\tvalid_0's binary_logloss: 0.133195\tvalid_1's auc: 0.840379\tvalid_1's binary_logloss: 0.143374\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[13]\tvalid_0's auc: 0.857693\tvalid_0's binary_logloss: 0.131411\tvalid_1's auc: 0.840669\tvalid_1's binary_logloss: 0.142221\n",
      "[14]\tvalid_0's auc: 0.859427\tvalid_0's binary_logloss: 0.130627\tvalid_1's auc: 0.840024\tvalid_1's binary_logloss: 0.141818\n",
      "[15]\tvalid_0's auc: 0.861064\tvalid_0's binary_logloss: 0.12997\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.141407\n",
      "[16]\tvalid_0's auc: 0.861905\tvalid_0's binary_logloss: 0.12935\tvalid_1's auc: 0.839151\tvalid_1's binary_logloss: 0.141108\n",
      "[17]\tvalid_0's auc: 0.863357\tvalid_0's binary_logloss: 0.128765\tvalid_1's auc: 0.839205\tvalid_1's binary_logloss: 0.14086\n",
      "[18]\tvalid_0's auc: 0.865057\tvalid_0's binary_logloss: 0.128197\tvalid_1's auc: 0.838756\tvalid_1's binary_logloss: 0.140615\n",
      "[19]\tvalid_0's auc: 0.866322\tvalid_0's binary_logloss: 0.127685\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.140439\n",
      "[20]\tvalid_0's auc: 0.867327\tvalid_0's binary_logloss: 0.127201\tvalid_1's auc: 0.838595\tvalid_1's binary_logloss: 0.140208\n",
      "[21]\tvalid_0's auc: 0.868281\tvalid_0's binary_logloss: 0.126821\tvalid_1's auc: 0.83842\tvalid_1's binary_logloss: 0.140081\n",
      "[22]\tvalid_0's auc: 0.869333\tvalid_0's binary_logloss: 0.126397\tvalid_1's auc: 0.838291\tvalid_1's binary_logloss: 0.139941\n",
      "[23]\tvalid_0's auc: 0.870664\tvalid_0's binary_logloss: 0.125953\tvalid_1's auc: 0.837637\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.871541\tvalid_0's binary_logloss: 0.125585\tvalid_1's auc: 0.837144\tvalid_1's binary_logloss: 0.139915\n",
      "[25]\tvalid_0's auc: 0.872827\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837438\tvalid_1's binary_logloss: 0.139775\n",
      "[26]\tvalid_0's auc: 0.873522\tvalid_0's binary_logloss: 0.12487\tvalid_1's auc: 0.83729\tvalid_1's binary_logloss: 0.139751\n",
      "[27]\tvalid_0's auc: 0.874428\tvalid_0's binary_logloss: 0.124521\tvalid_1's auc: 0.837295\tvalid_1's binary_logloss: 0.139667\n",
      "[28]\tvalid_0's auc: 0.875453\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.836916\tvalid_1's binary_logloss: 0.139693\n",
      "[29]\tvalid_0's auc: 0.876968\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.836543\tvalid_1's binary_logloss: 0.139692\n",
      "[30]\tvalid_0's auc: 0.878211\tvalid_0's binary_logloss: 0.123513\tvalid_1's auc: 0.836768\tvalid_1's binary_logloss: 0.139653\n",
      "[31]\tvalid_0's auc: 0.879123\tvalid_0's binary_logloss: 0.123238\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.879609\tvalid_0's binary_logloss: 0.122982\tvalid_1's auc: 0.836481\tvalid_1's binary_logloss: 0.139632\n",
      "[33]\tvalid_0's auc: 0.880297\tvalid_0's binary_logloss: 0.122728\tvalid_1's auc: 0.8369\tvalid_1's binary_logloss: 0.139575\n",
      "[34]\tvalid_0's auc: 0.881002\tvalid_0's binary_logloss: 0.122492\tvalid_1's auc: 0.836762\tvalid_1's binary_logloss: 0.139536\n",
      "[35]\tvalid_0's auc: 0.881621\tvalid_0's binary_logloss: 0.122231\tvalid_1's auc: 0.836948\tvalid_1's binary_logloss: 0.139471\n",
      "[36]\tvalid_0's auc: 0.882178\tvalid_0's binary_logloss: 0.121993\tvalid_1's auc: 0.83713\tvalid_1's binary_logloss: 0.139418\n",
      "[37]\tvalid_0's auc: 0.882783\tvalid_0's binary_logloss: 0.121741\tvalid_1's auc: 0.837135\tvalid_1's binary_logloss: 0.139368\n",
      "[38]\tvalid_0's auc: 0.88336\tvalid_0's binary_logloss: 0.121507\tvalid_1's auc: 0.836861\tvalid_1's binary_logloss: 0.139431\n",
      "[39]\tvalid_0's auc: 0.883753\tvalid_0's binary_logloss: 0.121298\tvalid_1's auc: 0.836288\tvalid_1's binary_logloss: 0.139548\n",
      "[40]\tvalid_0's auc: 0.884325\tvalid_0's binary_logloss: 0.121031\tvalid_1's auc: 0.83612\tvalid_1's binary_logloss: 0.139622\n",
      "[41]\tvalid_0's auc: 0.884814\tvalid_0's binary_logloss: 0.12081\tvalid_1's auc: 0.835963\tvalid_1's binary_logloss: 0.139644\n",
      "[42]\tvalid_0's auc: 0.885392\tvalid_0's binary_logloss: 0.120617\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.139624\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.821268\tvalid_0's binary_logloss: 0.156277\tvalid_1's auc: 0.816814\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.828863\tvalid_0's binary_logloss: 0.151005\tvalid_1's auc: 0.821376\tvalid_1's binary_logloss: 0.159886\n",
      "[3]\tvalid_0's auc: 0.837474\tvalid_0's binary_logloss: 0.147149\tvalid_1's auc: 0.828229\tvalid_1's binary_logloss: 0.156519\n",
      "[4]\tvalid_0's auc: 0.842962\tvalid_0's binary_logloss: 0.144152\tvalid_1's auc: 0.829952\tvalid_1's binary_logloss: 0.153687\n",
      "[5]\tvalid_0's auc: 0.84635\tvalid_0's binary_logloss: 0.141643\tvalid_1's auc: 0.834055\tvalid_1's binary_logloss: 0.15137\n",
      "[6]\tvalid_0's auc: 0.849269\tvalid_0's binary_logloss: 0.139637\tvalid_1's auc: 0.834861\tvalid_1's binary_logloss: 0.149513\n",
      "[7]\tvalid_0's auc: 0.851069\tvalid_0's binary_logloss: 0.137899\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.147828\n",
      "[8]\tvalid_0's auc: 0.852425\tvalid_0's binary_logloss: 0.136444\tvalid_1's auc: 0.837615\tvalid_1's binary_logloss: 0.146566\n",
      "[9]\tvalid_0's auc: 0.853725\tvalid_0's binary_logloss: 0.135223\tvalid_1's auc: 0.838944\tvalid_1's binary_logloss: 0.145455\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[11]\tvalid_0's auc: 0.856642\tvalid_0's binary_logloss: 0.13318\tvalid_1's auc: 0.83836\tvalid_1's binary_logloss: 0.143998\n",
      "[12]\tvalid_0's auc: 0.857381\tvalid_0's binary_logloss: 0.13235\tvalid_1's auc: 0.83849\tvalid_1's binary_logloss: 0.143384\n",
      "[13]\tvalid_0's auc: 0.858555\tvalid_0's binary_logloss: 0.13154\tvalid_1's auc: 0.83788\tvalid_1's binary_logloss: 0.142918\n",
      "[14]\tvalid_0's auc: 0.859092\tvalid_0's binary_logloss: 0.130843\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.142521\n",
      "[15]\tvalid_0's auc: 0.860202\tvalid_0's binary_logloss: 0.130174\tvalid_1's auc: 0.836385\tvalid_1's binary_logloss: 0.142279\n",
      "[16]\tvalid_0's auc: 0.861797\tvalid_0's binary_logloss: 0.129525\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.141987\n",
      "[17]\tvalid_0's auc: 0.863207\tvalid_0's binary_logloss: 0.128978\tvalid_1's auc: 0.835285\tvalid_1's binary_logloss: 0.141713\n",
      "[18]\tvalid_0's auc: 0.864433\tvalid_0's binary_logloss: 0.128402\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.141442\n",
      "[19]\tvalid_0's auc: 0.865245\tvalid_0's binary_logloss: 0.127948\tvalid_1's auc: 0.836123\tvalid_1's binary_logloss: 0.1412\n",
      "[20]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.127497\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.140979\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.12703\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.140825\n",
      "[22]\tvalid_0's auc: 0.86828\tvalid_0's binary_logloss: 0.126598\tvalid_1's auc: 0.836515\tvalid_1's binary_logloss: 0.140741\n",
      "[23]\tvalid_0's auc: 0.869182\tvalid_0's binary_logloss: 0.126269\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.140588\n",
      "[24]\tvalid_0's auc: 0.869979\tvalid_0's binary_logloss: 0.125886\tvalid_1's auc: 0.836766\tvalid_1's binary_logloss: 0.140496\n",
      "[25]\tvalid_0's auc: 0.870956\tvalid_0's binary_logloss: 0.125545\tvalid_1's auc: 0.837001\tvalid_1's binary_logloss: 0.140322\n",
      "[26]\tvalid_0's auc: 0.872886\tvalid_0's binary_logloss: 0.125108\tvalid_1's auc: 0.836911\tvalid_1's binary_logloss: 0.140274\n",
      "[27]\tvalid_0's auc: 0.873971\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.140247\n",
      "[28]\tvalid_0's auc: 0.875129\tvalid_0's binary_logloss: 0.124434\tvalid_1's auc: 0.837012\tvalid_1's binary_logloss: 0.140143\n",
      "[29]\tvalid_0's auc: 0.875873\tvalid_0's binary_logloss: 0.12414\tvalid_1's auc: 0.836866\tvalid_1's binary_logloss: 0.140163\n",
      "[30]\tvalid_0's auc: 0.876465\tvalid_0's binary_logloss: 0.123865\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.140195\n",
      "[31]\tvalid_0's auc: 0.877699\tvalid_0's binary_logloss: 0.123521\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.140186\n",
      "[32]\tvalid_0's auc: 0.878492\tvalid_0's binary_logloss: 0.123253\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.140145\n",
      "[33]\tvalid_0's auc: 0.879281\tvalid_0's binary_logloss: 0.122981\tvalid_1's auc: 0.836061\tvalid_1's binary_logloss: 0.140165\n",
      "[34]\tvalid_0's auc: 0.880016\tvalid_0's binary_logloss: 0.12271\tvalid_1's auc: 0.836238\tvalid_1's binary_logloss: 0.140112\n",
      "[35]\tvalid_0's auc: 0.880929\tvalid_0's binary_logloss: 0.122397\tvalid_1's auc: 0.836618\tvalid_1's binary_logloss: 0.140034\n",
      "[36]\tvalid_0's auc: 0.881746\tvalid_0's binary_logloss: 0.122132\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.140013\n",
      "[37]\tvalid_0's auc: 0.882622\tvalid_0's binary_logloss: 0.121854\tvalid_1's auc: 0.836926\tvalid_1's binary_logloss: 0.139982\n",
      "[38]\tvalid_0's auc: 0.883018\tvalid_0's binary_logloss: 0.121618\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.139968\n",
      "[39]\tvalid_0's auc: 0.883857\tvalid_0's binary_logloss: 0.12136\tvalid_1's auc: 0.837075\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.884437\tvalid_0's binary_logloss: 0.121112\tvalid_1's auc: 0.836834\tvalid_1's binary_logloss: 0.139996\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.825972\tvalid_0's binary_logloss: 0.15626\tvalid_1's auc: 0.817426\tvalid_1's binary_logloss: 0.165002\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830735\tvalid_0's binary_logloss: 0.150869\tvalid_1's auc: 0.821832\tvalid_1's binary_logloss: 0.159685\n",
      "[3]\tvalid_0's auc: 0.836213\tvalid_0's binary_logloss: 0.147022\tvalid_1's auc: 0.825847\tvalid_1's binary_logloss: 0.156023\n",
      "[4]\tvalid_0's auc: 0.839911\tvalid_0's binary_logloss: 0.143985\tvalid_1's auc: 0.830159\tvalid_1's binary_logloss: 0.153298\n",
      "[5]\tvalid_0's auc: 0.842712\tvalid_0's binary_logloss: 0.14152\tvalid_1's auc: 0.831253\tvalid_1's binary_logloss: 0.151107\n",
      "[6]\tvalid_0's auc: 0.84576\tvalid_0's binary_logloss: 0.139503\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.149167\n",
      "[7]\tvalid_0's auc: 0.84864\tvalid_0's binary_logloss: 0.137792\tvalid_1's auc: 0.836612\tvalid_1's binary_logloss: 0.147629\n",
      "[8]\tvalid_0's auc: 0.850006\tvalid_0's binary_logloss: 0.136329\tvalid_1's auc: 0.837077\tvalid_1's binary_logloss: 0.146348\n",
      "[9]\tvalid_0's auc: 0.852085\tvalid_0's binary_logloss: 0.135086\tvalid_1's auc: 0.838711\tvalid_1's binary_logloss: 0.145304\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[11]\tvalid_0's auc: 0.856458\tvalid_0's binary_logloss: 0.132947\tvalid_1's auc: 0.838948\tvalid_1's binary_logloss: 0.143547\n",
      "[12]\tvalid_0's auc: 0.857299\tvalid_0's binary_logloss: 0.132061\tvalid_1's auc: 0.839046\tvalid_1's binary_logloss: 0.142873\n",
      "[13]\tvalid_0's auc: 0.858451\tvalid_0's binary_logloss: 0.131304\tvalid_1's auc: 0.838455\tvalid_1's binary_logloss: 0.142387\n",
      "[14]\tvalid_0's auc: 0.860294\tvalid_0's binary_logloss: 0.130565\tvalid_1's auc: 0.838925\tvalid_1's binary_logloss: 0.141904\n",
      "[15]\tvalid_0's auc: 0.861473\tvalid_0's binary_logloss: 0.129923\tvalid_1's auc: 0.838733\tvalid_1's binary_logloss: 0.141518\n",
      "[16]\tvalid_0's auc: 0.862203\tvalid_0's binary_logloss: 0.129333\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.141178\n",
      "[17]\tvalid_0's auc: 0.863233\tvalid_0's binary_logloss: 0.128766\tvalid_1's auc: 0.838823\tvalid_1's binary_logloss: 0.140886\n",
      "[18]\tvalid_0's auc: 0.86399\tvalid_0's binary_logloss: 0.128208\tvalid_1's auc: 0.838336\tvalid_1's binary_logloss: 0.140669\n",
      "[19]\tvalid_0's auc: 0.864707\tvalid_0's binary_logloss: 0.127724\tvalid_1's auc: 0.83783\tvalid_1's binary_logloss: 0.140495\n",
      "[20]\tvalid_0's auc: 0.865576\tvalid_0's binary_logloss: 0.127256\tvalid_1's auc: 0.838481\tvalid_1's binary_logloss: 0.140248\n",
      "[21]\tvalid_0's auc: 0.866846\tvalid_0's binary_logloss: 0.126797\tvalid_1's auc: 0.838182\tvalid_1's binary_logloss: 0.140129\n",
      "[22]\tvalid_0's auc: 0.86837\tvalid_0's binary_logloss: 0.126354\tvalid_1's auc: 0.838279\tvalid_1's binary_logloss: 0.139978\n",
      "[23]\tvalid_0's auc: 0.869587\tvalid_0's binary_logloss: 0.125905\tvalid_1's auc: 0.83825\tvalid_1's binary_logloss: 0.139909\n",
      "[24]\tvalid_0's auc: 0.870532\tvalid_0's binary_logloss: 0.125527\tvalid_1's auc: 0.838429\tvalid_1's binary_logloss: 0.139818\n",
      "[25]\tvalid_0's auc: 0.871628\tvalid_0's binary_logloss: 0.125118\tvalid_1's auc: 0.837908\tvalid_1's binary_logloss: 0.139768\n",
      "[26]\tvalid_0's auc: 0.872816\tvalid_0's binary_logloss: 0.12478\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139683\n",
      "[27]\tvalid_0's auc: 0.873647\tvalid_0's binary_logloss: 0.124448\tvalid_1's auc: 0.837808\tvalid_1's binary_logloss: 0.139669\n",
      "[28]\tvalid_0's auc: 0.874326\tvalid_0's binary_logloss: 0.124117\tvalid_1's auc: 0.837756\tvalid_1's binary_logloss: 0.139635\n",
      "[29]\tvalid_0's auc: 0.875069\tvalid_0's binary_logloss: 0.123826\tvalid_1's auc: 0.838037\tvalid_1's binary_logloss: 0.139565\n",
      "[30]\tvalid_0's auc: 0.876092\tvalid_0's binary_logloss: 0.123541\tvalid_1's auc: 0.838013\tvalid_1's binary_logloss: 0.139571\n",
      "[31]\tvalid_0's auc: 0.877253\tvalid_0's binary_logloss: 0.123222\tvalid_1's auc: 0.838176\tvalid_1's binary_logloss: 0.139525\n",
      "[32]\tvalid_0's auc: 0.877859\tvalid_0's binary_logloss: 0.122952\tvalid_1's auc: 0.837999\tvalid_1's binary_logloss: 0.139539\n",
      "[33]\tvalid_0's auc: 0.878881\tvalid_0's binary_logloss: 0.122669\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139429\n",
      "[34]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.122378\tvalid_1's auc: 0.838388\tvalid_1's binary_logloss: 0.139425\n",
      "[35]\tvalid_0's auc: 0.880711\tvalid_0's binary_logloss: 0.122133\tvalid_1's auc: 0.838795\tvalid_1's binary_logloss: 0.139306\n",
      "[36]\tvalid_0's auc: 0.881763\tvalid_0's binary_logloss: 0.12187\tvalid_1's auc: 0.83878\tvalid_1's binary_logloss: 0.139315\n",
      "[37]\tvalid_0's auc: 0.882612\tvalid_0's binary_logloss: 0.121565\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139322\n",
      "[38]\tvalid_0's auc: 0.883169\tvalid_0's binary_logloss: 0.121312\tvalid_1's auc: 0.838615\tvalid_1's binary_logloss: 0.139324\n",
      "[39]\tvalid_0's auc: 0.883934\tvalid_0's binary_logloss: 0.12102\tvalid_1's auc: 0.838763\tvalid_1's binary_logloss: 0.139293\n",
      "[40]\tvalid_0's auc: 0.884499\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.838547\tvalid_1's binary_logloss: 0.13931\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823084\tvalid_0's binary_logloss: 0.156066\tvalid_1's auc: 0.821793\tvalid_1's binary_logloss: 0.164822\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.827813\tvalid_0's binary_logloss: 0.150805\tvalid_1's auc: 0.823891\tvalid_1's binary_logloss: 0.159732\n",
      "[3]\tvalid_0's auc: 0.836023\tvalid_0's binary_logloss: 0.147035\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.156124\n",
      "[4]\tvalid_0's auc: 0.842374\tvalid_0's binary_logloss: 0.143993\tvalid_1's auc: 0.832801\tvalid_1's binary_logloss: 0.153225\n",
      "[5]\tvalid_0's auc: 0.845121\tvalid_0's binary_logloss: 0.141663\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.15098\n",
      "[6]\tvalid_0's auc: 0.846404\tvalid_0's binary_logloss: 0.139689\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.14912\n",
      "[7]\tvalid_0's auc: 0.848157\tvalid_0's binary_logloss: 0.137973\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.147706\n",
      "[8]\tvalid_0's auc: 0.84954\tvalid_0's binary_logloss: 0.136555\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.146499\n",
      "[9]\tvalid_0's auc: 0.851438\tvalid_0's binary_logloss: 0.135283\tvalid_1's auc: 0.838446\tvalid_1's binary_logloss: 0.145447\n",
      "[10]\tvalid_0's auc: 0.853323\tvalid_0's binary_logloss: 0.134172\tvalid_1's auc: 0.838164\tvalid_1's binary_logloss: 0.144649\n",
      "[11]\tvalid_0's auc: 0.85454\tvalid_0's binary_logloss: 0.133213\tvalid_1's auc: 0.838387\tvalid_1's binary_logloss: 0.143878\n",
      "[12]\tvalid_0's auc: 0.856731\tvalid_0's binary_logloss: 0.1323\tvalid_1's auc: 0.83958\tvalid_1's binary_logloss: 0.143232\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[14]\tvalid_0's auc: 0.859616\tvalid_0's binary_logloss: 0.130695\tvalid_1's auc: 0.839638\tvalid_1's binary_logloss: 0.142197\n",
      "[15]\tvalid_0's auc: 0.86065\tvalid_0's binary_logloss: 0.130019\tvalid_1's auc: 0.839342\tvalid_1's binary_logloss: 0.141867\n",
      "[16]\tvalid_0's auc: 0.861879\tvalid_0's binary_logloss: 0.129426\tvalid_1's auc: 0.839474\tvalid_1's binary_logloss: 0.141484\n",
      "[17]\tvalid_0's auc: 0.86312\tvalid_0's binary_logloss: 0.128865\tvalid_1's auc: 0.838976\tvalid_1's binary_logloss: 0.141297\n",
      "[18]\tvalid_0's auc: 0.864292\tvalid_0's binary_logloss: 0.128302\tvalid_1's auc: 0.839738\tvalid_1's binary_logloss: 0.140953\n",
      "[19]\tvalid_0's auc: 0.86562\tvalid_0's binary_logloss: 0.12782\tvalid_1's auc: 0.839799\tvalid_1's binary_logloss: 0.140766\n",
      "[20]\tvalid_0's auc: 0.866802\tvalid_0's binary_logloss: 0.127322\tvalid_1's auc: 0.839807\tvalid_1's binary_logloss: 0.140536\n",
      "[21]\tvalid_0's auc: 0.868305\tvalid_0's binary_logloss: 0.126848\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.140335\n",
      "[22]\tvalid_0's auc: 0.869367\tvalid_0's binary_logloss: 0.126428\tvalid_1's auc: 0.839045\tvalid_1's binary_logloss: 0.140242\n",
      "[23]\tvalid_0's auc: 0.870018\tvalid_0's binary_logloss: 0.126051\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.140113\n",
      "[24]\tvalid_0's auc: 0.871076\tvalid_0's binary_logloss: 0.125665\tvalid_1's auc: 0.838918\tvalid_1's binary_logloss: 0.139963\n",
      "[25]\tvalid_0's auc: 0.871808\tvalid_0's binary_logloss: 0.12529\tvalid_1's auc: 0.838876\tvalid_1's binary_logloss: 0.139886\n",
      "[26]\tvalid_0's auc: 0.872679\tvalid_0's binary_logloss: 0.124953\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.139811\n",
      "[27]\tvalid_0's auc: 0.873565\tvalid_0's binary_logloss: 0.124623\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139786\n",
      "[28]\tvalid_0's auc: 0.874397\tvalid_0's binary_logloss: 0.124307\tvalid_1's auc: 0.83805\tvalid_1's binary_logloss: 0.139815\n",
      "[29]\tvalid_0's auc: 0.87544\tvalid_0's binary_logloss: 0.124018\tvalid_1's auc: 0.837719\tvalid_1's binary_logloss: 0.139819\n",
      "[30]\tvalid_0's auc: 0.876222\tvalid_0's binary_logloss: 0.123733\tvalid_1's auc: 0.838003\tvalid_1's binary_logloss: 0.139778\n",
      "[31]\tvalid_0's auc: 0.877142\tvalid_0's binary_logloss: 0.12348\tvalid_1's auc: 0.838078\tvalid_1's binary_logloss: 0.139735\n",
      "[32]\tvalid_0's auc: 0.877956\tvalid_0's binary_logloss: 0.123203\tvalid_1's auc: 0.838002\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878477\tvalid_0's binary_logloss: 0.122964\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139665\n",
      "[34]\tvalid_0's auc: 0.879048\tvalid_0's binary_logloss: 0.122668\tvalid_1's auc: 0.838296\tvalid_1's binary_logloss: 0.139589\n",
      "[35]\tvalid_0's auc: 0.879723\tvalid_0's binary_logloss: 0.122403\tvalid_1's auc: 0.838433\tvalid_1's binary_logloss: 0.139597\n",
      "[36]\tvalid_0's auc: 0.881202\tvalid_0's binary_logloss: 0.122123\tvalid_1's auc: 0.838596\tvalid_1's binary_logloss: 0.139557\n",
      "[37]\tvalid_0's auc: 0.882142\tvalid_0's binary_logloss: 0.121861\tvalid_1's auc: 0.838424\tvalid_1's binary_logloss: 0.139578\n",
      "[38]\tvalid_0's auc: 0.882706\tvalid_0's binary_logloss: 0.121634\tvalid_1's auc: 0.838625\tvalid_1's binary_logloss: 0.139548\n",
      "[39]\tvalid_0's auc: 0.883054\tvalid_0's binary_logloss: 0.121421\tvalid_1's auc: 0.838452\tvalid_1's binary_logloss: 0.139609\n",
      "[40]\tvalid_0's auc: 0.883797\tvalid_0's binary_logloss: 0.121128\tvalid_1's auc: 0.838612\tvalid_1's binary_logloss: 0.139576\n",
      "[41]\tvalid_0's auc: 0.884595\tvalid_0's binary_logloss: 0.120862\tvalid_1's auc: 0.838672\tvalid_1's binary_logloss: 0.139551\n",
      "[42]\tvalid_0's auc: 0.885101\tvalid_0's binary_logloss: 0.120643\tvalid_1's auc: 0.839085\tvalid_1's binary_logloss: 0.139462\n",
      "[43]\tvalid_0's auc: 0.885377\tvalid_0's binary_logloss: 0.120471\tvalid_1's auc: 0.838989\tvalid_1's binary_logloss: 0.13949\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823422\tvalid_0's binary_logloss: 0.156446\tvalid_1's auc: 0.819043\tvalid_1's binary_logloss: 0.165337\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830391\tvalid_0's binary_logloss: 0.151103\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.160151\n",
      "[3]\tvalid_0's auc: 0.836251\tvalid_0's binary_logloss: 0.14724\tvalid_1's auc: 0.829717\tvalid_1's binary_logloss: 0.156452\n",
      "[4]\tvalid_0's auc: 0.842516\tvalid_0's binary_logloss: 0.144162\tvalid_1's auc: 0.832695\tvalid_1's binary_logloss: 0.15358\n",
      "[5]\tvalid_0's auc: 0.846316\tvalid_0's binary_logloss: 0.141636\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.151246\n",
      "[6]\tvalid_0's auc: 0.847998\tvalid_0's binary_logloss: 0.139517\tvalid_1's auc: 0.836546\tvalid_1's binary_logloss: 0.149374\n",
      "[7]\tvalid_0's auc: 0.849074\tvalid_0's binary_logloss: 0.13782\tvalid_1's auc: 0.838333\tvalid_1's binary_logloss: 0.147794\n",
      "[8]\tvalid_0's auc: 0.85\tvalid_0's binary_logloss: 0.136391\tvalid_1's auc: 0.838986\tvalid_1's binary_logloss: 0.146497\n",
      "[9]\tvalid_0's auc: 0.851546\tvalid_0's binary_logloss: 0.135138\tvalid_1's auc: 0.839435\tvalid_1's binary_logloss: 0.145445\n",
      "[10]\tvalid_0's auc: 0.852573\tvalid_0's binary_logloss: 0.134059\tvalid_1's auc: 0.839729\tvalid_1's binary_logloss: 0.144614\n",
      "[11]\tvalid_0's auc: 0.854408\tvalid_0's binary_logloss: 0.133048\tvalid_1's auc: 0.840015\tvalid_1's binary_logloss: 0.143842\n",
      "[12]\tvalid_0's auc: 0.857486\tvalid_0's binary_logloss: 0.132117\tvalid_1's auc: 0.83955\tvalid_1's binary_logloss: 0.143278\n",
      "[13]\tvalid_0's auc: 0.859425\tvalid_0's binary_logloss: 0.131314\tvalid_1's auc: 0.840426\tvalid_1's binary_logloss: 0.142719\n",
      "[14]\tvalid_0's auc: 0.861454\tvalid_0's binary_logloss: 0.130495\tvalid_1's auc: 0.840751\tvalid_1's binary_logloss: 0.14226\n",
      "[15]\tvalid_0's auc: 0.862973\tvalid_0's binary_logloss: 0.12978\tvalid_1's auc: 0.840328\tvalid_1's binary_logloss: 0.14183\n",
      "[16]\tvalid_0's auc: 0.864608\tvalid_0's binary_logloss: 0.129092\tvalid_1's auc: 0.839958\tvalid_1's binary_logloss: 0.14153\n",
      "[17]\tvalid_0's auc: 0.865394\tvalid_0's binary_logloss: 0.128538\tvalid_1's auc: 0.840045\tvalid_1's binary_logloss: 0.141215\n",
      "[18]\tvalid_0's auc: 0.867204\tvalid_0's binary_logloss: 0.127947\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.1409\n",
      "[19]\tvalid_0's auc: 0.868095\tvalid_0's binary_logloss: 0.127461\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.14074\n",
      "[20]\tvalid_0's auc: 0.86902\tvalid_0's binary_logloss: 0.126956\tvalid_1's auc: 0.840596\tvalid_1's binary_logloss: 0.140606\n",
      "[21]\tvalid_0's auc: 0.869954\tvalid_0's binary_logloss: 0.126491\tvalid_1's auc: 0.840559\tvalid_1's binary_logloss: 0.140425\n",
      "[22]\tvalid_0's auc: 0.870971\tvalid_0's binary_logloss: 0.126075\tvalid_1's auc: 0.840789\tvalid_1's binary_logloss: 0.140251\n",
      "[23]\tvalid_0's auc: 0.872384\tvalid_0's binary_logloss: 0.125599\tvalid_1's auc: 0.840267\tvalid_1's binary_logloss: 0.14022\n",
      "[24]\tvalid_0's auc: 0.873433\tvalid_0's binary_logloss: 0.125215\tvalid_1's auc: 0.840763\tvalid_1's binary_logloss: 0.140023\n",
      "[25]\tvalid_0's auc: 0.874094\tvalid_0's binary_logloss: 0.124834\tvalid_1's auc: 0.840782\tvalid_1's binary_logloss: 0.139927\n",
      "[26]\tvalid_0's auc: 0.875299\tvalid_0's binary_logloss: 0.12446\tvalid_1's auc: 0.840852\tvalid_1's binary_logloss: 0.139864\n",
      "[27]\tvalid_0's auc: 0.875863\tvalid_0's binary_logloss: 0.124178\tvalid_1's auc: 0.840905\tvalid_1's binary_logloss: 0.139751\n",
      "[28]\tvalid_0's auc: 0.876477\tvalid_0's binary_logloss: 0.123899\tvalid_1's auc: 0.840828\tvalid_1's binary_logloss: 0.139688\n",
      "[29]\tvalid_0's auc: 0.877436\tvalid_0's binary_logloss: 0.123585\tvalid_1's auc: 0.840653\tvalid_1's binary_logloss: 0.139596\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[31]\tvalid_0's auc: 0.879246\tvalid_0's binary_logloss: 0.122979\tvalid_1's auc: 0.840819\tvalid_1's binary_logloss: 0.139442\n",
      "[32]\tvalid_0's auc: 0.880496\tvalid_0's binary_logloss: 0.122664\tvalid_1's auc: 0.840531\tvalid_1's binary_logloss: 0.139452\n",
      "[33]\tvalid_0's auc: 0.881439\tvalid_0's binary_logloss: 0.122371\tvalid_1's auc: 0.840279\tvalid_1's binary_logloss: 0.139455\n",
      "[34]\tvalid_0's auc: 0.882347\tvalid_0's binary_logloss: 0.122119\tvalid_1's auc: 0.840374\tvalid_1's binary_logloss: 0.139423\n",
      "[35]\tvalid_0's auc: 0.883154\tvalid_0's binary_logloss: 0.121847\tvalid_1's auc: 0.840528\tvalid_1's binary_logloss: 0.139369\n",
      "[36]\tvalid_0's auc: 0.883941\tvalid_0's binary_logloss: 0.121532\tvalid_1's auc: 0.840858\tvalid_1's binary_logloss: 0.139284\n",
      "[37]\tvalid_0's auc: 0.884407\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.840641\tvalid_1's binary_logloss: 0.139325\n",
      "[38]\tvalid_0's auc: 0.885324\tvalid_0's binary_logloss: 0.121016\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.13934\n",
      "[39]\tvalid_0's auc: 0.885824\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.840244\tvalid_1's binary_logloss: 0.139346\n",
      "[40]\tvalid_0's auc: 0.886492\tvalid_0's binary_logloss: 0.120515\tvalid_1's auc: 0.84003\tvalid_1's binary_logloss: 0.139395\n",
      "[41]\tvalid_0's auc: 0.887212\tvalid_0's binary_logloss: 0.120235\tvalid_1's auc: 0.839933\tvalid_1's binary_logloss: 0.139397\n",
      "[42]\tvalid_0's auc: 0.887679\tvalid_0's binary_logloss: 0.120004\tvalid_1's auc: 0.839795\tvalid_1's binary_logloss: 0.139391\n",
      "[43]\tvalid_0's auc: 0.88855\tvalid_0's binary_logloss: 0.119787\tvalid_1's auc: 0.839567\tvalid_1's binary_logloss: 0.139426\n",
      "[44]\tvalid_0's auc: 0.888918\tvalid_0's binary_logloss: 0.119598\tvalid_1's auc: 0.839591\tvalid_1's binary_logloss: 0.139427\n",
      "[45]\tvalid_0's auc: 0.889615\tvalid_0's binary_logloss: 0.119335\tvalid_1's auc: 0.839609\tvalid_1's binary_logloss: 0.139412\n",
      "[46]\tvalid_0's auc: 0.890166\tvalid_0's binary_logloss: 0.119099\tvalid_1's auc: 0.839346\tvalid_1's binary_logloss: 0.139475\n",
      "[47]\tvalid_0's auc: 0.890678\tvalid_0's binary_logloss: 0.118869\tvalid_1's auc: 0.839761\tvalid_1's binary_logloss: 0.1394\n",
      "[48]\tvalid_0's auc: 0.891058\tvalid_0's binary_logloss: 0.118665\tvalid_1's auc: 0.839755\tvalid_1's binary_logloss: 0.139409\n",
      "[49]\tvalid_0's auc: 0.891635\tvalid_0's binary_logloss: 0.118425\tvalid_1's auc: 0.839754\tvalid_1's binary_logloss: 0.139428\n",
      "[50]\tvalid_0's auc: 0.892346\tvalid_0's binary_logloss: 0.118168\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.139501\n",
      "[51]\tvalid_0's auc: 0.892736\tvalid_0's binary_logloss: 0.117984\tvalid_1's auc: 0.839121\tvalid_1's binary_logloss: 0.139524\n",
      "[52]\tvalid_0's auc: 0.893171\tvalid_0's binary_logloss: 0.117764\tvalid_1's auc: 0.838794\tvalid_1's binary_logloss: 0.139586\n",
      "[53]\tvalid_0's auc: 0.893573\tvalid_0's binary_logloss: 0.117568\tvalid_1's auc: 0.838694\tvalid_1's binary_logloss: 0.139581\n",
      "[54]\tvalid_0's auc: 0.894147\tvalid_0's binary_logloss: 0.117322\tvalid_1's auc: 0.838487\tvalid_1's binary_logloss: 0.139606\n",
      "[55]\tvalid_0's auc: 0.894518\tvalid_0's binary_logloss: 0.117157\tvalid_1's auc: 0.838831\tvalid_1's binary_logloss: 0.139538\n",
      "[56]\tvalid_0's auc: 0.894919\tvalid_0's binary_logloss: 0.116983\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139562\n",
      "[57]\tvalid_0's auc: 0.895096\tvalid_0's binary_logloss: 0.116832\tvalid_1's auc: 0.838982\tvalid_1's binary_logloss: 0.139544\n",
      "[58]\tvalid_0's auc: 0.895448\tvalid_0's binary_logloss: 0.116643\tvalid_1's auc: 0.839062\tvalid_1's binary_logloss: 0.139518\n",
      "[59]\tvalid_0's auc: 0.895699\tvalid_0's binary_logloss: 0.116514\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.139543\n",
      "[60]\tvalid_0's auc: 0.896178\tvalid_0's binary_logloss: 0.116313\tvalid_1's auc: 0.838833\tvalid_1's binary_logloss: 0.1396\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823664\tvalid_0's binary_logloss: 0.156198\tvalid_1's auc: 0.821078\tvalid_1's binary_logloss: 0.16488\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.82966\tvalid_0's binary_logloss: 0.150925\tvalid_1's auc: 0.826326\tvalid_1's binary_logloss: 0.159774\n",
      "[3]\tvalid_0's auc: 0.834498\tvalid_0's binary_logloss: 0.147158\tvalid_1's auc: 0.826852\tvalid_1's binary_logloss: 0.156113\n",
      "[4]\tvalid_0's auc: 0.83904\tvalid_0's binary_logloss: 0.144173\tvalid_1's auc: 0.831417\tvalid_1's binary_logloss: 0.153186\n",
      "[5]\tvalid_0's auc: 0.841964\tvalid_0's binary_logloss: 0.141745\tvalid_1's auc: 0.834593\tvalid_1's binary_logloss: 0.150797\n",
      "[6]\tvalid_0's auc: 0.845253\tvalid_0's binary_logloss: 0.139712\tvalid_1's auc: 0.836659\tvalid_1's binary_logloss: 0.149062\n",
      "[7]\tvalid_0's auc: 0.846545\tvalid_0's binary_logloss: 0.138053\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.147537\n",
      "[8]\tvalid_0's auc: 0.848885\tvalid_0's binary_logloss: 0.1366\tvalid_1's auc: 0.838153\tvalid_1's binary_logloss: 0.146268\n",
      "[9]\tvalid_0's auc: 0.850839\tvalid_0's binary_logloss: 0.135205\tvalid_1's auc: 0.839816\tvalid_1's binary_logloss: 0.145097\n",
      "[10]\tvalid_0's auc: 0.851902\tvalid_0's binary_logloss: 0.134136\tvalid_1's auc: 0.839977\tvalid_1's binary_logloss: 0.144182\n",
      "[11]\tvalid_0's auc: 0.853188\tvalid_0's binary_logloss: 0.133195\tvalid_1's auc: 0.840379\tvalid_1's binary_logloss: 0.143374\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[13]\tvalid_0's auc: 0.857693\tvalid_0's binary_logloss: 0.131411\tvalid_1's auc: 0.840669\tvalid_1's binary_logloss: 0.142221\n",
      "[14]\tvalid_0's auc: 0.859427\tvalid_0's binary_logloss: 0.130627\tvalid_1's auc: 0.840024\tvalid_1's binary_logloss: 0.141818\n",
      "[15]\tvalid_0's auc: 0.861064\tvalid_0's binary_logloss: 0.12997\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.141407\n",
      "[16]\tvalid_0's auc: 0.861905\tvalid_0's binary_logloss: 0.12935\tvalid_1's auc: 0.839151\tvalid_1's binary_logloss: 0.141108\n",
      "[17]\tvalid_0's auc: 0.863357\tvalid_0's binary_logloss: 0.128765\tvalid_1's auc: 0.839205\tvalid_1's binary_logloss: 0.14086\n",
      "[18]\tvalid_0's auc: 0.865057\tvalid_0's binary_logloss: 0.128197\tvalid_1's auc: 0.838756\tvalid_1's binary_logloss: 0.140615\n",
      "[19]\tvalid_0's auc: 0.866322\tvalid_0's binary_logloss: 0.127685\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.140439\n",
      "[20]\tvalid_0's auc: 0.867327\tvalid_0's binary_logloss: 0.127201\tvalid_1's auc: 0.838595\tvalid_1's binary_logloss: 0.140208\n",
      "[21]\tvalid_0's auc: 0.868281\tvalid_0's binary_logloss: 0.126821\tvalid_1's auc: 0.83842\tvalid_1's binary_logloss: 0.140081\n",
      "[22]\tvalid_0's auc: 0.869333\tvalid_0's binary_logloss: 0.126397\tvalid_1's auc: 0.838291\tvalid_1's binary_logloss: 0.139941\n",
      "[23]\tvalid_0's auc: 0.870664\tvalid_0's binary_logloss: 0.125953\tvalid_1's auc: 0.837637\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.871541\tvalid_0's binary_logloss: 0.125585\tvalid_1's auc: 0.837144\tvalid_1's binary_logloss: 0.139915\n",
      "[25]\tvalid_0's auc: 0.872827\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837438\tvalid_1's binary_logloss: 0.139775\n",
      "[26]\tvalid_0's auc: 0.873522\tvalid_0's binary_logloss: 0.12487\tvalid_1's auc: 0.83729\tvalid_1's binary_logloss: 0.139751\n",
      "[27]\tvalid_0's auc: 0.874428\tvalid_0's binary_logloss: 0.124521\tvalid_1's auc: 0.837295\tvalid_1's binary_logloss: 0.139667\n",
      "[28]\tvalid_0's auc: 0.875453\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.836916\tvalid_1's binary_logloss: 0.139693\n",
      "[29]\tvalid_0's auc: 0.876968\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.836543\tvalid_1's binary_logloss: 0.139692\n",
      "[30]\tvalid_0's auc: 0.878211\tvalid_0's binary_logloss: 0.123513\tvalid_1's auc: 0.836768\tvalid_1's binary_logloss: 0.139653\n",
      "[31]\tvalid_0's auc: 0.879123\tvalid_0's binary_logloss: 0.123238\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.879609\tvalid_0's binary_logloss: 0.122982\tvalid_1's auc: 0.836481\tvalid_1's binary_logloss: 0.139632\n",
      "[33]\tvalid_0's auc: 0.880297\tvalid_0's binary_logloss: 0.122728\tvalid_1's auc: 0.8369\tvalid_1's binary_logloss: 0.139575\n",
      "[34]\tvalid_0's auc: 0.881002\tvalid_0's binary_logloss: 0.122492\tvalid_1's auc: 0.836762\tvalid_1's binary_logloss: 0.139536\n",
      "[35]\tvalid_0's auc: 0.881621\tvalid_0's binary_logloss: 0.122231\tvalid_1's auc: 0.836948\tvalid_1's binary_logloss: 0.139471\n",
      "[36]\tvalid_0's auc: 0.882178\tvalid_0's binary_logloss: 0.121993\tvalid_1's auc: 0.83713\tvalid_1's binary_logloss: 0.139418\n",
      "[37]\tvalid_0's auc: 0.882783\tvalid_0's binary_logloss: 0.121741\tvalid_1's auc: 0.837135\tvalid_1's binary_logloss: 0.139368\n",
      "[38]\tvalid_0's auc: 0.88336\tvalid_0's binary_logloss: 0.121507\tvalid_1's auc: 0.836861\tvalid_1's binary_logloss: 0.139431\n",
      "[39]\tvalid_0's auc: 0.883753\tvalid_0's binary_logloss: 0.121298\tvalid_1's auc: 0.836288\tvalid_1's binary_logloss: 0.139548\n",
      "[40]\tvalid_0's auc: 0.884325\tvalid_0's binary_logloss: 0.121031\tvalid_1's auc: 0.83612\tvalid_1's binary_logloss: 0.139622\n",
      "[41]\tvalid_0's auc: 0.884814\tvalid_0's binary_logloss: 0.12081\tvalid_1's auc: 0.835963\tvalid_1's binary_logloss: 0.139644\n",
      "[42]\tvalid_0's auc: 0.885392\tvalid_0's binary_logloss: 0.120617\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.139624\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856101\tvalid_0's binary_logloss: 0.13225\tvalid_1's auc: 0.840855\tvalid_1's binary_logloss: 0.142715\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.821268\tvalid_0's binary_logloss: 0.156277\tvalid_1's auc: 0.816814\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.828863\tvalid_0's binary_logloss: 0.151005\tvalid_1's auc: 0.821376\tvalid_1's binary_logloss: 0.159886\n",
      "[3]\tvalid_0's auc: 0.837474\tvalid_0's binary_logloss: 0.147149\tvalid_1's auc: 0.828229\tvalid_1's binary_logloss: 0.156519\n",
      "[4]\tvalid_0's auc: 0.842962\tvalid_0's binary_logloss: 0.144152\tvalid_1's auc: 0.829952\tvalid_1's binary_logloss: 0.153687\n",
      "[5]\tvalid_0's auc: 0.84635\tvalid_0's binary_logloss: 0.141643\tvalid_1's auc: 0.834055\tvalid_1's binary_logloss: 0.15137\n",
      "[6]\tvalid_0's auc: 0.849269\tvalid_0's binary_logloss: 0.139637\tvalid_1's auc: 0.834861\tvalid_1's binary_logloss: 0.149513\n",
      "[7]\tvalid_0's auc: 0.851069\tvalid_0's binary_logloss: 0.137899\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.147828\n",
      "[8]\tvalid_0's auc: 0.852425\tvalid_0's binary_logloss: 0.136444\tvalid_1's auc: 0.837615\tvalid_1's binary_logloss: 0.146566\n",
      "[9]\tvalid_0's auc: 0.853725\tvalid_0's binary_logloss: 0.135223\tvalid_1's auc: 0.838944\tvalid_1's binary_logloss: 0.145455\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[11]\tvalid_0's auc: 0.856642\tvalid_0's binary_logloss: 0.13318\tvalid_1's auc: 0.83836\tvalid_1's binary_logloss: 0.143998\n",
      "[12]\tvalid_0's auc: 0.857381\tvalid_0's binary_logloss: 0.13235\tvalid_1's auc: 0.83849\tvalid_1's binary_logloss: 0.143384\n",
      "[13]\tvalid_0's auc: 0.858555\tvalid_0's binary_logloss: 0.13154\tvalid_1's auc: 0.83788\tvalid_1's binary_logloss: 0.142918\n",
      "[14]\tvalid_0's auc: 0.859092\tvalid_0's binary_logloss: 0.130843\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.142521\n",
      "[15]\tvalid_0's auc: 0.860202\tvalid_0's binary_logloss: 0.130174\tvalid_1's auc: 0.836385\tvalid_1's binary_logloss: 0.142279\n",
      "[16]\tvalid_0's auc: 0.861797\tvalid_0's binary_logloss: 0.129525\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.141987\n",
      "[17]\tvalid_0's auc: 0.863207\tvalid_0's binary_logloss: 0.128978\tvalid_1's auc: 0.835285\tvalid_1's binary_logloss: 0.141713\n",
      "[18]\tvalid_0's auc: 0.864433\tvalid_0's binary_logloss: 0.128402\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.141442\n",
      "[19]\tvalid_0's auc: 0.865245\tvalid_0's binary_logloss: 0.127948\tvalid_1's auc: 0.836123\tvalid_1's binary_logloss: 0.1412\n",
      "[20]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.127497\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.140979\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.12703\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.140825\n",
      "[22]\tvalid_0's auc: 0.86828\tvalid_0's binary_logloss: 0.126598\tvalid_1's auc: 0.836515\tvalid_1's binary_logloss: 0.140741\n",
      "[23]\tvalid_0's auc: 0.869182\tvalid_0's binary_logloss: 0.126269\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.140588\n",
      "[24]\tvalid_0's auc: 0.869979\tvalid_0's binary_logloss: 0.125886\tvalid_1's auc: 0.836766\tvalid_1's binary_logloss: 0.140496\n",
      "[25]\tvalid_0's auc: 0.870956\tvalid_0's binary_logloss: 0.125545\tvalid_1's auc: 0.837001\tvalid_1's binary_logloss: 0.140322\n",
      "[26]\tvalid_0's auc: 0.872886\tvalid_0's binary_logloss: 0.125108\tvalid_1's auc: 0.836911\tvalid_1's binary_logloss: 0.140274\n",
      "[27]\tvalid_0's auc: 0.873971\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.140247\n",
      "[28]\tvalid_0's auc: 0.875129\tvalid_0's binary_logloss: 0.124434\tvalid_1's auc: 0.837012\tvalid_1's binary_logloss: 0.140143\n",
      "[29]\tvalid_0's auc: 0.875873\tvalid_0's binary_logloss: 0.12414\tvalid_1's auc: 0.836866\tvalid_1's binary_logloss: 0.140163\n",
      "[30]\tvalid_0's auc: 0.876465\tvalid_0's binary_logloss: 0.123865\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.140195\n",
      "[31]\tvalid_0's auc: 0.877699\tvalid_0's binary_logloss: 0.123521\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.140186\n",
      "[32]\tvalid_0's auc: 0.878492\tvalid_0's binary_logloss: 0.123253\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.140145\n",
      "[33]\tvalid_0's auc: 0.879281\tvalid_0's binary_logloss: 0.122981\tvalid_1's auc: 0.836061\tvalid_1's binary_logloss: 0.140165\n",
      "[34]\tvalid_0's auc: 0.880016\tvalid_0's binary_logloss: 0.12271\tvalid_1's auc: 0.836238\tvalid_1's binary_logloss: 0.140112\n",
      "[35]\tvalid_0's auc: 0.880929\tvalid_0's binary_logloss: 0.122397\tvalid_1's auc: 0.836618\tvalid_1's binary_logloss: 0.140034\n",
      "[36]\tvalid_0's auc: 0.881746\tvalid_0's binary_logloss: 0.122132\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.140013\n",
      "[37]\tvalid_0's auc: 0.882622\tvalid_0's binary_logloss: 0.121854\tvalid_1's auc: 0.836926\tvalid_1's binary_logloss: 0.139982\n",
      "[38]\tvalid_0's auc: 0.883018\tvalid_0's binary_logloss: 0.121618\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.139968\n",
      "[39]\tvalid_0's auc: 0.883857\tvalid_0's binary_logloss: 0.12136\tvalid_1's auc: 0.837075\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.884437\tvalid_0's binary_logloss: 0.121112\tvalid_1's auc: 0.836834\tvalid_1's binary_logloss: 0.139996\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.85489\tvalid_0's binary_logloss: 0.134153\tvalid_1's auc: 0.839913\tvalid_1's binary_logloss: 0.144571\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.825972\tvalid_0's binary_logloss: 0.15626\tvalid_1's auc: 0.817426\tvalid_1's binary_logloss: 0.165002\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830735\tvalid_0's binary_logloss: 0.150869\tvalid_1's auc: 0.821832\tvalid_1's binary_logloss: 0.159685\n",
      "[3]\tvalid_0's auc: 0.836213\tvalid_0's binary_logloss: 0.147022\tvalid_1's auc: 0.825847\tvalid_1's binary_logloss: 0.156023\n",
      "[4]\tvalid_0's auc: 0.839911\tvalid_0's binary_logloss: 0.143985\tvalid_1's auc: 0.830159\tvalid_1's binary_logloss: 0.153298\n",
      "[5]\tvalid_0's auc: 0.842712\tvalid_0's binary_logloss: 0.14152\tvalid_1's auc: 0.831253\tvalid_1's binary_logloss: 0.151107\n",
      "[6]\tvalid_0's auc: 0.84576\tvalid_0's binary_logloss: 0.139503\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.149167\n",
      "[7]\tvalid_0's auc: 0.84864\tvalid_0's binary_logloss: 0.137792\tvalid_1's auc: 0.836612\tvalid_1's binary_logloss: 0.147629\n",
      "[8]\tvalid_0's auc: 0.850006\tvalid_0's binary_logloss: 0.136329\tvalid_1's auc: 0.837077\tvalid_1's binary_logloss: 0.146348\n",
      "[9]\tvalid_0's auc: 0.852085\tvalid_0's binary_logloss: 0.135086\tvalid_1's auc: 0.838711\tvalid_1's binary_logloss: 0.145304\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[11]\tvalid_0's auc: 0.856458\tvalid_0's binary_logloss: 0.132947\tvalid_1's auc: 0.838948\tvalid_1's binary_logloss: 0.143547\n",
      "[12]\tvalid_0's auc: 0.857299\tvalid_0's binary_logloss: 0.132061\tvalid_1's auc: 0.839046\tvalid_1's binary_logloss: 0.142873\n",
      "[13]\tvalid_0's auc: 0.858451\tvalid_0's binary_logloss: 0.131304\tvalid_1's auc: 0.838455\tvalid_1's binary_logloss: 0.142387\n",
      "[14]\tvalid_0's auc: 0.860294\tvalid_0's binary_logloss: 0.130565\tvalid_1's auc: 0.838925\tvalid_1's binary_logloss: 0.141904\n",
      "[15]\tvalid_0's auc: 0.861473\tvalid_0's binary_logloss: 0.129923\tvalid_1's auc: 0.838733\tvalid_1's binary_logloss: 0.141518\n",
      "[16]\tvalid_0's auc: 0.862203\tvalid_0's binary_logloss: 0.129333\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.141178\n",
      "[17]\tvalid_0's auc: 0.863233\tvalid_0's binary_logloss: 0.128766\tvalid_1's auc: 0.838823\tvalid_1's binary_logloss: 0.140886\n",
      "[18]\tvalid_0's auc: 0.86399\tvalid_0's binary_logloss: 0.128208\tvalid_1's auc: 0.838336\tvalid_1's binary_logloss: 0.140669\n",
      "[19]\tvalid_0's auc: 0.864707\tvalid_0's binary_logloss: 0.127724\tvalid_1's auc: 0.83783\tvalid_1's binary_logloss: 0.140495\n",
      "[20]\tvalid_0's auc: 0.865576\tvalid_0's binary_logloss: 0.127256\tvalid_1's auc: 0.838481\tvalid_1's binary_logloss: 0.140248\n",
      "[21]\tvalid_0's auc: 0.866846\tvalid_0's binary_logloss: 0.126797\tvalid_1's auc: 0.838182\tvalid_1's binary_logloss: 0.140129\n",
      "[22]\tvalid_0's auc: 0.86837\tvalid_0's binary_logloss: 0.126354\tvalid_1's auc: 0.838279\tvalid_1's binary_logloss: 0.139978\n",
      "[23]\tvalid_0's auc: 0.869587\tvalid_0's binary_logloss: 0.125905\tvalid_1's auc: 0.83825\tvalid_1's binary_logloss: 0.139909\n",
      "[24]\tvalid_0's auc: 0.870532\tvalid_0's binary_logloss: 0.125527\tvalid_1's auc: 0.838429\tvalid_1's binary_logloss: 0.139818\n",
      "[25]\tvalid_0's auc: 0.871628\tvalid_0's binary_logloss: 0.125118\tvalid_1's auc: 0.837908\tvalid_1's binary_logloss: 0.139768\n",
      "[26]\tvalid_0's auc: 0.872816\tvalid_0's binary_logloss: 0.12478\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139683\n",
      "[27]\tvalid_0's auc: 0.873647\tvalid_0's binary_logloss: 0.124448\tvalid_1's auc: 0.837808\tvalid_1's binary_logloss: 0.139669\n",
      "[28]\tvalid_0's auc: 0.874326\tvalid_0's binary_logloss: 0.124117\tvalid_1's auc: 0.837756\tvalid_1's binary_logloss: 0.139635\n",
      "[29]\tvalid_0's auc: 0.875069\tvalid_0's binary_logloss: 0.123826\tvalid_1's auc: 0.838037\tvalid_1's binary_logloss: 0.139565\n",
      "[30]\tvalid_0's auc: 0.876092\tvalid_0's binary_logloss: 0.123541\tvalid_1's auc: 0.838013\tvalid_1's binary_logloss: 0.139571\n",
      "[31]\tvalid_0's auc: 0.877253\tvalid_0's binary_logloss: 0.123222\tvalid_1's auc: 0.838176\tvalid_1's binary_logloss: 0.139525\n",
      "[32]\tvalid_0's auc: 0.877859\tvalid_0's binary_logloss: 0.122952\tvalid_1's auc: 0.837999\tvalid_1's binary_logloss: 0.139539\n",
      "[33]\tvalid_0's auc: 0.878881\tvalid_0's binary_logloss: 0.122669\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139429\n",
      "[34]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.122378\tvalid_1's auc: 0.838388\tvalid_1's binary_logloss: 0.139425\n",
      "[35]\tvalid_0's auc: 0.880711\tvalid_0's binary_logloss: 0.122133\tvalid_1's auc: 0.838795\tvalid_1's binary_logloss: 0.139306\n",
      "[36]\tvalid_0's auc: 0.881763\tvalid_0's binary_logloss: 0.12187\tvalid_1's auc: 0.83878\tvalid_1's binary_logloss: 0.139315\n",
      "[37]\tvalid_0's auc: 0.882612\tvalid_0's binary_logloss: 0.121565\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139322\n",
      "[38]\tvalid_0's auc: 0.883169\tvalid_0's binary_logloss: 0.121312\tvalid_1's auc: 0.838615\tvalid_1's binary_logloss: 0.139324\n",
      "[39]\tvalid_0's auc: 0.883934\tvalid_0's binary_logloss: 0.12102\tvalid_1's auc: 0.838763\tvalid_1's binary_logloss: 0.139293\n",
      "[40]\tvalid_0's auc: 0.884499\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.838547\tvalid_1's binary_logloss: 0.13931\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854171\tvalid_0's binary_logloss: 0.133973\tvalid_1's auc: 0.8397\tvalid_1's binary_logloss: 0.144311\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823084\tvalid_0's binary_logloss: 0.156066\tvalid_1's auc: 0.821793\tvalid_1's binary_logloss: 0.164822\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.827813\tvalid_0's binary_logloss: 0.150805\tvalid_1's auc: 0.823891\tvalid_1's binary_logloss: 0.159732\n",
      "[3]\tvalid_0's auc: 0.836023\tvalid_0's binary_logloss: 0.147035\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.156124\n",
      "[4]\tvalid_0's auc: 0.842374\tvalid_0's binary_logloss: 0.143993\tvalid_1's auc: 0.832801\tvalid_1's binary_logloss: 0.153225\n",
      "[5]\tvalid_0's auc: 0.845121\tvalid_0's binary_logloss: 0.141663\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.15098\n",
      "[6]\tvalid_0's auc: 0.846404\tvalid_0's binary_logloss: 0.139689\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.14912\n",
      "[7]\tvalid_0's auc: 0.848157\tvalid_0's binary_logloss: 0.137973\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.147706\n",
      "[8]\tvalid_0's auc: 0.84954\tvalid_0's binary_logloss: 0.136555\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.146499\n",
      "[9]\tvalid_0's auc: 0.851438\tvalid_0's binary_logloss: 0.135283\tvalid_1's auc: 0.838446\tvalid_1's binary_logloss: 0.145447\n",
      "[10]\tvalid_0's auc: 0.853323\tvalid_0's binary_logloss: 0.134172\tvalid_1's auc: 0.838164\tvalid_1's binary_logloss: 0.144649\n",
      "[11]\tvalid_0's auc: 0.85454\tvalid_0's binary_logloss: 0.133213\tvalid_1's auc: 0.838387\tvalid_1's binary_logloss: 0.143878\n",
      "[12]\tvalid_0's auc: 0.856731\tvalid_0's binary_logloss: 0.1323\tvalid_1's auc: 0.83958\tvalid_1's binary_logloss: 0.143232\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[14]\tvalid_0's auc: 0.859616\tvalid_0's binary_logloss: 0.130695\tvalid_1's auc: 0.839638\tvalid_1's binary_logloss: 0.142197\n",
      "[15]\tvalid_0's auc: 0.86065\tvalid_0's binary_logloss: 0.130019\tvalid_1's auc: 0.839342\tvalid_1's binary_logloss: 0.141867\n",
      "[16]\tvalid_0's auc: 0.861879\tvalid_0's binary_logloss: 0.129426\tvalid_1's auc: 0.839474\tvalid_1's binary_logloss: 0.141484\n",
      "[17]\tvalid_0's auc: 0.86312\tvalid_0's binary_logloss: 0.128865\tvalid_1's auc: 0.838976\tvalid_1's binary_logloss: 0.141297\n",
      "[18]\tvalid_0's auc: 0.864292\tvalid_0's binary_logloss: 0.128302\tvalid_1's auc: 0.839738\tvalid_1's binary_logloss: 0.140953\n",
      "[19]\tvalid_0's auc: 0.86562\tvalid_0's binary_logloss: 0.12782\tvalid_1's auc: 0.839799\tvalid_1's binary_logloss: 0.140766\n",
      "[20]\tvalid_0's auc: 0.866802\tvalid_0's binary_logloss: 0.127322\tvalid_1's auc: 0.839807\tvalid_1's binary_logloss: 0.140536\n",
      "[21]\tvalid_0's auc: 0.868305\tvalid_0's binary_logloss: 0.126848\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.140335\n",
      "[22]\tvalid_0's auc: 0.869367\tvalid_0's binary_logloss: 0.126428\tvalid_1's auc: 0.839045\tvalid_1's binary_logloss: 0.140242\n",
      "[23]\tvalid_0's auc: 0.870018\tvalid_0's binary_logloss: 0.126051\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.140113\n",
      "[24]\tvalid_0's auc: 0.871076\tvalid_0's binary_logloss: 0.125665\tvalid_1's auc: 0.838918\tvalid_1's binary_logloss: 0.139963\n",
      "[25]\tvalid_0's auc: 0.871808\tvalid_0's binary_logloss: 0.12529\tvalid_1's auc: 0.838876\tvalid_1's binary_logloss: 0.139886\n",
      "[26]\tvalid_0's auc: 0.872679\tvalid_0's binary_logloss: 0.124953\tvalid_1's auc: 0.838853\tvalid_1's binary_logloss: 0.139811\n",
      "[27]\tvalid_0's auc: 0.873565\tvalid_0's binary_logloss: 0.124623\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.139786\n",
      "[28]\tvalid_0's auc: 0.874397\tvalid_0's binary_logloss: 0.124307\tvalid_1's auc: 0.83805\tvalid_1's binary_logloss: 0.139815\n",
      "[29]\tvalid_0's auc: 0.87544\tvalid_0's binary_logloss: 0.124018\tvalid_1's auc: 0.837719\tvalid_1's binary_logloss: 0.139819\n",
      "[30]\tvalid_0's auc: 0.876222\tvalid_0's binary_logloss: 0.123733\tvalid_1's auc: 0.838003\tvalid_1's binary_logloss: 0.139778\n",
      "[31]\tvalid_0's auc: 0.877142\tvalid_0's binary_logloss: 0.12348\tvalid_1's auc: 0.838078\tvalid_1's binary_logloss: 0.139735\n",
      "[32]\tvalid_0's auc: 0.877956\tvalid_0's binary_logloss: 0.123203\tvalid_1's auc: 0.838002\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878477\tvalid_0's binary_logloss: 0.122964\tvalid_1's auc: 0.838203\tvalid_1's binary_logloss: 0.139665\n",
      "[34]\tvalid_0's auc: 0.879048\tvalid_0's binary_logloss: 0.122668\tvalid_1's auc: 0.838296\tvalid_1's binary_logloss: 0.139589\n",
      "[35]\tvalid_0's auc: 0.879723\tvalid_0's binary_logloss: 0.122403\tvalid_1's auc: 0.838433\tvalid_1's binary_logloss: 0.139597\n",
      "[36]\tvalid_0's auc: 0.881202\tvalid_0's binary_logloss: 0.122123\tvalid_1's auc: 0.838596\tvalid_1's binary_logloss: 0.139557\n",
      "[37]\tvalid_0's auc: 0.882142\tvalid_0's binary_logloss: 0.121861\tvalid_1's auc: 0.838424\tvalid_1's binary_logloss: 0.139578\n",
      "[38]\tvalid_0's auc: 0.882706\tvalid_0's binary_logloss: 0.121634\tvalid_1's auc: 0.838625\tvalid_1's binary_logloss: 0.139548\n",
      "[39]\tvalid_0's auc: 0.883054\tvalid_0's binary_logloss: 0.121421\tvalid_1's auc: 0.838452\tvalid_1's binary_logloss: 0.139609\n",
      "[40]\tvalid_0's auc: 0.883797\tvalid_0's binary_logloss: 0.121128\tvalid_1's auc: 0.838612\tvalid_1's binary_logloss: 0.139576\n",
      "[41]\tvalid_0's auc: 0.884595\tvalid_0's binary_logloss: 0.120862\tvalid_1's auc: 0.838672\tvalid_1's binary_logloss: 0.139551\n",
      "[42]\tvalid_0's auc: 0.885101\tvalid_0's binary_logloss: 0.120643\tvalid_1's auc: 0.839085\tvalid_1's binary_logloss: 0.139462\n",
      "[43]\tvalid_0's auc: 0.885377\tvalid_0's binary_logloss: 0.120471\tvalid_1's auc: 0.838989\tvalid_1's binary_logloss: 0.13949\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.85773\tvalid_0's binary_logloss: 0.131445\tvalid_1's auc: 0.840016\tvalid_1's binary_logloss: 0.142644\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823422\tvalid_0's binary_logloss: 0.156446\tvalid_1's auc: 0.819043\tvalid_1's binary_logloss: 0.165337\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830391\tvalid_0's binary_logloss: 0.151103\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.160151\n",
      "[3]\tvalid_0's auc: 0.836251\tvalid_0's binary_logloss: 0.14724\tvalid_1's auc: 0.829717\tvalid_1's binary_logloss: 0.156452\n",
      "[4]\tvalid_0's auc: 0.842516\tvalid_0's binary_logloss: 0.144162\tvalid_1's auc: 0.832695\tvalid_1's binary_logloss: 0.15358\n",
      "[5]\tvalid_0's auc: 0.846316\tvalid_0's binary_logloss: 0.141636\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.151246\n",
      "[6]\tvalid_0's auc: 0.847998\tvalid_0's binary_logloss: 0.139517\tvalid_1's auc: 0.836546\tvalid_1's binary_logloss: 0.149374\n",
      "[7]\tvalid_0's auc: 0.849074\tvalid_0's binary_logloss: 0.13782\tvalid_1's auc: 0.838333\tvalid_1's binary_logloss: 0.147794\n",
      "[8]\tvalid_0's auc: 0.85\tvalid_0's binary_logloss: 0.136391\tvalid_1's auc: 0.838986\tvalid_1's binary_logloss: 0.146497\n",
      "[9]\tvalid_0's auc: 0.851546\tvalid_0's binary_logloss: 0.135138\tvalid_1's auc: 0.839435\tvalid_1's binary_logloss: 0.145445\n",
      "[10]\tvalid_0's auc: 0.852573\tvalid_0's binary_logloss: 0.134059\tvalid_1's auc: 0.839729\tvalid_1's binary_logloss: 0.144614\n",
      "[11]\tvalid_0's auc: 0.854408\tvalid_0's binary_logloss: 0.133048\tvalid_1's auc: 0.840015\tvalid_1's binary_logloss: 0.143842\n",
      "[12]\tvalid_0's auc: 0.857486\tvalid_0's binary_logloss: 0.132117\tvalid_1's auc: 0.83955\tvalid_1's binary_logloss: 0.143278\n",
      "[13]\tvalid_0's auc: 0.859425\tvalid_0's binary_logloss: 0.131314\tvalid_1's auc: 0.840426\tvalid_1's binary_logloss: 0.142719\n",
      "[14]\tvalid_0's auc: 0.861454\tvalid_0's binary_logloss: 0.130495\tvalid_1's auc: 0.840751\tvalid_1's binary_logloss: 0.14226\n",
      "[15]\tvalid_0's auc: 0.862973\tvalid_0's binary_logloss: 0.12978\tvalid_1's auc: 0.840328\tvalid_1's binary_logloss: 0.14183\n",
      "[16]\tvalid_0's auc: 0.864608\tvalid_0's binary_logloss: 0.129092\tvalid_1's auc: 0.839958\tvalid_1's binary_logloss: 0.14153\n",
      "[17]\tvalid_0's auc: 0.865394\tvalid_0's binary_logloss: 0.128538\tvalid_1's auc: 0.840045\tvalid_1's binary_logloss: 0.141215\n",
      "[18]\tvalid_0's auc: 0.867204\tvalid_0's binary_logloss: 0.127947\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.1409\n",
      "[19]\tvalid_0's auc: 0.868095\tvalid_0's binary_logloss: 0.127461\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.14074\n",
      "[20]\tvalid_0's auc: 0.86902\tvalid_0's binary_logloss: 0.126956\tvalid_1's auc: 0.840596\tvalid_1's binary_logloss: 0.140606\n",
      "[21]\tvalid_0's auc: 0.869954\tvalid_0's binary_logloss: 0.126491\tvalid_1's auc: 0.840559\tvalid_1's binary_logloss: 0.140425\n",
      "[22]\tvalid_0's auc: 0.870971\tvalid_0's binary_logloss: 0.126075\tvalid_1's auc: 0.840789\tvalid_1's binary_logloss: 0.140251\n",
      "[23]\tvalid_0's auc: 0.872384\tvalid_0's binary_logloss: 0.125599\tvalid_1's auc: 0.840267\tvalid_1's binary_logloss: 0.14022\n",
      "[24]\tvalid_0's auc: 0.873433\tvalid_0's binary_logloss: 0.125215\tvalid_1's auc: 0.840763\tvalid_1's binary_logloss: 0.140023\n",
      "[25]\tvalid_0's auc: 0.874094\tvalid_0's binary_logloss: 0.124834\tvalid_1's auc: 0.840782\tvalid_1's binary_logloss: 0.139927\n",
      "[26]\tvalid_0's auc: 0.875299\tvalid_0's binary_logloss: 0.12446\tvalid_1's auc: 0.840852\tvalid_1's binary_logloss: 0.139864\n",
      "[27]\tvalid_0's auc: 0.875863\tvalid_0's binary_logloss: 0.124178\tvalid_1's auc: 0.840905\tvalid_1's binary_logloss: 0.139751\n",
      "[28]\tvalid_0's auc: 0.876477\tvalid_0's binary_logloss: 0.123899\tvalid_1's auc: 0.840828\tvalid_1's binary_logloss: 0.139688\n",
      "[29]\tvalid_0's auc: 0.877436\tvalid_0's binary_logloss: 0.123585\tvalid_1's auc: 0.840653\tvalid_1's binary_logloss: 0.139596\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[31]\tvalid_0's auc: 0.879246\tvalid_0's binary_logloss: 0.122979\tvalid_1's auc: 0.840819\tvalid_1's binary_logloss: 0.139442\n",
      "[32]\tvalid_0's auc: 0.880496\tvalid_0's binary_logloss: 0.122664\tvalid_1's auc: 0.840531\tvalid_1's binary_logloss: 0.139452\n",
      "[33]\tvalid_0's auc: 0.881439\tvalid_0's binary_logloss: 0.122371\tvalid_1's auc: 0.840279\tvalid_1's binary_logloss: 0.139455\n",
      "[34]\tvalid_0's auc: 0.882347\tvalid_0's binary_logloss: 0.122119\tvalid_1's auc: 0.840374\tvalid_1's binary_logloss: 0.139423\n",
      "[35]\tvalid_0's auc: 0.883154\tvalid_0's binary_logloss: 0.121847\tvalid_1's auc: 0.840528\tvalid_1's binary_logloss: 0.139369\n",
      "[36]\tvalid_0's auc: 0.883941\tvalid_0's binary_logloss: 0.121532\tvalid_1's auc: 0.840858\tvalid_1's binary_logloss: 0.139284\n",
      "[37]\tvalid_0's auc: 0.884407\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.840641\tvalid_1's binary_logloss: 0.139325\n",
      "[38]\tvalid_0's auc: 0.885324\tvalid_0's binary_logloss: 0.121016\tvalid_1's auc: 0.840498\tvalid_1's binary_logloss: 0.13934\n",
      "[39]\tvalid_0's auc: 0.885824\tvalid_0's binary_logloss: 0.120794\tvalid_1's auc: 0.840244\tvalid_1's binary_logloss: 0.139346\n",
      "[40]\tvalid_0's auc: 0.886492\tvalid_0's binary_logloss: 0.120515\tvalid_1's auc: 0.84003\tvalid_1's binary_logloss: 0.139395\n",
      "[41]\tvalid_0's auc: 0.887212\tvalid_0's binary_logloss: 0.120235\tvalid_1's auc: 0.839933\tvalid_1's binary_logloss: 0.139397\n",
      "[42]\tvalid_0's auc: 0.887679\tvalid_0's binary_logloss: 0.120004\tvalid_1's auc: 0.839795\tvalid_1's binary_logloss: 0.139391\n",
      "[43]\tvalid_0's auc: 0.88855\tvalid_0's binary_logloss: 0.119787\tvalid_1's auc: 0.839567\tvalid_1's binary_logloss: 0.139426\n",
      "[44]\tvalid_0's auc: 0.888918\tvalid_0's binary_logloss: 0.119598\tvalid_1's auc: 0.839591\tvalid_1's binary_logloss: 0.139427\n",
      "[45]\tvalid_0's auc: 0.889615\tvalid_0's binary_logloss: 0.119335\tvalid_1's auc: 0.839609\tvalid_1's binary_logloss: 0.139412\n",
      "[46]\tvalid_0's auc: 0.890166\tvalid_0's binary_logloss: 0.119099\tvalid_1's auc: 0.839346\tvalid_1's binary_logloss: 0.139475\n",
      "[47]\tvalid_0's auc: 0.890678\tvalid_0's binary_logloss: 0.118869\tvalid_1's auc: 0.839761\tvalid_1's binary_logloss: 0.1394\n",
      "[48]\tvalid_0's auc: 0.891058\tvalid_0's binary_logloss: 0.118665\tvalid_1's auc: 0.839755\tvalid_1's binary_logloss: 0.139409\n",
      "[49]\tvalid_0's auc: 0.891635\tvalid_0's binary_logloss: 0.118425\tvalid_1's auc: 0.839754\tvalid_1's binary_logloss: 0.139428\n",
      "[50]\tvalid_0's auc: 0.892346\tvalid_0's binary_logloss: 0.118168\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.139501\n",
      "[51]\tvalid_0's auc: 0.892736\tvalid_0's binary_logloss: 0.117984\tvalid_1's auc: 0.839121\tvalid_1's binary_logloss: 0.139524\n",
      "[52]\tvalid_0's auc: 0.893171\tvalid_0's binary_logloss: 0.117764\tvalid_1's auc: 0.838794\tvalid_1's binary_logloss: 0.139586\n",
      "[53]\tvalid_0's auc: 0.893573\tvalid_0's binary_logloss: 0.117568\tvalid_1's auc: 0.838694\tvalid_1's binary_logloss: 0.139581\n",
      "[54]\tvalid_0's auc: 0.894147\tvalid_0's binary_logloss: 0.117322\tvalid_1's auc: 0.838487\tvalid_1's binary_logloss: 0.139606\n",
      "[55]\tvalid_0's auc: 0.894518\tvalid_0's binary_logloss: 0.117157\tvalid_1's auc: 0.838831\tvalid_1's binary_logloss: 0.139538\n",
      "[56]\tvalid_0's auc: 0.894919\tvalid_0's binary_logloss: 0.116983\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139562\n",
      "[57]\tvalid_0's auc: 0.895096\tvalid_0's binary_logloss: 0.116832\tvalid_1's auc: 0.838982\tvalid_1's binary_logloss: 0.139544\n",
      "[58]\tvalid_0's auc: 0.895448\tvalid_0's binary_logloss: 0.116643\tvalid_1's auc: 0.839062\tvalid_1's binary_logloss: 0.139518\n",
      "[59]\tvalid_0's auc: 0.895699\tvalid_0's binary_logloss: 0.116514\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.139543\n",
      "[60]\tvalid_0's auc: 0.896178\tvalid_0's binary_logloss: 0.116313\tvalid_1's auc: 0.838833\tvalid_1's binary_logloss: 0.1396\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.878569\tvalid_0's binary_logloss: 0.123249\tvalid_1's auc: 0.841045\tvalid_1's binary_logloss: 0.139479\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.832025\tvalid_0's binary_logloss: 0.155465\tvalid_1's auc: 0.820076\tvalid_1's binary_logloss: 0.164546\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.844878\tvalid_0's binary_logloss: 0.14969\tvalid_1's auc: 0.828857\tvalid_1's binary_logloss: 0.159283\n",
      "[3]\tvalid_0's auc: 0.848608\tvalid_0's binary_logloss: 0.145495\tvalid_1's auc: 0.831668\tvalid_1's binary_logloss: 0.155726\n",
      "[4]\tvalid_0's auc: 0.85412\tvalid_0's binary_logloss: 0.142244\tvalid_1's auc: 0.832954\tvalid_1's binary_logloss: 0.153013\n",
      "[5]\tvalid_0's auc: 0.856985\tvalid_0's binary_logloss: 0.139541\tvalid_1's auc: 0.834294\tvalid_1's binary_logloss: 0.150762\n",
      "[6]\tvalid_0's auc: 0.860318\tvalid_0's binary_logloss: 0.137315\tvalid_1's auc: 0.834439\tvalid_1's binary_logloss: 0.148891\n",
      "[7]\tvalid_0's auc: 0.862354\tvalid_0's binary_logloss: 0.135314\tvalid_1's auc: 0.835254\tvalid_1's binary_logloss: 0.147306\n",
      "[8]\tvalid_0's auc: 0.864507\tvalid_0's binary_logloss: 0.133588\tvalid_1's auc: 0.834413\tvalid_1's binary_logloss: 0.146246\n",
      "[9]\tvalid_0's auc: 0.866506\tvalid_0's binary_logloss: 0.132094\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.14517\n",
      "[10]\tvalid_0's auc: 0.867622\tvalid_0's binary_logloss: 0.130807\tvalid_1's auc: 0.835059\tvalid_1's binary_logloss: 0.144333\n",
      "[11]\tvalid_0's auc: 0.869595\tvalid_0's binary_logloss: 0.12963\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.143624\n",
      "[12]\tvalid_0's auc: 0.871732\tvalid_0's binary_logloss: 0.128488\tvalid_1's auc: 0.837004\tvalid_1's binary_logloss: 0.142969\n",
      "[13]\tvalid_0's auc: 0.874689\tvalid_0's binary_logloss: 0.127457\tvalid_1's auc: 0.837217\tvalid_1's binary_logloss: 0.142409\n",
      "[14]\tvalid_0's auc: 0.876111\tvalid_0's binary_logloss: 0.126511\tvalid_1's auc: 0.837232\tvalid_1's binary_logloss: 0.141993\n",
      "[15]\tvalid_0's auc: 0.87877\tvalid_0's binary_logloss: 0.12553\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.141557\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[17]\tvalid_0's auc: 0.881444\tvalid_0's binary_logloss: 0.123911\tvalid_1's auc: 0.836877\tvalid_1's binary_logloss: 0.141158\n",
      "[18]\tvalid_0's auc: 0.882597\tvalid_0's binary_logloss: 0.123216\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.140956\n",
      "[19]\tvalid_0's auc: 0.884069\tvalid_0's binary_logloss: 0.1225\tvalid_1's auc: 0.836798\tvalid_1's binary_logloss: 0.140747\n",
      "[20]\tvalid_0's auc: 0.885553\tvalid_0's binary_logloss: 0.121835\tvalid_1's auc: 0.837335\tvalid_1's binary_logloss: 0.140578\n",
      "[21]\tvalid_0's auc: 0.886758\tvalid_0's binary_logloss: 0.121199\tvalid_1's auc: 0.837053\tvalid_1's binary_logloss: 0.1405\n",
      "[22]\tvalid_0's auc: 0.888245\tvalid_0's binary_logloss: 0.120566\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.140423\n",
      "[23]\tvalid_0's auc: 0.889287\tvalid_0's binary_logloss: 0.119999\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.140319\n",
      "[24]\tvalid_0's auc: 0.890242\tvalid_0's binary_logloss: 0.119535\tvalid_1's auc: 0.837226\tvalid_1's binary_logloss: 0.140192\n",
      "[25]\tvalid_0's auc: 0.89128\tvalid_0's binary_logloss: 0.119025\tvalid_1's auc: 0.836975\tvalid_1's binary_logloss: 0.140152\n",
      "[26]\tvalid_0's auc: 0.892936\tvalid_0's binary_logloss: 0.118515\tvalid_1's auc: 0.836466\tvalid_1's binary_logloss: 0.14011\n",
      "[27]\tvalid_0's auc: 0.894014\tvalid_0's binary_logloss: 0.118046\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140163\n",
      "[28]\tvalid_0's auc: 0.895806\tvalid_0's binary_logloss: 0.1175\tvalid_1's auc: 0.835987\tvalid_1's binary_logloss: 0.1401\n",
      "[29]\tvalid_0's auc: 0.896704\tvalid_0's binary_logloss: 0.117069\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140035\n",
      "[30]\tvalid_0's auc: 0.897739\tvalid_0's binary_logloss: 0.116577\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.139877\n",
      "[31]\tvalid_0's auc: 0.898365\tvalid_0's binary_logloss: 0.116187\tvalid_1's auc: 0.836258\tvalid_1's binary_logloss: 0.139893\n",
      "[32]\tvalid_0's auc: 0.899428\tvalid_0's binary_logloss: 0.115755\tvalid_1's auc: 0.836228\tvalid_1's binary_logloss: 0.139825\n",
      "[33]\tvalid_0's auc: 0.900129\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836132\tvalid_1's binary_logloss: 0.139815\n",
      "[34]\tvalid_0's auc: 0.900819\tvalid_0's binary_logloss: 0.115047\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.139786\n",
      "[35]\tvalid_0's auc: 0.901929\tvalid_0's binary_logloss: 0.114682\tvalid_1's auc: 0.836241\tvalid_1's binary_logloss: 0.139758\n",
      "[36]\tvalid_0's auc: 0.902923\tvalid_0's binary_logloss: 0.114287\tvalid_1's auc: 0.836594\tvalid_1's binary_logloss: 0.139739\n",
      "[37]\tvalid_0's auc: 0.903583\tvalid_0's binary_logloss: 0.113893\tvalid_1's auc: 0.836319\tvalid_1's binary_logloss: 0.139831\n",
      "[38]\tvalid_0's auc: 0.904289\tvalid_0's binary_logloss: 0.113536\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.139874\n",
      "[39]\tvalid_0's auc: 0.904948\tvalid_0's binary_logloss: 0.113207\tvalid_1's auc: 0.835797\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.905808\tvalid_0's binary_logloss: 0.112811\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.139967\n",
      "[41]\tvalid_0's auc: 0.906507\tvalid_0's binary_logloss: 0.112548\tvalid_1's auc: 0.835793\tvalid_1's binary_logloss: 0.139996\n",
      "[42]\tvalid_0's auc: 0.907263\tvalid_0's binary_logloss: 0.112199\tvalid_1's auc: 0.835583\tvalid_1's binary_logloss: 0.140069\n",
      "[43]\tvalid_0's auc: 0.907622\tvalid_0's binary_logloss: 0.111883\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.140122\n",
      "[44]\tvalid_0's auc: 0.908342\tvalid_0's binary_logloss: 0.111608\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.140227\n",
      "[45]\tvalid_0's auc: 0.908935\tvalid_0's binary_logloss: 0.111287\tvalid_1's auc: 0.834854\tvalid_1's binary_logloss: 0.140271\n",
      "[46]\tvalid_0's auc: 0.910346\tvalid_0's binary_logloss: 0.110886\tvalid_1's auc: 0.834699\tvalid_1's binary_logloss: 0.140295\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.832082\tvalid_0's binary_logloss: 0.155469\tvalid_1's auc: 0.814834\tvalid_1's binary_logloss: 0.164811\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840358\tvalid_0's binary_logloss: 0.149705\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.159739\n",
      "[3]\tvalid_0's auc: 0.846958\tvalid_0's binary_logloss: 0.145462\tvalid_1's auc: 0.829037\tvalid_1's binary_logloss: 0.155963\n",
      "[4]\tvalid_0's auc: 0.850608\tvalid_0's binary_logloss: 0.142192\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.153305\n",
      "[5]\tvalid_0's auc: 0.857054\tvalid_0's binary_logloss: 0.139496\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.150999\n",
      "[6]\tvalid_0's auc: 0.860917\tvalid_0's binary_logloss: 0.137183\tvalid_1's auc: 0.837251\tvalid_1's binary_logloss: 0.149102\n",
      "[7]\tvalid_0's auc: 0.862765\tvalid_0's binary_logloss: 0.135234\tvalid_1's auc: 0.838397\tvalid_1's binary_logloss: 0.14754\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[9]\tvalid_0's auc: 0.866709\tvalid_0's binary_logloss: 0.132066\tvalid_1's auc: 0.838734\tvalid_1's binary_logloss: 0.145324\n",
      "[10]\tvalid_0's auc: 0.868899\tvalid_0's binary_logloss: 0.130682\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.144425\n",
      "[11]\tvalid_0's auc: 0.87095\tvalid_0's binary_logloss: 0.129509\tvalid_1's auc: 0.837304\tvalid_1's binary_logloss: 0.143844\n",
      "[12]\tvalid_0's auc: 0.872258\tvalid_0's binary_logloss: 0.128409\tvalid_1's auc: 0.83669\tvalid_1's binary_logloss: 0.143316\n",
      "[13]\tvalid_0's auc: 0.874037\tvalid_0's binary_logloss: 0.127397\tvalid_1's auc: 0.835346\tvalid_1's binary_logloss: 0.142981\n",
      "[14]\tvalid_0's auc: 0.875949\tvalid_0's binary_logloss: 0.126455\tvalid_1's auc: 0.835276\tvalid_1's binary_logloss: 0.142607\n",
      "[15]\tvalid_0's auc: 0.877382\tvalid_0's binary_logloss: 0.125645\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.142362\n",
      "[16]\tvalid_0's auc: 0.878987\tvalid_0's binary_logloss: 0.124805\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.142102\n",
      "[17]\tvalid_0's auc: 0.880532\tvalid_0's binary_logloss: 0.124054\tvalid_1's auc: 0.833893\tvalid_1's binary_logloss: 0.141884\n",
      "[18]\tvalid_0's auc: 0.882045\tvalid_0's binary_logloss: 0.123344\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.141697\n",
      "[19]\tvalid_0's auc: 0.883566\tvalid_0's binary_logloss: 0.122594\tvalid_1's auc: 0.832707\tvalid_1's binary_logloss: 0.141615\n",
      "[20]\tvalid_0's auc: 0.885585\tvalid_0's binary_logloss: 0.121869\tvalid_1's auc: 0.833151\tvalid_1's binary_logloss: 0.141426\n",
      "[21]\tvalid_0's auc: 0.887553\tvalid_0's binary_logloss: 0.121164\tvalid_1's auc: 0.834052\tvalid_1's binary_logloss: 0.141225\n",
      "[22]\tvalid_0's auc: 0.88866\tvalid_0's binary_logloss: 0.120577\tvalid_1's auc: 0.834098\tvalid_1's binary_logloss: 0.141029\n",
      "[23]\tvalid_0's auc: 0.889845\tvalid_0's binary_logloss: 0.11997\tvalid_1's auc: 0.833894\tvalid_1's binary_logloss: 0.140951\n",
      "[24]\tvalid_0's auc: 0.890796\tvalid_0's binary_logloss: 0.119485\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.140844\n",
      "[25]\tvalid_0's auc: 0.89199\tvalid_0's binary_logloss: 0.118928\tvalid_1's auc: 0.833906\tvalid_1's binary_logloss: 0.140917\n",
      "[26]\tvalid_0's auc: 0.893398\tvalid_0's binary_logloss: 0.118364\tvalid_1's auc: 0.834288\tvalid_1's binary_logloss: 0.140784\n",
      "[27]\tvalid_0's auc: 0.894509\tvalid_0's binary_logloss: 0.117887\tvalid_1's auc: 0.834364\tvalid_1's binary_logloss: 0.140677\n",
      "[28]\tvalid_0's auc: 0.895524\tvalid_0's binary_logloss: 0.117424\tvalid_1's auc: 0.834009\tvalid_1's binary_logloss: 0.140715\n",
      "[29]\tvalid_0's auc: 0.896654\tvalid_0's binary_logloss: 0.116949\tvalid_1's auc: 0.833704\tvalid_1's binary_logloss: 0.140719\n",
      "[30]\tvalid_0's auc: 0.897948\tvalid_0's binary_logloss: 0.116488\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140635\n",
      "[31]\tvalid_0's auc: 0.898781\tvalid_0's binary_logloss: 0.116069\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140671\n",
      "[32]\tvalid_0's auc: 0.90009\tvalid_0's binary_logloss: 0.115625\tvalid_1's auc: 0.83384\tvalid_1's binary_logloss: 0.140667\n",
      "[33]\tvalid_0's auc: 0.901073\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.833911\tvalid_1's binary_logloss: 0.140619\n",
      "[34]\tvalid_0's auc: 0.902228\tvalid_0's binary_logloss: 0.114803\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.140595\n",
      "[35]\tvalid_0's auc: 0.902949\tvalid_0's binary_logloss: 0.114411\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.140641\n",
      "[36]\tvalid_0's auc: 0.90428\tvalid_0's binary_logloss: 0.114027\tvalid_1's auc: 0.833146\tvalid_1's binary_logloss: 0.140714\n",
      "[37]\tvalid_0's auc: 0.90518\tvalid_0's binary_logloss: 0.113632\tvalid_1's auc: 0.833423\tvalid_1's binary_logloss: 0.140663\n",
      "[38]\tvalid_0's auc: 0.905995\tvalid_0's binary_logloss: 0.113243\tvalid_1's auc: 0.83347\tvalid_1's binary_logloss: 0.140755\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833919\tvalid_0's binary_logloss: 0.155512\tvalid_1's auc: 0.820637\tvalid_1's binary_logloss: 0.164643\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842002\tvalid_0's binary_logloss: 0.149635\tvalid_1's auc: 0.827273\tvalid_1's binary_logloss: 0.15926\n",
      "[3]\tvalid_0's auc: 0.844839\tvalid_0's binary_logloss: 0.145363\tvalid_1's auc: 0.829328\tvalid_1's binary_logloss: 0.155446\n",
      "[4]\tvalid_0's auc: 0.851547\tvalid_0's binary_logloss: 0.142092\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.152516\n",
      "[5]\tvalid_0's auc: 0.85629\tvalid_0's binary_logloss: 0.139314\tvalid_1's auc: 0.837608\tvalid_1's binary_logloss: 0.150218\n",
      "[6]\tvalid_0's auc: 0.860698\tvalid_0's binary_logloss: 0.137026\tvalid_1's auc: 0.837977\tvalid_1's binary_logloss: 0.148376\n",
      "[7]\tvalid_0's auc: 0.863515\tvalid_0's binary_logloss: 0.135113\tvalid_1's auc: 0.838443\tvalid_1's binary_logloss: 0.146922\n",
      "[8]\tvalid_0's auc: 0.864625\tvalid_0's binary_logloss: 0.133401\tvalid_1's auc: 0.838988\tvalid_1's binary_logloss: 0.145624\n",
      "[9]\tvalid_0's auc: 0.866831\tvalid_0's binary_logloss: 0.131907\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.14464\n",
      "[10]\tvalid_0's auc: 0.868953\tvalid_0's binary_logloss: 0.130539\tvalid_1's auc: 0.83779\tvalid_1's binary_logloss: 0.143795\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[12]\tvalid_0's auc: 0.872964\tvalid_0's binary_logloss: 0.128158\tvalid_1's auc: 0.838184\tvalid_1's binary_logloss: 0.142277\n",
      "[13]\tvalid_0's auc: 0.874758\tvalid_0's binary_logloss: 0.127141\tvalid_1's auc: 0.837972\tvalid_1's binary_logloss: 0.141744\n",
      "[14]\tvalid_0's auc: 0.876311\tvalid_0's binary_logloss: 0.126137\tvalid_1's auc: 0.837484\tvalid_1's binary_logloss: 0.141408\n",
      "[15]\tvalid_0's auc: 0.877968\tvalid_0's binary_logloss: 0.12525\tvalid_1's auc: 0.836581\tvalid_1's binary_logloss: 0.141099\n",
      "[16]\tvalid_0's auc: 0.87963\tvalid_0's binary_logloss: 0.124439\tvalid_1's auc: 0.836006\tvalid_1's binary_logloss: 0.140886\n",
      "[17]\tvalid_0's auc: 0.881659\tvalid_0's binary_logloss: 0.123628\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.140605\n",
      "[18]\tvalid_0's auc: 0.882607\tvalid_0's binary_logloss: 0.122935\tvalid_1's auc: 0.836156\tvalid_1's binary_logloss: 0.140354\n",
      "[19]\tvalid_0's auc: 0.884204\tvalid_0's binary_logloss: 0.122205\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.140094\n",
      "[20]\tvalid_0's auc: 0.88564\tvalid_0's binary_logloss: 0.121562\tvalid_1's auc: 0.836976\tvalid_1's binary_logloss: 0.139982\n",
      "[21]\tvalid_0's auc: 0.886788\tvalid_0's binary_logloss: 0.120948\tvalid_1's auc: 0.83734\tvalid_1's binary_logloss: 0.139793\n",
      "[22]\tvalid_0's auc: 0.888424\tvalid_0's binary_logloss: 0.120314\tvalid_1's auc: 0.83802\tvalid_1's binary_logloss: 0.139623\n",
      "[23]\tvalid_0's auc: 0.889756\tvalid_0's binary_logloss: 0.119797\tvalid_1's auc: 0.837015\tvalid_1's binary_logloss: 0.139653\n",
      "[24]\tvalid_0's auc: 0.891304\tvalid_0's binary_logloss: 0.119202\tvalid_1's auc: 0.837202\tvalid_1's binary_logloss: 0.139584\n",
      "[25]\tvalid_0's auc: 0.892545\tvalid_0's binary_logloss: 0.118664\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.1395\n",
      "[26]\tvalid_0's auc: 0.893944\tvalid_0's binary_logloss: 0.118169\tvalid_1's auc: 0.837371\tvalid_1's binary_logloss: 0.139458\n",
      "[27]\tvalid_0's auc: 0.894982\tvalid_0's binary_logloss: 0.117651\tvalid_1's auc: 0.836907\tvalid_1's binary_logloss: 0.139528\n",
      "[28]\tvalid_0's auc: 0.896304\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837127\tvalid_1's binary_logloss: 0.139491\n",
      "[29]\tvalid_0's auc: 0.89754\tvalid_0's binary_logloss: 0.116665\tvalid_1's auc: 0.837063\tvalid_1's binary_logloss: 0.139497\n",
      "[30]\tvalid_0's auc: 0.898907\tvalid_0's binary_logloss: 0.116238\tvalid_1's auc: 0.836952\tvalid_1's binary_logloss: 0.139457\n",
      "[31]\tvalid_0's auc: 0.89958\tvalid_0's binary_logloss: 0.115802\tvalid_1's auc: 0.837327\tvalid_1's binary_logloss: 0.139384\n",
      "[32]\tvalid_0's auc: 0.900529\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836541\tvalid_1's binary_logloss: 0.139496\n",
      "[33]\tvalid_0's auc: 0.90188\tvalid_0's binary_logloss: 0.114972\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.139413\n",
      "[34]\tvalid_0's auc: 0.902879\tvalid_0's binary_logloss: 0.114528\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.13943\n",
      "[35]\tvalid_0's auc: 0.903932\tvalid_0's binary_logloss: 0.114157\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.139458\n",
      "[36]\tvalid_0's auc: 0.904707\tvalid_0's binary_logloss: 0.113777\tvalid_1's auc: 0.836824\tvalid_1's binary_logloss: 0.139459\n",
      "[37]\tvalid_0's auc: 0.905376\tvalid_0's binary_logloss: 0.113446\tvalid_1's auc: 0.836614\tvalid_1's binary_logloss: 0.139503\n",
      "[38]\tvalid_0's auc: 0.906535\tvalid_0's binary_logloss: 0.11295\tvalid_1's auc: 0.836328\tvalid_1's binary_logloss: 0.139575\n",
      "[39]\tvalid_0's auc: 0.907125\tvalid_0's binary_logloss: 0.112599\tvalid_1's auc: 0.83631\tvalid_1's binary_logloss: 0.139598\n",
      "[40]\tvalid_0's auc: 0.908267\tvalid_0's binary_logloss: 0.112224\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.139675\n",
      "[41]\tvalid_0's auc: 0.908916\tvalid_0's binary_logloss: 0.111848\tvalid_1's auc: 0.835954\tvalid_1's binary_logloss: 0.139752\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.830163\tvalid_0's binary_logloss: 0.155383\tvalid_1's auc: 0.817444\tvalid_1's binary_logloss: 0.164924\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840688\tvalid_0's binary_logloss: 0.14972\tvalid_1's auc: 0.825893\tvalid_1's binary_logloss: 0.159538\n",
      "[3]\tvalid_0's auc: 0.847811\tvalid_0's binary_logloss: 0.145576\tvalid_1's auc: 0.832086\tvalid_1's binary_logloss: 0.155889\n",
      "[4]\tvalid_0's auc: 0.85262\tvalid_0's binary_logloss: 0.142266\tvalid_1's auc: 0.83348\tvalid_1's binary_logloss: 0.153059\n",
      "[5]\tvalid_0's auc: 0.856853\tvalid_0's binary_logloss: 0.139575\tvalid_1's auc: 0.837158\tvalid_1's binary_logloss: 0.150847\n",
      "[6]\tvalid_0's auc: 0.859779\tvalid_0's binary_logloss: 0.13732\tvalid_1's auc: 0.839471\tvalid_1's binary_logloss: 0.148924\n",
      "[7]\tvalid_0's auc: 0.861819\tvalid_0's binary_logloss: 0.135402\tvalid_1's auc: 0.838324\tvalid_1's binary_logloss: 0.147505\n",
      "[8]\tvalid_0's auc: 0.863714\tvalid_0's binary_logloss: 0.133757\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.146279\n",
      "[9]\tvalid_0's auc: 0.864749\tvalid_0's binary_logloss: 0.132364\tvalid_1's auc: 0.838331\tvalid_1's binary_logloss: 0.14529\n",
      "[10]\tvalid_0's auc: 0.866663\tvalid_0's binary_logloss: 0.131026\tvalid_1's auc: 0.837673\tvalid_1's binary_logloss: 0.144419\n",
      "[11]\tvalid_0's auc: 0.868726\tvalid_0's binary_logloss: 0.12984\tvalid_1's auc: 0.838501\tvalid_1's binary_logloss: 0.143675\n",
      "[12]\tvalid_0's auc: 0.871558\tvalid_0's binary_logloss: 0.128733\tvalid_1's auc: 0.838492\tvalid_1's binary_logloss: 0.143092\n",
      "[13]\tvalid_0's auc: 0.873442\tvalid_0's binary_logloss: 0.127675\tvalid_1's auc: 0.839717\tvalid_1's binary_logloss: 0.142342\n",
      "[14]\tvalid_0's auc: 0.875241\tvalid_0's binary_logloss: 0.126727\tvalid_1's auc: 0.839554\tvalid_1's binary_logloss: 0.141894\n",
      "[15]\tvalid_0's auc: 0.877606\tvalid_0's binary_logloss: 0.125834\tvalid_1's auc: 0.839663\tvalid_1's binary_logloss: 0.141484\n",
      "[16]\tvalid_0's auc: 0.878882\tvalid_0's binary_logloss: 0.125061\tvalid_1's auc: 0.840269\tvalid_1's binary_logloss: 0.141121\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[18]\tvalid_0's auc: 0.881171\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.839956\tvalid_1's binary_logloss: 0.14074\n",
      "[19]\tvalid_0's auc: 0.882715\tvalid_0's binary_logloss: 0.12297\tvalid_1's auc: 0.839997\tvalid_1's binary_logloss: 0.140537\n",
      "[20]\tvalid_0's auc: 0.884031\tvalid_0's binary_logloss: 0.122325\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.140381\n",
      "[21]\tvalid_0's auc: 0.885764\tvalid_0's binary_logloss: 0.121625\tvalid_1's auc: 0.839843\tvalid_1's binary_logloss: 0.140197\n",
      "[22]\tvalid_0's auc: 0.887281\tvalid_0's binary_logloss: 0.120983\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140102\n",
      "[23]\tvalid_0's auc: 0.888433\tvalid_0's binary_logloss: 0.120453\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.140039\n",
      "[24]\tvalid_0's auc: 0.890216\tvalid_0's binary_logloss: 0.119857\tvalid_1's auc: 0.839006\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.891521\tvalid_0's binary_logloss: 0.119298\tvalid_1's auc: 0.83887\tvalid_1's binary_logloss: 0.139884\n",
      "[26]\tvalid_0's auc: 0.892429\tvalid_0's binary_logloss: 0.118862\tvalid_1's auc: 0.838468\tvalid_1's binary_logloss: 0.139871\n",
      "[27]\tvalid_0's auc: 0.893299\tvalid_0's binary_logloss: 0.11838\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139845\n",
      "[28]\tvalid_0's auc: 0.894251\tvalid_0's binary_logloss: 0.117957\tvalid_1's auc: 0.837679\tvalid_1's binary_logloss: 0.139855\n",
      "[29]\tvalid_0's auc: 0.895243\tvalid_0's binary_logloss: 0.117508\tvalid_1's auc: 0.837735\tvalid_1's binary_logloss: 0.139821\n",
      "[30]\tvalid_0's auc: 0.896095\tvalid_0's binary_logloss: 0.117089\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139898\n",
      "[31]\tvalid_0's auc: 0.897359\tvalid_0's binary_logloss: 0.116601\tvalid_1's auc: 0.837136\tvalid_1's binary_logloss: 0.139894\n",
      "[32]\tvalid_0's auc: 0.898643\tvalid_0's binary_logloss: 0.11607\tvalid_1's auc: 0.836864\tvalid_1's binary_logloss: 0.139923\n",
      "[33]\tvalid_0's auc: 0.89992\tvalid_0's binary_logloss: 0.115645\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139915\n",
      "[34]\tvalid_0's auc: 0.900901\tvalid_0's binary_logloss: 0.115264\tvalid_1's auc: 0.836791\tvalid_1's binary_logloss: 0.139982\n",
      "[35]\tvalid_0's auc: 0.901751\tvalid_0's binary_logloss: 0.114906\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.139951\n",
      "[36]\tvalid_0's auc: 0.903021\tvalid_0's binary_logloss: 0.114415\tvalid_1's auc: 0.836623\tvalid_1's binary_logloss: 0.139976\n",
      "[37]\tvalid_0's auc: 0.904251\tvalid_0's binary_logloss: 0.114061\tvalid_1's auc: 0.836728\tvalid_1's binary_logloss: 0.139975\n",
      "[38]\tvalid_0's auc: 0.90516\tvalid_0's binary_logloss: 0.113675\tvalid_1's auc: 0.837\tvalid_1's binary_logloss: 0.139923\n",
      "[39]\tvalid_0's auc: 0.90596\tvalid_0's binary_logloss: 0.113263\tvalid_1's auc: 0.837387\tvalid_1's binary_logloss: 0.13986\n",
      "[40]\tvalid_0's auc: 0.906683\tvalid_0's binary_logloss: 0.112912\tvalid_1's auc: 0.837328\tvalid_1's binary_logloss: 0.139857\n",
      "[41]\tvalid_0's auc: 0.907126\tvalid_0's binary_logloss: 0.112589\tvalid_1's auc: 0.836763\tvalid_1's binary_logloss: 0.139978\n",
      "[42]\tvalid_0's auc: 0.907766\tvalid_0's binary_logloss: 0.112228\tvalid_1's auc: 0.836668\tvalid_1's binary_logloss: 0.140037\n",
      "[43]\tvalid_0's auc: 0.908476\tvalid_0's binary_logloss: 0.111878\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.140074\n",
      "[44]\tvalid_0's auc: 0.908965\tvalid_0's binary_logloss: 0.111555\tvalid_1's auc: 0.836825\tvalid_1's binary_logloss: 0.140052\n",
      "[45]\tvalid_0's auc: 0.90954\tvalid_0's binary_logloss: 0.111283\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.140134\n",
      "[46]\tvalid_0's auc: 0.910195\tvalid_0's binary_logloss: 0.111029\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.140137\n",
      "[47]\tvalid_0's auc: 0.910771\tvalid_0's binary_logloss: 0.110662\tvalid_1's auc: 0.836357\tvalid_1's binary_logloss: 0.140222\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833594\tvalid_0's binary_logloss: 0.155635\tvalid_1's auc: 0.820913\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.846048\tvalid_0's binary_logloss: 0.149713\tvalid_1's auc: 0.830646\tvalid_1's binary_logloss: 0.159607\n",
      "[3]\tvalid_0's auc: 0.849539\tvalid_0's binary_logloss: 0.145369\tvalid_1's auc: 0.833531\tvalid_1's binary_logloss: 0.155847\n",
      "[4]\tvalid_0's auc: 0.8529\tvalid_0's binary_logloss: 0.142095\tvalid_1's auc: 0.832813\tvalid_1's binary_logloss: 0.15325\n",
      "[5]\tvalid_0's auc: 0.855497\tvalid_0's binary_logloss: 0.13934\tvalid_1's auc: 0.833555\tvalid_1's binary_logloss: 0.150958\n",
      "[6]\tvalid_0's auc: 0.860603\tvalid_0's binary_logloss: 0.13707\tvalid_1's auc: 0.836476\tvalid_1's binary_logloss: 0.149037\n",
      "[7]\tvalid_0's auc: 0.86401\tvalid_0's binary_logloss: 0.13507\tvalid_1's auc: 0.838639\tvalid_1's binary_logloss: 0.147363\n",
      "[8]\tvalid_0's auc: 0.866327\tvalid_0's binary_logloss: 0.133353\tvalid_1's auc: 0.83917\tvalid_1's binary_logloss: 0.146142\n",
      "[9]\tvalid_0's auc: 0.868666\tvalid_0's binary_logloss: 0.131872\tvalid_1's auc: 0.839119\tvalid_1's binary_logloss: 0.145095\n",
      "[10]\tvalid_0's auc: 0.870055\tvalid_0's binary_logloss: 0.130535\tvalid_1's auc: 0.839769\tvalid_1's binary_logloss: 0.144187\n",
      "[11]\tvalid_0's auc: 0.871923\tvalid_0's binary_logloss: 0.129272\tvalid_1's auc: 0.840793\tvalid_1's binary_logloss: 0.143281\n",
      "[12]\tvalid_0's auc: 0.87487\tvalid_0's binary_logloss: 0.128204\tvalid_1's auc: 0.841107\tvalid_1's binary_logloss: 0.142593\n",
      "[13]\tvalid_0's auc: 0.87716\tvalid_0's binary_logloss: 0.127155\tvalid_1's auc: 0.840555\tvalid_1's binary_logloss: 0.142065\n",
      "[14]\tvalid_0's auc: 0.879344\tvalid_0's binary_logloss: 0.126173\tvalid_1's auc: 0.841197\tvalid_1's binary_logloss: 0.141536\n",
      "[15]\tvalid_0's auc: 0.880521\tvalid_0's binary_logloss: 0.125283\tvalid_1's auc: 0.841423\tvalid_1's binary_logloss: 0.141157\n",
      "[16]\tvalid_0's auc: 0.882066\tvalid_0's binary_logloss: 0.1244\tvalid_1's auc: 0.841461\tvalid_1's binary_logloss: 0.140813\n",
      "[17]\tvalid_0's auc: 0.883582\tvalid_0's binary_logloss: 0.123652\tvalid_1's auc: 0.841626\tvalid_1's binary_logloss: 0.1405\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[19]\tvalid_0's auc: 0.885618\tvalid_0's binary_logloss: 0.122288\tvalid_1's auc: 0.841595\tvalid_1's binary_logloss: 0.140038\n",
      "[20]\tvalid_0's auc: 0.887262\tvalid_0's binary_logloss: 0.12156\tvalid_1's auc: 0.841475\tvalid_1's binary_logloss: 0.13984\n",
      "[21]\tvalid_0's auc: 0.888549\tvalid_0's binary_logloss: 0.120864\tvalid_1's auc: 0.841698\tvalid_1's binary_logloss: 0.139644\n",
      "[22]\tvalid_0's auc: 0.889783\tvalid_0's binary_logloss: 0.120226\tvalid_1's auc: 0.841265\tvalid_1's binary_logloss: 0.139524\n",
      "[23]\tvalid_0's auc: 0.891007\tvalid_0's binary_logloss: 0.119647\tvalid_1's auc: 0.840909\tvalid_1's binary_logloss: 0.139463\n",
      "[24]\tvalid_0's auc: 0.892111\tvalid_0's binary_logloss: 0.11912\tvalid_1's auc: 0.840884\tvalid_1's binary_logloss: 0.13939\n",
      "[25]\tvalid_0's auc: 0.892959\tvalid_0's binary_logloss: 0.118644\tvalid_1's auc: 0.840779\tvalid_1's binary_logloss: 0.139336\n",
      "[26]\tvalid_0's auc: 0.894356\tvalid_0's binary_logloss: 0.118128\tvalid_1's auc: 0.841299\tvalid_1's binary_logloss: 0.139198\n",
      "[27]\tvalid_0's auc: 0.895981\tvalid_0's binary_logloss: 0.117575\tvalid_1's auc: 0.8407\tvalid_1's binary_logloss: 0.139192\n",
      "[28]\tvalid_0's auc: 0.896969\tvalid_0's binary_logloss: 0.11709\tvalid_1's auc: 0.840437\tvalid_1's binary_logloss: 0.139222\n",
      "[29]\tvalid_0's auc: 0.898028\tvalid_0's binary_logloss: 0.116618\tvalid_1's auc: 0.840857\tvalid_1's binary_logloss: 0.139136\n",
      "[30]\tvalid_0's auc: 0.89908\tvalid_0's binary_logloss: 0.116142\tvalid_1's auc: 0.840827\tvalid_1's binary_logloss: 0.139074\n",
      "[31]\tvalid_0's auc: 0.900145\tvalid_0's binary_logloss: 0.115699\tvalid_1's auc: 0.840974\tvalid_1's binary_logloss: 0.138987\n",
      "[32]\tvalid_0's auc: 0.90112\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.840942\tvalid_1's binary_logloss: 0.139024\n",
      "[33]\tvalid_0's auc: 0.901846\tvalid_0's binary_logloss: 0.114793\tvalid_1's auc: 0.840933\tvalid_1's binary_logloss: 0.13904\n",
      "[34]\tvalid_0's auc: 0.902883\tvalid_0's binary_logloss: 0.114387\tvalid_1's auc: 0.840844\tvalid_1's binary_logloss: 0.139066\n",
      "[35]\tvalid_0's auc: 0.903648\tvalid_0's binary_logloss: 0.113998\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.13901\n",
      "[36]\tvalid_0's auc: 0.905129\tvalid_0's binary_logloss: 0.113587\tvalid_1's auc: 0.840769\tvalid_1's binary_logloss: 0.139037\n",
      "[37]\tvalid_0's auc: 0.906133\tvalid_0's binary_logloss: 0.113131\tvalid_1's auc: 0.84035\tvalid_1's binary_logloss: 0.139137\n",
      "[38]\tvalid_0's auc: 0.907\tvalid_0's binary_logloss: 0.112813\tvalid_1's auc: 0.840254\tvalid_1's binary_logloss: 0.139186\n",
      "[39]\tvalid_0's auc: 0.907829\tvalid_0's binary_logloss: 0.112418\tvalid_1's auc: 0.84009\tvalid_1's binary_logloss: 0.139236\n",
      "[40]\tvalid_0's auc: 0.908551\tvalid_0's binary_logloss: 0.112078\tvalid_1's auc: 0.839874\tvalid_1's binary_logloss: 0.139313\n",
      "[41]\tvalid_0's auc: 0.909258\tvalid_0's binary_logloss: 0.111745\tvalid_1's auc: 0.839426\tvalid_1's binary_logloss: 0.139447\n",
      "[42]\tvalid_0's auc: 0.909875\tvalid_0's binary_logloss: 0.111354\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139428\n",
      "[43]\tvalid_0's auc: 0.910434\tvalid_0's binary_logloss: 0.111052\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.139483\n",
      "[44]\tvalid_0's auc: 0.911375\tvalid_0's binary_logloss: 0.110624\tvalid_1's auc: 0.839582\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.912055\tvalid_0's binary_logloss: 0.110372\tvalid_1's auc: 0.839536\tvalid_1's binary_logloss: 0.139546\n",
      "[46]\tvalid_0's auc: 0.912574\tvalid_0's binary_logloss: 0.110057\tvalid_1's auc: 0.83948\tvalid_1's binary_logloss: 0.139584\n",
      "[47]\tvalid_0's auc: 0.91302\tvalid_0's binary_logloss: 0.109723\tvalid_1's auc: 0.839228\tvalid_1's binary_logloss: 0.139685\n",
      "[48]\tvalid_0's auc: 0.913378\tvalid_0's binary_logloss: 0.109457\tvalid_1's auc: 0.839315\tvalid_1's binary_logloss: 0.139695\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13500\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.832025\tvalid_0's binary_logloss: 0.155465\tvalid_1's auc: 0.820076\tvalid_1's binary_logloss: 0.164546\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.844878\tvalid_0's binary_logloss: 0.14969\tvalid_1's auc: 0.828857\tvalid_1's binary_logloss: 0.159283\n",
      "[3]\tvalid_0's auc: 0.848608\tvalid_0's binary_logloss: 0.145495\tvalid_1's auc: 0.831668\tvalid_1's binary_logloss: 0.155726\n",
      "[4]\tvalid_0's auc: 0.85412\tvalid_0's binary_logloss: 0.142244\tvalid_1's auc: 0.832954\tvalid_1's binary_logloss: 0.153013\n",
      "[5]\tvalid_0's auc: 0.856985\tvalid_0's binary_logloss: 0.139541\tvalid_1's auc: 0.834294\tvalid_1's binary_logloss: 0.150762\n",
      "[6]\tvalid_0's auc: 0.860318\tvalid_0's binary_logloss: 0.137315\tvalid_1's auc: 0.834439\tvalid_1's binary_logloss: 0.148891\n",
      "[7]\tvalid_0's auc: 0.862354\tvalid_0's binary_logloss: 0.135314\tvalid_1's auc: 0.835254\tvalid_1's binary_logloss: 0.147306\n",
      "[8]\tvalid_0's auc: 0.864507\tvalid_0's binary_logloss: 0.133588\tvalid_1's auc: 0.834413\tvalid_1's binary_logloss: 0.146246\n",
      "[9]\tvalid_0's auc: 0.866506\tvalid_0's binary_logloss: 0.132094\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.14517\n",
      "[10]\tvalid_0's auc: 0.867622\tvalid_0's binary_logloss: 0.130807\tvalid_1's auc: 0.835059\tvalid_1's binary_logloss: 0.144333\n",
      "[11]\tvalid_0's auc: 0.869595\tvalid_0's binary_logloss: 0.12963\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.143624\n",
      "[12]\tvalid_0's auc: 0.871732\tvalid_0's binary_logloss: 0.128488\tvalid_1's auc: 0.837004\tvalid_1's binary_logloss: 0.142969\n",
      "[13]\tvalid_0's auc: 0.874689\tvalid_0's binary_logloss: 0.127457\tvalid_1's auc: 0.837217\tvalid_1's binary_logloss: 0.142409\n",
      "[14]\tvalid_0's auc: 0.876111\tvalid_0's binary_logloss: 0.126511\tvalid_1's auc: 0.837232\tvalid_1's binary_logloss: 0.141993\n",
      "[15]\tvalid_0's auc: 0.87877\tvalid_0's binary_logloss: 0.12553\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.141557\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[17]\tvalid_0's auc: 0.881444\tvalid_0's binary_logloss: 0.123911\tvalid_1's auc: 0.836877\tvalid_1's binary_logloss: 0.141158\n",
      "[18]\tvalid_0's auc: 0.882597\tvalid_0's binary_logloss: 0.123216\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.140956\n",
      "[19]\tvalid_0's auc: 0.884069\tvalid_0's binary_logloss: 0.1225\tvalid_1's auc: 0.836798\tvalid_1's binary_logloss: 0.140747\n",
      "[20]\tvalid_0's auc: 0.885553\tvalid_0's binary_logloss: 0.121835\tvalid_1's auc: 0.837335\tvalid_1's binary_logloss: 0.140578\n",
      "[21]\tvalid_0's auc: 0.886758\tvalid_0's binary_logloss: 0.121199\tvalid_1's auc: 0.837053\tvalid_1's binary_logloss: 0.1405\n",
      "[22]\tvalid_0's auc: 0.888245\tvalid_0's binary_logloss: 0.120566\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.140423\n",
      "[23]\tvalid_0's auc: 0.889287\tvalid_0's binary_logloss: 0.119999\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.140319\n",
      "[24]\tvalid_0's auc: 0.890242\tvalid_0's binary_logloss: 0.119535\tvalid_1's auc: 0.837226\tvalid_1's binary_logloss: 0.140192\n",
      "[25]\tvalid_0's auc: 0.89128\tvalid_0's binary_logloss: 0.119025\tvalid_1's auc: 0.836975\tvalid_1's binary_logloss: 0.140152\n",
      "[26]\tvalid_0's auc: 0.892936\tvalid_0's binary_logloss: 0.118515\tvalid_1's auc: 0.836466\tvalid_1's binary_logloss: 0.14011\n",
      "[27]\tvalid_0's auc: 0.894014\tvalid_0's binary_logloss: 0.118046\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140163\n",
      "[28]\tvalid_0's auc: 0.895806\tvalid_0's binary_logloss: 0.1175\tvalid_1's auc: 0.835987\tvalid_1's binary_logloss: 0.1401\n",
      "[29]\tvalid_0's auc: 0.896704\tvalid_0's binary_logloss: 0.117069\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140035\n",
      "[30]\tvalid_0's auc: 0.897739\tvalid_0's binary_logloss: 0.116577\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.139877\n",
      "[31]\tvalid_0's auc: 0.898365\tvalid_0's binary_logloss: 0.116187\tvalid_1's auc: 0.836258\tvalid_1's binary_logloss: 0.139893\n",
      "[32]\tvalid_0's auc: 0.899428\tvalid_0's binary_logloss: 0.115755\tvalid_1's auc: 0.836228\tvalid_1's binary_logloss: 0.139825\n",
      "[33]\tvalid_0's auc: 0.900129\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836132\tvalid_1's binary_logloss: 0.139815\n",
      "[34]\tvalid_0's auc: 0.900819\tvalid_0's binary_logloss: 0.115047\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.139786\n",
      "[35]\tvalid_0's auc: 0.901929\tvalid_0's binary_logloss: 0.114682\tvalid_1's auc: 0.836241\tvalid_1's binary_logloss: 0.139758\n",
      "[36]\tvalid_0's auc: 0.902923\tvalid_0's binary_logloss: 0.114287\tvalid_1's auc: 0.836594\tvalid_1's binary_logloss: 0.139739\n",
      "[37]\tvalid_0's auc: 0.903583\tvalid_0's binary_logloss: 0.113893\tvalid_1's auc: 0.836319\tvalid_1's binary_logloss: 0.139831\n",
      "[38]\tvalid_0's auc: 0.904289\tvalid_0's binary_logloss: 0.113536\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.139874\n",
      "[39]\tvalid_0's auc: 0.904948\tvalid_0's binary_logloss: 0.113207\tvalid_1's auc: 0.835797\tvalid_1's binary_logloss: 0.139959\n",
      "[40]\tvalid_0's auc: 0.905808\tvalid_0's binary_logloss: 0.112811\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.139967\n",
      "[41]\tvalid_0's auc: 0.906507\tvalid_0's binary_logloss: 0.112548\tvalid_1's auc: 0.835793\tvalid_1's binary_logloss: 0.139996\n",
      "[42]\tvalid_0's auc: 0.907263\tvalid_0's binary_logloss: 0.112199\tvalid_1's auc: 0.835583\tvalid_1's binary_logloss: 0.140069\n",
      "[43]\tvalid_0's auc: 0.907622\tvalid_0's binary_logloss: 0.111883\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.140122\n",
      "[44]\tvalid_0's auc: 0.908342\tvalid_0's binary_logloss: 0.111608\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.140227\n",
      "[45]\tvalid_0's auc: 0.908935\tvalid_0's binary_logloss: 0.111287\tvalid_1's auc: 0.834854\tvalid_1's binary_logloss: 0.140271\n",
      "[46]\tvalid_0's auc: 0.910346\tvalid_0's binary_logloss: 0.110886\tvalid_1's auc: 0.834699\tvalid_1's binary_logloss: 0.140295\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.879918\tvalid_0's binary_logloss: 0.124701\tvalid_1's auc: 0.837709\tvalid_1's binary_logloss: 0.141283\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13620\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.832082\tvalid_0's binary_logloss: 0.155469\tvalid_1's auc: 0.814834\tvalid_1's binary_logloss: 0.164811\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840358\tvalid_0's binary_logloss: 0.149705\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.159739\n",
      "[3]\tvalid_0's auc: 0.846958\tvalid_0's binary_logloss: 0.145462\tvalid_1's auc: 0.829037\tvalid_1's binary_logloss: 0.155963\n",
      "[4]\tvalid_0's auc: 0.850608\tvalid_0's binary_logloss: 0.142192\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.153305\n",
      "[5]\tvalid_0's auc: 0.857054\tvalid_0's binary_logloss: 0.139496\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.150999\n",
      "[6]\tvalid_0's auc: 0.860917\tvalid_0's binary_logloss: 0.137183\tvalid_1's auc: 0.837251\tvalid_1's binary_logloss: 0.149102\n",
      "[7]\tvalid_0's auc: 0.862765\tvalid_0's binary_logloss: 0.135234\tvalid_1's auc: 0.838397\tvalid_1's binary_logloss: 0.14754\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[9]\tvalid_0's auc: 0.866709\tvalid_0's binary_logloss: 0.132066\tvalid_1's auc: 0.838734\tvalid_1's binary_logloss: 0.145324\n",
      "[10]\tvalid_0's auc: 0.868899\tvalid_0's binary_logloss: 0.130682\tvalid_1's auc: 0.838642\tvalid_1's binary_logloss: 0.144425\n",
      "[11]\tvalid_0's auc: 0.87095\tvalid_0's binary_logloss: 0.129509\tvalid_1's auc: 0.837304\tvalid_1's binary_logloss: 0.143844\n",
      "[12]\tvalid_0's auc: 0.872258\tvalid_0's binary_logloss: 0.128409\tvalid_1's auc: 0.83669\tvalid_1's binary_logloss: 0.143316\n",
      "[13]\tvalid_0's auc: 0.874037\tvalid_0's binary_logloss: 0.127397\tvalid_1's auc: 0.835346\tvalid_1's binary_logloss: 0.142981\n",
      "[14]\tvalid_0's auc: 0.875949\tvalid_0's binary_logloss: 0.126455\tvalid_1's auc: 0.835276\tvalid_1's binary_logloss: 0.142607\n",
      "[15]\tvalid_0's auc: 0.877382\tvalid_0's binary_logloss: 0.125645\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.142362\n",
      "[16]\tvalid_0's auc: 0.878987\tvalid_0's binary_logloss: 0.124805\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.142102\n",
      "[17]\tvalid_0's auc: 0.880532\tvalid_0's binary_logloss: 0.124054\tvalid_1's auc: 0.833893\tvalid_1's binary_logloss: 0.141884\n",
      "[18]\tvalid_0's auc: 0.882045\tvalid_0's binary_logloss: 0.123344\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.141697\n",
      "[19]\tvalid_0's auc: 0.883566\tvalid_0's binary_logloss: 0.122594\tvalid_1's auc: 0.832707\tvalid_1's binary_logloss: 0.141615\n",
      "[20]\tvalid_0's auc: 0.885585\tvalid_0's binary_logloss: 0.121869\tvalid_1's auc: 0.833151\tvalid_1's binary_logloss: 0.141426\n",
      "[21]\tvalid_0's auc: 0.887553\tvalid_0's binary_logloss: 0.121164\tvalid_1's auc: 0.834052\tvalid_1's binary_logloss: 0.141225\n",
      "[22]\tvalid_0's auc: 0.88866\tvalid_0's binary_logloss: 0.120577\tvalid_1's auc: 0.834098\tvalid_1's binary_logloss: 0.141029\n",
      "[23]\tvalid_0's auc: 0.889845\tvalid_0's binary_logloss: 0.11997\tvalid_1's auc: 0.833894\tvalid_1's binary_logloss: 0.140951\n",
      "[24]\tvalid_0's auc: 0.890796\tvalid_0's binary_logloss: 0.119485\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.140844\n",
      "[25]\tvalid_0's auc: 0.89199\tvalid_0's binary_logloss: 0.118928\tvalid_1's auc: 0.833906\tvalid_1's binary_logloss: 0.140917\n",
      "[26]\tvalid_0's auc: 0.893398\tvalid_0's binary_logloss: 0.118364\tvalid_1's auc: 0.834288\tvalid_1's binary_logloss: 0.140784\n",
      "[27]\tvalid_0's auc: 0.894509\tvalid_0's binary_logloss: 0.117887\tvalid_1's auc: 0.834364\tvalid_1's binary_logloss: 0.140677\n",
      "[28]\tvalid_0's auc: 0.895524\tvalid_0's binary_logloss: 0.117424\tvalid_1's auc: 0.834009\tvalid_1's binary_logloss: 0.140715\n",
      "[29]\tvalid_0's auc: 0.896654\tvalid_0's binary_logloss: 0.116949\tvalid_1's auc: 0.833704\tvalid_1's binary_logloss: 0.140719\n",
      "[30]\tvalid_0's auc: 0.897948\tvalid_0's binary_logloss: 0.116488\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140635\n",
      "[31]\tvalid_0's auc: 0.898781\tvalid_0's binary_logloss: 0.116069\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.140671\n",
      "[32]\tvalid_0's auc: 0.90009\tvalid_0's binary_logloss: 0.115625\tvalid_1's auc: 0.83384\tvalid_1's binary_logloss: 0.140667\n",
      "[33]\tvalid_0's auc: 0.901073\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.833911\tvalid_1's binary_logloss: 0.140619\n",
      "[34]\tvalid_0's auc: 0.902228\tvalid_0's binary_logloss: 0.114803\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.140595\n",
      "[35]\tvalid_0's auc: 0.902949\tvalid_0's binary_logloss: 0.114411\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.140641\n",
      "[36]\tvalid_0's auc: 0.90428\tvalid_0's binary_logloss: 0.114027\tvalid_1's auc: 0.833146\tvalid_1's binary_logloss: 0.140714\n",
      "[37]\tvalid_0's auc: 0.90518\tvalid_0's binary_logloss: 0.113632\tvalid_1's auc: 0.833423\tvalid_1's binary_logloss: 0.140663\n",
      "[38]\tvalid_0's auc: 0.905995\tvalid_0's binary_logloss: 0.113243\tvalid_1's auc: 0.83347\tvalid_1's binary_logloss: 0.140755\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.865325\tvalid_0's binary_logloss: 0.133564\tvalid_1's auc: 0.83904\tvalid_1's binary_logloss: 0.146192\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13525\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833919\tvalid_0's binary_logloss: 0.155512\tvalid_1's auc: 0.820637\tvalid_1's binary_logloss: 0.164643\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842002\tvalid_0's binary_logloss: 0.149635\tvalid_1's auc: 0.827273\tvalid_1's binary_logloss: 0.15926\n",
      "[3]\tvalid_0's auc: 0.844839\tvalid_0's binary_logloss: 0.145363\tvalid_1's auc: 0.829328\tvalid_1's binary_logloss: 0.155446\n",
      "[4]\tvalid_0's auc: 0.851547\tvalid_0's binary_logloss: 0.142092\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.152516\n",
      "[5]\tvalid_0's auc: 0.85629\tvalid_0's binary_logloss: 0.139314\tvalid_1's auc: 0.837608\tvalid_1's binary_logloss: 0.150218\n",
      "[6]\tvalid_0's auc: 0.860698\tvalid_0's binary_logloss: 0.137026\tvalid_1's auc: 0.837977\tvalid_1's binary_logloss: 0.148376\n",
      "[7]\tvalid_0's auc: 0.863515\tvalid_0's binary_logloss: 0.135113\tvalid_1's auc: 0.838443\tvalid_1's binary_logloss: 0.146922\n",
      "[8]\tvalid_0's auc: 0.864625\tvalid_0's binary_logloss: 0.133401\tvalid_1's auc: 0.838988\tvalid_1's binary_logloss: 0.145624\n",
      "[9]\tvalid_0's auc: 0.866831\tvalid_0's binary_logloss: 0.131907\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.14464\n",
      "[10]\tvalid_0's auc: 0.868953\tvalid_0's binary_logloss: 0.130539\tvalid_1's auc: 0.83779\tvalid_1's binary_logloss: 0.143795\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[12]\tvalid_0's auc: 0.872964\tvalid_0's binary_logloss: 0.128158\tvalid_1's auc: 0.838184\tvalid_1's binary_logloss: 0.142277\n",
      "[13]\tvalid_0's auc: 0.874758\tvalid_0's binary_logloss: 0.127141\tvalid_1's auc: 0.837972\tvalid_1's binary_logloss: 0.141744\n",
      "[14]\tvalid_0's auc: 0.876311\tvalid_0's binary_logloss: 0.126137\tvalid_1's auc: 0.837484\tvalid_1's binary_logloss: 0.141408\n",
      "[15]\tvalid_0's auc: 0.877968\tvalid_0's binary_logloss: 0.12525\tvalid_1's auc: 0.836581\tvalid_1's binary_logloss: 0.141099\n",
      "[16]\tvalid_0's auc: 0.87963\tvalid_0's binary_logloss: 0.124439\tvalid_1's auc: 0.836006\tvalid_1's binary_logloss: 0.140886\n",
      "[17]\tvalid_0's auc: 0.881659\tvalid_0's binary_logloss: 0.123628\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.140605\n",
      "[18]\tvalid_0's auc: 0.882607\tvalid_0's binary_logloss: 0.122935\tvalid_1's auc: 0.836156\tvalid_1's binary_logloss: 0.140354\n",
      "[19]\tvalid_0's auc: 0.884204\tvalid_0's binary_logloss: 0.122205\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.140094\n",
      "[20]\tvalid_0's auc: 0.88564\tvalid_0's binary_logloss: 0.121562\tvalid_1's auc: 0.836976\tvalid_1's binary_logloss: 0.139982\n",
      "[21]\tvalid_0's auc: 0.886788\tvalid_0's binary_logloss: 0.120948\tvalid_1's auc: 0.83734\tvalid_1's binary_logloss: 0.139793\n",
      "[22]\tvalid_0's auc: 0.888424\tvalid_0's binary_logloss: 0.120314\tvalid_1's auc: 0.83802\tvalid_1's binary_logloss: 0.139623\n",
      "[23]\tvalid_0's auc: 0.889756\tvalid_0's binary_logloss: 0.119797\tvalid_1's auc: 0.837015\tvalid_1's binary_logloss: 0.139653\n",
      "[24]\tvalid_0's auc: 0.891304\tvalid_0's binary_logloss: 0.119202\tvalid_1's auc: 0.837202\tvalid_1's binary_logloss: 0.139584\n",
      "[25]\tvalid_0's auc: 0.892545\tvalid_0's binary_logloss: 0.118664\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.1395\n",
      "[26]\tvalid_0's auc: 0.893944\tvalid_0's binary_logloss: 0.118169\tvalid_1's auc: 0.837371\tvalid_1's binary_logloss: 0.139458\n",
      "[27]\tvalid_0's auc: 0.894982\tvalid_0's binary_logloss: 0.117651\tvalid_1's auc: 0.836907\tvalid_1's binary_logloss: 0.139528\n",
      "[28]\tvalid_0's auc: 0.896304\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837127\tvalid_1's binary_logloss: 0.139491\n",
      "[29]\tvalid_0's auc: 0.89754\tvalid_0's binary_logloss: 0.116665\tvalid_1's auc: 0.837063\tvalid_1's binary_logloss: 0.139497\n",
      "[30]\tvalid_0's auc: 0.898907\tvalid_0's binary_logloss: 0.116238\tvalid_1's auc: 0.836952\tvalid_1's binary_logloss: 0.139457\n",
      "[31]\tvalid_0's auc: 0.89958\tvalid_0's binary_logloss: 0.115802\tvalid_1's auc: 0.837327\tvalid_1's binary_logloss: 0.139384\n",
      "[32]\tvalid_0's auc: 0.900529\tvalid_0's binary_logloss: 0.115374\tvalid_1's auc: 0.836541\tvalid_1's binary_logloss: 0.139496\n",
      "[33]\tvalid_0's auc: 0.90188\tvalid_0's binary_logloss: 0.114972\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.139413\n",
      "[34]\tvalid_0's auc: 0.902879\tvalid_0's binary_logloss: 0.114528\tvalid_1's auc: 0.836909\tvalid_1's binary_logloss: 0.13943\n",
      "[35]\tvalid_0's auc: 0.903932\tvalid_0's binary_logloss: 0.114157\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.139458\n",
      "[36]\tvalid_0's auc: 0.904707\tvalid_0's binary_logloss: 0.113777\tvalid_1's auc: 0.836824\tvalid_1's binary_logloss: 0.139459\n",
      "[37]\tvalid_0's auc: 0.905376\tvalid_0's binary_logloss: 0.113446\tvalid_1's auc: 0.836614\tvalid_1's binary_logloss: 0.139503\n",
      "[38]\tvalid_0's auc: 0.906535\tvalid_0's binary_logloss: 0.11295\tvalid_1's auc: 0.836328\tvalid_1's binary_logloss: 0.139575\n",
      "[39]\tvalid_0's auc: 0.907125\tvalid_0's binary_logloss: 0.112599\tvalid_1's auc: 0.83631\tvalid_1's binary_logloss: 0.139598\n",
      "[40]\tvalid_0's auc: 0.908267\tvalid_0's binary_logloss: 0.112224\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.139675\n",
      "[41]\tvalid_0's auc: 0.908916\tvalid_0's binary_logloss: 0.111848\tvalid_1's auc: 0.835954\tvalid_1's binary_logloss: 0.139752\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.871178\tvalid_0's binary_logloss: 0.129289\tvalid_1's auc: 0.839056\tvalid_1's binary_logloss: 0.142856\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13565\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.830163\tvalid_0's binary_logloss: 0.155383\tvalid_1's auc: 0.817444\tvalid_1's binary_logloss: 0.164924\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.840688\tvalid_0's binary_logloss: 0.14972\tvalid_1's auc: 0.825893\tvalid_1's binary_logloss: 0.159538\n",
      "[3]\tvalid_0's auc: 0.847811\tvalid_0's binary_logloss: 0.145576\tvalid_1's auc: 0.832086\tvalid_1's binary_logloss: 0.155889\n",
      "[4]\tvalid_0's auc: 0.85262\tvalid_0's binary_logloss: 0.142266\tvalid_1's auc: 0.83348\tvalid_1's binary_logloss: 0.153059\n",
      "[5]\tvalid_0's auc: 0.856853\tvalid_0's binary_logloss: 0.139575\tvalid_1's auc: 0.837158\tvalid_1's binary_logloss: 0.150847\n",
      "[6]\tvalid_0's auc: 0.859779\tvalid_0's binary_logloss: 0.13732\tvalid_1's auc: 0.839471\tvalid_1's binary_logloss: 0.148924\n",
      "[7]\tvalid_0's auc: 0.861819\tvalid_0's binary_logloss: 0.135402\tvalid_1's auc: 0.838324\tvalid_1's binary_logloss: 0.147505\n",
      "[8]\tvalid_0's auc: 0.863714\tvalid_0's binary_logloss: 0.133757\tvalid_1's auc: 0.838679\tvalid_1's binary_logloss: 0.146279\n",
      "[9]\tvalid_0's auc: 0.864749\tvalid_0's binary_logloss: 0.132364\tvalid_1's auc: 0.838331\tvalid_1's binary_logloss: 0.14529\n",
      "[10]\tvalid_0's auc: 0.866663\tvalid_0's binary_logloss: 0.131026\tvalid_1's auc: 0.837673\tvalid_1's binary_logloss: 0.144419\n",
      "[11]\tvalid_0's auc: 0.868726\tvalid_0's binary_logloss: 0.12984\tvalid_1's auc: 0.838501\tvalid_1's binary_logloss: 0.143675\n",
      "[12]\tvalid_0's auc: 0.871558\tvalid_0's binary_logloss: 0.128733\tvalid_1's auc: 0.838492\tvalid_1's binary_logloss: 0.143092\n",
      "[13]\tvalid_0's auc: 0.873442\tvalid_0's binary_logloss: 0.127675\tvalid_1's auc: 0.839717\tvalid_1's binary_logloss: 0.142342\n",
      "[14]\tvalid_0's auc: 0.875241\tvalid_0's binary_logloss: 0.126727\tvalid_1's auc: 0.839554\tvalid_1's binary_logloss: 0.141894\n",
      "[15]\tvalid_0's auc: 0.877606\tvalid_0's binary_logloss: 0.125834\tvalid_1's auc: 0.839663\tvalid_1's binary_logloss: 0.141484\n",
      "[16]\tvalid_0's auc: 0.878882\tvalid_0's binary_logloss: 0.125061\tvalid_1's auc: 0.840269\tvalid_1's binary_logloss: 0.141121\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[18]\tvalid_0's auc: 0.881171\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.839956\tvalid_1's binary_logloss: 0.14074\n",
      "[19]\tvalid_0's auc: 0.882715\tvalid_0's binary_logloss: 0.12297\tvalid_1's auc: 0.839997\tvalid_1's binary_logloss: 0.140537\n",
      "[20]\tvalid_0's auc: 0.884031\tvalid_0's binary_logloss: 0.122325\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.140381\n",
      "[21]\tvalid_0's auc: 0.885764\tvalid_0's binary_logloss: 0.121625\tvalid_1's auc: 0.839843\tvalid_1's binary_logloss: 0.140197\n",
      "[22]\tvalid_0's auc: 0.887281\tvalid_0's binary_logloss: 0.120983\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140102\n",
      "[23]\tvalid_0's auc: 0.888433\tvalid_0's binary_logloss: 0.120453\tvalid_1's auc: 0.838981\tvalid_1's binary_logloss: 0.140039\n",
      "[24]\tvalid_0's auc: 0.890216\tvalid_0's binary_logloss: 0.119857\tvalid_1's auc: 0.839006\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.891521\tvalid_0's binary_logloss: 0.119298\tvalid_1's auc: 0.83887\tvalid_1's binary_logloss: 0.139884\n",
      "[26]\tvalid_0's auc: 0.892429\tvalid_0's binary_logloss: 0.118862\tvalid_1's auc: 0.838468\tvalid_1's binary_logloss: 0.139871\n",
      "[27]\tvalid_0's auc: 0.893299\tvalid_0's binary_logloss: 0.11838\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139845\n",
      "[28]\tvalid_0's auc: 0.894251\tvalid_0's binary_logloss: 0.117957\tvalid_1's auc: 0.837679\tvalid_1's binary_logloss: 0.139855\n",
      "[29]\tvalid_0's auc: 0.895243\tvalid_0's binary_logloss: 0.117508\tvalid_1's auc: 0.837735\tvalid_1's binary_logloss: 0.139821\n",
      "[30]\tvalid_0's auc: 0.896095\tvalid_0's binary_logloss: 0.117089\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139898\n",
      "[31]\tvalid_0's auc: 0.897359\tvalid_0's binary_logloss: 0.116601\tvalid_1's auc: 0.837136\tvalid_1's binary_logloss: 0.139894\n",
      "[32]\tvalid_0's auc: 0.898643\tvalid_0's binary_logloss: 0.11607\tvalid_1's auc: 0.836864\tvalid_1's binary_logloss: 0.139923\n",
      "[33]\tvalid_0's auc: 0.89992\tvalid_0's binary_logloss: 0.115645\tvalid_1's auc: 0.837133\tvalid_1's binary_logloss: 0.139915\n",
      "[34]\tvalid_0's auc: 0.900901\tvalid_0's binary_logloss: 0.115264\tvalid_1's auc: 0.836791\tvalid_1's binary_logloss: 0.139982\n",
      "[35]\tvalid_0's auc: 0.901751\tvalid_0's binary_logloss: 0.114906\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.139951\n",
      "[36]\tvalid_0's auc: 0.903021\tvalid_0's binary_logloss: 0.114415\tvalid_1's auc: 0.836623\tvalid_1's binary_logloss: 0.139976\n",
      "[37]\tvalid_0's auc: 0.904251\tvalid_0's binary_logloss: 0.114061\tvalid_1's auc: 0.836728\tvalid_1's binary_logloss: 0.139975\n",
      "[38]\tvalid_0's auc: 0.90516\tvalid_0's binary_logloss: 0.113675\tvalid_1's auc: 0.837\tvalid_1's binary_logloss: 0.139923\n",
      "[39]\tvalid_0's auc: 0.90596\tvalid_0's binary_logloss: 0.113263\tvalid_1's auc: 0.837387\tvalid_1's binary_logloss: 0.13986\n",
      "[40]\tvalid_0's auc: 0.906683\tvalid_0's binary_logloss: 0.112912\tvalid_1's auc: 0.837328\tvalid_1's binary_logloss: 0.139857\n",
      "[41]\tvalid_0's auc: 0.907126\tvalid_0's binary_logloss: 0.112589\tvalid_1's auc: 0.836763\tvalid_1's binary_logloss: 0.139978\n",
      "[42]\tvalid_0's auc: 0.907766\tvalid_0's binary_logloss: 0.112228\tvalid_1's auc: 0.836668\tvalid_1's binary_logloss: 0.140037\n",
      "[43]\tvalid_0's auc: 0.908476\tvalid_0's binary_logloss: 0.111878\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.140074\n",
      "[44]\tvalid_0's auc: 0.908965\tvalid_0's binary_logloss: 0.111555\tvalid_1's auc: 0.836825\tvalid_1's binary_logloss: 0.140052\n",
      "[45]\tvalid_0's auc: 0.90954\tvalid_0's binary_logloss: 0.111283\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.140134\n",
      "[46]\tvalid_0's auc: 0.910195\tvalid_0's binary_logloss: 0.111029\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.140137\n",
      "[47]\tvalid_0's auc: 0.910771\tvalid_0's binary_logloss: 0.110662\tvalid_1's auc: 0.836357\tvalid_1's binary_logloss: 0.140222\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.88003\tvalid_0's binary_logloss: 0.124299\tvalid_1's auc: 0.840327\tvalid_1's binary_logloss: 0.140902\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13621\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.833594\tvalid_0's binary_logloss: 0.155635\tvalid_1's auc: 0.820913\tvalid_1's binary_logloss: 0.165016\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.846048\tvalid_0's binary_logloss: 0.149713\tvalid_1's auc: 0.830646\tvalid_1's binary_logloss: 0.159607\n",
      "[3]\tvalid_0's auc: 0.849539\tvalid_0's binary_logloss: 0.145369\tvalid_1's auc: 0.833531\tvalid_1's binary_logloss: 0.155847\n",
      "[4]\tvalid_0's auc: 0.8529\tvalid_0's binary_logloss: 0.142095\tvalid_1's auc: 0.832813\tvalid_1's binary_logloss: 0.15325\n",
      "[5]\tvalid_0's auc: 0.855497\tvalid_0's binary_logloss: 0.13934\tvalid_1's auc: 0.833555\tvalid_1's binary_logloss: 0.150958\n",
      "[6]\tvalid_0's auc: 0.860603\tvalid_0's binary_logloss: 0.13707\tvalid_1's auc: 0.836476\tvalid_1's binary_logloss: 0.149037\n",
      "[7]\tvalid_0's auc: 0.86401\tvalid_0's binary_logloss: 0.13507\tvalid_1's auc: 0.838639\tvalid_1's binary_logloss: 0.147363\n",
      "[8]\tvalid_0's auc: 0.866327\tvalid_0's binary_logloss: 0.133353\tvalid_1's auc: 0.83917\tvalid_1's binary_logloss: 0.146142\n",
      "[9]\tvalid_0's auc: 0.868666\tvalid_0's binary_logloss: 0.131872\tvalid_1's auc: 0.839119\tvalid_1's binary_logloss: 0.145095\n",
      "[10]\tvalid_0's auc: 0.870055\tvalid_0's binary_logloss: 0.130535\tvalid_1's auc: 0.839769\tvalid_1's binary_logloss: 0.144187\n",
      "[11]\tvalid_0's auc: 0.871923\tvalid_0's binary_logloss: 0.129272\tvalid_1's auc: 0.840793\tvalid_1's binary_logloss: 0.143281\n",
      "[12]\tvalid_0's auc: 0.87487\tvalid_0's binary_logloss: 0.128204\tvalid_1's auc: 0.841107\tvalid_1's binary_logloss: 0.142593\n",
      "[13]\tvalid_0's auc: 0.87716\tvalid_0's binary_logloss: 0.127155\tvalid_1's auc: 0.840555\tvalid_1's binary_logloss: 0.142065\n",
      "[14]\tvalid_0's auc: 0.879344\tvalid_0's binary_logloss: 0.126173\tvalid_1's auc: 0.841197\tvalid_1's binary_logloss: 0.141536\n",
      "[15]\tvalid_0's auc: 0.880521\tvalid_0's binary_logloss: 0.125283\tvalid_1's auc: 0.841423\tvalid_1's binary_logloss: 0.141157\n",
      "[16]\tvalid_0's auc: 0.882066\tvalid_0's binary_logloss: 0.1244\tvalid_1's auc: 0.841461\tvalid_1's binary_logloss: 0.140813\n",
      "[17]\tvalid_0's auc: 0.883582\tvalid_0's binary_logloss: 0.123652\tvalid_1's auc: 0.841626\tvalid_1's binary_logloss: 0.1405\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[19]\tvalid_0's auc: 0.885618\tvalid_0's binary_logloss: 0.122288\tvalid_1's auc: 0.841595\tvalid_1's binary_logloss: 0.140038\n",
      "[20]\tvalid_0's auc: 0.887262\tvalid_0's binary_logloss: 0.12156\tvalid_1's auc: 0.841475\tvalid_1's binary_logloss: 0.13984\n",
      "[21]\tvalid_0's auc: 0.888549\tvalid_0's binary_logloss: 0.120864\tvalid_1's auc: 0.841698\tvalid_1's binary_logloss: 0.139644\n",
      "[22]\tvalid_0's auc: 0.889783\tvalid_0's binary_logloss: 0.120226\tvalid_1's auc: 0.841265\tvalid_1's binary_logloss: 0.139524\n",
      "[23]\tvalid_0's auc: 0.891007\tvalid_0's binary_logloss: 0.119647\tvalid_1's auc: 0.840909\tvalid_1's binary_logloss: 0.139463\n",
      "[24]\tvalid_0's auc: 0.892111\tvalid_0's binary_logloss: 0.11912\tvalid_1's auc: 0.840884\tvalid_1's binary_logloss: 0.13939\n",
      "[25]\tvalid_0's auc: 0.892959\tvalid_0's binary_logloss: 0.118644\tvalid_1's auc: 0.840779\tvalid_1's binary_logloss: 0.139336\n",
      "[26]\tvalid_0's auc: 0.894356\tvalid_0's binary_logloss: 0.118128\tvalid_1's auc: 0.841299\tvalid_1's binary_logloss: 0.139198\n",
      "[27]\tvalid_0's auc: 0.895981\tvalid_0's binary_logloss: 0.117575\tvalid_1's auc: 0.8407\tvalid_1's binary_logloss: 0.139192\n",
      "[28]\tvalid_0's auc: 0.896969\tvalid_0's binary_logloss: 0.11709\tvalid_1's auc: 0.840437\tvalid_1's binary_logloss: 0.139222\n",
      "[29]\tvalid_0's auc: 0.898028\tvalid_0's binary_logloss: 0.116618\tvalid_1's auc: 0.840857\tvalid_1's binary_logloss: 0.139136\n",
      "[30]\tvalid_0's auc: 0.89908\tvalid_0's binary_logloss: 0.116142\tvalid_1's auc: 0.840827\tvalid_1's binary_logloss: 0.139074\n",
      "[31]\tvalid_0's auc: 0.900145\tvalid_0's binary_logloss: 0.115699\tvalid_1's auc: 0.840974\tvalid_1's binary_logloss: 0.138987\n",
      "[32]\tvalid_0's auc: 0.90112\tvalid_0's binary_logloss: 0.115215\tvalid_1's auc: 0.840942\tvalid_1's binary_logloss: 0.139024\n",
      "[33]\tvalid_0's auc: 0.901846\tvalid_0's binary_logloss: 0.114793\tvalid_1's auc: 0.840933\tvalid_1's binary_logloss: 0.13904\n",
      "[34]\tvalid_0's auc: 0.902883\tvalid_0's binary_logloss: 0.114387\tvalid_1's auc: 0.840844\tvalid_1's binary_logloss: 0.139066\n",
      "[35]\tvalid_0's auc: 0.903648\tvalid_0's binary_logloss: 0.113998\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.13901\n",
      "[36]\tvalid_0's auc: 0.905129\tvalid_0's binary_logloss: 0.113587\tvalid_1's auc: 0.840769\tvalid_1's binary_logloss: 0.139037\n",
      "[37]\tvalid_0's auc: 0.906133\tvalid_0's binary_logloss: 0.113131\tvalid_1's auc: 0.84035\tvalid_1's binary_logloss: 0.139137\n",
      "[38]\tvalid_0's auc: 0.907\tvalid_0's binary_logloss: 0.112813\tvalid_1's auc: 0.840254\tvalid_1's binary_logloss: 0.139186\n",
      "[39]\tvalid_0's auc: 0.907829\tvalid_0's binary_logloss: 0.112418\tvalid_1's auc: 0.84009\tvalid_1's binary_logloss: 0.139236\n",
      "[40]\tvalid_0's auc: 0.908551\tvalid_0's binary_logloss: 0.112078\tvalid_1's auc: 0.839874\tvalid_1's binary_logloss: 0.139313\n",
      "[41]\tvalid_0's auc: 0.909258\tvalid_0's binary_logloss: 0.111745\tvalid_1's auc: 0.839426\tvalid_1's binary_logloss: 0.139447\n",
      "[42]\tvalid_0's auc: 0.909875\tvalid_0's binary_logloss: 0.111354\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139428\n",
      "[43]\tvalid_0's auc: 0.910434\tvalid_0's binary_logloss: 0.111052\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.139483\n",
      "[44]\tvalid_0's auc: 0.911375\tvalid_0's binary_logloss: 0.110624\tvalid_1's auc: 0.839582\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.912055\tvalid_0's binary_logloss: 0.110372\tvalid_1's auc: 0.839536\tvalid_1's binary_logloss: 0.139546\n",
      "[46]\tvalid_0's auc: 0.912574\tvalid_0's binary_logloss: 0.110057\tvalid_1's auc: 0.83948\tvalid_1's binary_logloss: 0.139584\n",
      "[47]\tvalid_0's auc: 0.91302\tvalid_0's binary_logloss: 0.109723\tvalid_1's auc: 0.839228\tvalid_1's binary_logloss: 0.139685\n",
      "[48]\tvalid_0's auc: 0.913378\tvalid_0's binary_logloss: 0.109457\tvalid_1's auc: 0.839315\tvalid_1's binary_logloss: 0.139695\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.884494\tvalid_0's binary_logloss: 0.122936\tvalid_1's auc: 0.841739\tvalid_1's binary_logloss: 0.140193\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823879\tvalid_0's binary_logloss: 0.156213\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.16489\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829817\tvalid_0's binary_logloss: 0.151021\tvalid_1's auc: 0.825621\tvalid_1's binary_logloss: 0.159697\n",
      "[3]\tvalid_0's auc: 0.835232\tvalid_0's binary_logloss: 0.147177\tvalid_1's auc: 0.827536\tvalid_1's binary_logloss: 0.156048\n",
      "[4]\tvalid_0's auc: 0.83968\tvalid_0's binary_logloss: 0.144169\tvalid_1's auc: 0.829988\tvalid_1's binary_logloss: 0.15317\n",
      "[5]\tvalid_0's auc: 0.842369\tvalid_0's binary_logloss: 0.141776\tvalid_1's auc: 0.832821\tvalid_1's binary_logloss: 0.150835\n",
      "[6]\tvalid_0's auc: 0.845358\tvalid_0's binary_logloss: 0.13981\tvalid_1's auc: 0.835915\tvalid_1's binary_logloss: 0.148944\n",
      "[7]\tvalid_0's auc: 0.847188\tvalid_0's binary_logloss: 0.13809\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.147409\n",
      "[8]\tvalid_0's auc: 0.850075\tvalid_0's binary_logloss: 0.136655\tvalid_1's auc: 0.838523\tvalid_1's binary_logloss: 0.146144\n",
      "[9]\tvalid_0's auc: 0.851721\tvalid_0's binary_logloss: 0.135431\tvalid_1's auc: 0.839526\tvalid_1's binary_logloss: 0.14501\n",
      "[10]\tvalid_0's auc: 0.852681\tvalid_0's binary_logloss: 0.134272\tvalid_1's auc: 0.839568\tvalid_1's binary_logloss: 0.144144\n",
      "[11]\tvalid_0's auc: 0.853905\tvalid_0's binary_logloss: 0.133325\tvalid_1's auc: 0.839485\tvalid_1's binary_logloss: 0.143444\n",
      "[12]\tvalid_0's auc: 0.854971\tvalid_0's binary_logloss: 0.132446\tvalid_1's auc: 0.839402\tvalid_1's binary_logloss: 0.142813\n",
      "[13]\tvalid_0's auc: 0.857695\tvalid_0's binary_logloss: 0.131634\tvalid_1's auc: 0.839553\tvalid_1's binary_logloss: 0.142327\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[15]\tvalid_0's auc: 0.860717\tvalid_0's binary_logloss: 0.130253\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.141526\n",
      "[16]\tvalid_0's auc: 0.861684\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.839477\tvalid_1's binary_logloss: 0.141164\n",
      "[17]\tvalid_0's auc: 0.863005\tvalid_0's binary_logloss: 0.129116\tvalid_1's auc: 0.839652\tvalid_1's binary_logloss: 0.140811\n",
      "[18]\tvalid_0's auc: 0.864178\tvalid_0's binary_logloss: 0.128588\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140551\n",
      "[19]\tvalid_0's auc: 0.865462\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.838928\tvalid_1's binary_logloss: 0.140383\n",
      "[20]\tvalid_0's auc: 0.86641\tvalid_0's binary_logloss: 0.127645\tvalid_1's auc: 0.838283\tvalid_1's binary_logloss: 0.140237\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.127271\tvalid_1's auc: 0.838068\tvalid_1's binary_logloss: 0.140114\n",
      "[22]\tvalid_0's auc: 0.868689\tvalid_0's binary_logloss: 0.126832\tvalid_1's auc: 0.837975\tvalid_1's binary_logloss: 0.139969\n",
      "[23]\tvalid_0's auc: 0.869773\tvalid_0's binary_logloss: 0.126451\tvalid_1's auc: 0.837722\tvalid_1's binary_logloss: 0.139931\n",
      "[24]\tvalid_0's auc: 0.871205\tvalid_0's binary_logloss: 0.12605\tvalid_1's auc: 0.837453\tvalid_1's binary_logloss: 0.139824\n",
      "[25]\tvalid_0's auc: 0.871806\tvalid_0's binary_logloss: 0.125728\tvalid_1's auc: 0.837283\tvalid_1's binary_logloss: 0.13976\n",
      "[26]\tvalid_0's auc: 0.873412\tvalid_0's binary_logloss: 0.125313\tvalid_1's auc: 0.836946\tvalid_1's binary_logloss: 0.139742\n",
      "[27]\tvalid_0's auc: 0.874137\tvalid_0's binary_logloss: 0.124988\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.139799\n",
      "[28]\tvalid_0's auc: 0.874911\tvalid_0's binary_logloss: 0.124675\tvalid_1's auc: 0.836489\tvalid_1's binary_logloss: 0.139742\n",
      "[29]\tvalid_0's auc: 0.875538\tvalid_0's binary_logloss: 0.124397\tvalid_1's auc: 0.836554\tvalid_1's binary_logloss: 0.139712\n",
      "[30]\tvalid_0's auc: 0.876317\tvalid_0's binary_logloss: 0.124137\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.139716\n",
      "[31]\tvalid_0's auc: 0.87724\tvalid_0's binary_logloss: 0.123841\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.139683\n",
      "[32]\tvalid_0's auc: 0.877783\tvalid_0's binary_logloss: 0.123594\tvalid_1's auc: 0.835851\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878348\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.139824\n",
      "[34]\tvalid_0's auc: 0.878909\tvalid_0's binary_logloss: 0.123136\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.139745\n",
      "[35]\tvalid_0's auc: 0.879757\tvalid_0's binary_logloss: 0.122828\tvalid_1's auc: 0.835337\tvalid_1's binary_logloss: 0.139761\n",
      "[36]\tvalid_0's auc: 0.880504\tvalid_0's binary_logloss: 0.122572\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.139792\n",
      "[37]\tvalid_0's auc: 0.881015\tvalid_0's binary_logloss: 0.122349\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.139809\n",
      "[38]\tvalid_0's auc: 0.881565\tvalid_0's binary_logloss: 0.122148\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.139772\n",
      "[39]\tvalid_0's auc: 0.882176\tvalid_0's binary_logloss: 0.121925\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.13977\n",
      "[40]\tvalid_0's auc: 0.882818\tvalid_0's binary_logloss: 0.121683\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.139736\n",
      "[41]\tvalid_0's auc: 0.883353\tvalid_0's binary_logloss: 0.121428\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.139663\n",
      "[42]\tvalid_0's auc: 0.884062\tvalid_0's binary_logloss: 0.121195\tvalid_1's auc: 0.835313\tvalid_1's binary_logloss: 0.139727\n",
      "[43]\tvalid_0's auc: 0.884607\tvalid_0's binary_logloss: 0.120984\tvalid_1's auc: 0.835083\tvalid_1's binary_logloss: 0.139745\n",
      "[44]\tvalid_0's auc: 0.885155\tvalid_0's binary_logloss: 0.120752\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.139761\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.822096\tvalid_0's binary_logloss: 0.15642\tvalid_1's auc: 0.814231\tvalid_1's binary_logloss: 0.165423\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830899\tvalid_0's binary_logloss: 0.151112\tvalid_1's auc: 0.821277\tvalid_1's binary_logloss: 0.160161\n",
      "[3]\tvalid_0's auc: 0.83949\tvalid_0's binary_logloss: 0.147196\tvalid_1's auc: 0.828421\tvalid_1's binary_logloss: 0.156499\n",
      "[4]\tvalid_0's auc: 0.84292\tvalid_0's binary_logloss: 0.14418\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.153682\n",
      "[5]\tvalid_0's auc: 0.846745\tvalid_0's binary_logloss: 0.141793\tvalid_1's auc: 0.836391\tvalid_1's binary_logloss: 0.151366\n",
      "[6]\tvalid_0's auc: 0.849204\tvalid_0's binary_logloss: 0.139816\tvalid_1's auc: 0.838385\tvalid_1's binary_logloss: 0.149412\n",
      "[7]\tvalid_0's auc: 0.850163\tvalid_0's binary_logloss: 0.138129\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.147877\n",
      "[8]\tvalid_0's auc: 0.852051\tvalid_0's binary_logloss: 0.136672\tvalid_1's auc: 0.838308\tvalid_1's binary_logloss: 0.146579\n",
      "[9]\tvalid_0's auc: 0.853307\tvalid_0's binary_logloss: 0.13545\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.145501\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[11]\tvalid_0's auc: 0.855751\tvalid_0's binary_logloss: 0.133459\tvalid_1's auc: 0.839746\tvalid_1's binary_logloss: 0.143859\n",
      "[12]\tvalid_0's auc: 0.856423\tvalid_0's binary_logloss: 0.132613\tvalid_1's auc: 0.838761\tvalid_1's binary_logloss: 0.143262\n",
      "[13]\tvalid_0's auc: 0.857763\tvalid_0's binary_logloss: 0.131837\tvalid_1's auc: 0.838486\tvalid_1's binary_logloss: 0.142774\n",
      "[14]\tvalid_0's auc: 0.858818\tvalid_0's binary_logloss: 0.131136\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.142334\n",
      "[15]\tvalid_0's auc: 0.859873\tvalid_0's binary_logloss: 0.130476\tvalid_1's auc: 0.83747\tvalid_1's binary_logloss: 0.14209\n",
      "[16]\tvalid_0's auc: 0.86059\tvalid_0's binary_logloss: 0.129898\tvalid_1's auc: 0.837199\tvalid_1's binary_logloss: 0.141785\n",
      "[17]\tvalid_0's auc: 0.861469\tvalid_0's binary_logloss: 0.129391\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.141489\n",
      "[18]\tvalid_0's auc: 0.8626\tvalid_0's binary_logloss: 0.128887\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.141321\n",
      "[19]\tvalid_0's auc: 0.863942\tvalid_0's binary_logloss: 0.128362\tvalid_1's auc: 0.837273\tvalid_1's binary_logloss: 0.14108\n",
      "[20]\tvalid_0's auc: 0.865345\tvalid_0's binary_logloss: 0.12787\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.140905\n",
      "[21]\tvalid_0's auc: 0.866373\tvalid_0's binary_logloss: 0.127496\tvalid_1's auc: 0.838239\tvalid_1's binary_logloss: 0.140637\n",
      "[22]\tvalid_0's auc: 0.867435\tvalid_0's binary_logloss: 0.12708\tvalid_1's auc: 0.837639\tvalid_1's binary_logloss: 0.1406\n",
      "[23]\tvalid_0's auc: 0.868304\tvalid_0's binary_logloss: 0.12669\tvalid_1's auc: 0.837619\tvalid_1's binary_logloss: 0.140434\n",
      "[24]\tvalid_0's auc: 0.869271\tvalid_0's binary_logloss: 0.126307\tvalid_1's auc: 0.838019\tvalid_1's binary_logloss: 0.140281\n",
      "[25]\tvalid_0's auc: 0.870212\tvalid_0's binary_logloss: 0.125949\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.14025\n",
      "[26]\tvalid_0's auc: 0.871023\tvalid_0's binary_logloss: 0.125636\tvalid_1's auc: 0.837504\tvalid_1's binary_logloss: 0.140165\n",
      "[27]\tvalid_0's auc: 0.872756\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837762\tvalid_1's binary_logloss: 0.140044\n",
      "[28]\tvalid_0's auc: 0.874041\tvalid_0's binary_logloss: 0.124866\tvalid_1's auc: 0.837513\tvalid_1's binary_logloss: 0.14003\n",
      "[29]\tvalid_0's auc: 0.875088\tvalid_0's binary_logloss: 0.12452\tvalid_1's auc: 0.837397\tvalid_1's binary_logloss: 0.140013\n",
      "[30]\tvalid_0's auc: 0.876006\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.140044\n",
      "[31]\tvalid_0's auc: 0.876443\tvalid_0's binary_logloss: 0.123946\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.139984\n",
      "[32]\tvalid_0's auc: 0.877157\tvalid_0's binary_logloss: 0.123679\tvalid_1's auc: 0.837186\tvalid_1's binary_logloss: 0.139974\n",
      "[33]\tvalid_0's auc: 0.877846\tvalid_0's binary_logloss: 0.123426\tvalid_1's auc: 0.836741\tvalid_1's binary_logloss: 0.140021\n",
      "[34]\tvalid_0's auc: 0.879036\tvalid_0's binary_logloss: 0.123124\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.140057\n",
      "[35]\tvalid_0's auc: 0.879941\tvalid_0's binary_logloss: 0.12285\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.140035\n",
      "[36]\tvalid_0's auc: 0.880696\tvalid_0's binary_logloss: 0.122577\tvalid_1's auc: 0.836552\tvalid_1's binary_logloss: 0.140011\n",
      "[37]\tvalid_0's auc: 0.881398\tvalid_0's binary_logloss: 0.122348\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140062\n",
      "[38]\tvalid_0's auc: 0.882135\tvalid_0's binary_logloss: 0.122135\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.14006\n",
      "[39]\tvalid_0's auc: 0.882826\tvalid_0's binary_logloss: 0.121918\tvalid_1's auc: 0.836302\tvalid_1's binary_logloss: 0.140015\n",
      "[40]\tvalid_0's auc: 0.883347\tvalid_0's binary_logloss: 0.121692\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.139995\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.826319\tvalid_0's binary_logloss: 0.156309\tvalid_1's auc: 0.814027\tvalid_1's binary_logloss: 0.16516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.832276\tvalid_0's binary_logloss: 0.151075\tvalid_1's auc: 0.819879\tvalid_1's binary_logloss: 0.160057\n",
      "[3]\tvalid_0's auc: 0.836968\tvalid_0's binary_logloss: 0.147259\tvalid_1's auc: 0.825144\tvalid_1's binary_logloss: 0.156367\n",
      "[4]\tvalid_0's auc: 0.840937\tvalid_0's binary_logloss: 0.144237\tvalid_1's auc: 0.830372\tvalid_1's binary_logloss: 0.153364\n",
      "[5]\tvalid_0's auc: 0.845178\tvalid_0's binary_logloss: 0.141851\tvalid_1's auc: 0.835122\tvalid_1's binary_logloss: 0.151017\n",
      "[6]\tvalid_0's auc: 0.846202\tvalid_0's binary_logloss: 0.139881\tvalid_1's auc: 0.835139\tvalid_1's binary_logloss: 0.149202\n",
      "[7]\tvalid_0's auc: 0.849501\tvalid_0's binary_logloss: 0.13816\tvalid_1's auc: 0.838439\tvalid_1's binary_logloss: 0.147646\n",
      "[8]\tvalid_0's auc: 0.850898\tvalid_0's binary_logloss: 0.136639\tvalid_1's auc: 0.838862\tvalid_1's binary_logloss: 0.146267\n",
      "[9]\tvalid_0's auc: 0.85237\tvalid_0's binary_logloss: 0.135394\tvalid_1's auc: 0.838585\tvalid_1's binary_logloss: 0.145261\n",
      "[10]\tvalid_0's auc: 0.855108\tvalid_0's binary_logloss: 0.134315\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.144377\n",
      "[11]\tvalid_0's auc: 0.856895\tvalid_0's binary_logloss: 0.133347\tvalid_1's auc: 0.837858\tvalid_1's binary_logloss: 0.143552\n",
      "[12]\tvalid_0's auc: 0.857593\tvalid_0's binary_logloss: 0.132493\tvalid_1's auc: 0.837734\tvalid_1's binary_logloss: 0.14288\n",
      "[13]\tvalid_0's auc: 0.85875\tvalid_0's binary_logloss: 0.131727\tvalid_1's auc: 0.838214\tvalid_1's binary_logloss: 0.142368\n",
      "[14]\tvalid_0's auc: 0.859561\tvalid_0's binary_logloss: 0.131032\tvalid_1's auc: 0.837766\tvalid_1's binary_logloss: 0.14195\n",
      "[15]\tvalid_0's auc: 0.860666\tvalid_0's binary_logloss: 0.130386\tvalid_1's auc: 0.837751\tvalid_1's binary_logloss: 0.141607\n",
      "[16]\tvalid_0's auc: 0.861555\tvalid_0's binary_logloss: 0.129851\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.14128\n",
      "[17]\tvalid_0's auc: 0.863042\tvalid_0's binary_logloss: 0.129232\tvalid_1's auc: 0.83902\tvalid_1's binary_logloss: 0.141008\n",
      "[18]\tvalid_0's auc: 0.864262\tvalid_0's binary_logloss: 0.128631\tvalid_1's auc: 0.839058\tvalid_1's binary_logloss: 0.140747\n",
      "[19]\tvalid_0's auc: 0.86545\tvalid_0's binary_logloss: 0.128138\tvalid_1's auc: 0.838753\tvalid_1's binary_logloss: 0.140544\n",
      "[20]\tvalid_0's auc: 0.8663\tvalid_0's binary_logloss: 0.12769\tvalid_1's auc: 0.83863\tvalid_1's binary_logloss: 0.140304\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[22]\tvalid_0's auc: 0.868709\tvalid_0's binary_logloss: 0.126813\tvalid_1's auc: 0.839171\tvalid_1's binary_logloss: 0.14001\n",
      "[23]\tvalid_0's auc: 0.869543\tvalid_0's binary_logloss: 0.126412\tvalid_1's auc: 0.839032\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.870296\tvalid_0's binary_logloss: 0.126025\tvalid_1's auc: 0.839048\tvalid_1's binary_logloss: 0.139785\n",
      "[25]\tvalid_0's auc: 0.871119\tvalid_0's binary_logloss: 0.125654\tvalid_1's auc: 0.83856\tvalid_1's binary_logloss: 0.139743\n",
      "[26]\tvalid_0's auc: 0.871934\tvalid_0's binary_logloss: 0.12537\tvalid_1's auc: 0.838594\tvalid_1's binary_logloss: 0.139669\n",
      "[27]\tvalid_0's auc: 0.873048\tvalid_0's binary_logloss: 0.125049\tvalid_1's auc: 0.83847\tvalid_1's binary_logloss: 0.139655\n",
      "[28]\tvalid_0's auc: 0.873824\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.838229\tvalid_1's binary_logloss: 0.139655\n",
      "[29]\tvalid_0's auc: 0.874662\tvalid_0's binary_logloss: 0.124467\tvalid_1's auc: 0.838445\tvalid_1's binary_logloss: 0.139579\n",
      "[30]\tvalid_0's auc: 0.87542\tvalid_0's binary_logloss: 0.124168\tvalid_1's auc: 0.838156\tvalid_1's binary_logloss: 0.139548\n",
      "[31]\tvalid_0's auc: 0.876207\tvalid_0's binary_logloss: 0.123915\tvalid_1's auc: 0.838237\tvalid_1's binary_logloss: 0.139538\n",
      "[32]\tvalid_0's auc: 0.877156\tvalid_0's binary_logloss: 0.123623\tvalid_1's auc: 0.838271\tvalid_1's binary_logloss: 0.13947\n",
      "[33]\tvalid_0's auc: 0.87768\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.838713\tvalid_1's binary_logloss: 0.139346\n",
      "[34]\tvalid_0's auc: 0.87849\tvalid_0's binary_logloss: 0.123137\tvalid_1's auc: 0.838649\tvalid_1's binary_logloss: 0.139374\n",
      "[35]\tvalid_0's auc: 0.879407\tvalid_0's binary_logloss: 0.122839\tvalid_1's auc: 0.838892\tvalid_1's binary_logloss: 0.139274\n",
      "[36]\tvalid_0's auc: 0.879965\tvalid_0's binary_logloss: 0.122622\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.139304\n",
      "[37]\tvalid_0's auc: 0.880613\tvalid_0's binary_logloss: 0.122331\tvalid_1's auc: 0.839029\tvalid_1's binary_logloss: 0.139242\n",
      "[38]\tvalid_0's auc: 0.881276\tvalid_0's binary_logloss: 0.122084\tvalid_1's auc: 0.838779\tvalid_1's binary_logloss: 0.139277\n",
      "[39]\tvalid_0's auc: 0.881947\tvalid_0's binary_logloss: 0.121841\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139295\n",
      "[40]\tvalid_0's auc: 0.882617\tvalid_0's binary_logloss: 0.121559\tvalid_1's auc: 0.838919\tvalid_1's binary_logloss: 0.13924\n",
      "[41]\tvalid_0's auc: 0.883227\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.838817\tvalid_1's binary_logloss: 0.13925\n",
      "[42]\tvalid_0's auc: 0.883844\tvalid_0's binary_logloss: 0.121097\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.139244\n",
      "[43]\tvalid_0's auc: 0.884188\tvalid_0's binary_logloss: 0.12095\tvalid_1's auc: 0.838842\tvalid_1's binary_logloss: 0.139242\n",
      "[44]\tvalid_0's auc: 0.884844\tvalid_0's binary_logloss: 0.120718\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.139282\n",
      "[45]\tvalid_0's auc: 0.885417\tvalid_0's binary_logloss: 0.120493\tvalid_1's auc: 0.838678\tvalid_1's binary_logloss: 0.139288\n",
      "[46]\tvalid_0's auc: 0.885803\tvalid_0's binary_logloss: 0.120327\tvalid_1's auc: 0.838716\tvalid_1's binary_logloss: 0.139279\n",
      "[47]\tvalid_0's auc: 0.886486\tvalid_0's binary_logloss: 0.120099\tvalid_1's auc: 0.838668\tvalid_1's binary_logloss: 0.139274\n",
      "[48]\tvalid_0's auc: 0.887253\tvalid_0's binary_logloss: 0.119903\tvalid_1's auc: 0.838451\tvalid_1's binary_logloss: 0.139321\n",
      "[49]\tvalid_0's auc: 0.887742\tvalid_0's binary_logloss: 0.11971\tvalid_1's auc: 0.838484\tvalid_1's binary_logloss: 0.139332\n",
      "[50]\tvalid_0's auc: 0.888224\tvalid_0's binary_logloss: 0.119543\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139353\n",
      "[51]\tvalid_0's auc: 0.888667\tvalid_0's binary_logloss: 0.11938\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.1394\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823467\tvalid_0's binary_logloss: 0.156234\tvalid_1's auc: 0.818359\tvalid_1's binary_logloss: 0.165045\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.831432\tvalid_0's binary_logloss: 0.151096\tvalid_1's auc: 0.822806\tvalid_1's binary_logloss: 0.160035\n",
      "[3]\tvalid_0's auc: 0.837942\tvalid_0's binary_logloss: 0.147265\tvalid_1's auc: 0.827733\tvalid_1's binary_logloss: 0.156278\n",
      "[4]\tvalid_0's auc: 0.842228\tvalid_0's binary_logloss: 0.144266\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.153439\n",
      "[5]\tvalid_0's auc: 0.845913\tvalid_0's binary_logloss: 0.141908\tvalid_1's auc: 0.836078\tvalid_1's binary_logloss: 0.151112\n",
      "[6]\tvalid_0's auc: 0.847301\tvalid_0's binary_logloss: 0.139924\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.149212\n",
      "[7]\tvalid_0's auc: 0.848494\tvalid_0's binary_logloss: 0.138267\tvalid_1's auc: 0.837664\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.849608\tvalid_0's binary_logloss: 0.136839\tvalid_1's auc: 0.839054\tvalid_1's binary_logloss: 0.146332\n",
      "[9]\tvalid_0's auc: 0.851401\tvalid_0's binary_logloss: 0.135609\tvalid_1's auc: 0.839453\tvalid_1's binary_logloss: 0.145351\n",
      "[10]\tvalid_0's auc: 0.852795\tvalid_0's binary_logloss: 0.134534\tvalid_1's auc: 0.840274\tvalid_1's binary_logloss: 0.144391\n",
      "[11]\tvalid_0's auc: 0.853993\tvalid_0's binary_logloss: 0.133621\tvalid_1's auc: 0.840484\tvalid_1's binary_logloss: 0.143622\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[13]\tvalid_0's auc: 0.857408\tvalid_0's binary_logloss: 0.131982\tvalid_1's auc: 0.840313\tvalid_1's binary_logloss: 0.142428\n",
      "[14]\tvalid_0's auc: 0.858394\tvalid_0's binary_logloss: 0.131254\tvalid_1's auc: 0.840441\tvalid_1's binary_logloss: 0.141892\n",
      "[15]\tvalid_0's auc: 0.859543\tvalid_0's binary_logloss: 0.130617\tvalid_1's auc: 0.840527\tvalid_1's binary_logloss: 0.141536\n",
      "[16]\tvalid_0's auc: 0.860896\tvalid_0's binary_logloss: 0.130045\tvalid_1's auc: 0.839976\tvalid_1's binary_logloss: 0.141199\n",
      "[17]\tvalid_0's auc: 0.862165\tvalid_0's binary_logloss: 0.129495\tvalid_1's auc: 0.840423\tvalid_1's binary_logloss: 0.140913\n",
      "[18]\tvalid_0's auc: 0.863167\tvalid_0's binary_logloss: 0.128982\tvalid_1's auc: 0.840347\tvalid_1's binary_logloss: 0.140622\n",
      "[19]\tvalid_0's auc: 0.864691\tvalid_0's binary_logloss: 0.128474\tvalid_1's auc: 0.840438\tvalid_1's binary_logloss: 0.140372\n",
      "[20]\tvalid_0's auc: 0.865493\tvalid_0's binary_logloss: 0.128073\tvalid_1's auc: 0.840373\tvalid_1's binary_logloss: 0.140128\n",
      "[21]\tvalid_0's auc: 0.866463\tvalid_0's binary_logloss: 0.127636\tvalid_1's auc: 0.840418\tvalid_1's binary_logloss: 0.139909\n",
      "[22]\tvalid_0's auc: 0.867081\tvalid_0's binary_logloss: 0.12726\tvalid_1's auc: 0.840315\tvalid_1's binary_logloss: 0.139758\n",
      "[23]\tvalid_0's auc: 0.867656\tvalid_0's binary_logloss: 0.126888\tvalid_1's auc: 0.839878\tvalid_1's binary_logloss: 0.139751\n",
      "[24]\tvalid_0's auc: 0.868511\tvalid_0's binary_logloss: 0.12652\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.13964\n",
      "[25]\tvalid_0's auc: 0.869233\tvalid_0's binary_logloss: 0.126158\tvalid_1's auc: 0.840131\tvalid_1's binary_logloss: 0.139495\n",
      "[26]\tvalid_0's auc: 0.870146\tvalid_0's binary_logloss: 0.12583\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139487\n",
      "[27]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.125495\tvalid_1's auc: 0.83977\tvalid_1's binary_logloss: 0.139452\n",
      "[28]\tvalid_0's auc: 0.872449\tvalid_0's binary_logloss: 0.125203\tvalid_1's auc: 0.839707\tvalid_1's binary_logloss: 0.139417\n",
      "[29]\tvalid_0's auc: 0.87307\tvalid_0's binary_logloss: 0.124902\tvalid_1's auc: 0.840062\tvalid_1's binary_logloss: 0.13934\n",
      "[30]\tvalid_0's auc: 0.874009\tvalid_0's binary_logloss: 0.124599\tvalid_1's auc: 0.839797\tvalid_1's binary_logloss: 0.139335\n",
      "[31]\tvalid_0's auc: 0.874961\tvalid_0's binary_logloss: 0.124243\tvalid_1's auc: 0.839401\tvalid_1's binary_logloss: 0.139341\n",
      "[32]\tvalid_0's auc: 0.875534\tvalid_0's binary_logloss: 0.12399\tvalid_1's auc: 0.839344\tvalid_1's binary_logloss: 0.139318\n",
      "[33]\tvalid_0's auc: 0.876073\tvalid_0's binary_logloss: 0.12375\tvalid_1's auc: 0.839413\tvalid_1's binary_logloss: 0.139291\n",
      "[34]\tvalid_0's auc: 0.876721\tvalid_0's binary_logloss: 0.123522\tvalid_1's auc: 0.839706\tvalid_1's binary_logloss: 0.139235\n",
      "[35]\tvalid_0's auc: 0.877275\tvalid_0's binary_logloss: 0.123252\tvalid_1's auc: 0.840335\tvalid_1's binary_logloss: 0.139044\n",
      "[36]\tvalid_0's auc: 0.877922\tvalid_0's binary_logloss: 0.123055\tvalid_1's auc: 0.840293\tvalid_1's binary_logloss: 0.13902\n",
      "[37]\tvalid_0's auc: 0.878499\tvalid_0's binary_logloss: 0.122801\tvalid_1's auc: 0.840333\tvalid_1's binary_logloss: 0.138988\n",
      "[38]\tvalid_0's auc: 0.879297\tvalid_0's binary_logloss: 0.122522\tvalid_1's auc: 0.840156\tvalid_1's binary_logloss: 0.139034\n",
      "[39]\tvalid_0's auc: 0.880019\tvalid_0's binary_logloss: 0.122297\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.138997\n",
      "[40]\tvalid_0's auc: 0.88064\tvalid_0's binary_logloss: 0.122051\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.139001\n",
      "[41]\tvalid_0's auc: 0.88151\tvalid_0's binary_logloss: 0.121784\tvalid_1's auc: 0.839739\tvalid_1's binary_logloss: 0.13906\n",
      "[42]\tvalid_0's auc: 0.882288\tvalid_0's binary_logloss: 0.121573\tvalid_1's auc: 0.839558\tvalid_1's binary_logloss: 0.139089\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.822477\tvalid_0's binary_logloss: 0.156615\tvalid_1's auc: 0.818936\tvalid_1's binary_logloss: 0.16507\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829931\tvalid_0's binary_logloss: 0.151227\tvalid_1's auc: 0.824213\tvalid_1's binary_logloss: 0.159973\n",
      "[3]\tvalid_0's auc: 0.835788\tvalid_0's binary_logloss: 0.147372\tvalid_1's auc: 0.829555\tvalid_1's binary_logloss: 0.156407\n",
      "[4]\tvalid_0's auc: 0.842398\tvalid_0's binary_logloss: 0.14436\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.153426\n",
      "[5]\tvalid_0's auc: 0.84472\tvalid_0's binary_logloss: 0.141969\tvalid_1's auc: 0.835438\tvalid_1's binary_logloss: 0.15118\n",
      "[6]\tvalid_0's auc: 0.846873\tvalid_0's binary_logloss: 0.13984\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.149232\n",
      "[7]\tvalid_0's auc: 0.849397\tvalid_0's binary_logloss: 0.138081\tvalid_1's auc: 0.838165\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.850636\tvalid_0's binary_logloss: 0.136651\tvalid_1's auc: 0.839203\tvalid_1's binary_logloss: 0.146397\n",
      "[9]\tvalid_0's auc: 0.852058\tvalid_0's binary_logloss: 0.135397\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.145335\n",
      "[10]\tvalid_0's auc: 0.853752\tvalid_0's binary_logloss: 0.134296\tvalid_1's auc: 0.840124\tvalid_1's binary_logloss: 0.144474\n",
      "[11]\tvalid_0's auc: 0.855331\tvalid_0's binary_logloss: 0.133348\tvalid_1's auc: 0.839897\tvalid_1's binary_logloss: 0.143725\n",
      "[12]\tvalid_0's auc: 0.857453\tvalid_0's binary_logloss: 0.13245\tvalid_1's auc: 0.84039\tvalid_1's binary_logloss: 0.143067\n",
      "[13]\tvalid_0's auc: 0.858781\tvalid_0's binary_logloss: 0.131689\tvalid_1's auc: 0.840851\tvalid_1's binary_logloss: 0.14244\n",
      "[14]\tvalid_0's auc: 0.860635\tvalid_0's binary_logloss: 0.130982\tvalid_1's auc: 0.840623\tvalid_1's binary_logloss: 0.141945\n",
      "[15]\tvalid_0's auc: 0.861771\tvalid_0's binary_logloss: 0.130283\tvalid_1's auc: 0.84085\tvalid_1's binary_logloss: 0.141501\n",
      "[16]\tvalid_0's auc: 0.863226\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.840816\tvalid_1's binary_logloss: 0.14118\n",
      "[17]\tvalid_0's auc: 0.864022\tvalid_0's binary_logloss: 0.129132\tvalid_1's auc: 0.841034\tvalid_1's binary_logloss: 0.140867\n",
      "[18]\tvalid_0's auc: 0.865122\tvalid_0's binary_logloss: 0.128586\tvalid_1's auc: 0.841066\tvalid_1's binary_logloss: 0.140645\n",
      "[19]\tvalid_0's auc: 0.866114\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.841164\tvalid_1's binary_logloss: 0.140459\n",
      "[20]\tvalid_0's auc: 0.86733\tvalid_0's binary_logloss: 0.127618\tvalid_1's auc: 0.841078\tvalid_1's binary_logloss: 0.140192\n",
      "[21]\tvalid_0's auc: 0.86847\tvalid_0's binary_logloss: 0.12718\tvalid_1's auc: 0.842056\tvalid_1's binary_logloss: 0.139899\n",
      "[22]\tvalid_0's auc: 0.86912\tvalid_0's binary_logloss: 0.126786\tvalid_1's auc: 0.842604\tvalid_1's binary_logloss: 0.139581\n",
      "[23]\tvalid_0's auc: 0.8702\tvalid_0's binary_logloss: 0.1264\tvalid_1's auc: 0.842923\tvalid_1's binary_logloss: 0.13938\n",
      "[24]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.126012\tvalid_1's auc: 0.842853\tvalid_1's binary_logloss: 0.139199\n",
      "[25]\tvalid_0's auc: 0.871861\tvalid_0's binary_logloss: 0.125716\tvalid_1's auc: 0.842924\tvalid_1's binary_logloss: 0.139114\n",
      "[26]\tvalid_0's auc: 0.872932\tvalid_0's binary_logloss: 0.125379\tvalid_1's auc: 0.842821\tvalid_1's binary_logloss: 0.139002\n",
      "[27]\tvalid_0's auc: 0.873488\tvalid_0's binary_logloss: 0.125055\tvalid_1's auc: 0.842803\tvalid_1's binary_logloss: 0.138866\n",
      "[28]\tvalid_0's auc: 0.874282\tvalid_0's binary_logloss: 0.124763\tvalid_1's auc: 0.842697\tvalid_1's binary_logloss: 0.138796\n",
      "[29]\tvalid_0's auc: 0.875185\tvalid_0's binary_logloss: 0.124481\tvalid_1's auc: 0.843506\tvalid_1's binary_logloss: 0.138625\n",
      "[30]\tvalid_0's auc: 0.875805\tvalid_0's binary_logloss: 0.124216\tvalid_1's auc: 0.843564\tvalid_1's binary_logloss: 0.138532\n",
      "[31]\tvalid_0's auc: 0.877289\tvalid_0's binary_logloss: 0.123898\tvalid_1's auc: 0.84385\tvalid_1's binary_logloss: 0.138455\n",
      "[32]\tvalid_0's auc: 0.878137\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.843943\tvalid_1's binary_logloss: 0.138401\n",
      "[33]\tvalid_0's auc: 0.879141\tvalid_0's binary_logloss: 0.123349\tvalid_1's auc: 0.843945\tvalid_1's binary_logloss: 0.13837\n",
      "[34]\tvalid_0's auc: 0.879829\tvalid_0's binary_logloss: 0.123074\tvalid_1's auc: 0.844035\tvalid_1's binary_logloss: 0.13828\n",
      "[35]\tvalid_0's auc: 0.880826\tvalid_0's binary_logloss: 0.122813\tvalid_1's auc: 0.844275\tvalid_1's binary_logloss: 0.138226\n",
      "[36]\tvalid_0's auc: 0.881493\tvalid_0's binary_logloss: 0.122554\tvalid_1's auc: 0.844344\tvalid_1's binary_logloss: 0.138161\n",
      "[37]\tvalid_0's auc: 0.882368\tvalid_0's binary_logloss: 0.122305\tvalid_1's auc: 0.844143\tvalid_1's binary_logloss: 0.138162\n",
      "[38]\tvalid_0's auc: 0.882945\tvalid_0's binary_logloss: 0.122019\tvalid_1's auc: 0.844149\tvalid_1's binary_logloss: 0.13813\n",
      "[39]\tvalid_0's auc: 0.883584\tvalid_0's binary_logloss: 0.121799\tvalid_1's auc: 0.843977\tvalid_1's binary_logloss: 0.138149\n",
      "[40]\tvalid_0's auc: 0.88416\tvalid_0's binary_logloss: 0.121576\tvalid_1's auc: 0.844146\tvalid_1's binary_logloss: 0.138147\n",
      "[41]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.12135\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138128\n",
      "[42]\tvalid_0's auc: 0.885638\tvalid_0's binary_logloss: 0.121096\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138106\n",
      "[43]\tvalid_0's auc: 0.886395\tvalid_0's binary_logloss: 0.120905\tvalid_1's auc: 0.844184\tvalid_1's binary_logloss: 0.138052\n",
      "[44]\tvalid_0's auc: 0.887071\tvalid_0's binary_logloss: 0.120678\tvalid_1's auc: 0.844103\tvalid_1's binary_logloss: 0.138065\n",
      "[45]\tvalid_0's auc: 0.887784\tvalid_0's binary_logloss: 0.120428\tvalid_1's auc: 0.844152\tvalid_1's binary_logloss: 0.138057\n",
      "[46]\tvalid_0's auc: 0.888342\tvalid_0's binary_logloss: 0.120223\tvalid_1's auc: 0.844297\tvalid_1's binary_logloss: 0.138025\n",
      "[47]\tvalid_0's auc: 0.888722\tvalid_0's binary_logloss: 0.119986\tvalid_1's auc: 0.844276\tvalid_1's binary_logloss: 0.138002\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[49]\tvalid_0's auc: 0.889545\tvalid_0's binary_logloss: 0.119601\tvalid_1's auc: 0.844447\tvalid_1's binary_logloss: 0.138002\n",
      "[50]\tvalid_0's auc: 0.89018\tvalid_0's binary_logloss: 0.119358\tvalid_1's auc: 0.844336\tvalid_1's binary_logloss: 0.138021\n",
      "[51]\tvalid_0's auc: 0.890603\tvalid_0's binary_logloss: 0.119182\tvalid_1's auc: 0.84438\tvalid_1's binary_logloss: 0.138019\n",
      "[52]\tvalid_0's auc: 0.891517\tvalid_0's binary_logloss: 0.118924\tvalid_1's auc: 0.844393\tvalid_1's binary_logloss: 0.13803\n",
      "[53]\tvalid_0's auc: 0.891938\tvalid_0's binary_logloss: 0.118749\tvalid_1's auc: 0.844183\tvalid_1's binary_logloss: 0.138086\n",
      "[54]\tvalid_0's auc: 0.892252\tvalid_0's binary_logloss: 0.118601\tvalid_1's auc: 0.844352\tvalid_1's binary_logloss: 0.138077\n",
      "[55]\tvalid_0's auc: 0.892749\tvalid_0's binary_logloss: 0.118391\tvalid_1's auc: 0.84432\tvalid_1's binary_logloss: 0.138057\n",
      "[56]\tvalid_0's auc: 0.893267\tvalid_0's binary_logloss: 0.118246\tvalid_1's auc: 0.844305\tvalid_1's binary_logloss: 0.138061\n",
      "[57]\tvalid_0's auc: 0.893589\tvalid_0's binary_logloss: 0.118094\tvalid_1's auc: 0.844225\tvalid_1's binary_logloss: 0.138064\n",
      "[58]\tvalid_0's auc: 0.89387\tvalid_0's binary_logloss: 0.117959\tvalid_1's auc: 0.844327\tvalid_1's binary_logloss: 0.138044\n",
      "[59]\tvalid_0's auc: 0.894196\tvalid_0's binary_logloss: 0.117784\tvalid_1's auc: 0.844144\tvalid_1's binary_logloss: 0.138088\n",
      "[60]\tvalid_0's auc: 0.894754\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.843942\tvalid_1's binary_logloss: 0.138136\n",
      "[61]\tvalid_0's auc: 0.895224\tvalid_0's binary_logloss: 0.117358\tvalid_1's auc: 0.844107\tvalid_1's binary_logloss: 0.138135\n",
      "[62]\tvalid_0's auc: 0.895747\tvalid_0's binary_logloss: 0.117116\tvalid_1's auc: 0.844033\tvalid_1's binary_logloss: 0.138143\n",
      "[63]\tvalid_0's auc: 0.896042\tvalid_0's binary_logloss: 0.116934\tvalid_1's auc: 0.844057\tvalid_1's binary_logloss: 0.138188\n",
      "[64]\tvalid_0's auc: 0.89648\tvalid_0's binary_logloss: 0.116742\tvalid_1's auc: 0.843882\tvalid_1's binary_logloss: 0.138258\n",
      "[65]\tvalid_0's auc: 0.8968\tvalid_0's binary_logloss: 0.116596\tvalid_1's auc: 0.843553\tvalid_1's binary_logloss: 0.138317\n",
      "[66]\tvalid_0's auc: 0.89727\tvalid_0's binary_logloss: 0.116455\tvalid_1's auc: 0.843435\tvalid_1's binary_logloss: 0.138362\n",
      "[67]\tvalid_0's auc: 0.897643\tvalid_0's binary_logloss: 0.11627\tvalid_1's auc: 0.843148\tvalid_1's binary_logloss: 0.138424\n",
      "[68]\tvalid_0's auc: 0.898008\tvalid_0's binary_logloss: 0.116079\tvalid_1's auc: 0.843355\tvalid_1's binary_logloss: 0.138452\n",
      "[69]\tvalid_0's auc: 0.898293\tvalid_0's binary_logloss: 0.115943\tvalid_1's auc: 0.843203\tvalid_1's binary_logloss: 0.138515\n",
      "[70]\tvalid_0's auc: 0.898585\tvalid_0's binary_logloss: 0.115794\tvalid_1's auc: 0.84311\tvalid_1's binary_logloss: 0.138551\n",
      "[71]\tvalid_0's auc: 0.898878\tvalid_0's binary_logloss: 0.115634\tvalid_1's auc: 0.843163\tvalid_1's binary_logloss: 0.138557\n",
      "[72]\tvalid_0's auc: 0.89933\tvalid_0's binary_logloss: 0.11544\tvalid_1's auc: 0.843123\tvalid_1's binary_logloss: 0.138587\n",
      "[73]\tvalid_0's auc: 0.899665\tvalid_0's binary_logloss: 0.115279\tvalid_1's auc: 0.843158\tvalid_1's binary_logloss: 0.138606\n",
      "[74]\tvalid_0's auc: 0.899872\tvalid_0's binary_logloss: 0.115145\tvalid_1's auc: 0.843153\tvalid_1's binary_logloss: 0.138622\n",
      "[75]\tvalid_0's auc: 0.900318\tvalid_0's binary_logloss: 0.115012\tvalid_1's auc: 0.8431\tvalid_1's binary_logloss: 0.138652\n",
      "[76]\tvalid_0's auc: 0.900838\tvalid_0's binary_logloss: 0.114797\tvalid_1's auc: 0.843128\tvalid_1's binary_logloss: 0.138654\n",
      "[77]\tvalid_0's auc: 0.901053\tvalid_0's binary_logloss: 0.11465\tvalid_1's auc: 0.843183\tvalid_1's binary_logloss: 0.138667\n",
      "[78]\tvalid_0's auc: 0.901334\tvalid_0's binary_logloss: 0.114492\tvalid_1's auc: 0.843036\tvalid_1's binary_logloss: 0.138728\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.823879\tvalid_0's binary_logloss: 0.156213\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.16489\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829817\tvalid_0's binary_logloss: 0.151021\tvalid_1's auc: 0.825621\tvalid_1's binary_logloss: 0.159697\n",
      "[3]\tvalid_0's auc: 0.835232\tvalid_0's binary_logloss: 0.147177\tvalid_1's auc: 0.827536\tvalid_1's binary_logloss: 0.156048\n",
      "[4]\tvalid_0's auc: 0.83968\tvalid_0's binary_logloss: 0.144169\tvalid_1's auc: 0.829988\tvalid_1's binary_logloss: 0.15317\n",
      "[5]\tvalid_0's auc: 0.842369\tvalid_0's binary_logloss: 0.141776\tvalid_1's auc: 0.832821\tvalid_1's binary_logloss: 0.150835\n",
      "[6]\tvalid_0's auc: 0.845358\tvalid_0's binary_logloss: 0.13981\tvalid_1's auc: 0.835915\tvalid_1's binary_logloss: 0.148944\n",
      "[7]\tvalid_0's auc: 0.847188\tvalid_0's binary_logloss: 0.13809\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.147409\n",
      "[8]\tvalid_0's auc: 0.850075\tvalid_0's binary_logloss: 0.136655\tvalid_1's auc: 0.838523\tvalid_1's binary_logloss: 0.146144\n",
      "[9]\tvalid_0's auc: 0.851721\tvalid_0's binary_logloss: 0.135431\tvalid_1's auc: 0.839526\tvalid_1's binary_logloss: 0.14501\n",
      "[10]\tvalid_0's auc: 0.852681\tvalid_0's binary_logloss: 0.134272\tvalid_1's auc: 0.839568\tvalid_1's binary_logloss: 0.144144\n",
      "[11]\tvalid_0's auc: 0.853905\tvalid_0's binary_logloss: 0.133325\tvalid_1's auc: 0.839485\tvalid_1's binary_logloss: 0.143444\n",
      "[12]\tvalid_0's auc: 0.854971\tvalid_0's binary_logloss: 0.132446\tvalid_1's auc: 0.839402\tvalid_1's binary_logloss: 0.142813\n",
      "[13]\tvalid_0's auc: 0.857695\tvalid_0's binary_logloss: 0.131634\tvalid_1's auc: 0.839553\tvalid_1's binary_logloss: 0.142327\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[15]\tvalid_0's auc: 0.860717\tvalid_0's binary_logloss: 0.130253\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.141526\n",
      "[16]\tvalid_0's auc: 0.861684\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.839477\tvalid_1's binary_logloss: 0.141164\n",
      "[17]\tvalid_0's auc: 0.863005\tvalid_0's binary_logloss: 0.129116\tvalid_1's auc: 0.839652\tvalid_1's binary_logloss: 0.140811\n",
      "[18]\tvalid_0's auc: 0.864178\tvalid_0's binary_logloss: 0.128588\tvalid_1's auc: 0.839359\tvalid_1's binary_logloss: 0.140551\n",
      "[19]\tvalid_0's auc: 0.865462\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.838928\tvalid_1's binary_logloss: 0.140383\n",
      "[20]\tvalid_0's auc: 0.86641\tvalid_0's binary_logloss: 0.127645\tvalid_1's auc: 0.838283\tvalid_1's binary_logloss: 0.140237\n",
      "[21]\tvalid_0's auc: 0.867294\tvalid_0's binary_logloss: 0.127271\tvalid_1's auc: 0.838068\tvalid_1's binary_logloss: 0.140114\n",
      "[22]\tvalid_0's auc: 0.868689\tvalid_0's binary_logloss: 0.126832\tvalid_1's auc: 0.837975\tvalid_1's binary_logloss: 0.139969\n",
      "[23]\tvalid_0's auc: 0.869773\tvalid_0's binary_logloss: 0.126451\tvalid_1's auc: 0.837722\tvalid_1's binary_logloss: 0.139931\n",
      "[24]\tvalid_0's auc: 0.871205\tvalid_0's binary_logloss: 0.12605\tvalid_1's auc: 0.837453\tvalid_1's binary_logloss: 0.139824\n",
      "[25]\tvalid_0's auc: 0.871806\tvalid_0's binary_logloss: 0.125728\tvalid_1's auc: 0.837283\tvalid_1's binary_logloss: 0.13976\n",
      "[26]\tvalid_0's auc: 0.873412\tvalid_0's binary_logloss: 0.125313\tvalid_1's auc: 0.836946\tvalid_1's binary_logloss: 0.139742\n",
      "[27]\tvalid_0's auc: 0.874137\tvalid_0's binary_logloss: 0.124988\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.139799\n",
      "[28]\tvalid_0's auc: 0.874911\tvalid_0's binary_logloss: 0.124675\tvalid_1's auc: 0.836489\tvalid_1's binary_logloss: 0.139742\n",
      "[29]\tvalid_0's auc: 0.875538\tvalid_0's binary_logloss: 0.124397\tvalid_1's auc: 0.836554\tvalid_1's binary_logloss: 0.139712\n",
      "[30]\tvalid_0's auc: 0.876317\tvalid_0's binary_logloss: 0.124137\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.139716\n",
      "[31]\tvalid_0's auc: 0.87724\tvalid_0's binary_logloss: 0.123841\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.139683\n",
      "[32]\tvalid_0's auc: 0.877783\tvalid_0's binary_logloss: 0.123594\tvalid_1's auc: 0.835851\tvalid_1's binary_logloss: 0.139729\n",
      "[33]\tvalid_0's auc: 0.878348\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.139824\n",
      "[34]\tvalid_0's auc: 0.878909\tvalid_0's binary_logloss: 0.123136\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.139745\n",
      "[35]\tvalid_0's auc: 0.879757\tvalid_0's binary_logloss: 0.122828\tvalid_1's auc: 0.835337\tvalid_1's binary_logloss: 0.139761\n",
      "[36]\tvalid_0's auc: 0.880504\tvalid_0's binary_logloss: 0.122572\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.139792\n",
      "[37]\tvalid_0's auc: 0.881015\tvalid_0's binary_logloss: 0.122349\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.139809\n",
      "[38]\tvalid_0's auc: 0.881565\tvalid_0's binary_logloss: 0.122148\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.139772\n",
      "[39]\tvalid_0's auc: 0.882176\tvalid_0's binary_logloss: 0.121925\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.13977\n",
      "[40]\tvalid_0's auc: 0.882818\tvalid_0's binary_logloss: 0.121683\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.139736\n",
      "[41]\tvalid_0's auc: 0.883353\tvalid_0's binary_logloss: 0.121428\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.139663\n",
      "[42]\tvalid_0's auc: 0.884062\tvalid_0's binary_logloss: 0.121195\tvalid_1's auc: 0.835313\tvalid_1's binary_logloss: 0.139727\n",
      "[43]\tvalid_0's auc: 0.884607\tvalid_0's binary_logloss: 0.120984\tvalid_1's auc: 0.835083\tvalid_1's binary_logloss: 0.139745\n",
      "[44]\tvalid_0's auc: 0.885155\tvalid_0's binary_logloss: 0.120752\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.139761\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.859797\tvalid_0's binary_logloss: 0.130869\tvalid_1's auc: 0.839774\tvalid_1's binary_logloss: 0.141886\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.822096\tvalid_0's binary_logloss: 0.15642\tvalid_1's auc: 0.814231\tvalid_1's binary_logloss: 0.165423\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.830899\tvalid_0's binary_logloss: 0.151112\tvalid_1's auc: 0.821277\tvalid_1's binary_logloss: 0.160161\n",
      "[3]\tvalid_0's auc: 0.83949\tvalid_0's binary_logloss: 0.147196\tvalid_1's auc: 0.828421\tvalid_1's binary_logloss: 0.156499\n",
      "[4]\tvalid_0's auc: 0.84292\tvalid_0's binary_logloss: 0.14418\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.153682\n",
      "[5]\tvalid_0's auc: 0.846745\tvalid_0's binary_logloss: 0.141793\tvalid_1's auc: 0.836391\tvalid_1's binary_logloss: 0.151366\n",
      "[6]\tvalid_0's auc: 0.849204\tvalid_0's binary_logloss: 0.139816\tvalid_1's auc: 0.838385\tvalid_1's binary_logloss: 0.149412\n",
      "[7]\tvalid_0's auc: 0.850163\tvalid_0's binary_logloss: 0.138129\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.147877\n",
      "[8]\tvalid_0's auc: 0.852051\tvalid_0's binary_logloss: 0.136672\tvalid_1's auc: 0.838308\tvalid_1's binary_logloss: 0.146579\n",
      "[9]\tvalid_0's auc: 0.853307\tvalid_0's binary_logloss: 0.13545\tvalid_1's auc: 0.839618\tvalid_1's binary_logloss: 0.145501\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[11]\tvalid_0's auc: 0.855751\tvalid_0's binary_logloss: 0.133459\tvalid_1's auc: 0.839746\tvalid_1's binary_logloss: 0.143859\n",
      "[12]\tvalid_0's auc: 0.856423\tvalid_0's binary_logloss: 0.132613\tvalid_1's auc: 0.838761\tvalid_1's binary_logloss: 0.143262\n",
      "[13]\tvalid_0's auc: 0.857763\tvalid_0's binary_logloss: 0.131837\tvalid_1's auc: 0.838486\tvalid_1's binary_logloss: 0.142774\n",
      "[14]\tvalid_0's auc: 0.858818\tvalid_0's binary_logloss: 0.131136\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.142334\n",
      "[15]\tvalid_0's auc: 0.859873\tvalid_0's binary_logloss: 0.130476\tvalid_1's auc: 0.83747\tvalid_1's binary_logloss: 0.14209\n",
      "[16]\tvalid_0's auc: 0.86059\tvalid_0's binary_logloss: 0.129898\tvalid_1's auc: 0.837199\tvalid_1's binary_logloss: 0.141785\n",
      "[17]\tvalid_0's auc: 0.861469\tvalid_0's binary_logloss: 0.129391\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.141489\n",
      "[18]\tvalid_0's auc: 0.8626\tvalid_0's binary_logloss: 0.128887\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.141321\n",
      "[19]\tvalid_0's auc: 0.863942\tvalid_0's binary_logloss: 0.128362\tvalid_1's auc: 0.837273\tvalid_1's binary_logloss: 0.14108\n",
      "[20]\tvalid_0's auc: 0.865345\tvalid_0's binary_logloss: 0.12787\tvalid_1's auc: 0.837663\tvalid_1's binary_logloss: 0.140905\n",
      "[21]\tvalid_0's auc: 0.866373\tvalid_0's binary_logloss: 0.127496\tvalid_1's auc: 0.838239\tvalid_1's binary_logloss: 0.140637\n",
      "[22]\tvalid_0's auc: 0.867435\tvalid_0's binary_logloss: 0.12708\tvalid_1's auc: 0.837639\tvalid_1's binary_logloss: 0.1406\n",
      "[23]\tvalid_0's auc: 0.868304\tvalid_0's binary_logloss: 0.12669\tvalid_1's auc: 0.837619\tvalid_1's binary_logloss: 0.140434\n",
      "[24]\tvalid_0's auc: 0.869271\tvalid_0's binary_logloss: 0.126307\tvalid_1's auc: 0.838019\tvalid_1's binary_logloss: 0.140281\n",
      "[25]\tvalid_0's auc: 0.870212\tvalid_0's binary_logloss: 0.125949\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.14025\n",
      "[26]\tvalid_0's auc: 0.871023\tvalid_0's binary_logloss: 0.125636\tvalid_1's auc: 0.837504\tvalid_1's binary_logloss: 0.140165\n",
      "[27]\tvalid_0's auc: 0.872756\tvalid_0's binary_logloss: 0.125201\tvalid_1's auc: 0.837762\tvalid_1's binary_logloss: 0.140044\n",
      "[28]\tvalid_0's auc: 0.874041\tvalid_0's binary_logloss: 0.124866\tvalid_1's auc: 0.837513\tvalid_1's binary_logloss: 0.14003\n",
      "[29]\tvalid_0's auc: 0.875088\tvalid_0's binary_logloss: 0.12452\tvalid_1's auc: 0.837397\tvalid_1's binary_logloss: 0.140013\n",
      "[30]\tvalid_0's auc: 0.876006\tvalid_0's binary_logloss: 0.124204\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.140044\n",
      "[31]\tvalid_0's auc: 0.876443\tvalid_0's binary_logloss: 0.123946\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.139984\n",
      "[32]\tvalid_0's auc: 0.877157\tvalid_0's binary_logloss: 0.123679\tvalid_1's auc: 0.837186\tvalid_1's binary_logloss: 0.139974\n",
      "[33]\tvalid_0's auc: 0.877846\tvalid_0's binary_logloss: 0.123426\tvalid_1's auc: 0.836741\tvalid_1's binary_logloss: 0.140021\n",
      "[34]\tvalid_0's auc: 0.879036\tvalid_0's binary_logloss: 0.123124\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.140057\n",
      "[35]\tvalid_0's auc: 0.879941\tvalid_0's binary_logloss: 0.12285\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.140035\n",
      "[36]\tvalid_0's auc: 0.880696\tvalid_0's binary_logloss: 0.122577\tvalid_1's auc: 0.836552\tvalid_1's binary_logloss: 0.140011\n",
      "[37]\tvalid_0's auc: 0.881398\tvalid_0's binary_logloss: 0.122348\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.140062\n",
      "[38]\tvalid_0's auc: 0.882135\tvalid_0's binary_logloss: 0.122135\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.14006\n",
      "[39]\tvalid_0's auc: 0.882826\tvalid_0's binary_logloss: 0.121918\tvalid_1's auc: 0.836302\tvalid_1's binary_logloss: 0.140015\n",
      "[40]\tvalid_0's auc: 0.883347\tvalid_0's binary_logloss: 0.121692\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.139995\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.854219\tvalid_0's binary_logloss: 0.134393\tvalid_1's auc: 0.840095\tvalid_1's binary_logloss: 0.144508\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.826319\tvalid_0's binary_logloss: 0.156309\tvalid_1's auc: 0.814027\tvalid_1's binary_logloss: 0.16516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.832276\tvalid_0's binary_logloss: 0.151075\tvalid_1's auc: 0.819879\tvalid_1's binary_logloss: 0.160057\n",
      "[3]\tvalid_0's auc: 0.836968\tvalid_0's binary_logloss: 0.147259\tvalid_1's auc: 0.825144\tvalid_1's binary_logloss: 0.156367\n",
      "[4]\tvalid_0's auc: 0.840937\tvalid_0's binary_logloss: 0.144237\tvalid_1's auc: 0.830372\tvalid_1's binary_logloss: 0.153364\n",
      "[5]\tvalid_0's auc: 0.845178\tvalid_0's binary_logloss: 0.141851\tvalid_1's auc: 0.835122\tvalid_1's binary_logloss: 0.151017\n",
      "[6]\tvalid_0's auc: 0.846202\tvalid_0's binary_logloss: 0.139881\tvalid_1's auc: 0.835139\tvalid_1's binary_logloss: 0.149202\n",
      "[7]\tvalid_0's auc: 0.849501\tvalid_0's binary_logloss: 0.13816\tvalid_1's auc: 0.838439\tvalid_1's binary_logloss: 0.147646\n",
      "[8]\tvalid_0's auc: 0.850898\tvalid_0's binary_logloss: 0.136639\tvalid_1's auc: 0.838862\tvalid_1's binary_logloss: 0.146267\n",
      "[9]\tvalid_0's auc: 0.85237\tvalid_0's binary_logloss: 0.135394\tvalid_1's auc: 0.838585\tvalid_1's binary_logloss: 0.145261\n",
      "[10]\tvalid_0's auc: 0.855108\tvalid_0's binary_logloss: 0.134315\tvalid_1's auc: 0.837555\tvalid_1's binary_logloss: 0.144377\n",
      "[11]\tvalid_0's auc: 0.856895\tvalid_0's binary_logloss: 0.133347\tvalid_1's auc: 0.837858\tvalid_1's binary_logloss: 0.143552\n",
      "[12]\tvalid_0's auc: 0.857593\tvalid_0's binary_logloss: 0.132493\tvalid_1's auc: 0.837734\tvalid_1's binary_logloss: 0.14288\n",
      "[13]\tvalid_0's auc: 0.85875\tvalid_0's binary_logloss: 0.131727\tvalid_1's auc: 0.838214\tvalid_1's binary_logloss: 0.142368\n",
      "[14]\tvalid_0's auc: 0.859561\tvalid_0's binary_logloss: 0.131032\tvalid_1's auc: 0.837766\tvalid_1's binary_logloss: 0.14195\n",
      "[15]\tvalid_0's auc: 0.860666\tvalid_0's binary_logloss: 0.130386\tvalid_1's auc: 0.837751\tvalid_1's binary_logloss: 0.141607\n",
      "[16]\tvalid_0's auc: 0.861555\tvalid_0's binary_logloss: 0.129851\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.14128\n",
      "[17]\tvalid_0's auc: 0.863042\tvalid_0's binary_logloss: 0.129232\tvalid_1's auc: 0.83902\tvalid_1's binary_logloss: 0.141008\n",
      "[18]\tvalid_0's auc: 0.864262\tvalid_0's binary_logloss: 0.128631\tvalid_1's auc: 0.839058\tvalid_1's binary_logloss: 0.140747\n",
      "[19]\tvalid_0's auc: 0.86545\tvalid_0's binary_logloss: 0.128138\tvalid_1's auc: 0.838753\tvalid_1's binary_logloss: 0.140544\n",
      "[20]\tvalid_0's auc: 0.8663\tvalid_0's binary_logloss: 0.12769\tvalid_1's auc: 0.83863\tvalid_1's binary_logloss: 0.140304\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[22]\tvalid_0's auc: 0.868709\tvalid_0's binary_logloss: 0.126813\tvalid_1's auc: 0.839171\tvalid_1's binary_logloss: 0.14001\n",
      "[23]\tvalid_0's auc: 0.869543\tvalid_0's binary_logloss: 0.126412\tvalid_1's auc: 0.839032\tvalid_1's binary_logloss: 0.139916\n",
      "[24]\tvalid_0's auc: 0.870296\tvalid_0's binary_logloss: 0.126025\tvalid_1's auc: 0.839048\tvalid_1's binary_logloss: 0.139785\n",
      "[25]\tvalid_0's auc: 0.871119\tvalid_0's binary_logloss: 0.125654\tvalid_1's auc: 0.83856\tvalid_1's binary_logloss: 0.139743\n",
      "[26]\tvalid_0's auc: 0.871934\tvalid_0's binary_logloss: 0.12537\tvalid_1's auc: 0.838594\tvalid_1's binary_logloss: 0.139669\n",
      "[27]\tvalid_0's auc: 0.873048\tvalid_0's binary_logloss: 0.125049\tvalid_1's auc: 0.83847\tvalid_1's binary_logloss: 0.139655\n",
      "[28]\tvalid_0's auc: 0.873824\tvalid_0's binary_logloss: 0.124767\tvalid_1's auc: 0.838229\tvalid_1's binary_logloss: 0.139655\n",
      "[29]\tvalid_0's auc: 0.874662\tvalid_0's binary_logloss: 0.124467\tvalid_1's auc: 0.838445\tvalid_1's binary_logloss: 0.139579\n",
      "[30]\tvalid_0's auc: 0.87542\tvalid_0's binary_logloss: 0.124168\tvalid_1's auc: 0.838156\tvalid_1's binary_logloss: 0.139548\n",
      "[31]\tvalid_0's auc: 0.876207\tvalid_0's binary_logloss: 0.123915\tvalid_1's auc: 0.838237\tvalid_1's binary_logloss: 0.139538\n",
      "[32]\tvalid_0's auc: 0.877156\tvalid_0's binary_logloss: 0.123623\tvalid_1's auc: 0.838271\tvalid_1's binary_logloss: 0.13947\n",
      "[33]\tvalid_0's auc: 0.87768\tvalid_0's binary_logloss: 0.12338\tvalid_1's auc: 0.838713\tvalid_1's binary_logloss: 0.139346\n",
      "[34]\tvalid_0's auc: 0.87849\tvalid_0's binary_logloss: 0.123137\tvalid_1's auc: 0.838649\tvalid_1's binary_logloss: 0.139374\n",
      "[35]\tvalid_0's auc: 0.879407\tvalid_0's binary_logloss: 0.122839\tvalid_1's auc: 0.838892\tvalid_1's binary_logloss: 0.139274\n",
      "[36]\tvalid_0's auc: 0.879965\tvalid_0's binary_logloss: 0.122622\tvalid_1's auc: 0.838744\tvalid_1's binary_logloss: 0.139304\n",
      "[37]\tvalid_0's auc: 0.880613\tvalid_0's binary_logloss: 0.122331\tvalid_1's auc: 0.839029\tvalid_1's binary_logloss: 0.139242\n",
      "[38]\tvalid_0's auc: 0.881276\tvalid_0's binary_logloss: 0.122084\tvalid_1's auc: 0.838779\tvalid_1's binary_logloss: 0.139277\n",
      "[39]\tvalid_0's auc: 0.881947\tvalid_0's binary_logloss: 0.121841\tvalid_1's auc: 0.838866\tvalid_1's binary_logloss: 0.139295\n",
      "[40]\tvalid_0's auc: 0.882617\tvalid_0's binary_logloss: 0.121559\tvalid_1's auc: 0.838919\tvalid_1's binary_logloss: 0.13924\n",
      "[41]\tvalid_0's auc: 0.883227\tvalid_0's binary_logloss: 0.121308\tvalid_1's auc: 0.838817\tvalid_1's binary_logloss: 0.13925\n",
      "[42]\tvalid_0's auc: 0.883844\tvalid_0's binary_logloss: 0.121097\tvalid_1's auc: 0.838851\tvalid_1's binary_logloss: 0.139244\n",
      "[43]\tvalid_0's auc: 0.884188\tvalid_0's binary_logloss: 0.12095\tvalid_1's auc: 0.838842\tvalid_1's binary_logloss: 0.139242\n",
      "[44]\tvalid_0's auc: 0.884844\tvalid_0's binary_logloss: 0.120718\tvalid_1's auc: 0.838637\tvalid_1's binary_logloss: 0.139282\n",
      "[45]\tvalid_0's auc: 0.885417\tvalid_0's binary_logloss: 0.120493\tvalid_1's auc: 0.838678\tvalid_1's binary_logloss: 0.139288\n",
      "[46]\tvalid_0's auc: 0.885803\tvalid_0's binary_logloss: 0.120327\tvalid_1's auc: 0.838716\tvalid_1's binary_logloss: 0.139279\n",
      "[47]\tvalid_0's auc: 0.886486\tvalid_0's binary_logloss: 0.120099\tvalid_1's auc: 0.838668\tvalid_1's binary_logloss: 0.139274\n",
      "[48]\tvalid_0's auc: 0.887253\tvalid_0's binary_logloss: 0.119903\tvalid_1's auc: 0.838451\tvalid_1's binary_logloss: 0.139321\n",
      "[49]\tvalid_0's auc: 0.887742\tvalid_0's binary_logloss: 0.11971\tvalid_1's auc: 0.838484\tvalid_1's binary_logloss: 0.139332\n",
      "[50]\tvalid_0's auc: 0.888224\tvalid_0's binary_logloss: 0.119543\tvalid_1's auc: 0.838409\tvalid_1's binary_logloss: 0.139353\n",
      "[51]\tvalid_0's auc: 0.888667\tvalid_0's binary_logloss: 0.11938\tvalid_1's auc: 0.838246\tvalid_1's binary_logloss: 0.1394\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.867585\tvalid_0's binary_logloss: 0.127262\tvalid_1's auc: 0.839226\tvalid_1's binary_logloss: 0.14013\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.823467\tvalid_0's binary_logloss: 0.156234\tvalid_1's auc: 0.818359\tvalid_1's binary_logloss: 0.165045\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.831432\tvalid_0's binary_logloss: 0.151096\tvalid_1's auc: 0.822806\tvalid_1's binary_logloss: 0.160035\n",
      "[3]\tvalid_0's auc: 0.837942\tvalid_0's binary_logloss: 0.147265\tvalid_1's auc: 0.827733\tvalid_1's binary_logloss: 0.156278\n",
      "[4]\tvalid_0's auc: 0.842228\tvalid_0's binary_logloss: 0.144266\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.153439\n",
      "[5]\tvalid_0's auc: 0.845913\tvalid_0's binary_logloss: 0.141908\tvalid_1's auc: 0.836078\tvalid_1's binary_logloss: 0.151112\n",
      "[6]\tvalid_0's auc: 0.847301\tvalid_0's binary_logloss: 0.139924\tvalid_1's auc: 0.837962\tvalid_1's binary_logloss: 0.149212\n",
      "[7]\tvalid_0's auc: 0.848494\tvalid_0's binary_logloss: 0.138267\tvalid_1's auc: 0.837664\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.849608\tvalid_0's binary_logloss: 0.136839\tvalid_1's auc: 0.839054\tvalid_1's binary_logloss: 0.146332\n",
      "[9]\tvalid_0's auc: 0.851401\tvalid_0's binary_logloss: 0.135609\tvalid_1's auc: 0.839453\tvalid_1's binary_logloss: 0.145351\n",
      "[10]\tvalid_0's auc: 0.852795\tvalid_0's binary_logloss: 0.134534\tvalid_1's auc: 0.840274\tvalid_1's binary_logloss: 0.144391\n",
      "[11]\tvalid_0's auc: 0.853993\tvalid_0's binary_logloss: 0.133621\tvalid_1's auc: 0.840484\tvalid_1's binary_logloss: 0.143622\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[13]\tvalid_0's auc: 0.857408\tvalid_0's binary_logloss: 0.131982\tvalid_1's auc: 0.840313\tvalid_1's binary_logloss: 0.142428\n",
      "[14]\tvalid_0's auc: 0.858394\tvalid_0's binary_logloss: 0.131254\tvalid_1's auc: 0.840441\tvalid_1's binary_logloss: 0.141892\n",
      "[15]\tvalid_0's auc: 0.859543\tvalid_0's binary_logloss: 0.130617\tvalid_1's auc: 0.840527\tvalid_1's binary_logloss: 0.141536\n",
      "[16]\tvalid_0's auc: 0.860896\tvalid_0's binary_logloss: 0.130045\tvalid_1's auc: 0.839976\tvalid_1's binary_logloss: 0.141199\n",
      "[17]\tvalid_0's auc: 0.862165\tvalid_0's binary_logloss: 0.129495\tvalid_1's auc: 0.840423\tvalid_1's binary_logloss: 0.140913\n",
      "[18]\tvalid_0's auc: 0.863167\tvalid_0's binary_logloss: 0.128982\tvalid_1's auc: 0.840347\tvalid_1's binary_logloss: 0.140622\n",
      "[19]\tvalid_0's auc: 0.864691\tvalid_0's binary_logloss: 0.128474\tvalid_1's auc: 0.840438\tvalid_1's binary_logloss: 0.140372\n",
      "[20]\tvalid_0's auc: 0.865493\tvalid_0's binary_logloss: 0.128073\tvalid_1's auc: 0.840373\tvalid_1's binary_logloss: 0.140128\n",
      "[21]\tvalid_0's auc: 0.866463\tvalid_0's binary_logloss: 0.127636\tvalid_1's auc: 0.840418\tvalid_1's binary_logloss: 0.139909\n",
      "[22]\tvalid_0's auc: 0.867081\tvalid_0's binary_logloss: 0.12726\tvalid_1's auc: 0.840315\tvalid_1's binary_logloss: 0.139758\n",
      "[23]\tvalid_0's auc: 0.867656\tvalid_0's binary_logloss: 0.126888\tvalid_1's auc: 0.839878\tvalid_1's binary_logloss: 0.139751\n",
      "[24]\tvalid_0's auc: 0.868511\tvalid_0's binary_logloss: 0.12652\tvalid_1's auc: 0.839944\tvalid_1's binary_logloss: 0.13964\n",
      "[25]\tvalid_0's auc: 0.869233\tvalid_0's binary_logloss: 0.126158\tvalid_1's auc: 0.840131\tvalid_1's binary_logloss: 0.139495\n",
      "[26]\tvalid_0's auc: 0.870146\tvalid_0's binary_logloss: 0.12583\tvalid_1's auc: 0.839809\tvalid_1's binary_logloss: 0.139487\n",
      "[27]\tvalid_0's auc: 0.871289\tvalid_0's binary_logloss: 0.125495\tvalid_1's auc: 0.83977\tvalid_1's binary_logloss: 0.139452\n",
      "[28]\tvalid_0's auc: 0.872449\tvalid_0's binary_logloss: 0.125203\tvalid_1's auc: 0.839707\tvalid_1's binary_logloss: 0.139417\n",
      "[29]\tvalid_0's auc: 0.87307\tvalid_0's binary_logloss: 0.124902\tvalid_1's auc: 0.840062\tvalid_1's binary_logloss: 0.13934\n",
      "[30]\tvalid_0's auc: 0.874009\tvalid_0's binary_logloss: 0.124599\tvalid_1's auc: 0.839797\tvalid_1's binary_logloss: 0.139335\n",
      "[31]\tvalid_0's auc: 0.874961\tvalid_0's binary_logloss: 0.124243\tvalid_1's auc: 0.839401\tvalid_1's binary_logloss: 0.139341\n",
      "[32]\tvalid_0's auc: 0.875534\tvalid_0's binary_logloss: 0.12399\tvalid_1's auc: 0.839344\tvalid_1's binary_logloss: 0.139318\n",
      "[33]\tvalid_0's auc: 0.876073\tvalid_0's binary_logloss: 0.12375\tvalid_1's auc: 0.839413\tvalid_1's binary_logloss: 0.139291\n",
      "[34]\tvalid_0's auc: 0.876721\tvalid_0's binary_logloss: 0.123522\tvalid_1's auc: 0.839706\tvalid_1's binary_logloss: 0.139235\n",
      "[35]\tvalid_0's auc: 0.877275\tvalid_0's binary_logloss: 0.123252\tvalid_1's auc: 0.840335\tvalid_1's binary_logloss: 0.139044\n",
      "[36]\tvalid_0's auc: 0.877922\tvalid_0's binary_logloss: 0.123055\tvalid_1's auc: 0.840293\tvalid_1's binary_logloss: 0.13902\n",
      "[37]\tvalid_0's auc: 0.878499\tvalid_0's binary_logloss: 0.122801\tvalid_1's auc: 0.840333\tvalid_1's binary_logloss: 0.138988\n",
      "[38]\tvalid_0's auc: 0.879297\tvalid_0's binary_logloss: 0.122522\tvalid_1's auc: 0.840156\tvalid_1's binary_logloss: 0.139034\n",
      "[39]\tvalid_0's auc: 0.880019\tvalid_0's binary_logloss: 0.122297\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.138997\n",
      "[40]\tvalid_0's auc: 0.88064\tvalid_0's binary_logloss: 0.122051\tvalid_1's auc: 0.840237\tvalid_1's binary_logloss: 0.139001\n",
      "[41]\tvalid_0's auc: 0.88151\tvalid_0's binary_logloss: 0.121784\tvalid_1's auc: 0.839739\tvalid_1's binary_logloss: 0.13906\n",
      "[42]\tvalid_0's auc: 0.882288\tvalid_0's binary_logloss: 0.121573\tvalid_1's auc: 0.839558\tvalid_1's binary_logloss: 0.139089\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.856046\tvalid_0's binary_logloss: 0.132732\tvalid_1's auc: 0.840999\tvalid_1's binary_logloss: 0.142898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.822477\tvalid_0's binary_logloss: 0.156615\tvalid_1's auc: 0.818936\tvalid_1's binary_logloss: 0.16507\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.829931\tvalid_0's binary_logloss: 0.151227\tvalid_1's auc: 0.824213\tvalid_1's binary_logloss: 0.159973\n",
      "[3]\tvalid_0's auc: 0.835788\tvalid_0's binary_logloss: 0.147372\tvalid_1's auc: 0.829555\tvalid_1's binary_logloss: 0.156407\n",
      "[4]\tvalid_0's auc: 0.842398\tvalid_0's binary_logloss: 0.14436\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.153426\n",
      "[5]\tvalid_0's auc: 0.84472\tvalid_0's binary_logloss: 0.141969\tvalid_1's auc: 0.835438\tvalid_1's binary_logloss: 0.15118\n",
      "[6]\tvalid_0's auc: 0.846873\tvalid_0's binary_logloss: 0.13984\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.149232\n",
      "[7]\tvalid_0's auc: 0.849397\tvalid_0's binary_logloss: 0.138081\tvalid_1's auc: 0.838165\tvalid_1's binary_logloss: 0.147687\n",
      "[8]\tvalid_0's auc: 0.850636\tvalid_0's binary_logloss: 0.136651\tvalid_1's auc: 0.839203\tvalid_1's binary_logloss: 0.146397\n",
      "[9]\tvalid_0's auc: 0.852058\tvalid_0's binary_logloss: 0.135397\tvalid_1's auc: 0.839642\tvalid_1's binary_logloss: 0.145335\n",
      "[10]\tvalid_0's auc: 0.853752\tvalid_0's binary_logloss: 0.134296\tvalid_1's auc: 0.840124\tvalid_1's binary_logloss: 0.144474\n",
      "[11]\tvalid_0's auc: 0.855331\tvalid_0's binary_logloss: 0.133348\tvalid_1's auc: 0.839897\tvalid_1's binary_logloss: 0.143725\n",
      "[12]\tvalid_0's auc: 0.857453\tvalid_0's binary_logloss: 0.13245\tvalid_1's auc: 0.84039\tvalid_1's binary_logloss: 0.143067\n",
      "[13]\tvalid_0's auc: 0.858781\tvalid_0's binary_logloss: 0.131689\tvalid_1's auc: 0.840851\tvalid_1's binary_logloss: 0.14244\n",
      "[14]\tvalid_0's auc: 0.860635\tvalid_0's binary_logloss: 0.130982\tvalid_1's auc: 0.840623\tvalid_1's binary_logloss: 0.141945\n",
      "[15]\tvalid_0's auc: 0.861771\tvalid_0's binary_logloss: 0.130283\tvalid_1's auc: 0.84085\tvalid_1's binary_logloss: 0.141501\n",
      "[16]\tvalid_0's auc: 0.863226\tvalid_0's binary_logloss: 0.12968\tvalid_1's auc: 0.840816\tvalid_1's binary_logloss: 0.14118\n",
      "[17]\tvalid_0's auc: 0.864022\tvalid_0's binary_logloss: 0.129132\tvalid_1's auc: 0.841034\tvalid_1's binary_logloss: 0.140867\n",
      "[18]\tvalid_0's auc: 0.865122\tvalid_0's binary_logloss: 0.128586\tvalid_1's auc: 0.841066\tvalid_1's binary_logloss: 0.140645\n",
      "[19]\tvalid_0's auc: 0.866114\tvalid_0's binary_logloss: 0.128091\tvalid_1's auc: 0.841164\tvalid_1's binary_logloss: 0.140459\n",
      "[20]\tvalid_0's auc: 0.86733\tvalid_0's binary_logloss: 0.127618\tvalid_1's auc: 0.841078\tvalid_1's binary_logloss: 0.140192\n",
      "[21]\tvalid_0's auc: 0.86847\tvalid_0's binary_logloss: 0.12718\tvalid_1's auc: 0.842056\tvalid_1's binary_logloss: 0.139899\n",
      "[22]\tvalid_0's auc: 0.86912\tvalid_0's binary_logloss: 0.126786\tvalid_1's auc: 0.842604\tvalid_1's binary_logloss: 0.139581\n",
      "[23]\tvalid_0's auc: 0.8702\tvalid_0's binary_logloss: 0.1264\tvalid_1's auc: 0.842923\tvalid_1's binary_logloss: 0.13938\n",
      "[24]\tvalid_0's auc: 0.871154\tvalid_0's binary_logloss: 0.126012\tvalid_1's auc: 0.842853\tvalid_1's binary_logloss: 0.139199\n",
      "[25]\tvalid_0's auc: 0.871861\tvalid_0's binary_logloss: 0.125716\tvalid_1's auc: 0.842924\tvalid_1's binary_logloss: 0.139114\n",
      "[26]\tvalid_0's auc: 0.872932\tvalid_0's binary_logloss: 0.125379\tvalid_1's auc: 0.842821\tvalid_1's binary_logloss: 0.139002\n",
      "[27]\tvalid_0's auc: 0.873488\tvalid_0's binary_logloss: 0.125055\tvalid_1's auc: 0.842803\tvalid_1's binary_logloss: 0.138866\n",
      "[28]\tvalid_0's auc: 0.874282\tvalid_0's binary_logloss: 0.124763\tvalid_1's auc: 0.842697\tvalid_1's binary_logloss: 0.138796\n",
      "[29]\tvalid_0's auc: 0.875185\tvalid_0's binary_logloss: 0.124481\tvalid_1's auc: 0.843506\tvalid_1's binary_logloss: 0.138625\n",
      "[30]\tvalid_0's auc: 0.875805\tvalid_0's binary_logloss: 0.124216\tvalid_1's auc: 0.843564\tvalid_1's binary_logloss: 0.138532\n",
      "[31]\tvalid_0's auc: 0.877289\tvalid_0's binary_logloss: 0.123898\tvalid_1's auc: 0.84385\tvalid_1's binary_logloss: 0.138455\n",
      "[32]\tvalid_0's auc: 0.878137\tvalid_0's binary_logloss: 0.123613\tvalid_1's auc: 0.843943\tvalid_1's binary_logloss: 0.138401\n",
      "[33]\tvalid_0's auc: 0.879141\tvalid_0's binary_logloss: 0.123349\tvalid_1's auc: 0.843945\tvalid_1's binary_logloss: 0.13837\n",
      "[34]\tvalid_0's auc: 0.879829\tvalid_0's binary_logloss: 0.123074\tvalid_1's auc: 0.844035\tvalid_1's binary_logloss: 0.13828\n",
      "[35]\tvalid_0's auc: 0.880826\tvalid_0's binary_logloss: 0.122813\tvalid_1's auc: 0.844275\tvalid_1's binary_logloss: 0.138226\n",
      "[36]\tvalid_0's auc: 0.881493\tvalid_0's binary_logloss: 0.122554\tvalid_1's auc: 0.844344\tvalid_1's binary_logloss: 0.138161\n",
      "[37]\tvalid_0's auc: 0.882368\tvalid_0's binary_logloss: 0.122305\tvalid_1's auc: 0.844143\tvalid_1's binary_logloss: 0.138162\n",
      "[38]\tvalid_0's auc: 0.882945\tvalid_0's binary_logloss: 0.122019\tvalid_1's auc: 0.844149\tvalid_1's binary_logloss: 0.13813\n",
      "[39]\tvalid_0's auc: 0.883584\tvalid_0's binary_logloss: 0.121799\tvalid_1's auc: 0.843977\tvalid_1's binary_logloss: 0.138149\n",
      "[40]\tvalid_0's auc: 0.88416\tvalid_0's binary_logloss: 0.121576\tvalid_1's auc: 0.844146\tvalid_1's binary_logloss: 0.138147\n",
      "[41]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.12135\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138128\n",
      "[42]\tvalid_0's auc: 0.885638\tvalid_0's binary_logloss: 0.121096\tvalid_1's auc: 0.843995\tvalid_1's binary_logloss: 0.138106\n",
      "[43]\tvalid_0's auc: 0.886395\tvalid_0's binary_logloss: 0.120905\tvalid_1's auc: 0.844184\tvalid_1's binary_logloss: 0.138052\n",
      "[44]\tvalid_0's auc: 0.887071\tvalid_0's binary_logloss: 0.120678\tvalid_1's auc: 0.844103\tvalid_1's binary_logloss: 0.138065\n",
      "[45]\tvalid_0's auc: 0.887784\tvalid_0's binary_logloss: 0.120428\tvalid_1's auc: 0.844152\tvalid_1's binary_logloss: 0.138057\n",
      "[46]\tvalid_0's auc: 0.888342\tvalid_0's binary_logloss: 0.120223\tvalid_1's auc: 0.844297\tvalid_1's binary_logloss: 0.138025\n",
      "[47]\tvalid_0's auc: 0.888722\tvalid_0's binary_logloss: 0.119986\tvalid_1's auc: 0.844276\tvalid_1's binary_logloss: 0.138002\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[49]\tvalid_0's auc: 0.889545\tvalid_0's binary_logloss: 0.119601\tvalid_1's auc: 0.844447\tvalid_1's binary_logloss: 0.138002\n",
      "[50]\tvalid_0's auc: 0.89018\tvalid_0's binary_logloss: 0.119358\tvalid_1's auc: 0.844336\tvalid_1's binary_logloss: 0.138021\n",
      "[51]\tvalid_0's auc: 0.890603\tvalid_0's binary_logloss: 0.119182\tvalid_1's auc: 0.84438\tvalid_1's binary_logloss: 0.138019\n",
      "[52]\tvalid_0's auc: 0.891517\tvalid_0's binary_logloss: 0.118924\tvalid_1's auc: 0.844393\tvalid_1's binary_logloss: 0.13803\n",
      "[53]\tvalid_0's auc: 0.891938\tvalid_0's binary_logloss: 0.118749\tvalid_1's auc: 0.844183\tvalid_1's binary_logloss: 0.138086\n",
      "[54]\tvalid_0's auc: 0.892252\tvalid_0's binary_logloss: 0.118601\tvalid_1's auc: 0.844352\tvalid_1's binary_logloss: 0.138077\n",
      "[55]\tvalid_0's auc: 0.892749\tvalid_0's binary_logloss: 0.118391\tvalid_1's auc: 0.84432\tvalid_1's binary_logloss: 0.138057\n",
      "[56]\tvalid_0's auc: 0.893267\tvalid_0's binary_logloss: 0.118246\tvalid_1's auc: 0.844305\tvalid_1's binary_logloss: 0.138061\n",
      "[57]\tvalid_0's auc: 0.893589\tvalid_0's binary_logloss: 0.118094\tvalid_1's auc: 0.844225\tvalid_1's binary_logloss: 0.138064\n",
      "[58]\tvalid_0's auc: 0.89387\tvalid_0's binary_logloss: 0.117959\tvalid_1's auc: 0.844327\tvalid_1's binary_logloss: 0.138044\n",
      "[59]\tvalid_0's auc: 0.894196\tvalid_0's binary_logloss: 0.117784\tvalid_1's auc: 0.844144\tvalid_1's binary_logloss: 0.138088\n",
      "[60]\tvalid_0's auc: 0.894754\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.843942\tvalid_1's binary_logloss: 0.138136\n",
      "[61]\tvalid_0's auc: 0.895224\tvalid_0's binary_logloss: 0.117358\tvalid_1's auc: 0.844107\tvalid_1's binary_logloss: 0.138135\n",
      "[62]\tvalid_0's auc: 0.895747\tvalid_0's binary_logloss: 0.117116\tvalid_1's auc: 0.844033\tvalid_1's binary_logloss: 0.138143\n",
      "[63]\tvalid_0's auc: 0.896042\tvalid_0's binary_logloss: 0.116934\tvalid_1's auc: 0.844057\tvalid_1's binary_logloss: 0.138188\n",
      "[64]\tvalid_0's auc: 0.89648\tvalid_0's binary_logloss: 0.116742\tvalid_1's auc: 0.843882\tvalid_1's binary_logloss: 0.138258\n",
      "[65]\tvalid_0's auc: 0.8968\tvalid_0's binary_logloss: 0.116596\tvalid_1's auc: 0.843553\tvalid_1's binary_logloss: 0.138317\n",
      "[66]\tvalid_0's auc: 0.89727\tvalid_0's binary_logloss: 0.116455\tvalid_1's auc: 0.843435\tvalid_1's binary_logloss: 0.138362\n",
      "[67]\tvalid_0's auc: 0.897643\tvalid_0's binary_logloss: 0.11627\tvalid_1's auc: 0.843148\tvalid_1's binary_logloss: 0.138424\n",
      "[68]\tvalid_0's auc: 0.898008\tvalid_0's binary_logloss: 0.116079\tvalid_1's auc: 0.843355\tvalid_1's binary_logloss: 0.138452\n",
      "[69]\tvalid_0's auc: 0.898293\tvalid_0's binary_logloss: 0.115943\tvalid_1's auc: 0.843203\tvalid_1's binary_logloss: 0.138515\n",
      "[70]\tvalid_0's auc: 0.898585\tvalid_0's binary_logloss: 0.115794\tvalid_1's auc: 0.84311\tvalid_1's binary_logloss: 0.138551\n",
      "[71]\tvalid_0's auc: 0.898878\tvalid_0's binary_logloss: 0.115634\tvalid_1's auc: 0.843163\tvalid_1's binary_logloss: 0.138557\n",
      "[72]\tvalid_0's auc: 0.89933\tvalid_0's binary_logloss: 0.11544\tvalid_1's auc: 0.843123\tvalid_1's binary_logloss: 0.138587\n",
      "[73]\tvalid_0's auc: 0.899665\tvalid_0's binary_logloss: 0.115279\tvalid_1's auc: 0.843158\tvalid_1's binary_logloss: 0.138606\n",
      "[74]\tvalid_0's auc: 0.899872\tvalid_0's binary_logloss: 0.115145\tvalid_1's auc: 0.843153\tvalid_1's binary_logloss: 0.138622\n",
      "[75]\tvalid_0's auc: 0.900318\tvalid_0's binary_logloss: 0.115012\tvalid_1's auc: 0.8431\tvalid_1's binary_logloss: 0.138652\n",
      "[76]\tvalid_0's auc: 0.900838\tvalid_0's binary_logloss: 0.114797\tvalid_1's auc: 0.843128\tvalid_1's binary_logloss: 0.138654\n",
      "[77]\tvalid_0's auc: 0.901053\tvalid_0's binary_logloss: 0.11465\tvalid_1's auc: 0.843183\tvalid_1's binary_logloss: 0.138667\n",
      "[78]\tvalid_0's auc: 0.901334\tvalid_0's binary_logloss: 0.114492\tvalid_1's auc: 0.843036\tvalid_1's binary_logloss: 0.138728\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.889206\tvalid_0's binary_logloss: 0.119781\tvalid_1's auc: 0.844708\tvalid_1's binary_logloss: 0.137947\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.833136\tvalid_0's binary_logloss: 0.155618\tvalid_1's auc: 0.823516\tvalid_1's binary_logloss: 0.164757\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842036\tvalid_0's binary_logloss: 0.149972\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.159717\n",
      "[3]\tvalid_0's auc: 0.847172\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.830898\tvalid_1's binary_logloss: 0.156155\n",
      "[4]\tvalid_0's auc: 0.854159\tvalid_0's binary_logloss: 0.142767\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.153226\n",
      "[5]\tvalid_0's auc: 0.857704\tvalid_0's binary_logloss: 0.140143\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.15094\n",
      "[6]\tvalid_0's auc: 0.860316\tvalid_0's binary_logloss: 0.137951\tvalid_1's auc: 0.836175\tvalid_1's binary_logloss: 0.149162\n",
      "[7]\tvalid_0's auc: 0.862439\tvalid_0's binary_logloss: 0.136077\tvalid_1's auc: 0.835532\tvalid_1's binary_logloss: 0.147649\n",
      "[8]\tvalid_0's auc: 0.864272\tvalid_0's binary_logloss: 0.134388\tvalid_1's auc: 0.83563\tvalid_1's binary_logloss: 0.146354\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[10]\tvalid_0's auc: 0.867535\tvalid_0's binary_logloss: 0.13164\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.144361\n",
      "[11]\tvalid_0's auc: 0.869515\tvalid_0's binary_logloss: 0.130402\tvalid_1's auc: 0.83647\tvalid_1's binary_logloss: 0.143633\n",
      "[12]\tvalid_0's auc: 0.870746\tvalid_0's binary_logloss: 0.129418\tvalid_1's auc: 0.836512\tvalid_1's binary_logloss: 0.14302\n",
      "[13]\tvalid_0's auc: 0.872719\tvalid_0's binary_logloss: 0.12844\tvalid_1's auc: 0.836236\tvalid_1's binary_logloss: 0.142554\n",
      "[14]\tvalid_0's auc: 0.874567\tvalid_0's binary_logloss: 0.127509\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.142114\n",
      "[15]\tvalid_0's auc: 0.876764\tvalid_0's binary_logloss: 0.126626\tvalid_1's auc: 0.836237\tvalid_1's binary_logloss: 0.141748\n",
      "[16]\tvalid_0's auc: 0.87792\tvalid_0's binary_logloss: 0.125854\tvalid_1's auc: 0.836368\tvalid_1's binary_logloss: 0.141474\n",
      "[17]\tvalid_0's auc: 0.879062\tvalid_0's binary_logloss: 0.125102\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.14123\n",
      "[18]\tvalid_0's auc: 0.880333\tvalid_0's binary_logloss: 0.12445\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.14109\n",
      "[19]\tvalid_0's auc: 0.881986\tvalid_0's binary_logloss: 0.123735\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.140974\n",
      "[20]\tvalid_0's auc: 0.883497\tvalid_0's binary_logloss: 0.123057\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.140833\n",
      "[21]\tvalid_0's auc: 0.88477\tvalid_0's binary_logloss: 0.122502\tvalid_1's auc: 0.83413\tvalid_1's binary_logloss: 0.140756\n",
      "[22]\tvalid_0's auc: 0.886052\tvalid_0's binary_logloss: 0.121963\tvalid_1's auc: 0.833448\tvalid_1's binary_logloss: 0.140744\n",
      "[23]\tvalid_0's auc: 0.88729\tvalid_0's binary_logloss: 0.121374\tvalid_1's auc: 0.832949\tvalid_1's binary_logloss: 0.140705\n",
      "[24]\tvalid_0's auc: 0.888202\tvalid_0's binary_logloss: 0.120845\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.140716\n",
      "[25]\tvalid_0's auc: 0.889261\tvalid_0's binary_logloss: 0.120276\tvalid_1's auc: 0.832717\tvalid_1's binary_logloss: 0.140524\n",
      "[26]\tvalid_0's auc: 0.89008\tvalid_0's binary_logloss: 0.119792\tvalid_1's auc: 0.832126\tvalid_1's binary_logloss: 0.140541\n",
      "[27]\tvalid_0's auc: 0.891071\tvalid_0's binary_logloss: 0.119365\tvalid_1's auc: 0.832245\tvalid_1's binary_logloss: 0.140458\n",
      "[28]\tvalid_0's auc: 0.891965\tvalid_0's binary_logloss: 0.118917\tvalid_1's auc: 0.832098\tvalid_1's binary_logloss: 0.140348\n",
      "[29]\tvalid_0's auc: 0.893292\tvalid_0's binary_logloss: 0.118413\tvalid_1's auc: 0.832091\tvalid_1's binary_logloss: 0.140371\n",
      "[30]\tvalid_0's auc: 0.894193\tvalid_0's binary_logloss: 0.118022\tvalid_1's auc: 0.831601\tvalid_1's binary_logloss: 0.140412\n",
      "[31]\tvalid_0's auc: 0.894983\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.140402\n",
      "[32]\tvalid_0's auc: 0.896347\tvalid_0's binary_logloss: 0.117114\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.14049\n",
      "[33]\tvalid_0's auc: 0.897531\tvalid_0's binary_logloss: 0.116696\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.140462\n",
      "[34]\tvalid_0's auc: 0.898503\tvalid_0's binary_logloss: 0.116337\tvalid_1's auc: 0.831998\tvalid_1's binary_logloss: 0.140436\n",
      "[35]\tvalid_0's auc: 0.899431\tvalid_0's binary_logloss: 0.115966\tvalid_1's auc: 0.832323\tvalid_1's binary_logloss: 0.140357\n",
      "[36]\tvalid_0's auc: 0.900259\tvalid_0's binary_logloss: 0.115619\tvalid_1's auc: 0.832052\tvalid_1's binary_logloss: 0.140411\n",
      "[37]\tvalid_0's auc: 0.901414\tvalid_0's binary_logloss: 0.115269\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.14042\n",
      "[38]\tvalid_0's auc: 0.902365\tvalid_0's binary_logloss: 0.114862\tvalid_1's auc: 0.832015\tvalid_1's binary_logloss: 0.140464\n",
      "[39]\tvalid_0's auc: 0.90309\tvalid_0's binary_logloss: 0.114499\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.140399\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.833297\tvalid_0's binary_logloss: 0.155798\tvalid_1's auc: 0.814648\tvalid_1's binary_logloss: 0.165178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.84496\tvalid_0's binary_logloss: 0.150106\tvalid_1's auc: 0.825101\tvalid_1's binary_logloss: 0.159672\n",
      "[3]\tvalid_0's auc: 0.848339\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.829756\tvalid_1's binary_logloss: 0.156122\n",
      "[4]\tvalid_0's auc: 0.852327\tvalid_0's binary_logloss: 0.142785\tvalid_1's auc: 0.83262\tvalid_1's binary_logloss: 0.153215\n",
      "[5]\tvalid_0's auc: 0.856991\tvalid_0's binary_logloss: 0.140075\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.150936\n",
      "[6]\tvalid_0's auc: 0.860123\tvalid_0's binary_logloss: 0.13786\tvalid_1's auc: 0.837776\tvalid_1's binary_logloss: 0.149015\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[8]\tvalid_0's auc: 0.863556\tvalid_0's binary_logloss: 0.134329\tvalid_1's auc: 0.837522\tvalid_1's binary_logloss: 0.146495\n",
      "[9]\tvalid_0's auc: 0.865702\tvalid_0's binary_logloss: 0.132867\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.145505\n",
      "[10]\tvalid_0's auc: 0.867419\tvalid_0's binary_logloss: 0.131589\tvalid_1's auc: 0.83738\tvalid_1's binary_logloss: 0.144639\n",
      "[11]\tvalid_0's auc: 0.869474\tvalid_0's binary_logloss: 0.130487\tvalid_1's auc: 0.837061\tvalid_1's binary_logloss: 0.143902\n",
      "[12]\tvalid_0's auc: 0.871188\tvalid_0's binary_logloss: 0.12944\tvalid_1's auc: 0.83674\tvalid_1's binary_logloss: 0.14338\n",
      "[13]\tvalid_0's auc: 0.873292\tvalid_0's binary_logloss: 0.128408\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.142955\n",
      "[14]\tvalid_0's auc: 0.875272\tvalid_0's binary_logloss: 0.127498\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.142577\n",
      "[15]\tvalid_0's auc: 0.876333\tvalid_0's binary_logloss: 0.126687\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.142233\n",
      "[16]\tvalid_0's auc: 0.878172\tvalid_0's binary_logloss: 0.125868\tvalid_1's auc: 0.835135\tvalid_1's binary_logloss: 0.141915\n",
      "[17]\tvalid_0's auc: 0.879493\tvalid_0's binary_logloss: 0.125166\tvalid_1's auc: 0.834462\tvalid_1's binary_logloss: 0.141684\n",
      "[18]\tvalid_0's auc: 0.880697\tvalid_0's binary_logloss: 0.124485\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.141381\n",
      "[19]\tvalid_0's auc: 0.881751\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.141089\n",
      "[20]\tvalid_0's auc: 0.883208\tvalid_0's binary_logloss: 0.123231\tvalid_1's auc: 0.834617\tvalid_1's binary_logloss: 0.141074\n",
      "[21]\tvalid_0's auc: 0.884441\tvalid_0's binary_logloss: 0.122672\tvalid_1's auc: 0.835086\tvalid_1's binary_logloss: 0.140871\n",
      "[22]\tvalid_0's auc: 0.885795\tvalid_0's binary_logloss: 0.122047\tvalid_1's auc: 0.834691\tvalid_1's binary_logloss: 0.140833\n",
      "[23]\tvalid_0's auc: 0.88703\tvalid_0's binary_logloss: 0.121437\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.14067\n",
      "[24]\tvalid_0's auc: 0.888628\tvalid_0's binary_logloss: 0.120866\tvalid_1's auc: 0.834703\tvalid_1's binary_logloss: 0.140607\n",
      "[25]\tvalid_0's auc: 0.889539\tvalid_0's binary_logloss: 0.120354\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.140572\n",
      "[26]\tvalid_0's auc: 0.890707\tvalid_0's binary_logloss: 0.119835\tvalid_1's auc: 0.834353\tvalid_1's binary_logloss: 0.140508\n",
      "[27]\tvalid_0's auc: 0.89189\tvalid_0's binary_logloss: 0.119344\tvalid_1's auc: 0.833736\tvalid_1's binary_logloss: 0.14057\n",
      "[28]\tvalid_0's auc: 0.892973\tvalid_0's binary_logloss: 0.118875\tvalid_1's auc: 0.83339\tvalid_1's binary_logloss: 0.140614\n",
      "[29]\tvalid_0's auc: 0.894538\tvalid_0's binary_logloss: 0.118402\tvalid_1's auc: 0.833262\tvalid_1's binary_logloss: 0.140617\n",
      "[30]\tvalid_0's auc: 0.895805\tvalid_0's binary_logloss: 0.117902\tvalid_1's auc: 0.832581\tvalid_1's binary_logloss: 0.140733\n",
      "[31]\tvalid_0's auc: 0.897165\tvalid_0's binary_logloss: 0.117449\tvalid_1's auc: 0.832965\tvalid_1's binary_logloss: 0.14067\n",
      "[32]\tvalid_0's auc: 0.898106\tvalid_0's binary_logloss: 0.117027\tvalid_1's auc: 0.832548\tvalid_1's binary_logloss: 0.140717\n",
      "[33]\tvalid_0's auc: 0.898897\tvalid_0's binary_logloss: 0.116646\tvalid_1's auc: 0.832294\tvalid_1's binary_logloss: 0.140755\n",
      "[34]\tvalid_0's auc: 0.899579\tvalid_0's binary_logloss: 0.11632\tvalid_1's auc: 0.832478\tvalid_1's binary_logloss: 0.14074\n",
      "[35]\tvalid_0's auc: 0.900941\tvalid_0's binary_logloss: 0.115884\tvalid_1's auc: 0.83257\tvalid_1's binary_logloss: 0.140703\n",
      "[36]\tvalid_0's auc: 0.902074\tvalid_0's binary_logloss: 0.115452\tvalid_1's auc: 0.832369\tvalid_1's binary_logloss: 0.140774\n",
      "[37]\tvalid_0's auc: 0.902849\tvalid_0's binary_logloss: 0.115101\tvalid_1's auc: 0.832046\tvalid_1's binary_logloss: 0.140792\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.834438\tvalid_0's binary_logloss: 0.155707\tvalid_1's auc: 0.821419\tvalid_1's binary_logloss: 0.164715\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845934\tvalid_0's binary_logloss: 0.150048\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.159506\n",
      "[3]\tvalid_0's auc: 0.849836\tvalid_0's binary_logloss: 0.145927\tvalid_1's auc: 0.831719\tvalid_1's binary_logloss: 0.155735\n",
      "[4]\tvalid_0's auc: 0.854642\tvalid_0's binary_logloss: 0.142686\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.152919\n",
      "[5]\tvalid_0's auc: 0.856628\tvalid_0's binary_logloss: 0.139976\tvalid_1's auc: 0.83701\tvalid_1's binary_logloss: 0.15048\n",
      "[6]\tvalid_0's auc: 0.859766\tvalid_0's binary_logloss: 0.137707\tvalid_1's auc: 0.83737\tvalid_1's binary_logloss: 0.148709\n",
      "[7]\tvalid_0's auc: 0.861667\tvalid_0's binary_logloss: 0.13588\tvalid_1's auc: 0.837028\tvalid_1's binary_logloss: 0.147239\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[9]\tvalid_0's auc: 0.866131\tvalid_0's binary_logloss: 0.132702\tvalid_1's auc: 0.837967\tvalid_1's binary_logloss: 0.144848\n",
      "[10]\tvalid_0's auc: 0.867742\tvalid_0's binary_logloss: 0.1314\tvalid_1's auc: 0.837692\tvalid_1's binary_logloss: 0.143974\n",
      "[11]\tvalid_0's auc: 0.869179\tvalid_0's binary_logloss: 0.130269\tvalid_1's auc: 0.837036\tvalid_1's binary_logloss: 0.143346\n",
      "[12]\tvalid_0's auc: 0.870565\tvalid_0's binary_logloss: 0.129231\tvalid_1's auc: 0.836722\tvalid_1's binary_logloss: 0.14276\n",
      "[13]\tvalid_0's auc: 0.871715\tvalid_0's binary_logloss: 0.128325\tvalid_1's auc: 0.836964\tvalid_1's binary_logloss: 0.14221\n",
      "[14]\tvalid_0's auc: 0.873118\tvalid_0's binary_logloss: 0.127433\tvalid_1's auc: 0.836616\tvalid_1's binary_logloss: 0.141769\n",
      "[15]\tvalid_0's auc: 0.874777\tvalid_0's binary_logloss: 0.126525\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.141352\n",
      "[16]\tvalid_0's auc: 0.876077\tvalid_0's binary_logloss: 0.125761\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.141109\n",
      "[17]\tvalid_0's auc: 0.87775\tvalid_0's binary_logloss: 0.125008\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.140988\n",
      "[18]\tvalid_0's auc: 0.879171\tvalid_0's binary_logloss: 0.124326\tvalid_1's auc: 0.837265\tvalid_1's binary_logloss: 0.140636\n",
      "[19]\tvalid_0's auc: 0.880771\tvalid_0's binary_logloss: 0.123637\tvalid_1's auc: 0.836922\tvalid_1's binary_logloss: 0.140454\n",
      "[20]\tvalid_0's auc: 0.882476\tvalid_0's binary_logloss: 0.123001\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.140307\n",
      "[21]\tvalid_0's auc: 0.883998\tvalid_0's binary_logloss: 0.122399\tvalid_1's auc: 0.83698\tvalid_1's binary_logloss: 0.140209\n",
      "[22]\tvalid_0's auc: 0.885371\tvalid_0's binary_logloss: 0.121789\tvalid_1's auc: 0.836641\tvalid_1's binary_logloss: 0.140165\n",
      "[23]\tvalid_0's auc: 0.886707\tvalid_0's binary_logloss: 0.121228\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.140035\n",
      "[24]\tvalid_0's auc: 0.887902\tvalid_0's binary_logloss: 0.120685\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.139977\n",
      "[25]\tvalid_0's auc: 0.889092\tvalid_0's binary_logloss: 0.12018\tvalid_1's auc: 0.83633\tvalid_1's binary_logloss: 0.139976\n",
      "[26]\tvalid_0's auc: 0.890287\tvalid_0's binary_logloss: 0.119694\tvalid_1's auc: 0.836088\tvalid_1's binary_logloss: 0.13994\n",
      "[27]\tvalid_0's auc: 0.891557\tvalid_0's binary_logloss: 0.11921\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.139925\n",
      "[28]\tvalid_0's auc: 0.892479\tvalid_0's binary_logloss: 0.118767\tvalid_1's auc: 0.836047\tvalid_1's binary_logloss: 0.139873\n",
      "[29]\tvalid_0's auc: 0.893752\tvalid_0's binary_logloss: 0.118311\tvalid_1's auc: 0.836111\tvalid_1's binary_logloss: 0.139884\n",
      "[30]\tvalid_0's auc: 0.894906\tvalid_0's binary_logloss: 0.117808\tvalid_1's auc: 0.836072\tvalid_1's binary_logloss: 0.139896\n",
      "[31]\tvalid_0's auc: 0.895735\tvalid_0's binary_logloss: 0.117395\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.139865\n",
      "[32]\tvalid_0's auc: 0.896982\tvalid_0's binary_logloss: 0.116948\tvalid_1's auc: 0.836178\tvalid_1's binary_logloss: 0.139866\n",
      "[33]\tvalid_0's auc: 0.898332\tvalid_0's binary_logloss: 0.116584\tvalid_1's auc: 0.836498\tvalid_1's binary_logloss: 0.139828\n",
      "[34]\tvalid_0's auc: 0.899324\tvalid_0's binary_logloss: 0.116129\tvalid_1's auc: 0.836499\tvalid_1's binary_logloss: 0.139874\n",
      "[35]\tvalid_0's auc: 0.900175\tvalid_0's binary_logloss: 0.11578\tvalid_1's auc: 0.836226\tvalid_1's binary_logloss: 0.139924\n",
      "[36]\tvalid_0's auc: 0.901261\tvalid_0's binary_logloss: 0.115448\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.13999\n",
      "[37]\tvalid_0's auc: 0.901964\tvalid_0's binary_logloss: 0.115083\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.14012\n",
      "[38]\tvalid_0's auc: 0.902511\tvalid_0's binary_logloss: 0.114769\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.140207\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.831709\tvalid_0's binary_logloss: 0.155602\tvalid_1's auc: 0.817142\tvalid_1's binary_logloss: 0.164826\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845013\tvalid_0's binary_logloss: 0.15006\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.159674\n",
      "[3]\tvalid_0's auc: 0.847843\tvalid_0's binary_logloss: 0.145936\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.155788\n",
      "[4]\tvalid_0's auc: 0.853126\tvalid_0's binary_logloss: 0.142751\tvalid_1's auc: 0.836086\tvalid_1's binary_logloss: 0.152883\n",
      "[5]\tvalid_0's auc: 0.855373\tvalid_0's binary_logloss: 0.140124\tvalid_1's auc: 0.836802\tvalid_1's binary_logloss: 0.150648\n",
      "[6]\tvalid_0's auc: 0.858982\tvalid_0's binary_logloss: 0.137929\tvalid_1's auc: 0.837196\tvalid_1's binary_logloss: 0.148838\n",
      "[7]\tvalid_0's auc: 0.860432\tvalid_0's binary_logloss: 0.136116\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.147355\n",
      "[8]\tvalid_0's auc: 0.86237\tvalid_0's binary_logloss: 0.134493\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.146137\n",
      "[9]\tvalid_0's auc: 0.864538\tvalid_0's binary_logloss: 0.133112\tvalid_1's auc: 0.837924\tvalid_1's binary_logloss: 0.145039\n",
      "[10]\tvalid_0's auc: 0.866285\tvalid_0's binary_logloss: 0.131888\tvalid_1's auc: 0.837794\tvalid_1's binary_logloss: 0.14412\n",
      "[11]\tvalid_0's auc: 0.867679\tvalid_0's binary_logloss: 0.130774\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.143337\n",
      "[12]\tvalid_0's auc: 0.869423\tvalid_0's binary_logloss: 0.129754\tvalid_1's auc: 0.839862\tvalid_1's binary_logloss: 0.142609\n",
      "[13]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.128815\tvalid_1's auc: 0.838873\tvalid_1's binary_logloss: 0.142215\n",
      "[14]\tvalid_0's auc: 0.871813\tvalid_0's binary_logloss: 0.128007\tvalid_1's auc: 0.83922\tvalid_1's binary_logloss: 0.141872\n",
      "[15]\tvalid_0's auc: 0.873349\tvalid_0's binary_logloss: 0.127226\tvalid_1's auc: 0.838558\tvalid_1's binary_logloss: 0.141577\n",
      "[16]\tvalid_0's auc: 0.875071\tvalid_0's binary_logloss: 0.126463\tvalid_1's auc: 0.838328\tvalid_1's binary_logloss: 0.141336\n",
      "[17]\tvalid_0's auc: 0.87671\tvalid_0's binary_logloss: 0.125734\tvalid_1's auc: 0.838859\tvalid_1's binary_logloss: 0.140993\n",
      "[18]\tvalid_0's auc: 0.877745\tvalid_0's binary_logloss: 0.12506\tvalid_1's auc: 0.838826\tvalid_1's binary_logloss: 0.140774\n",
      "[19]\tvalid_0's auc: 0.87955\tvalid_0's binary_logloss: 0.124346\tvalid_1's auc: 0.838685\tvalid_1's binary_logloss: 0.14062\n",
      "[20]\tvalid_0's auc: 0.88095\tvalid_0's binary_logloss: 0.123758\tvalid_1's auc: 0.839472\tvalid_1's binary_logloss: 0.140278\n",
      "[21]\tvalid_0's auc: 0.882333\tvalid_0's binary_logloss: 0.123172\tvalid_1's auc: 0.839953\tvalid_1's binary_logloss: 0.139987\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[23]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.122106\tvalid_1's auc: 0.840085\tvalid_1's binary_logloss: 0.139652\n",
      "[24]\tvalid_0's auc: 0.886267\tvalid_0's binary_logloss: 0.121544\tvalid_1's auc: 0.839519\tvalid_1's binary_logloss: 0.13967\n",
      "[25]\tvalid_0's auc: 0.887231\tvalid_0's binary_logloss: 0.12107\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.139554\n",
      "[26]\tvalid_0's auc: 0.888362\tvalid_0's binary_logloss: 0.120592\tvalid_1's auc: 0.839436\tvalid_1's binary_logloss: 0.139477\n",
      "[27]\tvalid_0's auc: 0.889402\tvalid_0's binary_logloss: 0.12012\tvalid_1's auc: 0.839576\tvalid_1's binary_logloss: 0.139364\n",
      "[28]\tvalid_0's auc: 0.890567\tvalid_0's binary_logloss: 0.119695\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.139379\n",
      "[29]\tvalid_0's auc: 0.891561\tvalid_0's binary_logloss: 0.119229\tvalid_1's auc: 0.838494\tvalid_1's binary_logloss: 0.139484\n",
      "[30]\tvalid_0's auc: 0.892335\tvalid_0's binary_logloss: 0.118804\tvalid_1's auc: 0.838442\tvalid_1's binary_logloss: 0.139471\n",
      "[31]\tvalid_0's auc: 0.893386\tvalid_0's binary_logloss: 0.118372\tvalid_1's auc: 0.838123\tvalid_1's binary_logloss: 0.139487\n",
      "[32]\tvalid_0's auc: 0.894414\tvalid_0's binary_logloss: 0.117941\tvalid_1's auc: 0.838093\tvalid_1's binary_logloss: 0.139521\n",
      "[33]\tvalid_0's auc: 0.895465\tvalid_0's binary_logloss: 0.117514\tvalid_1's auc: 0.837947\tvalid_1's binary_logloss: 0.139537\n",
      "[34]\tvalid_0's auc: 0.896166\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837807\tvalid_1's binary_logloss: 0.139577\n",
      "[35]\tvalid_0's auc: 0.896684\tvalid_0's binary_logloss: 0.116863\tvalid_1's auc: 0.837668\tvalid_1's binary_logloss: 0.139588\n",
      "[36]\tvalid_0's auc: 0.897535\tvalid_0's binary_logloss: 0.116484\tvalid_1's auc: 0.837261\tvalid_1's binary_logloss: 0.139733\n",
      "[37]\tvalid_0's auc: 0.898253\tvalid_0's binary_logloss: 0.116123\tvalid_1's auc: 0.837235\tvalid_1's binary_logloss: 0.139781\n",
      "[38]\tvalid_0's auc: 0.898964\tvalid_0's binary_logloss: 0.115828\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.139841\n",
      "[39]\tvalid_0's auc: 0.89972\tvalid_0's binary_logloss: 0.115476\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.13991\n",
      "[40]\tvalid_0's auc: 0.900293\tvalid_0's binary_logloss: 0.115122\tvalid_1's auc: 0.837147\tvalid_1's binary_logloss: 0.139846\n",
      "[41]\tvalid_0's auc: 0.900934\tvalid_0's binary_logloss: 0.114813\tvalid_1's auc: 0.836986\tvalid_1's binary_logloss: 0.139923\n",
      "[42]\tvalid_0's auc: 0.901636\tvalid_0's binary_logloss: 0.114489\tvalid_1's auc: 0.836537\tvalid_1's binary_logloss: 0.140017\n",
      "[43]\tvalid_0's auc: 0.90272\tvalid_0's binary_logloss: 0.114161\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.140025\n",
      "[44]\tvalid_0's auc: 0.903084\tvalid_0's binary_logloss: 0.113909\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.140037\n",
      "[45]\tvalid_0's auc: 0.903622\tvalid_0's binary_logloss: 0.113641\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.140106\n",
      "[46]\tvalid_0's auc: 0.904201\tvalid_0's binary_logloss: 0.113301\tvalid_1's auc: 0.83619\tvalid_1's binary_logloss: 0.140186\n",
      "[47]\tvalid_0's auc: 0.904762\tvalid_0's binary_logloss: 0.112961\tvalid_1's auc: 0.836219\tvalid_1's binary_logloss: 0.14019\n",
      "[48]\tvalid_0's auc: 0.905387\tvalid_0's binary_logloss: 0.11272\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.140252\n",
      "[49]\tvalid_0's auc: 0.90574\tvalid_0's binary_logloss: 0.112462\tvalid_1's auc: 0.835874\tvalid_1's binary_logloss: 0.140337\n",
      "[50]\tvalid_0's auc: 0.906329\tvalid_0's binary_logloss: 0.112158\tvalid_1's auc: 0.835754\tvalid_1's binary_logloss: 0.140395\n",
      "[51]\tvalid_0's auc: 0.906807\tvalid_0's binary_logloss: 0.111885\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140381\n",
      "[52]\tvalid_0's auc: 0.907054\tvalid_0's binary_logloss: 0.111647\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.14054\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.832354\tvalid_0's binary_logloss: 0.156011\tvalid_1's auc: 0.824432\tvalid_1's binary_logloss: 0.164746\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845573\tvalid_0's binary_logloss: 0.150188\tvalid_1's auc: 0.832252\tvalid_1's binary_logloss: 0.159476\n",
      "[3]\tvalid_0's auc: 0.848609\tvalid_0's binary_logloss: 0.145958\tvalid_1's auc: 0.834138\tvalid_1's binary_logloss: 0.155738\n",
      "[4]\tvalid_0's auc: 0.851924\tvalid_0's binary_logloss: 0.142678\tvalid_1's auc: 0.834388\tvalid_1's binary_logloss: 0.152853\n",
      "[5]\tvalid_0's auc: 0.854459\tvalid_0's binary_logloss: 0.140096\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.150614\n",
      "[6]\tvalid_0's auc: 0.860195\tvalid_0's binary_logloss: 0.137818\tvalid_1's auc: 0.837402\tvalid_1's binary_logloss: 0.148623\n",
      "[7]\tvalid_0's auc: 0.861877\tvalid_0's binary_logloss: 0.135948\tvalid_1's auc: 0.837505\tvalid_1's binary_logloss: 0.14706\n",
      "[8]\tvalid_0's auc: 0.863997\tvalid_0's binary_logloss: 0.134369\tvalid_1's auc: 0.837955\tvalid_1's binary_logloss: 0.145859\n",
      "[9]\tvalid_0's auc: 0.866333\tvalid_0's binary_logloss: 0.132937\tvalid_1's auc: 0.839366\tvalid_1's binary_logloss: 0.144812\n",
      "[10]\tvalid_0's auc: 0.867965\tvalid_0's binary_logloss: 0.131647\tvalid_1's auc: 0.839399\tvalid_1's binary_logloss: 0.143987\n",
      "[11]\tvalid_0's auc: 0.869851\tvalid_0's binary_logloss: 0.130406\tvalid_1's auc: 0.839421\tvalid_1's binary_logloss: 0.14329\n",
      "[12]\tvalid_0's auc: 0.872223\tvalid_0's binary_logloss: 0.129323\tvalid_1's auc: 0.839253\tvalid_1's binary_logloss: 0.142712\n",
      "[13]\tvalid_0's auc: 0.873776\tvalid_0's binary_logloss: 0.12837\tvalid_1's auc: 0.838607\tvalid_1's binary_logloss: 0.142208\n",
      "[14]\tvalid_0's auc: 0.875666\tvalid_0's binary_logloss: 0.127409\tvalid_1's auc: 0.839513\tvalid_1's binary_logloss: 0.141711\n",
      "[15]\tvalid_0's auc: 0.876977\tvalid_0's binary_logloss: 0.126591\tvalid_1's auc: 0.839539\tvalid_1's binary_logloss: 0.141288\n",
      "[16]\tvalid_0's auc: 0.878097\tvalid_0's binary_logloss: 0.125796\tvalid_1's auc: 0.839021\tvalid_1's binary_logloss: 0.141036\n",
      "[17]\tvalid_0's auc: 0.879098\tvalid_0's binary_logloss: 0.125088\tvalid_1's auc: 0.837465\tvalid_1's binary_logloss: 0.1409\n",
      "[18]\tvalid_0's auc: 0.880601\tvalid_0's binary_logloss: 0.124364\tvalid_1's auc: 0.837466\tvalid_1's binary_logloss: 0.140701\n",
      "[19]\tvalid_0's auc: 0.88248\tvalid_0's binary_logloss: 0.123621\tvalid_1's auc: 0.838247\tvalid_1's binary_logloss: 0.140429\n",
      "[20]\tvalid_0's auc: 0.883936\tvalid_0's binary_logloss: 0.122911\tvalid_1's auc: 0.83793\tvalid_1's binary_logloss: 0.140317\n",
      "[21]\tvalid_0's auc: 0.88529\tvalid_0's binary_logloss: 0.122327\tvalid_1's auc: 0.838792\tvalid_1's binary_logloss: 0.140098\n",
      "[22]\tvalid_0's auc: 0.88648\tvalid_0's binary_logloss: 0.121732\tvalid_1's auc: 0.838403\tvalid_1's binary_logloss: 0.139974\n",
      "[23]\tvalid_0's auc: 0.887765\tvalid_0's binary_logloss: 0.121176\tvalid_1's auc: 0.838404\tvalid_1's binary_logloss: 0.139891\n",
      "[24]\tvalid_0's auc: 0.888887\tvalid_0's binary_logloss: 0.120591\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.890044\tvalid_0's binary_logloss: 0.120074\tvalid_1's auc: 0.838114\tvalid_1's binary_logloss: 0.139883\n",
      "[26]\tvalid_0's auc: 0.891051\tvalid_0's binary_logloss: 0.119588\tvalid_1's auc: 0.838544\tvalid_1's binary_logloss: 0.139784\n",
      "[27]\tvalid_0's auc: 0.892157\tvalid_0's binary_logloss: 0.119094\tvalid_1's auc: 0.838348\tvalid_1's binary_logloss: 0.139788\n",
      "[28]\tvalid_0's auc: 0.893116\tvalid_0's binary_logloss: 0.118639\tvalid_1's auc: 0.838654\tvalid_1's binary_logloss: 0.139723\n",
      "[29]\tvalid_0's auc: 0.894065\tvalid_0's binary_logloss: 0.118191\tvalid_1's auc: 0.83815\tvalid_1's binary_logloss: 0.13979\n",
      "[30]\tvalid_0's auc: 0.895189\tvalid_0's binary_logloss: 0.117742\tvalid_1's auc: 0.838393\tvalid_1's binary_logloss: 0.139755\n",
      "[31]\tvalid_0's auc: 0.896336\tvalid_0's binary_logloss: 0.117289\tvalid_1's auc: 0.838384\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.897473\tvalid_0's binary_logloss: 0.116901\tvalid_1's auc: 0.838447\tvalid_1's binary_logloss: 0.139683\n",
      "[33]\tvalid_0's auc: 0.898375\tvalid_0's binary_logloss: 0.116464\tvalid_1's auc: 0.838512\tvalid_1's binary_logloss: 0.139636\n",
      "[34]\tvalid_0's auc: 0.899242\tvalid_0's binary_logloss: 0.116054\tvalid_1's auc: 0.838475\tvalid_1's binary_logloss: 0.139614\n",
      "[35]\tvalid_0's auc: 0.900316\tvalid_0's binary_logloss: 0.115653\tvalid_1's auc: 0.838522\tvalid_1's binary_logloss: 0.13957\n",
      "[36]\tvalid_0's auc: 0.901114\tvalid_0's binary_logloss: 0.11531\tvalid_1's auc: 0.838721\tvalid_1's binary_logloss: 0.139537\n",
      "[37]\tvalid_0's auc: 0.901919\tvalid_0's binary_logloss: 0.114911\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.139581\n",
      "[38]\tvalid_0's auc: 0.902827\tvalid_0's binary_logloss: 0.114566\tvalid_1's auc: 0.839027\tvalid_1's binary_logloss: 0.139517\n",
      "[39]\tvalid_0's auc: 0.903647\tvalid_0's binary_logloss: 0.114176\tvalid_1's auc: 0.839264\tvalid_1's binary_logloss: 0.13948\n",
      "[40]\tvalid_0's auc: 0.904461\tvalid_0's binary_logloss: 0.11382\tvalid_1's auc: 0.839535\tvalid_1's binary_logloss: 0.13945\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[42]\tvalid_0's auc: 0.90573\tvalid_0's binary_logloss: 0.11309\tvalid_1's auc: 0.839177\tvalid_1's binary_logloss: 0.139527\n",
      "[43]\tvalid_0's auc: 0.906484\tvalid_0's binary_logloss: 0.112737\tvalid_1's auc: 0.839561\tvalid_1's binary_logloss: 0.139494\n",
      "[44]\tvalid_0's auc: 0.907269\tvalid_0's binary_logloss: 0.112432\tvalid_1's auc: 0.839357\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.907761\tvalid_0's binary_logloss: 0.112094\tvalid_1's auc: 0.839145\tvalid_1's binary_logloss: 0.139503\n",
      "[46]\tvalid_0's auc: 0.908229\tvalid_0's binary_logloss: 0.111774\tvalid_1's auc: 0.839064\tvalid_1's binary_logloss: 0.139515\n",
      "[47]\tvalid_0's auc: 0.908961\tvalid_0's binary_logloss: 0.111399\tvalid_1's auc: 0.838752\tvalid_1's binary_logloss: 0.139561\n",
      "[48]\tvalid_0's auc: 0.909623\tvalid_0's binary_logloss: 0.111156\tvalid_1's auc: 0.838658\tvalid_1's binary_logloss: 0.139589\n",
      "[49]\tvalid_0's auc: 0.910075\tvalid_0's binary_logloss: 0.110845\tvalid_1's auc: 0.838588\tvalid_1's binary_logloss: 0.13959\n",
      "[50]\tvalid_0's auc: 0.910737\tvalid_0's binary_logloss: 0.110566\tvalid_1's auc: 0.838609\tvalid_1's binary_logloss: 0.139608\n",
      "[51]\tvalid_0's auc: 0.911115\tvalid_0's binary_logloss: 0.110282\tvalid_1's auc: 0.838459\tvalid_1's binary_logloss: 0.139669\n",
      "[52]\tvalid_0's auc: 0.911601\tvalid_0's binary_logloss: 0.10999\tvalid_1's auc: 0.838303\tvalid_1's binary_logloss: 0.139708\n",
      "[53]\tvalid_0's auc: 0.911908\tvalid_0's binary_logloss: 0.109751\tvalid_1's auc: 0.838117\tvalid_1's binary_logloss: 0.13975\n",
      "[54]\tvalid_0's auc: 0.912261\tvalid_0's binary_logloss: 0.109498\tvalid_1's auc: 0.838252\tvalid_1's binary_logloss: 0.139711\n",
      "[55]\tvalid_0's auc: 0.912616\tvalid_0's binary_logloss: 0.109226\tvalid_1's auc: 0.837936\tvalid_1's binary_logloss: 0.13983\n",
      "[56]\tvalid_0's auc: 0.913202\tvalid_0's binary_logloss: 0.108936\tvalid_1's auc: 0.83804\tvalid_1's binary_logloss: 0.13983\n",
      "[57]\tvalid_0's auc: 0.913592\tvalid_0's binary_logloss: 0.10867\tvalid_1's auc: 0.838083\tvalid_1's binary_logloss: 0.139818\n",
      "[58]\tvalid_0's auc: 0.913818\tvalid_0's binary_logloss: 0.108421\tvalid_1's auc: 0.837716\tvalid_1's binary_logloss: 0.139971\n",
      "[59]\tvalid_0's auc: 0.914378\tvalid_0's binary_logloss: 0.108194\tvalid_1's auc: 0.837836\tvalid_1's binary_logloss: 0.139971\n",
      "[60]\tvalid_0's auc: 0.91493\tvalid_0's binary_logloss: 0.107966\tvalid_1's auc: 0.837549\tvalid_1's binary_logloss: 0.140068\n",
      "[61]\tvalid_0's auc: 0.915354\tvalid_0's binary_logloss: 0.107682\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.140197\n",
      "[62]\tvalid_0's auc: 0.915606\tvalid_0's binary_logloss: 0.107477\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.140336\n",
      "[63]\tvalid_0's auc: 0.916315\tvalid_0's binary_logloss: 0.107178\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.140384\n",
      "[64]\tvalid_0's auc: 0.916522\tvalid_0's binary_logloss: 0.10698\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.140446\n",
      "[65]\tvalid_0's auc: 0.917048\tvalid_0's binary_logloss: 0.106704\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.140528\n",
      "[66]\tvalid_0's auc: 0.917714\tvalid_0's binary_logloss: 0.1065\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.140589\n",
      "[67]\tvalid_0's auc: 0.918245\tvalid_0's binary_logloss: 0.106235\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.140673\n",
      "[68]\tvalid_0's auc: 0.918757\tvalid_0's binary_logloss: 0.105956\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.140696\n",
      "[69]\tvalid_0's auc: 0.919319\tvalid_0's binary_logloss: 0.105704\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.140788\n",
      "[70]\tvalid_0's auc: 0.919498\tvalid_0's binary_logloss: 0.105505\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.140912\n",
      "[71]\tvalid_0's auc: 0.919774\tvalid_0's binary_logloss: 0.105296\tvalid_1's auc: 0.834571\tvalid_1's binary_logloss: 0.141016\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13272\n",
      "[LightGBM] [Info] Number of data points in the train set: 48652, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203551\n",
      "[LightGBM] [Info] Start training from score -3.203551\n",
      "[1]\tvalid_0's auc: 0.833136\tvalid_0's binary_logloss: 0.155618\tvalid_1's auc: 0.823516\tvalid_1's binary_logloss: 0.164757\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.842036\tvalid_0's binary_logloss: 0.149972\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.159717\n",
      "[3]\tvalid_0's auc: 0.847172\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.830898\tvalid_1's binary_logloss: 0.156155\n",
      "[4]\tvalid_0's auc: 0.854159\tvalid_0's binary_logloss: 0.142767\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.153226\n",
      "[5]\tvalid_0's auc: 0.857704\tvalid_0's binary_logloss: 0.140143\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.15094\n",
      "[6]\tvalid_0's auc: 0.860316\tvalid_0's binary_logloss: 0.137951\tvalid_1's auc: 0.836175\tvalid_1's binary_logloss: 0.149162\n",
      "[7]\tvalid_0's auc: 0.862439\tvalid_0's binary_logloss: 0.136077\tvalid_1's auc: 0.835532\tvalid_1's binary_logloss: 0.147649\n",
      "[8]\tvalid_0's auc: 0.864272\tvalid_0's binary_logloss: 0.134388\tvalid_1's auc: 0.83563\tvalid_1's binary_logloss: 0.146354\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[10]\tvalid_0's auc: 0.867535\tvalid_0's binary_logloss: 0.13164\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.144361\n",
      "[11]\tvalid_0's auc: 0.869515\tvalid_0's binary_logloss: 0.130402\tvalid_1's auc: 0.83647\tvalid_1's binary_logloss: 0.143633\n",
      "[12]\tvalid_0's auc: 0.870746\tvalid_0's binary_logloss: 0.129418\tvalid_1's auc: 0.836512\tvalid_1's binary_logloss: 0.14302\n",
      "[13]\tvalid_0's auc: 0.872719\tvalid_0's binary_logloss: 0.12844\tvalid_1's auc: 0.836236\tvalid_1's binary_logloss: 0.142554\n",
      "[14]\tvalid_0's auc: 0.874567\tvalid_0's binary_logloss: 0.127509\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.142114\n",
      "[15]\tvalid_0's auc: 0.876764\tvalid_0's binary_logloss: 0.126626\tvalid_1's auc: 0.836237\tvalid_1's binary_logloss: 0.141748\n",
      "[16]\tvalid_0's auc: 0.87792\tvalid_0's binary_logloss: 0.125854\tvalid_1's auc: 0.836368\tvalid_1's binary_logloss: 0.141474\n",
      "[17]\tvalid_0's auc: 0.879062\tvalid_0's binary_logloss: 0.125102\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.14123\n",
      "[18]\tvalid_0's auc: 0.880333\tvalid_0's binary_logloss: 0.12445\tvalid_1's auc: 0.835408\tvalid_1's binary_logloss: 0.14109\n",
      "[19]\tvalid_0's auc: 0.881986\tvalid_0's binary_logloss: 0.123735\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.140974\n",
      "[20]\tvalid_0's auc: 0.883497\tvalid_0's binary_logloss: 0.123057\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.140833\n",
      "[21]\tvalid_0's auc: 0.88477\tvalid_0's binary_logloss: 0.122502\tvalid_1's auc: 0.83413\tvalid_1's binary_logloss: 0.140756\n",
      "[22]\tvalid_0's auc: 0.886052\tvalid_0's binary_logloss: 0.121963\tvalid_1's auc: 0.833448\tvalid_1's binary_logloss: 0.140744\n",
      "[23]\tvalid_0's auc: 0.88729\tvalid_0's binary_logloss: 0.121374\tvalid_1's auc: 0.832949\tvalid_1's binary_logloss: 0.140705\n",
      "[24]\tvalid_0's auc: 0.888202\tvalid_0's binary_logloss: 0.120845\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.140716\n",
      "[25]\tvalid_0's auc: 0.889261\tvalid_0's binary_logloss: 0.120276\tvalid_1's auc: 0.832717\tvalid_1's binary_logloss: 0.140524\n",
      "[26]\tvalid_0's auc: 0.89008\tvalid_0's binary_logloss: 0.119792\tvalid_1's auc: 0.832126\tvalid_1's binary_logloss: 0.140541\n",
      "[27]\tvalid_0's auc: 0.891071\tvalid_0's binary_logloss: 0.119365\tvalid_1's auc: 0.832245\tvalid_1's binary_logloss: 0.140458\n",
      "[28]\tvalid_0's auc: 0.891965\tvalid_0's binary_logloss: 0.118917\tvalid_1's auc: 0.832098\tvalid_1's binary_logloss: 0.140348\n",
      "[29]\tvalid_0's auc: 0.893292\tvalid_0's binary_logloss: 0.118413\tvalid_1's auc: 0.832091\tvalid_1's binary_logloss: 0.140371\n",
      "[30]\tvalid_0's auc: 0.894193\tvalid_0's binary_logloss: 0.118022\tvalid_1's auc: 0.831601\tvalid_1's binary_logloss: 0.140412\n",
      "[31]\tvalid_0's auc: 0.894983\tvalid_0's binary_logloss: 0.117589\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.140402\n",
      "[32]\tvalid_0's auc: 0.896347\tvalid_0's binary_logloss: 0.117114\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.14049\n",
      "[33]\tvalid_0's auc: 0.897531\tvalid_0's binary_logloss: 0.116696\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.140462\n",
      "[34]\tvalid_0's auc: 0.898503\tvalid_0's binary_logloss: 0.116337\tvalid_1's auc: 0.831998\tvalid_1's binary_logloss: 0.140436\n",
      "[35]\tvalid_0's auc: 0.899431\tvalid_0's binary_logloss: 0.115966\tvalid_1's auc: 0.832323\tvalid_1's binary_logloss: 0.140357\n",
      "[36]\tvalid_0's auc: 0.900259\tvalid_0's binary_logloss: 0.115619\tvalid_1's auc: 0.832052\tvalid_1's binary_logloss: 0.140411\n",
      "[37]\tvalid_0's auc: 0.901414\tvalid_0's binary_logloss: 0.115269\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.14042\n",
      "[38]\tvalid_0's auc: 0.902365\tvalid_0's binary_logloss: 0.114862\tvalid_1's auc: 0.832015\tvalid_1's binary_logloss: 0.140464\n",
      "[39]\tvalid_0's auc: 0.90309\tvalid_0's binary_logloss: 0.114499\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.140399\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.866024\tvalid_0's binary_logloss: 0.132932\tvalid_1's auc: 0.836913\tvalid_1's binary_logloss: 0.145234\n",
      "[LightGBM] [Info] Number of positive: 1900, number of negative: 46753\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13355\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039052 -> initscore=-3.203025\n",
      "[LightGBM] [Info] Start training from score -3.203025\n",
      "[1]\tvalid_0's auc: 0.833297\tvalid_0's binary_logloss: 0.155798\tvalid_1's auc: 0.814648\tvalid_1's binary_logloss: 0.165178\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.84496\tvalid_0's binary_logloss: 0.150106\tvalid_1's auc: 0.825101\tvalid_1's binary_logloss: 0.159672\n",
      "[3]\tvalid_0's auc: 0.848339\tvalid_0's binary_logloss: 0.145999\tvalid_1's auc: 0.829756\tvalid_1's binary_logloss: 0.156122\n",
      "[4]\tvalid_0's auc: 0.852327\tvalid_0's binary_logloss: 0.142785\tvalid_1's auc: 0.83262\tvalid_1's binary_logloss: 0.153215\n",
      "[5]\tvalid_0's auc: 0.856991\tvalid_0's binary_logloss: 0.140075\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.150936\n",
      "[6]\tvalid_0's auc: 0.860123\tvalid_0's binary_logloss: 0.13786\tvalid_1's auc: 0.837776\tvalid_1's binary_logloss: 0.149015\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[8]\tvalid_0's auc: 0.863556\tvalid_0's binary_logloss: 0.134329\tvalid_1's auc: 0.837522\tvalid_1's binary_logloss: 0.146495\n",
      "[9]\tvalid_0's auc: 0.865702\tvalid_0's binary_logloss: 0.132867\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.145505\n",
      "[10]\tvalid_0's auc: 0.867419\tvalid_0's binary_logloss: 0.131589\tvalid_1's auc: 0.83738\tvalid_1's binary_logloss: 0.144639\n",
      "[11]\tvalid_0's auc: 0.869474\tvalid_0's binary_logloss: 0.130487\tvalid_1's auc: 0.837061\tvalid_1's binary_logloss: 0.143902\n",
      "[12]\tvalid_0's auc: 0.871188\tvalid_0's binary_logloss: 0.12944\tvalid_1's auc: 0.83674\tvalid_1's binary_logloss: 0.14338\n",
      "[13]\tvalid_0's auc: 0.873292\tvalid_0's binary_logloss: 0.128408\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.142955\n",
      "[14]\tvalid_0's auc: 0.875272\tvalid_0's binary_logloss: 0.127498\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.142577\n",
      "[15]\tvalid_0's auc: 0.876333\tvalid_0's binary_logloss: 0.126687\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.142233\n",
      "[16]\tvalid_0's auc: 0.878172\tvalid_0's binary_logloss: 0.125868\tvalid_1's auc: 0.835135\tvalid_1's binary_logloss: 0.141915\n",
      "[17]\tvalid_0's auc: 0.879493\tvalid_0's binary_logloss: 0.125166\tvalid_1's auc: 0.834462\tvalid_1's binary_logloss: 0.141684\n",
      "[18]\tvalid_0's auc: 0.880697\tvalid_0's binary_logloss: 0.124485\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.141381\n",
      "[19]\tvalid_0's auc: 0.881751\tvalid_0's binary_logloss: 0.123851\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.141089\n",
      "[20]\tvalid_0's auc: 0.883208\tvalid_0's binary_logloss: 0.123231\tvalid_1's auc: 0.834617\tvalid_1's binary_logloss: 0.141074\n",
      "[21]\tvalid_0's auc: 0.884441\tvalid_0's binary_logloss: 0.122672\tvalid_1's auc: 0.835086\tvalid_1's binary_logloss: 0.140871\n",
      "[22]\tvalid_0's auc: 0.885795\tvalid_0's binary_logloss: 0.122047\tvalid_1's auc: 0.834691\tvalid_1's binary_logloss: 0.140833\n",
      "[23]\tvalid_0's auc: 0.88703\tvalid_0's binary_logloss: 0.121437\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.14067\n",
      "[24]\tvalid_0's auc: 0.888628\tvalid_0's binary_logloss: 0.120866\tvalid_1's auc: 0.834703\tvalid_1's binary_logloss: 0.140607\n",
      "[25]\tvalid_0's auc: 0.889539\tvalid_0's binary_logloss: 0.120354\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.140572\n",
      "[26]\tvalid_0's auc: 0.890707\tvalid_0's binary_logloss: 0.119835\tvalid_1's auc: 0.834353\tvalid_1's binary_logloss: 0.140508\n",
      "[27]\tvalid_0's auc: 0.89189\tvalid_0's binary_logloss: 0.119344\tvalid_1's auc: 0.833736\tvalid_1's binary_logloss: 0.14057\n",
      "[28]\tvalid_0's auc: 0.892973\tvalid_0's binary_logloss: 0.118875\tvalid_1's auc: 0.83339\tvalid_1's binary_logloss: 0.140614\n",
      "[29]\tvalid_0's auc: 0.894538\tvalid_0's binary_logloss: 0.118402\tvalid_1's auc: 0.833262\tvalid_1's binary_logloss: 0.140617\n",
      "[30]\tvalid_0's auc: 0.895805\tvalid_0's binary_logloss: 0.117902\tvalid_1's auc: 0.832581\tvalid_1's binary_logloss: 0.140733\n",
      "[31]\tvalid_0's auc: 0.897165\tvalid_0's binary_logloss: 0.117449\tvalid_1's auc: 0.832965\tvalid_1's binary_logloss: 0.14067\n",
      "[32]\tvalid_0's auc: 0.898106\tvalid_0's binary_logloss: 0.117027\tvalid_1's auc: 0.832548\tvalid_1's binary_logloss: 0.140717\n",
      "[33]\tvalid_0's auc: 0.898897\tvalid_0's binary_logloss: 0.116646\tvalid_1's auc: 0.832294\tvalid_1's binary_logloss: 0.140755\n",
      "[34]\tvalid_0's auc: 0.899579\tvalid_0's binary_logloss: 0.11632\tvalid_1's auc: 0.832478\tvalid_1's binary_logloss: 0.14074\n",
      "[35]\tvalid_0's auc: 0.900941\tvalid_0's binary_logloss: 0.115884\tvalid_1's auc: 0.83257\tvalid_1's binary_logloss: 0.140703\n",
      "[36]\tvalid_0's auc: 0.902074\tvalid_0's binary_logloss: 0.115452\tvalid_1's auc: 0.832369\tvalid_1's binary_logloss: 0.140774\n",
      "[37]\tvalid_0's auc: 0.902849\tvalid_0's binary_logloss: 0.115101\tvalid_1's auc: 0.832046\tvalid_1's binary_logloss: 0.140792\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.862074\tvalid_0's binary_logloss: 0.135927\tvalid_1's auc: 0.837932\tvalid_1's binary_logloss: 0.147666\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13293\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.834438\tvalid_0's binary_logloss: 0.155707\tvalid_1's auc: 0.821419\tvalid_1's binary_logloss: 0.164715\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845934\tvalid_0's binary_logloss: 0.150048\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.159506\n",
      "[3]\tvalid_0's auc: 0.849836\tvalid_0's binary_logloss: 0.145927\tvalid_1's auc: 0.831719\tvalid_1's binary_logloss: 0.155735\n",
      "[4]\tvalid_0's auc: 0.854642\tvalid_0's binary_logloss: 0.142686\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.152919\n",
      "[5]\tvalid_0's auc: 0.856628\tvalid_0's binary_logloss: 0.139976\tvalid_1's auc: 0.83701\tvalid_1's binary_logloss: 0.15048\n",
      "[6]\tvalid_0's auc: 0.859766\tvalid_0's binary_logloss: 0.137707\tvalid_1's auc: 0.83737\tvalid_1's binary_logloss: 0.148709\n",
      "[7]\tvalid_0's auc: 0.861667\tvalid_0's binary_logloss: 0.13588\tvalid_1's auc: 0.837028\tvalid_1's binary_logloss: 0.147239\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[9]\tvalid_0's auc: 0.866131\tvalid_0's binary_logloss: 0.132702\tvalid_1's auc: 0.837967\tvalid_1's binary_logloss: 0.144848\n",
      "[10]\tvalid_0's auc: 0.867742\tvalid_0's binary_logloss: 0.1314\tvalid_1's auc: 0.837692\tvalid_1's binary_logloss: 0.143974\n",
      "[11]\tvalid_0's auc: 0.869179\tvalid_0's binary_logloss: 0.130269\tvalid_1's auc: 0.837036\tvalid_1's binary_logloss: 0.143346\n",
      "[12]\tvalid_0's auc: 0.870565\tvalid_0's binary_logloss: 0.129231\tvalid_1's auc: 0.836722\tvalid_1's binary_logloss: 0.14276\n",
      "[13]\tvalid_0's auc: 0.871715\tvalid_0's binary_logloss: 0.128325\tvalid_1's auc: 0.836964\tvalid_1's binary_logloss: 0.14221\n",
      "[14]\tvalid_0's auc: 0.873118\tvalid_0's binary_logloss: 0.127433\tvalid_1's auc: 0.836616\tvalid_1's binary_logloss: 0.141769\n",
      "[15]\tvalid_0's auc: 0.874777\tvalid_0's binary_logloss: 0.126525\tvalid_1's auc: 0.837268\tvalid_1's binary_logloss: 0.141352\n",
      "[16]\tvalid_0's auc: 0.876077\tvalid_0's binary_logloss: 0.125761\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.141109\n",
      "[17]\tvalid_0's auc: 0.87775\tvalid_0's binary_logloss: 0.125008\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.140988\n",
      "[18]\tvalid_0's auc: 0.879171\tvalid_0's binary_logloss: 0.124326\tvalid_1's auc: 0.837265\tvalid_1's binary_logloss: 0.140636\n",
      "[19]\tvalid_0's auc: 0.880771\tvalid_0's binary_logloss: 0.123637\tvalid_1's auc: 0.836922\tvalid_1's binary_logloss: 0.140454\n",
      "[20]\tvalid_0's auc: 0.882476\tvalid_0's binary_logloss: 0.123001\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.140307\n",
      "[21]\tvalid_0's auc: 0.883998\tvalid_0's binary_logloss: 0.122399\tvalid_1's auc: 0.83698\tvalid_1's binary_logloss: 0.140209\n",
      "[22]\tvalid_0's auc: 0.885371\tvalid_0's binary_logloss: 0.121789\tvalid_1's auc: 0.836641\tvalid_1's binary_logloss: 0.140165\n",
      "[23]\tvalid_0's auc: 0.886707\tvalid_0's binary_logloss: 0.121228\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.140035\n",
      "[24]\tvalid_0's auc: 0.887902\tvalid_0's binary_logloss: 0.120685\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.139977\n",
      "[25]\tvalid_0's auc: 0.889092\tvalid_0's binary_logloss: 0.12018\tvalid_1's auc: 0.83633\tvalid_1's binary_logloss: 0.139976\n",
      "[26]\tvalid_0's auc: 0.890287\tvalid_0's binary_logloss: 0.119694\tvalid_1's auc: 0.836088\tvalid_1's binary_logloss: 0.13994\n",
      "[27]\tvalid_0's auc: 0.891557\tvalid_0's binary_logloss: 0.11921\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.139925\n",
      "[28]\tvalid_0's auc: 0.892479\tvalid_0's binary_logloss: 0.118767\tvalid_1's auc: 0.836047\tvalid_1's binary_logloss: 0.139873\n",
      "[29]\tvalid_0's auc: 0.893752\tvalid_0's binary_logloss: 0.118311\tvalid_1's auc: 0.836111\tvalid_1's binary_logloss: 0.139884\n",
      "[30]\tvalid_0's auc: 0.894906\tvalid_0's binary_logloss: 0.117808\tvalid_1's auc: 0.836072\tvalid_1's binary_logloss: 0.139896\n",
      "[31]\tvalid_0's auc: 0.895735\tvalid_0's binary_logloss: 0.117395\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.139865\n",
      "[32]\tvalid_0's auc: 0.896982\tvalid_0's binary_logloss: 0.116948\tvalid_1's auc: 0.836178\tvalid_1's binary_logloss: 0.139866\n",
      "[33]\tvalid_0's auc: 0.898332\tvalid_0's binary_logloss: 0.116584\tvalid_1's auc: 0.836498\tvalid_1's binary_logloss: 0.139828\n",
      "[34]\tvalid_0's auc: 0.899324\tvalid_0's binary_logloss: 0.116129\tvalid_1's auc: 0.836499\tvalid_1's binary_logloss: 0.139874\n",
      "[35]\tvalid_0's auc: 0.900175\tvalid_0's binary_logloss: 0.11578\tvalid_1's auc: 0.836226\tvalid_1's binary_logloss: 0.139924\n",
      "[36]\tvalid_0's auc: 0.901261\tvalid_0's binary_logloss: 0.115448\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.13999\n",
      "[37]\tvalid_0's auc: 0.901964\tvalid_0's binary_logloss: 0.115083\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.14012\n",
      "[38]\tvalid_0's auc: 0.902511\tvalid_0's binary_logloss: 0.114769\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.140207\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.863565\tvalid_0's binary_logloss: 0.134173\tvalid_1's auc: 0.838026\tvalid_1's binary_logloss: 0.145898\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13331\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.831709\tvalid_0's binary_logloss: 0.155602\tvalid_1's auc: 0.817142\tvalid_1's binary_logloss: 0.164826\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845013\tvalid_0's binary_logloss: 0.15006\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.159674\n",
      "[3]\tvalid_0's auc: 0.847843\tvalid_0's binary_logloss: 0.145936\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.155788\n",
      "[4]\tvalid_0's auc: 0.853126\tvalid_0's binary_logloss: 0.142751\tvalid_1's auc: 0.836086\tvalid_1's binary_logloss: 0.152883\n",
      "[5]\tvalid_0's auc: 0.855373\tvalid_0's binary_logloss: 0.140124\tvalid_1's auc: 0.836802\tvalid_1's binary_logloss: 0.150648\n",
      "[6]\tvalid_0's auc: 0.858982\tvalid_0's binary_logloss: 0.137929\tvalid_1's auc: 0.837196\tvalid_1's binary_logloss: 0.148838\n",
      "[7]\tvalid_0's auc: 0.860432\tvalid_0's binary_logloss: 0.136116\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.147355\n",
      "[8]\tvalid_0's auc: 0.86237\tvalid_0's binary_logloss: 0.134493\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.146137\n",
      "[9]\tvalid_0's auc: 0.864538\tvalid_0's binary_logloss: 0.133112\tvalid_1's auc: 0.837924\tvalid_1's binary_logloss: 0.145039\n",
      "[10]\tvalid_0's auc: 0.866285\tvalid_0's binary_logloss: 0.131888\tvalid_1's auc: 0.837794\tvalid_1's binary_logloss: 0.14412\n",
      "[11]\tvalid_0's auc: 0.867679\tvalid_0's binary_logloss: 0.130774\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.143337\n",
      "[12]\tvalid_0's auc: 0.869423\tvalid_0's binary_logloss: 0.129754\tvalid_1's auc: 0.839862\tvalid_1's binary_logloss: 0.142609\n",
      "[13]\tvalid_0's auc: 0.870621\tvalid_0's binary_logloss: 0.128815\tvalid_1's auc: 0.838873\tvalid_1's binary_logloss: 0.142215\n",
      "[14]\tvalid_0's auc: 0.871813\tvalid_0's binary_logloss: 0.128007\tvalid_1's auc: 0.83922\tvalid_1's binary_logloss: 0.141872\n",
      "[15]\tvalid_0's auc: 0.873349\tvalid_0's binary_logloss: 0.127226\tvalid_1's auc: 0.838558\tvalid_1's binary_logloss: 0.141577\n",
      "[16]\tvalid_0's auc: 0.875071\tvalid_0's binary_logloss: 0.126463\tvalid_1's auc: 0.838328\tvalid_1's binary_logloss: 0.141336\n",
      "[17]\tvalid_0's auc: 0.87671\tvalid_0's binary_logloss: 0.125734\tvalid_1's auc: 0.838859\tvalid_1's binary_logloss: 0.140993\n",
      "[18]\tvalid_0's auc: 0.877745\tvalid_0's binary_logloss: 0.12506\tvalid_1's auc: 0.838826\tvalid_1's binary_logloss: 0.140774\n",
      "[19]\tvalid_0's auc: 0.87955\tvalid_0's binary_logloss: 0.124346\tvalid_1's auc: 0.838685\tvalid_1's binary_logloss: 0.14062\n",
      "[20]\tvalid_0's auc: 0.88095\tvalid_0's binary_logloss: 0.123758\tvalid_1's auc: 0.839472\tvalid_1's binary_logloss: 0.140278\n",
      "[21]\tvalid_0's auc: 0.882333\tvalid_0's binary_logloss: 0.123172\tvalid_1's auc: 0.839953\tvalid_1's binary_logloss: 0.139987\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[23]\tvalid_0's auc: 0.884939\tvalid_0's binary_logloss: 0.122106\tvalid_1's auc: 0.840085\tvalid_1's binary_logloss: 0.139652\n",
      "[24]\tvalid_0's auc: 0.886267\tvalid_0's binary_logloss: 0.121544\tvalid_1's auc: 0.839519\tvalid_1's binary_logloss: 0.13967\n",
      "[25]\tvalid_0's auc: 0.887231\tvalid_0's binary_logloss: 0.12107\tvalid_1's auc: 0.839583\tvalid_1's binary_logloss: 0.139554\n",
      "[26]\tvalid_0's auc: 0.888362\tvalid_0's binary_logloss: 0.120592\tvalid_1's auc: 0.839436\tvalid_1's binary_logloss: 0.139477\n",
      "[27]\tvalid_0's auc: 0.889402\tvalid_0's binary_logloss: 0.12012\tvalid_1's auc: 0.839576\tvalid_1's binary_logloss: 0.139364\n",
      "[28]\tvalid_0's auc: 0.890567\tvalid_0's binary_logloss: 0.119695\tvalid_1's auc: 0.839325\tvalid_1's binary_logloss: 0.139379\n",
      "[29]\tvalid_0's auc: 0.891561\tvalid_0's binary_logloss: 0.119229\tvalid_1's auc: 0.838494\tvalid_1's binary_logloss: 0.139484\n",
      "[30]\tvalid_0's auc: 0.892335\tvalid_0's binary_logloss: 0.118804\tvalid_1's auc: 0.838442\tvalid_1's binary_logloss: 0.139471\n",
      "[31]\tvalid_0's auc: 0.893386\tvalid_0's binary_logloss: 0.118372\tvalid_1's auc: 0.838123\tvalid_1's binary_logloss: 0.139487\n",
      "[32]\tvalid_0's auc: 0.894414\tvalid_0's binary_logloss: 0.117941\tvalid_1's auc: 0.838093\tvalid_1's binary_logloss: 0.139521\n",
      "[33]\tvalid_0's auc: 0.895465\tvalid_0's binary_logloss: 0.117514\tvalid_1's auc: 0.837947\tvalid_1's binary_logloss: 0.139537\n",
      "[34]\tvalid_0's auc: 0.896166\tvalid_0's binary_logloss: 0.117168\tvalid_1's auc: 0.837807\tvalid_1's binary_logloss: 0.139577\n",
      "[35]\tvalid_0's auc: 0.896684\tvalid_0's binary_logloss: 0.116863\tvalid_1's auc: 0.837668\tvalid_1's binary_logloss: 0.139588\n",
      "[36]\tvalid_0's auc: 0.897535\tvalid_0's binary_logloss: 0.116484\tvalid_1's auc: 0.837261\tvalid_1's binary_logloss: 0.139733\n",
      "[37]\tvalid_0's auc: 0.898253\tvalid_0's binary_logloss: 0.116123\tvalid_1's auc: 0.837235\tvalid_1's binary_logloss: 0.139781\n",
      "[38]\tvalid_0's auc: 0.898964\tvalid_0's binary_logloss: 0.115828\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.139841\n",
      "[39]\tvalid_0's auc: 0.89972\tvalid_0's binary_logloss: 0.115476\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.13991\n",
      "[40]\tvalid_0's auc: 0.900293\tvalid_0's binary_logloss: 0.115122\tvalid_1's auc: 0.837147\tvalid_1's binary_logloss: 0.139846\n",
      "[41]\tvalid_0's auc: 0.900934\tvalid_0's binary_logloss: 0.114813\tvalid_1's auc: 0.836986\tvalid_1's binary_logloss: 0.139923\n",
      "[42]\tvalid_0's auc: 0.901636\tvalid_0's binary_logloss: 0.114489\tvalid_1's auc: 0.836537\tvalid_1's binary_logloss: 0.140017\n",
      "[43]\tvalid_0's auc: 0.90272\tvalid_0's binary_logloss: 0.114161\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.140025\n",
      "[44]\tvalid_0's auc: 0.903084\tvalid_0's binary_logloss: 0.113909\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.140037\n",
      "[45]\tvalid_0's auc: 0.903622\tvalid_0's binary_logloss: 0.113641\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.140106\n",
      "[46]\tvalid_0's auc: 0.904201\tvalid_0's binary_logloss: 0.113301\tvalid_1's auc: 0.83619\tvalid_1's binary_logloss: 0.140186\n",
      "[47]\tvalid_0's auc: 0.904762\tvalid_0's binary_logloss: 0.112961\tvalid_1's auc: 0.836219\tvalid_1's binary_logloss: 0.14019\n",
      "[48]\tvalid_0's auc: 0.905387\tvalid_0's binary_logloss: 0.11272\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.140252\n",
      "[49]\tvalid_0's auc: 0.90574\tvalid_0's binary_logloss: 0.112462\tvalid_1's auc: 0.835874\tvalid_1's binary_logloss: 0.140337\n",
      "[50]\tvalid_0's auc: 0.906329\tvalid_0's binary_logloss: 0.112158\tvalid_1's auc: 0.835754\tvalid_1's binary_logloss: 0.140395\n",
      "[51]\tvalid_0's auc: 0.906807\tvalid_0's binary_logloss: 0.111885\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.140381\n",
      "[52]\tvalid_0's auc: 0.907054\tvalid_0's binary_logloss: 0.111647\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.14054\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.883759\tvalid_0's binary_logloss: 0.122627\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.139783\n",
      "[LightGBM] [Info] Number of positive: 1899, number of negative: 46754\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13336\n",
      "[LightGBM] [Info] Number of data points in the train set: 48653, number of used features: 192\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039032 -> initscore=-3.203572\n",
      "[LightGBM] [Info] Start training from score -3.203572\n",
      "[1]\tvalid_0's auc: 0.832354\tvalid_0's binary_logloss: 0.156011\tvalid_1's auc: 0.824432\tvalid_1's binary_logloss: 0.164746\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's auc: 0.845573\tvalid_0's binary_logloss: 0.150188\tvalid_1's auc: 0.832252\tvalid_1's binary_logloss: 0.159476\n",
      "[3]\tvalid_0's auc: 0.848609\tvalid_0's binary_logloss: 0.145958\tvalid_1's auc: 0.834138\tvalid_1's binary_logloss: 0.155738\n",
      "[4]\tvalid_0's auc: 0.851924\tvalid_0's binary_logloss: 0.142678\tvalid_1's auc: 0.834388\tvalid_1's binary_logloss: 0.152853\n",
      "[5]\tvalid_0's auc: 0.854459\tvalid_0's binary_logloss: 0.140096\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.150614\n",
      "[6]\tvalid_0's auc: 0.860195\tvalid_0's binary_logloss: 0.137818\tvalid_1's auc: 0.837402\tvalid_1's binary_logloss: 0.148623\n",
      "[7]\tvalid_0's auc: 0.861877\tvalid_0's binary_logloss: 0.135948\tvalid_1's auc: 0.837505\tvalid_1's binary_logloss: 0.14706\n",
      "[8]\tvalid_0's auc: 0.863997\tvalid_0's binary_logloss: 0.134369\tvalid_1's auc: 0.837955\tvalid_1's binary_logloss: 0.145859\n",
      "[9]\tvalid_0's auc: 0.866333\tvalid_0's binary_logloss: 0.132937\tvalid_1's auc: 0.839366\tvalid_1's binary_logloss: 0.144812\n",
      "[10]\tvalid_0's auc: 0.867965\tvalid_0's binary_logloss: 0.131647\tvalid_1's auc: 0.839399\tvalid_1's binary_logloss: 0.143987\n",
      "[11]\tvalid_0's auc: 0.869851\tvalid_0's binary_logloss: 0.130406\tvalid_1's auc: 0.839421\tvalid_1's binary_logloss: 0.14329\n",
      "[12]\tvalid_0's auc: 0.872223\tvalid_0's binary_logloss: 0.129323\tvalid_1's auc: 0.839253\tvalid_1's binary_logloss: 0.142712\n",
      "[13]\tvalid_0's auc: 0.873776\tvalid_0's binary_logloss: 0.12837\tvalid_1's auc: 0.838607\tvalid_1's binary_logloss: 0.142208\n",
      "[14]\tvalid_0's auc: 0.875666\tvalid_0's binary_logloss: 0.127409\tvalid_1's auc: 0.839513\tvalid_1's binary_logloss: 0.141711\n",
      "[15]\tvalid_0's auc: 0.876977\tvalid_0's binary_logloss: 0.126591\tvalid_1's auc: 0.839539\tvalid_1's binary_logloss: 0.141288\n",
      "[16]\tvalid_0's auc: 0.878097\tvalid_0's binary_logloss: 0.125796\tvalid_1's auc: 0.839021\tvalid_1's binary_logloss: 0.141036\n",
      "[17]\tvalid_0's auc: 0.879098\tvalid_0's binary_logloss: 0.125088\tvalid_1's auc: 0.837465\tvalid_1's binary_logloss: 0.1409\n",
      "[18]\tvalid_0's auc: 0.880601\tvalid_0's binary_logloss: 0.124364\tvalid_1's auc: 0.837466\tvalid_1's binary_logloss: 0.140701\n",
      "[19]\tvalid_0's auc: 0.88248\tvalid_0's binary_logloss: 0.123621\tvalid_1's auc: 0.838247\tvalid_1's binary_logloss: 0.140429\n",
      "[20]\tvalid_0's auc: 0.883936\tvalid_0's binary_logloss: 0.122911\tvalid_1's auc: 0.83793\tvalid_1's binary_logloss: 0.140317\n",
      "[21]\tvalid_0's auc: 0.88529\tvalid_0's binary_logloss: 0.122327\tvalid_1's auc: 0.838792\tvalid_1's binary_logloss: 0.140098\n",
      "[22]\tvalid_0's auc: 0.88648\tvalid_0's binary_logloss: 0.121732\tvalid_1's auc: 0.838403\tvalid_1's binary_logloss: 0.139974\n",
      "[23]\tvalid_0's auc: 0.887765\tvalid_0's binary_logloss: 0.121176\tvalid_1's auc: 0.838404\tvalid_1's binary_logloss: 0.139891\n",
      "[24]\tvalid_0's auc: 0.888887\tvalid_0's binary_logloss: 0.120591\tvalid_1's auc: 0.838112\tvalid_1's binary_logloss: 0.139904\n",
      "[25]\tvalid_0's auc: 0.890044\tvalid_0's binary_logloss: 0.120074\tvalid_1's auc: 0.838114\tvalid_1's binary_logloss: 0.139883\n",
      "[26]\tvalid_0's auc: 0.891051\tvalid_0's binary_logloss: 0.119588\tvalid_1's auc: 0.838544\tvalid_1's binary_logloss: 0.139784\n",
      "[27]\tvalid_0's auc: 0.892157\tvalid_0's binary_logloss: 0.119094\tvalid_1's auc: 0.838348\tvalid_1's binary_logloss: 0.139788\n",
      "[28]\tvalid_0's auc: 0.893116\tvalid_0's binary_logloss: 0.118639\tvalid_1's auc: 0.838654\tvalid_1's binary_logloss: 0.139723\n",
      "[29]\tvalid_0's auc: 0.894065\tvalid_0's binary_logloss: 0.118191\tvalid_1's auc: 0.83815\tvalid_1's binary_logloss: 0.13979\n",
      "[30]\tvalid_0's auc: 0.895189\tvalid_0's binary_logloss: 0.117742\tvalid_1's auc: 0.838393\tvalid_1's binary_logloss: 0.139755\n",
      "[31]\tvalid_0's auc: 0.896336\tvalid_0's binary_logloss: 0.117289\tvalid_1's auc: 0.838384\tvalid_1's binary_logloss: 0.139687\n",
      "[32]\tvalid_0's auc: 0.897473\tvalid_0's binary_logloss: 0.116901\tvalid_1's auc: 0.838447\tvalid_1's binary_logloss: 0.139683\n",
      "[33]\tvalid_0's auc: 0.898375\tvalid_0's binary_logloss: 0.116464\tvalid_1's auc: 0.838512\tvalid_1's binary_logloss: 0.139636\n",
      "[34]\tvalid_0's auc: 0.899242\tvalid_0's binary_logloss: 0.116054\tvalid_1's auc: 0.838475\tvalid_1's binary_logloss: 0.139614\n",
      "[35]\tvalid_0's auc: 0.900316\tvalid_0's binary_logloss: 0.115653\tvalid_1's auc: 0.838522\tvalid_1's binary_logloss: 0.13957\n",
      "[36]\tvalid_0's auc: 0.901114\tvalid_0's binary_logloss: 0.11531\tvalid_1's auc: 0.838721\tvalid_1's binary_logloss: 0.139537\n",
      "[37]\tvalid_0's auc: 0.901919\tvalid_0's binary_logloss: 0.114911\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.139581\n",
      "[38]\tvalid_0's auc: 0.902827\tvalid_0's binary_logloss: 0.114566\tvalid_1's auc: 0.839027\tvalid_1's binary_logloss: 0.139517\n",
      "[39]\tvalid_0's auc: 0.903647\tvalid_0's binary_logloss: 0.114176\tvalid_1's auc: 0.839264\tvalid_1's binary_logloss: 0.13948\n",
      "[40]\tvalid_0's auc: 0.904461\tvalid_0's binary_logloss: 0.11382\tvalid_1's auc: 0.839535\tvalid_1's binary_logloss: 0.13945\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[42]\tvalid_0's auc: 0.90573\tvalid_0's binary_logloss: 0.11309\tvalid_1's auc: 0.839177\tvalid_1's binary_logloss: 0.139527\n",
      "[43]\tvalid_0's auc: 0.906484\tvalid_0's binary_logloss: 0.112737\tvalid_1's auc: 0.839561\tvalid_1's binary_logloss: 0.139494\n",
      "[44]\tvalid_0's auc: 0.907269\tvalid_0's binary_logloss: 0.112432\tvalid_1's auc: 0.839357\tvalid_1's binary_logloss: 0.139519\n",
      "[45]\tvalid_0's auc: 0.907761\tvalid_0's binary_logloss: 0.112094\tvalid_1's auc: 0.839145\tvalid_1's binary_logloss: 0.139503\n",
      "[46]\tvalid_0's auc: 0.908229\tvalid_0's binary_logloss: 0.111774\tvalid_1's auc: 0.839064\tvalid_1's binary_logloss: 0.139515\n",
      "[47]\tvalid_0's auc: 0.908961\tvalid_0's binary_logloss: 0.111399\tvalid_1's auc: 0.838752\tvalid_1's binary_logloss: 0.139561\n",
      "[48]\tvalid_0's auc: 0.909623\tvalid_0's binary_logloss: 0.111156\tvalid_1's auc: 0.838658\tvalid_1's binary_logloss: 0.139589\n",
      "[49]\tvalid_0's auc: 0.910075\tvalid_0's binary_logloss: 0.110845\tvalid_1's auc: 0.838588\tvalid_1's binary_logloss: 0.13959\n",
      "[50]\tvalid_0's auc: 0.910737\tvalid_0's binary_logloss: 0.110566\tvalid_1's auc: 0.838609\tvalid_1's binary_logloss: 0.139608\n",
      "[51]\tvalid_0's auc: 0.911115\tvalid_0's binary_logloss: 0.110282\tvalid_1's auc: 0.838459\tvalid_1's binary_logloss: 0.139669\n",
      "[52]\tvalid_0's auc: 0.911601\tvalid_0's binary_logloss: 0.10999\tvalid_1's auc: 0.838303\tvalid_1's binary_logloss: 0.139708\n",
      "[53]\tvalid_0's auc: 0.911908\tvalid_0's binary_logloss: 0.109751\tvalid_1's auc: 0.838117\tvalid_1's binary_logloss: 0.13975\n",
      "[54]\tvalid_0's auc: 0.912261\tvalid_0's binary_logloss: 0.109498\tvalid_1's auc: 0.838252\tvalid_1's binary_logloss: 0.139711\n",
      "[55]\tvalid_0's auc: 0.912616\tvalid_0's binary_logloss: 0.109226\tvalid_1's auc: 0.837936\tvalid_1's binary_logloss: 0.13983\n",
      "[56]\tvalid_0's auc: 0.913202\tvalid_0's binary_logloss: 0.108936\tvalid_1's auc: 0.83804\tvalid_1's binary_logloss: 0.13983\n",
      "[57]\tvalid_0's auc: 0.913592\tvalid_0's binary_logloss: 0.10867\tvalid_1's auc: 0.838083\tvalid_1's binary_logloss: 0.139818\n",
      "[58]\tvalid_0's auc: 0.913818\tvalid_0's binary_logloss: 0.108421\tvalid_1's auc: 0.837716\tvalid_1's binary_logloss: 0.139971\n",
      "[59]\tvalid_0's auc: 0.914378\tvalid_0's binary_logloss: 0.108194\tvalid_1's auc: 0.837836\tvalid_1's binary_logloss: 0.139971\n",
      "[60]\tvalid_0's auc: 0.91493\tvalid_0's binary_logloss: 0.107966\tvalid_1's auc: 0.837549\tvalid_1's binary_logloss: 0.140068\n",
      "[61]\tvalid_0's auc: 0.915354\tvalid_0's binary_logloss: 0.107682\tvalid_1's auc: 0.837021\tvalid_1's binary_logloss: 0.140197\n",
      "[62]\tvalid_0's auc: 0.915606\tvalid_0's binary_logloss: 0.107477\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.140336\n",
      "[63]\tvalid_0's auc: 0.916315\tvalid_0's binary_logloss: 0.107178\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.140384\n",
      "[64]\tvalid_0's auc: 0.916522\tvalid_0's binary_logloss: 0.10698\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.140446\n",
      "[65]\tvalid_0's auc: 0.917048\tvalid_0's binary_logloss: 0.106704\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.140528\n",
      "[66]\tvalid_0's auc: 0.917714\tvalid_0's binary_logloss: 0.1065\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.140589\n",
      "[67]\tvalid_0's auc: 0.918245\tvalid_0's binary_logloss: 0.106235\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.140673\n",
      "[68]\tvalid_0's auc: 0.918757\tvalid_0's binary_logloss: 0.105956\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.140696\n",
      "[69]\tvalid_0's auc: 0.919319\tvalid_0's binary_logloss: 0.105704\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.140788\n",
      "[70]\tvalid_0's auc: 0.919498\tvalid_0's binary_logloss: 0.105505\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.140912\n",
      "[71]\tvalid_0's auc: 0.919774\tvalid_0's binary_logloss: 0.105296\tvalid_1's auc: 0.834571\tvalid_1's binary_logloss: 0.141016\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.905119\tvalid_0's binary_logloss: 0.113454\tvalid_1's auc: 0.839726\tvalid_1's binary_logloss: 0.139429\n",
      "[LightGBM] [Info] Number of positive: 2374, number of negative: 58442\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14119\n",
      "[LightGBM] [Info] Number of data points in the train set: 60816, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039036 -> initscore=-3.203459\n",
      "[LightGBM] [Info] Start training from score -3.203459\n",
      "[1]\ttraining's auc: 0.823615\ttraining's binary_logloss: 0.15611\tvalid_1's auc: 0.816534\tvalid_1's binary_logloss: 0.165167\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's auc: 0.828024\ttraining's binary_logloss: 0.150857\tvalid_1's auc: 0.81932\tvalid_1's binary_logloss: 0.160019\n",
      "[3]\ttraining's auc: 0.837813\ttraining's binary_logloss: 0.146978\tvalid_1's auc: 0.827935\tvalid_1's binary_logloss: 0.156362\n",
      "[4]\ttraining's auc: 0.843266\ttraining's binary_logloss: 0.143948\tvalid_1's auc: 0.833269\tvalid_1's binary_logloss: 0.153469\n",
      "[5]\ttraining's auc: 0.845655\ttraining's binary_logloss: 0.141503\tvalid_1's auc: 0.83486\tvalid_1's binary_logloss: 0.151262\n",
      "[6]\ttraining's auc: 0.847931\ttraining's binary_logloss: 0.139443\tvalid_1's auc: 0.836656\tvalid_1's binary_logloss: 0.149439\n",
      "[7]\ttraining's auc: 0.851488\ttraining's binary_logloss: 0.137661\tvalid_1's auc: 0.838769\tvalid_1's binary_logloss: 0.147844\n",
      "[8]\ttraining's auc: 0.853055\ttraining's binary_logloss: 0.136151\tvalid_1's auc: 0.839353\tvalid_1's binary_logloss: 0.146502\n",
      "[9]\ttraining's auc: 0.854852\ttraining's binary_logloss: 0.1349\tvalid_1's auc: 0.839985\tvalid_1's binary_logloss: 0.145462\n",
      "[10]\ttraining's auc: 0.856554\ttraining's binary_logloss: 0.133735\tvalid_1's auc: 0.8401\tvalid_1's binary_logloss: 0.144512\n",
      "[11]\ttraining's auc: 0.8574\ttraining's binary_logloss: 0.132732\tvalid_1's auc: 0.840377\tvalid_1's binary_logloss: 0.14369\n",
      "[12]\ttraining's auc: 0.858235\ttraining's binary_logloss: 0.131853\tvalid_1's auc: 0.840823\tvalid_1's binary_logloss: 0.143055\n",
      "[13]\ttraining's auc: 0.860313\ttraining's binary_logloss: 0.131012\tvalid_1's auc: 0.840551\tvalid_1's binary_logloss: 0.142537\n",
      "[14]\ttraining's auc: 0.862628\ttraining's binary_logloss: 0.130207\tvalid_1's auc: 0.8399\tvalid_1's binary_logloss: 0.142111\n",
      "[15]\ttraining's auc: 0.863868\ttraining's binary_logloss: 0.129561\tvalid_1's auc: 0.839069\tvalid_1's binary_logloss: 0.141814\n",
      "[16]\ttraining's auc: 0.865458\ttraining's binary_logloss: 0.12886\tvalid_1's auc: 0.839346\tvalid_1's binary_logloss: 0.141461\n",
      "[17]\ttraining's auc: 0.866419\ttraining's binary_logloss: 0.128257\tvalid_1's auc: 0.83894\tvalid_1's binary_logloss: 0.141177\n",
      "[18]\ttraining's auc: 0.868293\ttraining's binary_logloss: 0.127661\tvalid_1's auc: 0.838527\tvalid_1's binary_logloss: 0.141015\n",
      "[19]\ttraining's auc: 0.869733\ttraining's binary_logloss: 0.127122\tvalid_1's auc: 0.839252\tvalid_1's binary_logloss: 0.140751\n",
      "[20]\ttraining's auc: 0.870564\ttraining's binary_logloss: 0.126628\tvalid_1's auc: 0.838945\tvalid_1's binary_logloss: 0.140564\n",
      "[21]\ttraining's auc: 0.871881\ttraining's binary_logloss: 0.126119\tvalid_1's auc: 0.839852\tvalid_1's binary_logloss: 0.140326\n",
      "[22]\ttraining's auc: 0.872801\ttraining's binary_logloss: 0.125613\tvalid_1's auc: 0.839769\tvalid_1's binary_logloss: 0.140091\n",
      "[23]\ttraining's auc: 0.873499\ttraining's binary_logloss: 0.125185\tvalid_1's auc: 0.839908\tvalid_1's binary_logloss: 0.139988\n",
      "[24]\ttraining's auc: 0.874671\ttraining's binary_logloss: 0.12476\tvalid_1's auc: 0.840116\tvalid_1's binary_logloss: 0.139829\n",
      "[25]\ttraining's auc: 0.876493\ttraining's binary_logloss: 0.124266\tvalid_1's auc: 0.840774\tvalid_1's binary_logloss: 0.139593\n",
      "[26]\ttraining's auc: 0.878107\ttraining's binary_logloss: 0.123828\tvalid_1's auc: 0.840924\tvalid_1's binary_logloss: 0.139489\n",
      "[27]\ttraining's auc: 0.879418\ttraining's binary_logloss: 0.12344\tvalid_1's auc: 0.840793\tvalid_1's binary_logloss: 0.13942\n",
      "[28]\ttraining's auc: 0.880391\ttraining's binary_logloss: 0.123097\tvalid_1's auc: 0.840479\tvalid_1's binary_logloss: 0.139408\n",
      "[29]\ttraining's auc: 0.8814\ttraining's binary_logloss: 0.122748\tvalid_1's auc: 0.841327\tvalid_1's binary_logloss: 0.139219\n",
      "[30]\ttraining's auc: 0.882664\ttraining's binary_logloss: 0.122385\tvalid_1's auc: 0.841785\tvalid_1's binary_logloss: 0.139112\n",
      "[31]\ttraining's auc: 0.883641\ttraining's binary_logloss: 0.122039\tvalid_1's auc: 0.841598\tvalid_1's binary_logloss: 0.139065\n",
      "[32]\ttraining's auc: 0.88499\ttraining's binary_logloss: 0.121694\tvalid_1's auc: 0.841465\tvalid_1's binary_logloss: 0.139091\n",
      "[33]\ttraining's auc: 0.886051\ttraining's binary_logloss: 0.121395\tvalid_1's auc: 0.841002\tvalid_1's binary_logloss: 0.139073\n",
      "[34]\ttraining's auc: 0.8868\ttraining's binary_logloss: 0.121118\tvalid_1's auc: 0.840943\tvalid_1's binary_logloss: 0.139069\n",
      "[35]\ttraining's auc: 0.887588\ttraining's binary_logloss: 0.120813\tvalid_1's auc: 0.841145\tvalid_1's binary_logloss: 0.139022\n",
      "[36]\ttraining's auc: 0.888487\ttraining's binary_logloss: 0.120555\tvalid_1's auc: 0.840875\tvalid_1's binary_logloss: 0.139067\n",
      "[37]\ttraining's auc: 0.889104\ttraining's binary_logloss: 0.12028\tvalid_1's auc: 0.840681\tvalid_1's binary_logloss: 0.139107\n",
      "[38]\ttraining's auc: 0.89005\ttraining's binary_logloss: 0.119966\tvalid_1's auc: 0.840363\tvalid_1's binary_logloss: 0.139114\n",
      "[39]\ttraining's auc: 0.890714\ttraining's binary_logloss: 0.11968\tvalid_1's auc: 0.840428\tvalid_1's binary_logloss: 0.139105\n",
      "[40]\ttraining's auc: 0.891404\ttraining's binary_logloss: 0.119442\tvalid_1's auc: 0.840378\tvalid_1's binary_logloss: 0.139097\n",
      "[41]\ttraining's auc: 0.892277\ttraining's binary_logloss: 0.11918\tvalid_1's auc: 0.840193\tvalid_1's binary_logloss: 0.139118\n",
      "[42]\ttraining's auc: 0.89285\ttraining's binary_logloss: 0.118953\tvalid_1's auc: 0.8401\tvalid_1's binary_logloss: 0.139133\n",
      "[43]\ttraining's auc: 0.893788\ttraining's binary_logloss: 0.118689\tvalid_1's auc: 0.839852\tvalid_1's binary_logloss: 0.139177\n",
      "[44]\ttraining's auc: 0.894586\ttraining's binary_logloss: 0.11839\tvalid_1's auc: 0.8399\tvalid_1's binary_logloss: 0.139139\n",
      "[45]\ttraining's auc: 0.895251\ttraining's binary_logloss: 0.118161\tvalid_1's auc: 0.840011\tvalid_1's binary_logloss: 0.139144\n",
      "[46]\ttraining's auc: 0.896025\ttraining's binary_logloss: 0.117845\tvalid_1's auc: 0.839995\tvalid_1's binary_logloss: 0.139135\n",
      "[47]\ttraining's auc: 0.896818\ttraining's binary_logloss: 0.117559\tvalid_1's auc: 0.839781\tvalid_1's binary_logloss: 0.139195\n",
      "[48]\ttraining's auc: 0.897288\ttraining's binary_logloss: 0.117346\tvalid_1's auc: 0.83979\tvalid_1's binary_logloss: 0.139207\n",
      "[49]\ttraining's auc: 0.898215\ttraining's binary_logloss: 0.117087\tvalid_1's auc: 0.83987\tvalid_1's binary_logloss: 0.13921\n",
      "[50]\ttraining's auc: 0.89878\ttraining's binary_logloss: 0.116882\tvalid_1's auc: 0.839742\tvalid_1's binary_logloss: 0.139189\n",
      "[51]\ttraining's auc: 0.899301\ttraining's binary_logloss: 0.116682\tvalid_1's auc: 0.840374\tvalid_1's binary_logloss: 0.139083\n",
      "[52]\ttraining's auc: 0.899777\ttraining's binary_logloss: 0.116507\tvalid_1's auc: 0.840236\tvalid_1's binary_logloss: 0.13909\n",
      "[53]\ttraining's auc: 0.900385\ttraining's binary_logloss: 0.116289\tvalid_1's auc: 0.840295\tvalid_1's binary_logloss: 0.139088\n",
      "[54]\ttraining's auc: 0.90072\ttraining's binary_logloss: 0.116111\tvalid_1's auc: 0.840598\tvalid_1's binary_logloss: 0.13907\n",
      "[55]\ttraining's auc: 0.901395\ttraining's binary_logloss: 0.115833\tvalid_1's auc: 0.840401\tvalid_1's binary_logloss: 0.139114\n",
      "[56]\ttraining's auc: 0.901889\ttraining's binary_logloss: 0.115625\tvalid_1's auc: 0.840361\tvalid_1's binary_logloss: 0.139117\n",
      "[57]\ttraining's auc: 0.902488\ttraining's binary_logloss: 0.115403\tvalid_1's auc: 0.840028\tvalid_1's binary_logloss: 0.139168\n",
      "[58]\ttraining's auc: 0.902947\ttraining's binary_logloss: 0.115196\tvalid_1's auc: 0.839885\tvalid_1's binary_logloss: 0.13922\n",
      "[59]\ttraining's auc: 0.903381\ttraining's binary_logloss: 0.115005\tvalid_1's auc: 0.839548\tvalid_1's binary_logloss: 0.139269\n",
      "[60]\ttraining's auc: 0.903902\ttraining's binary_logloss: 0.114765\tvalid_1's auc: 0.839759\tvalid_1's binary_logloss: 0.139219\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.882664\ttraining's binary_logloss: 0.122385\tvalid_1's auc: 0.841785\tvalid_1's binary_logloss: 0.139112\n",
      "GridSearchCV 최적 파라미터 :  {'max_depth': 128, 'min_child_samples': 60, 'num_leaves': 32, 'subsample': 0.8}\n",
      "ROC AUC : 0.8418\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators = 200, verbosity = 1)\n",
    "\n",
    "params = {'num_leaves' : [32,64],\n",
    "         'max_depth' :[128,160],\n",
    "         'min_child_samples' :[60,100],\n",
    "         'subsample':[0.8,1]}\n",
    "\n",
    "gridcv = GridSearchCV(lgbm_clf, param_grid = params)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric = 'auc',\n",
    "          eval_set = [(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "print('GridSearchCV 최적 파라미터 : ', gridcv.best_params_ )\n",
    "lgbm_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:,1], average ='macro')\n",
    "\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
