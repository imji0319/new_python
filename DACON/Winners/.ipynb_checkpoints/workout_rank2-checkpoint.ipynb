{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [운동 동작 분류 AI - Private 2위 공유 코드](https://dacon.io/codeshare/2396?dtype=recent&s_id=0)\n",
    "\n",
    "1D-CNN 에 global-average-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "import time\n",
    "import datetime\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "from tqdm import tqdm\n",
    "from numpy.fft import fft, fftshift\n",
    "from numpy.fft import *\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../workout/train_features.csv')\n",
    "test = pd.read_csv('../workout/test_features.csv')\n",
    "train_label = pd.read_csv('../workout/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0           0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1           0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2           0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3           0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4           0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...       ...   ...       ...       ...       ...        ...         ...   \n",
       "1874995  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "1874996  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "1874997  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "1874998  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "1874999  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "              gy_z  \n",
       "0       -31.676112  \n",
       "1       -24.927216  \n",
       "2       -25.019629  \n",
       "3       -27.454013  \n",
       "4       -27.961234  \n",
       "...            ...  \n",
       "1874995 -76.290437  \n",
       "1874996 -76.625087  \n",
       "1874997 -79.365125  \n",
       "1874998 -80.259478  \n",
       "1874999 -80.676229  \n",
       "\n",
       "[1875000 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "### 1. 에너지 변수 생성\n",
    "가속도, 자이로, (자이로-가속도) 센서값을 에너지로 표현 \n",
    "\n",
    "[<img src = \"가속도에너지.png\">](https://patents.google.com/patent/KR20120049076A/ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy'] = ( train['acc_x'] ** 2 + train['acc_y'] ** 2 + train['acc_z'] ** 2 ) ** (1/3) # 세제곱근의 이유는??? \n",
    "train['gy_Energy'] = (train['gy_x'] ** 2 + train['gy_y'] ** 2 + train['gy_z'] ** 2) ** (1/3)\n",
    "train['gy_acc_Energy'] = ((train['gy_x'] - train['acc_x']) ** 2 +\\\n",
    "                          (train['gy_y'] - train['acc_y']) ** 2 + \\\n",
    "                          (train['gy_z'] - train['acc_z']) ** 2 ) ** (1/3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['acc_Energy'] = ( test['acc_x'] ** 2 + test['acc_y'] ** 2 + test['acc_z'] ** 2 ) ** (1/3) # 세제곱근의 이유는??? \n",
    "test['gy_Energy'] = (test['gy_x'] ** 2 + test['gy_y'] ** 2 + test['gy_z'] ** 2) ** (1/3)\n",
    "test['gy_acc_Energy'] = ((test['gy_x'] - test['acc_x']) ** 2 +\\\n",
    "                          (test['gy_y'] - test['acc_y']) ** 2 + \\\n",
    "                          (test['gy_z'] - test['acc_z']) ** 2 ) ** (1/3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시간 대비 변화량 변수 생성\n",
    "id 별 데이터는 0.02 초마다 측정된 값임으로 이전 시간 대비 변화량을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.02\n",
    "\n",
    "def jerk_signal(signal):\n",
    "    a = [ (signal[i + 1] - signal[i])/dt \n",
    "         for i in range(len(signal) -1) ]\n",
    "    \n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [01:09<00:00, 45.06it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "\n",
    "for i in tqdm(train['id'].unique()): # tqbm : 상태 진행률을 알 수 있는 라이브러리 함수   \n",
    "    temp = train.loc[train['id'] == i]\n",
    "    \n",
    "    for v in train.columns[2:]:\n",
    "        values = jerk_signal(temp[v].values)\n",
    "        values = np.insert(values, 0,0)\n",
    "        temp.loc[:, v +'_dt'] = values\n",
    "        \n",
    "    train_df.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.211795</td>\n",
       "      <td>-0.078760</td>\n",
       "      <td>0.854627</td>\n",
       "      <td>18.231943</td>\n",
       "      <td>10.211164</td>\n",
       "      <td>7.390348</td>\n",
       "      <td>0.921085</td>\n",
       "      <td>7.890641</td>\n",
       "      <td>7.877131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.256963</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>0.802172</td>\n",
       "      <td>26.524263</td>\n",
       "      <td>0.980852</td>\n",
       "      <td>7.947258</td>\n",
       "      <td>0.892051</td>\n",
       "      <td>9.156352</td>\n",
       "      <td>9.162819</td>\n",
       "      <td>-2.258425</td>\n",
       "      <td>3.010219</td>\n",
       "      <td>-2.622744</td>\n",
       "      <td>414.615996</td>\n",
       "      <td>-461.515561</td>\n",
       "      <td>27.845534</td>\n",
       "      <td>-1.451712</td>\n",
       "      <td>63.285557</td>\n",
       "      <td>64.284406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.257005</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>0.806032</td>\n",
       "      <td>17.569390</td>\n",
       "      <td>-3.953200</td>\n",
       "      <td>1.982548</td>\n",
       "      <td>0.894510</td>\n",
       "      <td>6.898128</td>\n",
       "      <td>6.943637</td>\n",
       "      <td>-0.002074</td>\n",
       "      <td>0.857103</td>\n",
       "      <td>0.193035</td>\n",
       "      <td>-447.743657</td>\n",
       "      <td>-246.702614</td>\n",
       "      <td>-298.235490</td>\n",
       "      <td>0.122978</td>\n",
       "      <td>-112.911205</td>\n",
       "      <td>-110.959118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  time     acc_x     acc_y     acc_z       gy_x       gy_y      gy_z  \\\n",
       "600   1     0 -0.211795 -0.078760  0.854627  18.231943  10.211164  7.390348   \n",
       "601   1     1 -0.256963 -0.018555  0.802172  26.524263   0.980852  7.947258   \n",
       "602   1     2 -0.257005 -0.001413  0.806032  17.569390  -3.953200  1.982548   \n",
       "\n",
       "     acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  acc_z_dt  \\\n",
       "600    0.921085   7.890641       7.877131  0.000000  0.000000  0.000000   \n",
       "601    0.892051   9.156352       9.162819 -2.258425  3.010219 -2.622744   \n",
       "602    0.894510   6.898128       6.943637 -0.002074  0.857103  0.193035   \n",
       "\n",
       "        gy_x_dt     gy_y_dt     gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "600    0.000000    0.000000    0.000000       0.000000      0.000000   \n",
       "601  414.615996 -461.515561   27.845534      -1.451712     63.285557   \n",
       "602 -447.743657 -246.702614 -298.235490       0.122978   -112.911205   \n",
       "\n",
       "     gy_acc_Energy_dt  \n",
       "600          0.000000  \n",
       "601         64.284406  \n",
       "602       -110.959118  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:16<00:00, 47.25it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = []\n",
    "\n",
    "for i in tqdm(test['id'].unique()) : \n",
    "    temp = test.loc[test['id'] == i ]\n",
    "    \n",
    "    for v in test.columns[2:] : \n",
    "        values = jerk_signal(temp[v].values)\n",
    "        values = np.insert(values, 0,0)\n",
    "        temp.loc[:, v+'_dt'] = values \n",
    "        \n",
    "    test_df.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>1.529324</td>\n",
       "      <td>-0.338265</td>\n",
       "      <td>62.204081</td>\n",
       "      <td>-20.624492</td>\n",
       "      <td>-65.532643</td>\n",
       "      <td>1.365448</td>\n",
       "      <td>20.479452</td>\n",
       "      <td>20.466287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>3126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414260</td>\n",
       "      <td>1.676796</td>\n",
       "      <td>-0.318979</td>\n",
       "      <td>58.016820</td>\n",
       "      <td>-11.494501</td>\n",
       "      <td>-64.522573</td>\n",
       "      <td>1.455745</td>\n",
       "      <td>19.713617</td>\n",
       "      <td>19.672706</td>\n",
       "      <td>5.501907</td>\n",
       "      <td>7.373596</td>\n",
       "      <td>0.964346</td>\n",
       "      <td>-209.363042</td>\n",
       "      <td>456.499577</td>\n",
       "      <td>50.503475</td>\n",
       "      <td>4.514839</td>\n",
       "      <td>-38.291750</td>\n",
       "      <td>-39.679035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>3126</td>\n",
       "      <td>2</td>\n",
       "      <td>0.411078</td>\n",
       "      <td>1.708743</td>\n",
       "      <td>-0.343120</td>\n",
       "      <td>33.829160</td>\n",
       "      <td>11.935488</td>\n",
       "      <td>-59.098773</td>\n",
       "      <td>1.474613</td>\n",
       "      <td>16.844643</td>\n",
       "      <td>16.719243</td>\n",
       "      <td>-0.159097</td>\n",
       "      <td>1.597344</td>\n",
       "      <td>-1.207063</td>\n",
       "      <td>-1209.383042</td>\n",
       "      <td>1171.499427</td>\n",
       "      <td>271.190020</td>\n",
       "      <td>0.943391</td>\n",
       "      <td>-143.448672</td>\n",
       "      <td>-147.673179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  time     acc_x     acc_y     acc_z       gy_x       gy_y  \\\n",
       "600  3126     0  0.304222  1.529324 -0.338265  62.204081 -20.624492   \n",
       "601  3126     1  0.414260  1.676796 -0.318979  58.016820 -11.494501   \n",
       "602  3126     2  0.411078  1.708743 -0.343120  33.829160  11.935488   \n",
       "\n",
       "          gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "600 -65.532643    1.365448  20.479452      20.466287  0.000000  0.000000   \n",
       "601 -64.522573    1.455745  19.713617      19.672706  5.501907  7.373596   \n",
       "602 -59.098773    1.474613  16.844643      16.719243 -0.159097  1.597344   \n",
       "\n",
       "     acc_z_dt      gy_x_dt      gy_y_dt     gy_z_dt  acc_Energy_dt  \\\n",
       "600  0.000000     0.000000     0.000000    0.000000       0.000000   \n",
       "601  0.964346  -209.363042   456.499577   50.503475       4.514839   \n",
       "602 -1.207063 -1209.383042  1171.499427  271.190020       0.943391   \n",
       "\n",
       "     gy_Energy_dt  gy_acc_Energy_dt  \n",
       "600      0.000000          0.000000  \n",
       "601    -38.291750        -39.679035  \n",
       "602   -143.448672       -147.673179  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[1].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 푸리에 변환 \n",
    "[푸리에 변환(Fourier transform, FT)](https://ko.wikipedia.org/wiki/푸리에_변환)은 시간이나 공간에 대한 함수를 시간 또는 공간 주파수 성분으로 분해하는 변환.     \n",
    "`fftpack`을 활용하여 고속푸리에변환(FFT, Fast Fourier Transform) 을 할 수 있음.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT \n",
    "\n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal = fftpack.fft(t_signal)      # fft() : FFT 계산 \n",
    "    amplitude_f_signal = np.abs(complex_f_signal) # 음수 처리 \n",
    "    \n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "      <td>1.146962</td>\n",
       "      <td>12.465436</td>\n",
       "      <td>12.427938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "      <td>1.200703</td>\n",
       "      <td>12.913284</td>\n",
       "      <td>12.865692</td>\n",
       "      <td>4.080495</td>\n",
       "      <td>-0.980114</td>\n",
       "      <td>-1.699854</td>\n",
       "      <td>44.735403</td>\n",
       "      <td>-429.504677</td>\n",
       "      <td>337.444793</td>\n",
       "      <td>2.687024</td>\n",
       "      <td>22.392358</td>\n",
       "      <td>21.887693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "      <td>1.217403</td>\n",
       "      <td>13.725729</td>\n",
       "      <td>13.692643</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>-3.546937</td>\n",
       "      <td>-196.018888</td>\n",
       "      <td>-249.173073</td>\n",
       "      <td>-4.620631</td>\n",
       "      <td>0.835012</td>\n",
       "      <td>40.622253</td>\n",
       "      <td>41.347563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "      <td>1.209981</td>\n",
       "      <td>15.374021</td>\n",
       "      <td>15.314907</td>\n",
       "      <td>-0.575711</td>\n",
       "      <td>-1.762585</td>\n",
       "      <td>1.908626</td>\n",
       "      <td>316.513181</td>\n",
       "      <td>-473.763910</td>\n",
       "      <td>-121.719195</td>\n",
       "      <td>-0.371100</td>\n",
       "      <td>82.414636</td>\n",
       "      <td>81.113199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "      <td>1.211254</td>\n",
       "      <td>16.074363</td>\n",
       "      <td>16.017964</td>\n",
       "      <td>0.389598</td>\n",
       "      <td>2.130453</td>\n",
       "      <td>-0.365665</td>\n",
       "      <td>78.686055</td>\n",
       "      <td>-215.435892</td>\n",
       "      <td>-25.361098</td>\n",
       "      <td>0.063656</td>\n",
       "      <td>35.017060</td>\n",
       "      <td>35.152822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "      <td>1.009050</td>\n",
       "      <td>25.963234</td>\n",
       "      <td>25.897316</td>\n",
       "      <td>1.484646</td>\n",
       "      <td>0.303666</td>\n",
       "      <td>0.800069</td>\n",
       "      <td>-150.644663</td>\n",
       "      <td>-34.630282</td>\n",
       "      <td>-8.380088</td>\n",
       "      <td>-0.679712</td>\n",
       "      <td>8.387109</td>\n",
       "      <td>8.432977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "      <td>1.002827</td>\n",
       "      <td>25.784692</td>\n",
       "      <td>25.722482</td>\n",
       "      <td>1.474659</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>1.775771</td>\n",
       "      <td>-39.061611</td>\n",
       "      <td>110.842743</td>\n",
       "      <td>-16.732496</td>\n",
       "      <td>-0.311171</td>\n",
       "      <td>-8.927089</td>\n",
       "      <td>-8.741727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "      <td>1.006239</td>\n",
       "      <td>25.628060</td>\n",
       "      <td>25.572145</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>-0.407957</td>\n",
       "      <td>1.744566</td>\n",
       "      <td>113.799702</td>\n",
       "      <td>151.036858</td>\n",
       "      <td>-137.001896</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>-7.831611</td>\n",
       "      <td>-7.516832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "      <td>1.001038</td>\n",
       "      <td>25.626266</td>\n",
       "      <td>25.573288</td>\n",
       "      <td>1.709833</td>\n",
       "      <td>-0.796984</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>211.827245</td>\n",
       "      <td>-18.171144</td>\n",
       "      <td>-44.717652</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.089713</td>\n",
       "      <td>0.057150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "      <td>0.990773</td>\n",
       "      <td>25.645131</td>\n",
       "      <td>25.595348</td>\n",
       "      <td>2.609116</td>\n",
       "      <td>-0.883512</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>285.946217</td>\n",
       "      <td>-52.118894</td>\n",
       "      <td>-20.837588</td>\n",
       "      <td>-0.513215</td>\n",
       "      <td>0.943240</td>\n",
       "      <td>1.102985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0           0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1           0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2           0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3           0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4           0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...       ...   ...       ...       ...       ...        ...         ...   \n",
       "1874995  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "1874996  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "1874997  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "1874998  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "1874999  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0       -31.676112    1.146962  12.465436      12.427938  0.000000  0.000000   \n",
       "1       -24.927216    1.200703  12.913284      12.865692  4.080495 -0.980114   \n",
       "2       -25.019629    1.217403  13.725729      13.692643  0.845632  0.192961   \n",
       "3       -27.454013    1.209981  15.374021      15.314907 -0.575711 -1.762585   \n",
       "4       -27.961234    1.211254  16.074363      16.017964  0.389598  2.130453   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995 -76.290437    1.009050  25.963234      25.897316  1.484646  0.303666   \n",
       "1874996 -76.625087    1.002827  25.784692      25.722482  1.474659 -0.005442   \n",
       "1874997 -79.365125    1.006239  25.628060      25.572145  0.915321 -0.407957   \n",
       "1874998 -80.259478    1.001038  25.626266      25.573288  1.709833 -0.796984   \n",
       "1874999 -80.676229    0.990773  25.645131      25.595348  2.609116 -0.883512   \n",
       "\n",
       "         acc_z_dt     gy_x_dt     gy_y_dt     gy_z_dt  acc_Energy_dt  \\\n",
       "0        0.000000    0.000000    0.000000    0.000000       0.000000   \n",
       "1       -1.699854   44.735403 -429.504677  337.444793       2.687024   \n",
       "2       -3.546937 -196.018888 -249.173073   -4.620631       0.835012   \n",
       "3        1.908626  316.513181 -473.763910 -121.719195      -0.371100   \n",
       "4       -0.365665   78.686055 -215.435892  -25.361098       0.063656   \n",
       "...           ...         ...         ...         ...            ...   \n",
       "1874995  0.800069 -150.644663  -34.630282   -8.380088      -0.679712   \n",
       "1874996  1.775771  -39.061611  110.842743  -16.732496      -0.311171   \n",
       "1874997  1.744566  113.799702  151.036858 -137.001896       0.170620   \n",
       "1874998  0.479107  211.827245  -18.171144  -44.717652      -0.260074   \n",
       "1874999  0.534668  285.946217  -52.118894  -20.837588      -0.513215   \n",
       "\n",
       "         gy_Energy_dt  gy_acc_Energy_dt  \n",
       "0            0.000000          0.000000  \n",
       "1           22.392358         21.887693  \n",
       "2           40.622253         41.347563  \n",
       "3           82.414636         81.113199  \n",
       "4           35.017060         35.152822  \n",
       "...               ...               ...  \n",
       "1874995      8.387109          8.432977  \n",
       "1874996     -8.927089         -8.741727  \n",
       "1874997     -7.831611         -7.516832  \n",
       "1874998     -0.089713          0.057150  \n",
       "1874999      0.943240          1.102985  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat(train_df)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [00:15<00:00, 206.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>558.797337</td>\n",
       "      <td>131.082711</td>\n",
       "      <td>222.252919</td>\n",
       "      <td>1119.161589</td>\n",
       "      <td>2015.703683</td>\n",
       "      <td>709.264425</td>\n",
       "      <td>1.146962</td>\n",
       "      <td>12.465436</td>\n",
       "      <td>12.427938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.233175</td>\n",
       "      <td>15.689279</td>\n",
       "      <td>12.229014</td>\n",
       "      <td>221.599635</td>\n",
       "      <td>361.903330</td>\n",
       "      <td>477.080942</td>\n",
       "      <td>1.200703</td>\n",
       "      <td>12.913284</td>\n",
       "      <td>12.865692</td>\n",
       "      <td>4.080495</td>\n",
       "      <td>-0.980114</td>\n",
       "      <td>-1.699854</td>\n",
       "      <td>44.735403</td>\n",
       "      <td>-429.504677</td>\n",
       "      <td>337.444793</td>\n",
       "      <td>2.687024</td>\n",
       "      <td>22.392358</td>\n",
       "      <td>21.887693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.832535</td>\n",
       "      <td>8.199566</td>\n",
       "      <td>3.901211</td>\n",
       "      <td>357.200415</td>\n",
       "      <td>430.568986</td>\n",
       "      <td>452.096143</td>\n",
       "      <td>1.217403</td>\n",
       "      <td>13.725729</td>\n",
       "      <td>13.692643</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.192961</td>\n",
       "      <td>-3.546937</td>\n",
       "      <td>-196.018888</td>\n",
       "      <td>-249.173073</td>\n",
       "      <td>-4.620631</td>\n",
       "      <td>0.835012</td>\n",
       "      <td>40.622253</td>\n",
       "      <td>41.347563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.675383</td>\n",
       "      <td>5.330015</td>\n",
       "      <td>2.527445</td>\n",
       "      <td>340.433376</td>\n",
       "      <td>787.558320</td>\n",
       "      <td>467.307109</td>\n",
       "      <td>1.209981</td>\n",
       "      <td>15.374021</td>\n",
       "      <td>15.314907</td>\n",
       "      <td>-0.575711</td>\n",
       "      <td>-1.762585</td>\n",
       "      <td>1.908626</td>\n",
       "      <td>316.513181</td>\n",
       "      <td>-473.763910</td>\n",
       "      <td>-121.719195</td>\n",
       "      <td>-0.371100</td>\n",
       "      <td>82.414636</td>\n",
       "      <td>81.113199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.415275</td>\n",
       "      <td>7.980024</td>\n",
       "      <td>6.566908</td>\n",
       "      <td>128.188871</td>\n",
       "      <td>1372.095224</td>\n",
       "      <td>715.824074</td>\n",
       "      <td>1.211254</td>\n",
       "      <td>16.074363</td>\n",
       "      <td>16.017964</td>\n",
       "      <td>0.389598</td>\n",
       "      <td>2.130453</td>\n",
       "      <td>-0.365665</td>\n",
       "      <td>78.686055</td>\n",
       "      <td>-215.435892</td>\n",
       "      <td>-25.361098</td>\n",
       "      <td>0.063656</td>\n",
       "      <td>35.017060</td>\n",
       "      <td>35.152822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>11.743654</td>\n",
       "      <td>3.796333</td>\n",
       "      <td>12.513870</td>\n",
       "      <td>715.873677</td>\n",
       "      <td>1124.494889</td>\n",
       "      <td>645.627066</td>\n",
       "      <td>1.009050</td>\n",
       "      <td>25.963234</td>\n",
       "      <td>25.897316</td>\n",
       "      <td>1.484646</td>\n",
       "      <td>0.303666</td>\n",
       "      <td>0.800069</td>\n",
       "      <td>-150.644663</td>\n",
       "      <td>-34.630282</td>\n",
       "      <td>-8.380088</td>\n",
       "      <td>-0.679712</td>\n",
       "      <td>8.387109</td>\n",
       "      <td>8.432977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>211.498089</td>\n",
       "      <td>82.888508</td>\n",
       "      <td>86.807874</td>\n",
       "      <td>5515.261695</td>\n",
       "      <td>28917.564390</td>\n",
       "      <td>20218.747027</td>\n",
       "      <td>1.002827</td>\n",
       "      <td>25.784692</td>\n",
       "      <td>25.722482</td>\n",
       "      <td>1.474659</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>1.775771</td>\n",
       "      <td>-39.061611</td>\n",
       "      <td>110.842743</td>\n",
       "      <td>-16.732496</td>\n",
       "      <td>-0.311171</td>\n",
       "      <td>-8.927089</td>\n",
       "      <td>-8.741727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>12.175349</td>\n",
       "      <td>6.200258</td>\n",
       "      <td>2.084554</td>\n",
       "      <td>343.695161</td>\n",
       "      <td>464.375112</td>\n",
       "      <td>78.097163</td>\n",
       "      <td>1.006239</td>\n",
       "      <td>25.628060</td>\n",
       "      <td>25.572145</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>-0.407957</td>\n",
       "      <td>1.744566</td>\n",
       "      <td>113.799702</td>\n",
       "      <td>151.036858</td>\n",
       "      <td>-137.001896</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>-7.831611</td>\n",
       "      <td>-7.516832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>19.116783</td>\n",
       "      <td>3.830800</td>\n",
       "      <td>6.938661</td>\n",
       "      <td>791.376179</td>\n",
       "      <td>2724.373764</td>\n",
       "      <td>1131.590078</td>\n",
       "      <td>1.001038</td>\n",
       "      <td>25.626266</td>\n",
       "      <td>25.573288</td>\n",
       "      <td>1.709833</td>\n",
       "      <td>-0.796984</td>\n",
       "      <td>0.479107</td>\n",
       "      <td>211.827245</td>\n",
       "      <td>-18.171144</td>\n",
       "      <td>-44.717652</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.089713</td>\n",
       "      <td>0.057150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>22.306532</td>\n",
       "      <td>4.721920</td>\n",
       "      <td>15.463388</td>\n",
       "      <td>357.639418</td>\n",
       "      <td>2058.364675</td>\n",
       "      <td>977.868201</td>\n",
       "      <td>0.990773</td>\n",
       "      <td>25.645131</td>\n",
       "      <td>25.595348</td>\n",
       "      <td>2.609116</td>\n",
       "      <td>-0.883512</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>285.946217</td>\n",
       "      <td>-52.118894</td>\n",
       "      <td>-20.837588</td>\n",
       "      <td>-0.513215</td>\n",
       "      <td>0.943240</td>\n",
       "      <td>1.102985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time       acc_x       acc_y       acc_z         gy_x  \\\n",
       "0           0     0  558.797337  131.082711  222.252919  1119.161589   \n",
       "1           0     1    3.233175   15.689279   12.229014   221.599635   \n",
       "2           0     2    4.832535    8.199566    3.901211   357.200415   \n",
       "3           0     3    5.675383    5.330015    2.527445   340.433376   \n",
       "4           0     4    7.415275    7.980024    6.566908   128.188871   \n",
       "...       ...   ...         ...         ...         ...          ...   \n",
       "1874995  3124   595   11.743654    3.796333   12.513870   715.873677   \n",
       "1874996  3124   596  211.498089   82.888508   86.807874  5515.261695   \n",
       "1874997  3124   597   12.175349    6.200258    2.084554   343.695161   \n",
       "1874998  3124   598   19.116783    3.830800    6.938661   791.376179   \n",
       "1874999  3124   599   22.306532    4.721920   15.463388   357.639418   \n",
       "\n",
       "                 gy_y          gy_z  acc_Energy  gy_Energy  gy_acc_Energy  \\\n",
       "0         2015.703683    709.264425    1.146962  12.465436      12.427938   \n",
       "1          361.903330    477.080942    1.200703  12.913284      12.865692   \n",
       "2          430.568986    452.096143    1.217403  13.725729      13.692643   \n",
       "3          787.558320    467.307109    1.209981  15.374021      15.314907   \n",
       "4         1372.095224    715.824074    1.211254  16.074363      16.017964   \n",
       "...               ...           ...         ...        ...            ...   \n",
       "1874995   1124.494889    645.627066    1.009050  25.963234      25.897316   \n",
       "1874996  28917.564390  20218.747027    1.002827  25.784692      25.722482   \n",
       "1874997    464.375112     78.097163    1.006239  25.628060      25.572145   \n",
       "1874998   2724.373764   1131.590078    1.001038  25.626266      25.573288   \n",
       "1874999   2058.364675    977.868201    0.990773  25.645131      25.595348   \n",
       "\n",
       "         acc_x_dt  acc_y_dt  acc_z_dt     gy_x_dt     gy_y_dt     gy_z_dt  \\\n",
       "0        0.000000  0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "1        4.080495 -0.980114 -1.699854   44.735403 -429.504677  337.444793   \n",
       "2        0.845632  0.192961 -3.546937 -196.018888 -249.173073   -4.620631   \n",
       "3       -0.575711 -1.762585  1.908626  316.513181 -473.763910 -121.719195   \n",
       "4        0.389598  2.130453 -0.365665   78.686055 -215.435892  -25.361098   \n",
       "...           ...       ...       ...         ...         ...         ...   \n",
       "1874995  1.484646  0.303666  0.800069 -150.644663  -34.630282   -8.380088   \n",
       "1874996  1.474659 -0.005442  1.775771  -39.061611  110.842743  -16.732496   \n",
       "1874997  0.915321 -0.407957  1.744566  113.799702  151.036858 -137.001896   \n",
       "1874998  1.709833 -0.796984  0.479107  211.827245  -18.171144  -44.717652   \n",
       "1874999  2.609116 -0.883512  0.534668  285.946217  -52.118894  -20.837588   \n",
       "\n",
       "         acc_Energy_dt  gy_Energy_dt  gy_acc_Energy_dt  \n",
       "0             0.000000      0.000000          0.000000  \n",
       "1             2.687024     22.392358         21.887693  \n",
       "2             0.835012     40.622253         41.347563  \n",
       "3            -0.371100     82.414636         81.113199  \n",
       "4             0.063656     35.017060         35.152822  \n",
       "...                ...           ...               ...  \n",
       "1874995      -0.679712      8.387109          8.432977  \n",
       "1874996      -0.311171     -8.927089         -8.741727  \n",
       "1874997       0.170620     -7.831611         -7.516832  \n",
       "1874998      -0.260074     -0.089713          0.057150  \n",
       "1874999      -0.513215      0.943240          1.102985  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft = []\n",
    "\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp = train.loc[train['id'] == i] \n",
    "    \n",
    "    for i in train.columns[2:8]: \n",
    "        temp[i] = fourier_transform_one_signal(temp[i].values)\n",
    "        \n",
    "    fft.append(temp)\n",
    "\n",
    "train = pd.concat(fft)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:02<00:00, 286.63it/s]\n"
     ]
    }
   ],
   "source": [
    "fft_t = []\n",
    "\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp = test.loc[test['id'] == i]\n",
    "    \n",
    "    for i in test.columns[2:8]:\n",
    "        temp[i] = fourier_transform_one_signal(temp[i].values)\n",
    "        \n",
    "    fft_t.append(temp)\n",
    "    \n",
    "test = pd.concat(fft_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Standard Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = train.columns\n",
    "train_s = train.copy()\n",
    "test_s = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_s.iloc[:,2:] = scaler.fit_transform(train_s.iloc[:,2:])\n",
    "train_sc = pd.DataFrame(train_s, columns = col )\n",
    "\n",
    "test_s.iloc[:, 2:] = scaler.fit_transform(test_s.iloc[:,2:])\n",
    "test_sc = pd.DataFrame(test_s, columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.356382</td>\n",
       "      <td>8.807207</td>\n",
       "      <td>19.465910</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.869226</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.495681</td>\n",
       "      <td>-0.272719</td>\n",
       "      <td>-0.276391</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.833464</td>\n",
       "      <td>0.820412</td>\n",
       "      <td>-0.282128</td>\n",
       "      <td>-0.093560</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.742974</td>\n",
       "      <td>-0.236152</td>\n",
       "      <td>-0.240632</td>\n",
       "      <td>0.416836</td>\n",
       "      <td>-0.118821</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.349095</td>\n",
       "      <td>0.377085</td>\n",
       "      <td>0.564992</td>\n",
       "      <td>0.166566</td>\n",
       "      <td>0.162871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.315921</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.182551</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.819822</td>\n",
       "      <td>-0.169815</td>\n",
       "      <td>-0.173080</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>-0.531727</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>-0.202368</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.175645</td>\n",
       "      <td>0.300944</td>\n",
       "      <td>0.306341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.117634</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.785669</td>\n",
       "      <td>-0.035229</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>-0.058780</td>\n",
       "      <td>-0.213920</td>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>-0.385106</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.077915</td>\n",
       "      <td>0.609008</td>\n",
       "      <td>0.599518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151477</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>-0.350724</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.791528</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.259227</td>\n",
       "      <td>-0.055206</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.259626</td>\n",
       "      <td>0.260669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>0.112282</td>\n",
       "      <td>-0.138940</td>\n",
       "      <td>0.829394</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.027804</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.142794</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>0.063674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>10.220817</td>\n",
       "      <td>5.476964</td>\n",
       "      <td>7.441373</td>\n",
       "      <td>3.605246</td>\n",
       "      <td>16.530576</td>\n",
       "      <td>11.843241</td>\n",
       "      <td>-0.167578</td>\n",
       "      <td>0.814816</td>\n",
       "      <td>0.809618</td>\n",
       "      <td>0.150658</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.265559</td>\n",
       "      <td>-0.027936</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.065316</td>\n",
       "      <td>-0.064300</td>\n",
       "      <td>-0.062949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.177768</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>-0.192468</td>\n",
       "      <td>-0.033904</td>\n",
       "      <td>-0.227861</td>\n",
       "      <td>-0.151875</td>\n",
       "      <td>0.802027</td>\n",
       "      <td>0.797338</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>-0.049283</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>-0.152712</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>-0.056225</td>\n",
       "      <td>-0.053918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>0.728823</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>1.281790</td>\n",
       "      <td>0.403540</td>\n",
       "      <td>-0.175811</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.797431</td>\n",
       "      <td>0.174681</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>-0.014412</td>\n",
       "      <td>-0.049662</td>\n",
       "      <td>-0.054574</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>0.886204</td>\n",
       "      <td>0.075614</td>\n",
       "      <td>1.107553</td>\n",
       "      <td>-0.182228</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>-0.223043</td>\n",
       "      <td>0.803421</td>\n",
       "      <td>0.799233</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>-0.107081</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>-0.042034</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.107792</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.009633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.495681  -0.272719      -0.276391  0.000027  0.000298   \n",
       "1         0.011266    0.742974  -0.236152      -0.240632  0.416836 -0.118821   \n",
       "2        -0.003708    0.819822  -0.169815      -0.173080  0.086405  0.023750   \n",
       "3         0.005408    0.785669  -0.035229      -0.040560 -0.058780 -0.213920   \n",
       "4         0.154354    0.791528   0.021954       0.016872  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.138940   0.829394       0.823900  0.151679  0.037205   \n",
       "1874996  11.843241   -0.167578   0.814816       0.809618  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.151875   0.802027       0.797338  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.175811   0.801880       0.797431  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.223043   0.803421       0.799233  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000101      0.001505   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.564992      0.166566   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.175645      0.300944   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.077915      0.609008   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.013483      0.259626   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.142794      0.063329   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.065316     -0.064300   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.035970     -0.056225   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.054574      0.000843   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.107792      0.008458   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001501  \n",
       "1                0.162871  \n",
       "2                0.306341  \n",
       "3                0.599518  \n",
       "4                0.260669  \n",
       "...                   ...  \n",
       "1874995          0.063674  \n",
       "1874996         -0.062949  \n",
       "1874997         -0.053918  \n",
       "1874998          0.001922  \n",
       "1874999          0.009633  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링 : 1D-CNN with Global average pooling   \n",
    "\n",
    "[`tensorflow_addons`](https://www.tensorflow.org/addons/overview?hl=ko) \n",
    "    : 새로운 기능을 사용할 수 있도록 하는 repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa \n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv1D, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import GlobalAveragePooling1D, Dense\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 600, 18)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(train_sc.iloc[:,2:]).reshape(3125,600,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_label['label'].values\n",
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CNN 모델 구조  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, classes):\n",
    "    \n",
    "    seed(2021)\n",
    "    tf.random.set_seed(2021)\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    # 1st\n",
    "    conv1 = Conv1D(filters = 128, kernel_size = 9, padding ='same')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation(activation = 'relu')(conv1)\n",
    "    conv1 = Dropout(rate = 0.3)(conv1)\n",
    "    \n",
    "    # 2nd\n",
    "    conv2 = Conv1D(256, kernel_size = 6, padding = 'same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Dropout(rate = 0.4)(conv2)\n",
    "    \n",
    "    # 3rd\n",
    "    conv3 = Conv1D(128, kernel_size = 3, padding ='same')(conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    \n",
    "    \n",
    "    gap = GlobalAveragePooling1D()(conv3)\n",
    "    \n",
    "    output_layer = Dense(classes, activation = 'softmax')(gap)\n",
    "    \n",
    "    model = keras.models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 10 Kold stratifiedKFlod\n",
    "\n",
    "[`ReduceLROnPlateau()`](https://teddylee777.github.io/tensorflow/keras-콜백함수-vol-01) : 콜백함수로 학습률 조정.    \n",
    "[`EarlyStopping()`](https://3months.tistory.com/424) : 효율적 운영을 위한 early stoping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(10, random_state = 2021, shuffle = True )\n",
    "reLR = ReduceLROnPlateau(patience = 4, verbose = 1, factor = 0.5 )\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = 8, mode = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`ModelCheckpoint()`](https://deep-deep-deep.tistory.com/53) : 학습 모델 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Fold1--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 3.3854 - accuracy: 0.3490 - val_loss: 3.1174 - val_accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 1.9729 - accuracy: 0.5509 - val_loss: 1.9238 - val_accuracy: 0.5304\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.7849 - accuracy: 0.5650 - val_loss: 2.0366 - val_accuracy: 0.5495\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.5553 - accuracy: 0.6142 - val_loss: 1.9209 - val_accuracy: 0.5623\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.3838 - accuracy: 0.6454 - val_loss: 1.5153 - val_accuracy: 0.6070\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 1.2684 - accuracy: 0.6767 - val_loss: 1.4039 - val_accuracy: 0.6230\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.1646 - accuracy: 0.6891 - val_loss: 1.2551 - val_accuracy: 0.6518\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.0604 - accuracy: 0.7159 - val_loss: 1.1977 - val_accuracy: 0.6741\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.9700 - accuracy: 0.7389 - val_loss: 1.1093 - val_accuracy: 0.7093\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 0.9056 - accuracy: 0.7567 - val_loss: 0.9842 - val_accuracy: 0.7572\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.8777 - accuracy: 0.7563 - val_loss: 0.9517 - val_accuracy: 0.7604\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1982s 46s/step - loss: 0.7888 - accuracy: 0.7879 - val_loss: 1.1032 - val_accuracy: 0.7316\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.7502 - accuracy: 0.7793 - val_loss: 0.9430 - val_accuracy: 0.7764\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 67s 2s/step - loss: 0.7097 - accuracy: 0.8031 - val_loss: 0.8521 - val_accuracy: 0.7732\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.6790 - accuracy: 0.8017 - val_loss: 0.7806 - val_accuracy: 0.8051\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.6185 - accuracy: 0.8329 - val_loss: 0.7704 - val_accuracy: 0.8179\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.5849 - accuracy: 0.8358 - val_loss: 0.7489 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.5724 - accuracy: 0.8268 - val_loss: 0.7251 - val_accuracy: 0.8083\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.5382 - accuracy: 0.8487 - val_loss: 0.7075 - val_accuracy: 0.8051\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.5011 - accuracy: 0.8574 - val_loss: 0.6735 - val_accuracy: 0.8051\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.5079 - accuracy: 0.8555 - val_loss: 0.7700 - val_accuracy: 0.8147\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.4766 - accuracy: 0.8564 - val_loss: 0.6516 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.4498 - accuracy: 0.8747 - val_loss: 0.6706 - val_accuracy: 0.8019\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.4300 - accuracy: 0.8766 - val_loss: 0.6868 - val_accuracy: 0.8179\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.4535 - accuracy: 0.8777 - val_loss: 0.6615 - val_accuracy: 0.8051\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.4018 - accuracy: 0.8835 - val_loss: 0.7527 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.3789 - accuracy: 0.8994 - val_loss: 0.6047 - val_accuracy: 0.8275\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.3585 - accuracy: 0.9017 - val_loss: 0.6083 - val_accuracy: 0.8339\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3498 - accuracy: 0.8988 - val_loss: 0.6170 - val_accuracy: 0.8211\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.3658 - accuracy: 0.9043 - val_loss: 0.5920 - val_accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.3489 - accuracy: 0.9032 - val_loss: 0.6040 - val_accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.3325 - accuracy: 0.9070 - val_loss: 0.5878 - val_accuracy: 0.8339\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.3065 - accuracy: 0.9177 - val_loss: 0.6032 - val_accuracy: 0.8179\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3196 - accuracy: 0.9135 - val_loss: 0.5764 - val_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3119 - accuracy: 0.9125 - val_loss: 0.6370 - val_accuracy: 0.8211\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.3217 - accuracy: 0.9089 - val_loss: 0.5917 - val_accuracy: 0.8211\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3030 - accuracy: 0.9181 - val_loss: 0.5923 - val_accuracy: 0.8275\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2936 - accuracy: 0.9169 - val_loss: 0.5966 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2800 - accuracy: 0.9289 - val_loss: 0.5588 - val_accuracy: 0.8371\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2814 - accuracy: 0.9205 - val_loss: 0.5524 - val_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2616 - accuracy: 0.9350 - val_loss: 0.5575 - val_accuracy: 0.8371\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2758 - accuracy: 0.9315 - val_loss: 0.5544 - val_accuracy: 0.8530\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2768 - accuracy: 0.9293 - val_loss: 0.5700 - val_accuracy: 0.8371\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2535 - accuracy: 0.9424 - val_loss: 0.5568 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2425 - accuracy: 0.9413 - val_loss: 0.5619 - val_accuracy: 0.8435\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2502 - accuracy: 0.9404 - val_loss: 0.5547 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2558 - accuracy: 0.9390 - val_loss: 0.5456 - val_accuracy: 0.8530\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2543 - accuracy: 0.9352 - val_loss: 0.5485 - val_accuracy: 0.8435\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2359s 55s/step - loss: 0.2464 - accuracy: 0.9328 - val_loss: 0.5490 - val_accuracy: 0.8339\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2499 - accuracy: 0.9331 - val_loss: 0.5485 - val_accuracy: 0.8371\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 67s 2s/step - loss: 0.2363 - accuracy: 0.9427 - val_loss: 0.5487 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 70s 2s/step - loss: 0.2758 - accuracy: 0.9265 - val_loss: 0.5413 - val_accuracy: 0.8466\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.2349 - accuracy: 0.9443 - val_loss: 0.5385 - val_accuracy: 0.8530\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.2363 - accuracy: 0.9446 - val_loss: 0.5420 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.2568 - accuracy: 0.9403 - val_loss: 0.5407 - val_accuracy: 0.8435\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.2567 - accuracy: 0.9362 - val_loss: 0.5373 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2387 - accuracy: 0.9402 - val_loss: 0.5415 - val_accuracy: 0.8498\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2440 - accuracy: 0.9417 - val_loss: 0.5426 - val_accuracy: 0.8530\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2211 - accuracy: 0.9483 - val_loss: 0.5384 - val_accuracy: 0.8498\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2508 - accuracy: 0.9337 - val_loss: 0.5398 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2486 - accuracy: 0.9397 - val_loss: 0.5385 - val_accuracy: 0.8498\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2383 - accuracy: 0.9474 - val_loss: 0.5382 - val_accuracy: 0.8498\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2293 - accuracy: 0.9441 - val_loss: 0.5375 - val_accuracy: 0.8435\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2343 - accuracy: 0.9422 - val_loss: 0.5380 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 0.5373 - accuracy: 0.8530\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 0.5373 - accuracy: 0.8530\n",
      "--------------------Fold2--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 3.4087 - accuracy: 0.3354 - val_loss: 3.2237 - val_accuracy: 0.3099\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 2.0136 - accuracy: 0.5430 - val_loss: 1.8954 - val_accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 1.7352 - accuracy: 0.5815 - val_loss: 1.9616 - val_accuracy: 0.5431\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 1.5308 - accuracy: 0.6188 - val_loss: 1.6230 - val_accuracy: 0.5751\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 1.4247 - accuracy: 0.6293 - val_loss: 1.5203 - val_accuracy: 0.6006\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 1.2450 - accuracy: 0.6781 - val_loss: 1.4236 - val_accuracy: 0.6166\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 1.1710 - accuracy: 0.6863 - val_loss: 1.3082 - val_accuracy: 0.6486\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 1.1034 - accuracy: 0.7054 - val_loss: 1.2182 - val_accuracy: 0.6741\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.0044 - accuracy: 0.7237 - val_loss: 1.0480 - val_accuracy: 0.7220\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.9427 - accuracy: 0.7454 - val_loss: 0.9405 - val_accuracy: 0.7764\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.8382 - accuracy: 0.7715 - val_loss: 0.8992 - val_accuracy: 0.7476\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.8011 - accuracy: 0.7708 - val_loss: 0.8800 - val_accuracy: 0.7540\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.7520 - accuracy: 0.7948 - val_loss: 0.8025 - val_accuracy: 0.7540\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.7264 - accuracy: 0.7883 - val_loss: 0.7777 - val_accuracy: 0.7859\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.6689 - accuracy: 0.8136 - val_loss: 0.7419 - val_accuracy: 0.7796\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.6282 - accuracy: 0.8181 - val_loss: 0.8452 - val_accuracy: 0.7891\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.6129 - accuracy: 0.8314 - val_loss: 0.6878 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5733 - accuracy: 0.8363 - val_loss: 0.6894 - val_accuracy: 0.8147\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.5297 - accuracy: 0.8589 - val_loss: 0.6190 - val_accuracy: 0.8307\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.5017 - accuracy: 0.8481 - val_loss: 0.6277 - val_accuracy: 0.8179\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4878 - accuracy: 0.8642 - val_loss: 0.6295 - val_accuracy: 0.8339\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4676 - accuracy: 0.8749 - val_loss: 0.6402 - val_accuracy: 0.8243\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4753 - accuracy: 0.8649 - val_loss: 0.6114 - val_accuracy: 0.8083\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4283 - accuracy: 0.8803 - val_loss: 0.6293 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4299 - accuracy: 0.8717 - val_loss: 0.6238 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4101 - accuracy: 0.8847 - val_loss: 0.6309 - val_accuracy: 0.8115\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4111 - accuracy: 0.8874 - val_loss: 0.5665 - val_accuracy: 0.8147\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4005 - accuracy: 0.8882 - val_loss: 0.5566 - val_accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3776 - accuracy: 0.8893 - val_loss: 0.5555 - val_accuracy: 0.8307\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3808 - accuracy: 0.8913 - val_loss: 0.6003 - val_accuracy: 0.8307\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3594 - accuracy: 0.9015 - val_loss: 0.5548 - val_accuracy: 0.8275\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.3410 - accuracy: 0.8984 - val_loss: 0.6756 - val_accuracy: 0.7827\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3477 - accuracy: 0.8951 - val_loss: 0.5654 - val_accuracy: 0.8179\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3151 - accuracy: 0.9112 - val_loss: 0.5506 - val_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3168 - accuracy: 0.9221 - val_loss: 0.5151 - val_accuracy: 0.8403\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3255 - accuracy: 0.9155 - val_loss: 0.5316 - val_accuracy: 0.8403\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3029 - accuracy: 0.9147 - val_loss: 0.5546 - val_accuracy: 0.8243\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3142 - accuracy: 0.9076 - val_loss: 0.5679 - val_accuracy: 0.8211\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2851 - accuracy: 0.9201 - val_loss: 0.5673 - val_accuracy: 0.8083\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2826 - accuracy: 0.9224 - val_loss: 0.5391 - val_accuracy: 0.8275\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2687 - accuracy: 0.9221 - val_loss: 0.5161 - val_accuracy: 0.8307\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2792 - accuracy: 0.9231 - val_loss: 0.5007 - val_accuracy: 0.8339\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2377 - accuracy: 0.9447 - val_loss: 0.5057 - val_accuracy: 0.8275\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2614 - accuracy: 0.9281 - val_loss: 0.5121 - val_accuracy: 0.8371\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2575 - accuracy: 0.9310 - val_loss: 0.5448 - val_accuracy: 0.8307\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2423 - accuracy: 0.9363 - val_loss: 0.5203 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2353 - accuracy: 0.9429 - val_loss: 0.4888 - val_accuracy: 0.8562\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2101 - accuracy: 0.9489 - val_loss: 0.4764 - val_accuracy: 0.8435\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2378 - accuracy: 0.9376 - val_loss: 0.4835 - val_accuracy: 0.8562\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2013 - accuracy: 0.9500 - val_loss: 0.5066 - val_accuracy: 0.8371\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2087 - accuracy: 0.9513 - val_loss: 0.4919 - val_accuracy: 0.8403\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2033 - accuracy: 0.9476 - val_loss: 0.4880 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1983 - accuracy: 0.9524 - val_loss: 0.4831 - val_accuracy: 0.8466\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.1848 - accuracy: 0.9579 - val_loss: 0.4923 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1983 - accuracy: 0.9528 - val_loss: 0.4760 - val_accuracy: 0.8435\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1921 - accuracy: 0.9562 - val_loss: 0.4876 - val_accuracy: 0.8466\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1833 - accuracy: 0.9536 - val_loss: 0.4827 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.1927 - accuracy: 0.9505 - val_loss: 0.4795 - val_accuracy: 0.8435\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1987 - accuracy: 0.9520 - val_loss: 0.4806 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1871 - accuracy: 0.9512 - val_loss: 0.4781 - val_accuracy: 0.8530\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1871 - accuracy: 0.9579 - val_loss: 0.4770 - val_accuracy: 0.8466\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1899 - accuracy: 0.9482 - val_loss: 0.4827 - val_accuracy: 0.8403\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.1735 - accuracy: 0.9637 - val_loss: 0.4762 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.4760 - accuracy: 0.8435\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 0.4760 - accuracy: 0.8435\n",
      "--------------------Fold3--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 87s 2s/step - loss: 3.3707 - accuracy: 0.3413 - val_loss: 3.1705 - val_accuracy: 0.3323\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 87s 2s/step - loss: 1.9792 - accuracy: 0.5496 - val_loss: 1.8587 - val_accuracy: 0.5527\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 1.7008 - accuracy: 0.5952 - val_loss: 1.7980 - val_accuracy: 0.5527\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 1.5330 - accuracy: 0.6170 - val_loss: 1.5763 - val_accuracy: 0.5751\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 88s 2s/step - loss: 1.3841 - accuracy: 0.6438 - val_loss: 1.5879 - val_accuracy: 0.6038\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2097s 49s/step - loss: 1.2318 - accuracy: 0.6813 - val_loss: 1.3254 - val_accuracy: 0.6326\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 1.1609 - accuracy: 0.6962 - val_loss: 1.1644 - val_accuracy: 0.6869\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 70s 2s/step - loss: 1.0540 - accuracy: 0.7217 - val_loss: 1.0811 - val_accuracy: 0.7252\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 1.0408 - accuracy: 0.7128 - val_loss: 1.0462 - val_accuracy: 0.7412\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.8959 - accuracy: 0.7589 - val_loss: 0.9339 - val_accuracy: 0.7508\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.8660 - accuracy: 0.7485 - val_loss: 0.9013 - val_accuracy: 0.7764\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.7915 - accuracy: 0.7907 - val_loss: 0.8715 - val_accuracy: 0.7827\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.7471 - accuracy: 0.7863 - val_loss: 0.7616 - val_accuracy: 0.7987\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.7215 - accuracy: 0.7970 - val_loss: 0.7652 - val_accuracy: 0.7732\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.6329 - accuracy: 0.8114 - val_loss: 0.7756 - val_accuracy: 0.7796\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.6021 - accuracy: 0.8294 - val_loss: 0.7440 - val_accuracy: 0.7796\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.6129 - accuracy: 0.8206 - val_loss: 0.7284 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5611 - accuracy: 0.8362 - val_loss: 0.6938 - val_accuracy: 0.8051\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5360 - accuracy: 0.8583 - val_loss: 0.6132 - val_accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5039 - accuracy: 0.8519 - val_loss: 0.6390 - val_accuracy: 0.8211\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5003 - accuracy: 0.8556 - val_loss: 0.6486 - val_accuracy: 0.8371\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.4629 - accuracy: 0.8723 - val_loss: 0.6248 - val_accuracy: 0.8211\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4752 - accuracy: 0.8623 - val_loss: 0.5716 - val_accuracy: 0.8275\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4595 - accuracy: 0.8645 - val_loss: 0.5876 - val_accuracy: 0.8339\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4231 - accuracy: 0.8717 - val_loss: 0.5817 - val_accuracy: 0.8179\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4002 - accuracy: 0.8800 - val_loss: 0.5329 - val_accuracy: 0.8530\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4306 - accuracy: 0.8692 - val_loss: 0.5040 - val_accuracy: 0.8498\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3943 - accuracy: 0.8834 - val_loss: 0.5557 - val_accuracy: 0.8435\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3769 - accuracy: 0.8913 - val_loss: 0.5405 - val_accuracy: 0.8307\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3763 - accuracy: 0.8882 - val_loss: 0.6964 - val_accuracy: 0.7859\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3791 - accuracy: 0.8881 - val_loss: 0.5060 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.3333 - accuracy: 0.9110 - val_loss: 0.5012 - val_accuracy: 0.8466\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.3182 - accuracy: 0.9121 - val_loss: 0.5010 - val_accuracy: 0.8371\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3196 - accuracy: 0.9114 - val_loss: 0.5339 - val_accuracy: 0.8435\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.3111 - accuracy: 0.9110 - val_loss: 0.4793 - val_accuracy: 0.8498\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2837 - accuracy: 0.9220 - val_loss: 0.4980 - val_accuracy: 0.8307\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2833 - accuracy: 0.9263 - val_loss: 0.4835 - val_accuracy: 0.8466\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2911 - accuracy: 0.9139 - val_loss: 0.4666 - val_accuracy: 0.8594\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2801 - accuracy: 0.9168 - val_loss: 0.4601 - val_accuracy: 0.8594\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2849 - accuracy: 0.9193 - val_loss: 0.4741 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2855 - accuracy: 0.9255 - val_loss: 0.4779 - val_accuracy: 0.8530\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2939 - accuracy: 0.9169 - val_loss: 0.4949 - val_accuracy: 0.8371\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.2833 - accuracy: 0.9291 - val_loss: 0.4983 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.2539 - accuracy: 0.9336 - val_loss: 0.4501 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2020s 47s/step - loss: 0.2474 - accuracy: 0.9384 - val_loss: 0.4543 - val_accuracy: 0.8594\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2527 - accuracy: 0.9271 - val_loss: 0.4467 - val_accuracy: 0.8562\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.2369 - accuracy: 0.9373 - val_loss: 0.4415 - val_accuracy: 0.8594\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.2501 - accuracy: 0.9351 - val_loss: 0.4388 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.2392 - accuracy: 0.9411 - val_loss: 0.4343 - val_accuracy: 0.8722\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2391 - accuracy: 0.9336 - val_loss: 0.4374 - val_accuracy: 0.8658\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2344 - accuracy: 0.9364 - val_loss: 0.4540 - val_accuracy: 0.8530\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2675 - accuracy: 0.9258 - val_loss: 0.4318 - val_accuracy: 0.8626\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2359 - accuracy: 0.9346 - val_loss: 0.4346 - val_accuracy: 0.8530\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2528 - accuracy: 0.9293 - val_loss: 0.4552 - val_accuracy: 0.8466\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2281 - accuracy: 0.9453 - val_loss: 0.4332 - val_accuracy: 0.8690\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2316 - accuracy: 0.9367 - val_loss: 0.4335 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2290 - accuracy: 0.9386 - val_loss: 0.4307 - val_accuracy: 0.8722\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2187 - accuracy: 0.9424 - val_loss: 0.4451 - val_accuracy: 0.8594\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2178 - accuracy: 0.9425 - val_loss: 0.4289 - val_accuracy: 0.8530\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2264 - accuracy: 0.9413 - val_loss: 0.4286 - val_accuracy: 0.8658\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1989 - accuracy: 0.9472 - val_loss: 0.4290 - val_accuracy: 0.8562\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2219 - accuracy: 0.9399 - val_loss: 0.4277 - val_accuracy: 0.8594\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2217 - accuracy: 0.9460 - val_loss: 0.4284 - val_accuracy: 0.8594\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1871 - accuracy: 0.9506 - val_loss: 0.4264 - val_accuracy: 0.8722\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2162 - accuracy: 0.9503 - val_loss: 0.4307 - val_accuracy: 0.8690\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2222 - accuracy: 0.9500 - val_loss: 0.4305 - val_accuracy: 0.8658\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2025 - accuracy: 0.9416 - val_loss: 0.4381 - val_accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1996 - accuracy: 0.9544 - val_loss: 0.4299 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1895 - accuracy: 0.9510 - val_loss: 0.4259 - val_accuracy: 0.8754\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2041 - accuracy: 0.9473 - val_loss: 0.4238 - val_accuracy: 0.8722\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1904 - accuracy: 0.9533 - val_loss: 0.4255 - val_accuracy: 0.8722\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1976 - accuracy: 0.9441 - val_loss: 0.4209 - val_accuracy: 0.8722\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2006 - accuracy: 0.9517 - val_loss: 0.4218 - val_accuracy: 0.8722\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1990 - accuracy: 0.9585 - val_loss: 0.4212 - val_accuracy: 0.8626\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2024 - accuracy: 0.9451 - val_loss: 0.4195 - val_accuracy: 0.8690\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1905 - accuracy: 0.9509 - val_loss: 0.4209 - val_accuracy: 0.8658\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1955 - accuracy: 0.9516 - val_loss: 0.4218 - val_accuracy: 0.8658\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2077 - accuracy: 0.9437 - val_loss: 0.4224 - val_accuracy: 0.8658\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.1814 - accuracy: 0.9594 - val_loss: 0.4196 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1951 - accuracy: 0.9554 - val_loss: 0.4218 - val_accuracy: 0.8690\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2022 - accuracy: 0.9485 - val_loss: 0.4209 - val_accuracy: 0.8658\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1944 - accuracy: 0.9522 - val_loss: 0.4213 - val_accuracy: 0.8658\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.1932 - accuracy: 0.9527 - val_loss: 0.4220 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.4195 - accuracy: 0.8690\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.4195 - accuracy: 0.8690\n",
      "--------------------Fold4--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 87s 2s/step - loss: 3.3705 - accuracy: 0.3537 - val_loss: 3.0872 - val_accuracy: 0.3610\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.9608 - accuracy: 0.5554 - val_loss: 1.9842 - val_accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 1.7313 - accuracy: 0.5809 - val_loss: 1.9141 - val_accuracy: 0.5335\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.5518 - accuracy: 0.6213 - val_loss: 1.9570 - val_accuracy: 0.5240\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.3651 - accuracy: 0.6499 - val_loss: 1.6625 - val_accuracy: 0.5783\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 1.2732 - accuracy: 0.6592 - val_loss: 1.4683 - val_accuracy: 0.6326\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3281s 76s/step - loss: 1.1636 - accuracy: 0.6978 - val_loss: 1.3159 - val_accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 1.0988 - accuracy: 0.7057 - val_loss: 1.4110 - val_accuracy: 0.6422\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.9743 - accuracy: 0.7415 - val_loss: 1.1892 - val_accuracy: 0.6837\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.8991 - accuracy: 0.7398 - val_loss: 1.1117 - val_accuracy: 0.6997\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.8420 - accuracy: 0.7694 - val_loss: 1.0400 - val_accuracy: 0.7061\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.7760 - accuracy: 0.7835 - val_loss: 1.0687 - val_accuracy: 0.7125\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.7301 - accuracy: 0.7858 - val_loss: 1.0384 - val_accuracy: 0.7220\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.6822 - accuracy: 0.8058 - val_loss: 0.9756 - val_accuracy: 0.7412\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.6238 - accuracy: 0.8294 - val_loss: 0.9922 - val_accuracy: 0.7604\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.6077 - accuracy: 0.8291 - val_loss: 0.8604 - val_accuracy: 0.7444\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5804 - accuracy: 0.8350 - val_loss: 0.8508 - val_accuracy: 0.7508\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5684 - accuracy: 0.8351 - val_loss: 0.8513 - val_accuracy: 0.7668\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5501 - accuracy: 0.8437 - val_loss: 0.8236 - val_accuracy: 0.7700\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5329 - accuracy: 0.8443 - val_loss: 0.8215 - val_accuracy: 0.7764\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4905 - accuracy: 0.8703 - val_loss: 0.7632 - val_accuracy: 0.7987\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4559 - accuracy: 0.8627 - val_loss: 0.7834 - val_accuracy: 0.7764\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4958 - accuracy: 0.8511 - val_loss: 0.7791 - val_accuracy: 0.7987\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4391 - accuracy: 0.8738 - val_loss: 0.7414 - val_accuracy: 0.7923\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4402 - accuracy: 0.8765 - val_loss: 0.7722 - val_accuracy: 0.7764\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4002 - accuracy: 0.8951 - val_loss: 0.7480 - val_accuracy: 0.7796\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.4235 - accuracy: 0.8708 - val_loss: 0.7972 - val_accuracy: 0.7636\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4007 - accuracy: 0.8785 - val_loss: 0.7183 - val_accuracy: 0.7827\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3715 - accuracy: 0.8898 - val_loss: 0.7659 - val_accuracy: 0.7891\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3731 - accuracy: 0.8953 - val_loss: 0.8985 - val_accuracy: 0.7764\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3743 - accuracy: 0.8991 - val_loss: 0.7492 - val_accuracy: 0.7923\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3613 - accuracy: 0.9050 - val_loss: 0.7365 - val_accuracy: 0.7796\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3365 - accuracy: 0.8993 - val_loss: 0.7010 - val_accuracy: 0.7764\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3107 - accuracy: 0.9120 - val_loss: 0.6550 - val_accuracy: 0.8115\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3153 - accuracy: 0.9153 - val_loss: 0.6554 - val_accuracy: 0.8211\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2844 - accuracy: 0.9254 - val_loss: 0.6710 - val_accuracy: 0.7955\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2895 - accuracy: 0.9197 - val_loss: 0.6743 - val_accuracy: 0.8019\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2767 - accuracy: 0.9294 - val_loss: 0.6960 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2612 - accuracy: 0.9311 - val_loss: 0.6271 - val_accuracy: 0.8115\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2758 - accuracy: 0.9217 - val_loss: 0.6482 - val_accuracy: 0.8179\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2462 - accuracy: 0.9376 - val_loss: 0.6312 - val_accuracy: 0.8179\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2552 - accuracy: 0.9352 - val_loss: 0.6444 - val_accuracy: 0.8147\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2708 - accuracy: 0.9318 - val_loss: 0.6346 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2648 - accuracy: 0.9345 - val_loss: 0.6247 - val_accuracy: 0.8275\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2396 - accuracy: 0.9393 - val_loss: 0.6264 - val_accuracy: 0.8115\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1257s 29s/step - loss: 0.2385 - accuracy: 0.9400 - val_loss: 0.6274 - val_accuracy: 0.8115\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 149s 3s/step - loss: 0.2335 - accuracy: 0.9423 - val_loss: 0.6230 - val_accuracy: 0.8275\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2295s 53s/step - loss: 0.2398 - accuracy: 0.9359 - val_loss: 0.6386 - val_accuracy: 0.8211\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2494 - accuracy: 0.9352 - val_loss: 0.6265 - val_accuracy: 0.8115\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 66s 2s/step - loss: 0.2352 - accuracy: 0.9319 - val_loss: 0.6317 - val_accuracy: 0.8147\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.2264 - accuracy: 0.9454 - val_loss: 0.6172 - val_accuracy: 0.8147\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.2358 - accuracy: 0.9382 - val_loss: 0.6255 - val_accuracy: 0.8275\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.2367 - accuracy: 0.9401 - val_loss: 0.6257 - val_accuracy: 0.8307\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.2153 - accuracy: 0.9469 - val_loss: 0.6203 - val_accuracy: 0.8307\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2262 - accuracy: 0.9450 - val_loss: 0.6233 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2190 - accuracy: 0.9459 - val_loss: 0.6235 - val_accuracy: 0.8243\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2171 - accuracy: 0.9432 - val_loss: 0.6191 - val_accuracy: 0.8243\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2194 - accuracy: 0.9431 - val_loss: 0.6134 - val_accuracy: 0.8275\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2235 - accuracy: 0.9418 - val_loss: 0.6219 - val_accuracy: 0.8275\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2316 - accuracy: 0.9451 - val_loss: 0.6187 - val_accuracy: 0.8211\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2310 - accuracy: 0.9395 - val_loss: 0.6135 - val_accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2161 - accuracy: 0.9457 - val_loss: 0.6187 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2275 - accuracy: 0.9404 - val_loss: 0.6144 - val_accuracy: 0.8243\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2120 - accuracy: 0.9454 - val_loss: 0.6129 - val_accuracy: 0.8243\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2102 - accuracy: 0.9481 - val_loss: 0.6114 - val_accuracy: 0.8275\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2234 - accuracy: 0.9459 - val_loss: 0.6137 - val_accuracy: 0.8243\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2055 - accuracy: 0.9516 - val_loss: 0.6118 - val_accuracy: 0.8275\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2179 - accuracy: 0.9456 - val_loss: 0.6102 - val_accuracy: 0.8275\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2229 - accuracy: 0.9459 - val_loss: 0.6133 - val_accuracy: 0.8243\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2285 - accuracy: 0.9376 - val_loss: 0.6099 - val_accuracy: 0.8275\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2040 - accuracy: 0.9416 - val_loss: 0.6126 - val_accuracy: 0.8211\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2338 - accuracy: 0.9415 - val_loss: 0.6107 - val_accuracy: 0.8275\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2196 - accuracy: 0.9456 - val_loss: 0.6113 - val_accuracy: 0.8211\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2235 - accuracy: 0.9461 - val_loss: 0.6067 - val_accuracy: 0.8339\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2029 - accuracy: 0.9444 - val_loss: 0.6131 - val_accuracy: 0.8307\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2247 - accuracy: 0.9432 - val_loss: 0.6165 - val_accuracy: 0.8275\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2061 - accuracy: 0.9521 - val_loss: 0.6083 - val_accuracy: 0.8275\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2250 - accuracy: 0.9385 - val_loss: 0.6078 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2180 - accuracy: 0.9448 - val_loss: 0.6107 - val_accuracy: 0.8275\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2195 - accuracy: 0.9485 - val_loss: 0.6091 - val_accuracy: 0.8243\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2195 - accuracy: 0.9433 - val_loss: 0.6109 - val_accuracy: 0.8243\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2122 - accuracy: 0.9465 - val_loss: 0.6107 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.6067 - accuracy: 0.8339\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.6067 - accuracy: 0.8339\n",
      "--------------------Fold5--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 3.4280 - accuracy: 0.3378 - val_loss: 3.4401 - val_accuracy: 0.2396\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 2.0556 - accuracy: 0.5336 - val_loss: 1.9426 - val_accuracy: 0.5463\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 1.7248 - accuracy: 0.5904 - val_loss: 2.1423 - val_accuracy: 0.5304\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.5706 - accuracy: 0.6246 - val_loss: 1.7899 - val_accuracy: 0.5527\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.3814 - accuracy: 0.6504 - val_loss: 1.5217 - val_accuracy: 0.5974\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.2676 - accuracy: 0.6763 - val_loss: 1.3980 - val_accuracy: 0.6230\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.1304 - accuracy: 0.7112 - val_loss: 1.2484 - val_accuracy: 0.6645\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.0769 - accuracy: 0.7100 - val_loss: 1.1635 - val_accuracy: 0.6901\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.9718 - accuracy: 0.7418 - val_loss: 1.0910 - val_accuracy: 0.7125\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.9310 - accuracy: 0.7524 - val_loss: 1.0065 - val_accuracy: 0.7188\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.8544 - accuracy: 0.7763 - val_loss: 0.9652 - val_accuracy: 0.7157\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.8054 - accuracy: 0.7751 - val_loss: 0.8792 - val_accuracy: 0.7540\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.7212 - accuracy: 0.8037 - val_loss: 0.8127 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.6980 - accuracy: 0.8039 - val_loss: 0.7678 - val_accuracy: 0.7796\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.6521 - accuracy: 0.8231 - val_loss: 0.7337 - val_accuracy: 0.7859\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.6420 - accuracy: 0.8096 - val_loss: 0.7200 - val_accuracy: 0.8019\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.5681 - accuracy: 0.8414 - val_loss: 0.8334 - val_accuracy: 0.7444\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2805s 65s/step - loss: 0.5706 - accuracy: 0.8235 - val_loss: 0.7519 - val_accuracy: 0.7923\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.5430 - accuracy: 0.8461 - val_loss: 0.6941 - val_accuracy: 0.8083\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 4279s 26s/step - loss: 0.5373 - accuracy: 0.8372 - val_loss: 0.6456 - val_accuracy: 0.8275\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 0.4919 - accuracy: 0.8545 - val_loss: 0.6798 - val_accuracy: 0.7891\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 10080s 234s/step - loss: 0.5072 - accuracy: 0.8588 - val_loss: 0.7378 - val_accuracy: 0.8147\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3252s 76s/step - loss: 0.4606 - accuracy: 0.8656 - val_loss: 0.6276 - val_accuracy: 0.7987\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3248s 76s/step - loss: 0.4823 - accuracy: 0.8557 - val_loss: 0.5894 - val_accuracy: 0.8147\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3252s 76s/step - loss: 0.4498 - accuracy: 0.8729 - val_loss: 0.5677 - val_accuracy: 0.8083\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1008s 23s/step - loss: 0.4560 - accuracy: 0.8614 - val_loss: 0.6308 - val_accuracy: 0.7955\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.4194 - accuracy: 0.8744 - val_loss: 0.6123 - val_accuracy: 0.8179\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.3938 - accuracy: 0.8819 - val_loss: 0.5996 - val_accuracy: 0.8051\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.3916 - accuracy: 0.8845 - val_loss: 0.5694 - val_accuracy: 0.8243\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3403 - accuracy: 0.9042 - val_loss: 0.5289 - val_accuracy: 0.8307\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3634 - accuracy: 0.8967 - val_loss: 0.5074 - val_accuracy: 0.8371\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3472 - accuracy: 0.9073 - val_loss: 0.4972 - val_accuracy: 0.8275\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.3258 - accuracy: 0.9057 - val_loss: 0.5021 - val_accuracy: 0.8339\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3163 - accuracy: 0.9156 - val_loss: 0.5266 - val_accuracy: 0.8403\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3122 - accuracy: 0.9123 - val_loss: 0.6090 - val_accuracy: 0.7987\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3334 - accuracy: 0.9053 - val_loss: 0.5101 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2976 - accuracy: 0.9236 - val_loss: 0.4913 - val_accuracy: 0.8530\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.3016 - accuracy: 0.9177 - val_loss: 0.4952 - val_accuracy: 0.8339\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2995 - accuracy: 0.9214 - val_loss: 0.4883 - val_accuracy: 0.8435\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2905 - accuracy: 0.9107 - val_loss: 0.4901 - val_accuracy: 0.8403\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2861 - accuracy: 0.9243 - val_loss: 0.4880 - val_accuracy: 0.8435\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2724 - accuracy: 0.9242 - val_loss: 0.4735 - val_accuracy: 0.8530\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2799 - accuracy: 0.9293 - val_loss: 0.4618 - val_accuracy: 0.8530\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 67s 2s/step - loss: 0.2685 - accuracy: 0.9317 - val_loss: 0.4874 - val_accuracy: 0.8562\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2737 - accuracy: 0.9241 - val_loss: 0.4644 - val_accuracy: 0.8530\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2715 - accuracy: 0.9335 - val_loss: 0.4702 - val_accuracy: 0.8498\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2480 - accuracy: 0.9402 - val_loss: 0.4754 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2479 - accuracy: 0.9339 - val_loss: 0.4669 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2338 - accuracy: 0.9424 - val_loss: 0.4676 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2780 - accuracy: 0.9290 - val_loss: 0.4574 - val_accuracy: 0.8530\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2458 - accuracy: 0.9332 - val_loss: 0.4545 - val_accuracy: 0.8594\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2546 - accuracy: 0.9332 - val_loss: 0.4646 - val_accuracy: 0.8658\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2596 - accuracy: 0.9333 - val_loss: 0.4564 - val_accuracy: 0.8594\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2574 - accuracy: 0.9333 - val_loss: 0.4540 - val_accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2418 - accuracy: 0.9383 - val_loss: 0.4525 - val_accuracy: 0.8658\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2404 - accuracy: 0.9382 - val_loss: 0.4573 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2355 - accuracy: 0.9415 - val_loss: 0.4529 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2499 - accuracy: 0.9356 - val_loss: 0.4571 - val_accuracy: 0.8466\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2261 - accuracy: 0.9371 - val_loss: 0.4620 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.2215 - accuracy: 0.9465 - val_loss: 0.4474 - val_accuracy: 0.8626\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2405 - accuracy: 0.9385 - val_loss: 0.4488 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 68s 2s/step - loss: 0.2292 - accuracy: 0.9389 - val_loss: 0.4517 - val_accuracy: 0.8658\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.2240 - accuracy: 0.9394 - val_loss: 0.4592 - val_accuracy: 0.8594\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.2252 - accuracy: 0.9498 - val_loss: 0.4557 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2268 - accuracy: 0.9408 - val_loss: 0.4545 - val_accuracy: 0.8562\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.2176 - accuracy: 0.9493 - val_loss: 0.4542 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.2195 - accuracy: 0.9481 - val_loss: 0.4513 - val_accuracy: 0.8626\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.2359 - accuracy: 0.9344 - val_loss: 0.4475 - val_accuracy: 0.8626\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 1s 119ms/step - loss: 0.4474 - accuracy: 0.8626\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.4474 - accuracy: 0.8626\n",
      "--------------------Fold6--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 3.4188 - accuracy: 0.3564 - val_loss: 3.3161 - val_accuracy: 0.2949\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.9763 - accuracy: 0.5473 - val_loss: 1.9981 - val_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 57s 1s/step - loss: 1.7944 - accuracy: 0.5669 - val_loss: 2.0553 - val_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 58s 1s/step - loss: 1.5199 - accuracy: 0.6241 - val_loss: 2.0350 - val_accuracy: 0.5481\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 356s 8s/step - loss: 1.4265 - accuracy: 0.6381 - val_loss: 1.7119 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2429s 56s/step - loss: 1.2329 - accuracy: 0.6804 - val_loss: 1.6299 - val_accuracy: 0.5962\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.1803 - accuracy: 0.6827 - val_loss: 1.4578 - val_accuracy: 0.6186\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 66s 2s/step - loss: 1.0296 - accuracy: 0.7256 - val_loss: 1.2573 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.9721 - accuracy: 0.7382 - val_loss: 1.1679 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.9243 - accuracy: 0.7477 - val_loss: 1.1304 - val_accuracy: 0.7115\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.8642 - accuracy: 0.7619 - val_loss: 1.0847 - val_accuracy: 0.7276\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.7988 - accuracy: 0.7785 - val_loss: 0.9951 - val_accuracy: 0.7244\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.7608 - accuracy: 0.7856 - val_loss: 0.9642 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 76s 2s/step - loss: 0.6820 - accuracy: 0.8073 - val_loss: 0.9213 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.6852 - accuracy: 0.7809 - val_loss: 0.8482 - val_accuracy: 0.7853\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.6437 - accuracy: 0.8096 - val_loss: 0.8618 - val_accuracy: 0.7756\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.5797 - accuracy: 0.8296 - val_loss: 0.8226 - val_accuracy: 0.7628\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.5271 - accuracy: 0.8507 - val_loss: 0.7842 - val_accuracy: 0.7885\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5473 - accuracy: 0.8422 - val_loss: 0.8061 - val_accuracy: 0.7692\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5280 - accuracy: 0.8385 - val_loss: 0.7182 - val_accuracy: 0.8045\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.5311 - accuracy: 0.8414 - val_loss: 0.8203 - val_accuracy: 0.7692\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.5032 - accuracy: 0.8453 - val_loss: 0.6907 - val_accuracy: 0.8141\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.4579 - accuracy: 0.8590 - val_loss: 0.7535 - val_accuracy: 0.7853\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4455 - accuracy: 0.8618 - val_loss: 0.6757 - val_accuracy: 0.8269\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4172 - accuracy: 0.8776 - val_loss: 0.7052 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4236 - accuracy: 0.8685 - val_loss: 0.6758 - val_accuracy: 0.8301\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4188 - accuracy: 0.8795 - val_loss: 0.7066 - val_accuracy: 0.8013\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4288 - accuracy: 0.8692 - val_loss: 0.6716 - val_accuracy: 0.8173\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4123 - accuracy: 0.8779 - val_loss: 0.6837 - val_accuracy: 0.7949\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3694 - accuracy: 0.8884 - val_loss: 0.6358 - val_accuracy: 0.8141\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.3735 - accuracy: 0.8909 - val_loss: 0.6989 - val_accuracy: 0.8109\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3635 - accuracy: 0.8977 - val_loss: 0.6375 - val_accuracy: 0.8365\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3597 - accuracy: 0.8907 - val_loss: 0.6186 - val_accuracy: 0.8397\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3302 - accuracy: 0.8999 - val_loss: 0.6590 - val_accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3151 - accuracy: 0.9108 - val_loss: 0.6680 - val_accuracy: 0.8205\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3270 - accuracy: 0.9083 - val_loss: 0.6621 - val_accuracy: 0.8237\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.3270 - accuracy: 0.9107 - val_loss: 0.6393 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2959 - accuracy: 0.9183 - val_loss: 0.6465 - val_accuracy: 0.8269\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2808 - accuracy: 0.9179 - val_loss: 0.6414 - val_accuracy: 0.8269\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2564 - accuracy: 0.9296 - val_loss: 0.6189 - val_accuracy: 0.8365\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2590 - accuracy: 0.9310 - val_loss: 0.6343 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 0.6186 - accuracy: 0.8397\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.6186 - accuracy: 0.8397\n",
      "--------------------Fold7--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 3.4262 - accuracy: 0.3292 - val_loss: 3.4110 - val_accuracy: 0.2212\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.9775 - accuracy: 0.5514 - val_loss: 1.8772 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.7194 - accuracy: 0.5812 - val_loss: 1.9901 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.5073 - accuracy: 0.6303 - val_loss: 1.7868 - val_accuracy: 0.5513\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.3914 - accuracy: 0.6520 - val_loss: 1.6566 - val_accuracy: 0.5737\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 1.2870 - accuracy: 0.6613 - val_loss: 1.3819 - val_accuracy: 0.6314\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 1.1338 - accuracy: 0.7004 - val_loss: 1.3432 - val_accuracy: 0.6346\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 1.0872 - accuracy: 0.7066 - val_loss: 1.2199 - val_accuracy: 0.6571\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 1.0002 - accuracy: 0.7416 - val_loss: 1.0760 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.9168 - accuracy: 0.7501 - val_loss: 1.0125 - val_accuracy: 0.7308\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.8365 - accuracy: 0.7753 - val_loss: 0.9547 - val_accuracy: 0.7115\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.7707 - accuracy: 0.7841 - val_loss: 0.9048 - val_accuracy: 0.7724\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.7418 - accuracy: 0.7909 - val_loss: 0.8610 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.7022 - accuracy: 0.8049 - val_loss: 0.8308 - val_accuracy: 0.7436\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.6933 - accuracy: 0.8072 - val_loss: 0.7538 - val_accuracy: 0.7756\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.6268 - accuracy: 0.8138 - val_loss: 0.7549 - val_accuracy: 0.7981\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5932 - accuracy: 0.8311 - val_loss: 0.7188 - val_accuracy: 0.8173\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.6067 - accuracy: 0.8221 - val_loss: 0.7264 - val_accuracy: 0.8013\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.5251 - accuracy: 0.8552 - val_loss: 0.7605 - val_accuracy: 0.7788\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.5286 - accuracy: 0.8494 - val_loss: 0.6511 - val_accuracy: 0.8141\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.5131 - accuracy: 0.8577 - val_loss: 0.6375 - val_accuracy: 0.8141\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4959 - accuracy: 0.8553 - val_loss: 0.7802 - val_accuracy: 0.7788\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.4809 - accuracy: 0.8566 - val_loss: 0.6246 - val_accuracy: 0.8013\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4762 - accuracy: 0.8558 - val_loss: 0.6614 - val_accuracy: 0.7949\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4726 - accuracy: 0.8703 - val_loss: 0.6196 - val_accuracy: 0.8173\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3938 - accuracy: 0.8902 - val_loss: 0.5730 - val_accuracy: 0.8494\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.4079 - accuracy: 0.8748 - val_loss: 0.5742 - val_accuracy: 0.8397\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3920 - accuracy: 0.8896 - val_loss: 0.5462 - val_accuracy: 0.8045\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3981 - accuracy: 0.8909 - val_loss: 0.5707 - val_accuracy: 0.8494\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.3771 - accuracy: 0.8903 - val_loss: 0.5828 - val_accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3654 - accuracy: 0.8960 - val_loss: 0.5532 - val_accuracy: 0.8269\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.3530 - accuracy: 0.8939 - val_loss: 0.5972 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3127 - accuracy: 0.9165 - val_loss: 0.5141 - val_accuracy: 0.8429\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3195 - accuracy: 0.9095 - val_loss: 0.5573 - val_accuracy: 0.8397\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.3291 - accuracy: 0.9091 - val_loss: 0.5460 - val_accuracy: 0.8429\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3112s 72s/step - loss: 0.2874 - accuracy: 0.9245 - val_loss: 0.5482 - val_accuracy: 0.8237\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.3093 - accuracy: 0.9132 - val_loss: 0.5018 - val_accuracy: 0.8462\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.3207 - accuracy: 0.9103 - val_loss: 0.5445 - val_accuracy: 0.8237\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2767 - accuracy: 0.9250 - val_loss: 0.5390 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.2791 - accuracy: 0.9307 - val_loss: 0.5227 - val_accuracy: 0.8526\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.2929 - accuracy: 0.9162 - val_loss: 0.5266 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.2509 - accuracy: 0.9399 - val_loss: 0.4961 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2540 - accuracy: 0.9379 - val_loss: 0.4989 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2598 - accuracy: 0.9336 - val_loss: 0.4887 - val_accuracy: 0.8429\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2477 - accuracy: 0.9341 - val_loss: 0.4910 - val_accuracy: 0.8494\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.2617 - accuracy: 0.9268 - val_loss: 0.4839 - val_accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 70s 2s/step - loss: 0.2393 - accuracy: 0.9370 - val_loss: 0.4821 - val_accuracy: 0.8429\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2448 - accuracy: 0.9372 - val_loss: 0.4931 - val_accuracy: 0.8397\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2371 - accuracy: 0.9353 - val_loss: 0.5126 - val_accuracy: 0.8462\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.2255 - accuracy: 0.9426 - val_loss: 0.4856 - val_accuracy: 0.8526\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2253 - accuracy: 0.9428 - val_loss: 0.4836 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.2309 - accuracy: 0.9455 - val_loss: 0.4830 - val_accuracy: 0.8494\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2351 - accuracy: 0.9387 - val_loss: 0.4705 - val_accuracy: 0.8494\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2341 - accuracy: 0.9378 - val_loss: 0.4786 - val_accuracy: 0.8526\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2262 - accuracy: 0.9421 - val_loss: 0.4777 - val_accuracy: 0.8462\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2200 - accuracy: 0.9426 - val_loss: 0.4690 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2396 - accuracy: 0.9391 - val_loss: 0.4684 - val_accuracy: 0.8526\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2312 - accuracy: 0.9384 - val_loss: 0.4573 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2326 - accuracy: 0.9411 - val_loss: 0.4657 - val_accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2286 - accuracy: 0.9462 - val_loss: 0.4593 - val_accuracy: 0.8558\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2072 - accuracy: 0.9491 - val_loss: 0.4680 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2174 - accuracy: 0.9461 - val_loss: 0.4734 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2126 - accuracy: 0.9454 - val_loss: 0.4682 - val_accuracy: 0.8494\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2223 - accuracy: 0.9386 - val_loss: 0.4605 - val_accuracy: 0.8558\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.1989 - accuracy: 0.9553 - val_loss: 0.4651 - val_accuracy: 0.8526\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2106 - accuracy: 0.9474 - val_loss: 0.4625 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 2s 165ms/step - loss: 0.4573 - accuracy: 0.8590\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.4573 - accuracy: 0.8590\n",
      "--------------------Fold8--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 3.3943 - accuracy: 0.3472 - val_loss: 3.2597 - val_accuracy: 0.3173\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 2.0112 - accuracy: 0.5400 - val_loss: 1.8587 - val_accuracy: 0.5353\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.7212 - accuracy: 0.5914 - val_loss: 1.8840 - val_accuracy: 0.5641\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.5070 - accuracy: 0.6342 - val_loss: 1.8746 - val_accuracy: 0.5673\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.4495 - accuracy: 0.6292 - val_loss: 1.5787 - val_accuracy: 0.6058\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.2839 - accuracy: 0.6592 - val_loss: 1.4411 - val_accuracy: 0.6346\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.1325 - accuracy: 0.7068 - val_loss: 1.2492 - val_accuracy: 0.6442\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 1.0402 - accuracy: 0.7190 - val_loss: 1.2063 - val_accuracy: 0.6603\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.9885 - accuracy: 0.7351 - val_loss: 1.0558 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.8680 - accuracy: 0.7673 - val_loss: 1.0071 - val_accuracy: 0.7179\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.8300 - accuracy: 0.7669 - val_loss: 0.9470 - val_accuracy: 0.7179\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.7942 - accuracy: 0.7890 - val_loss: 0.9054 - val_accuracy: 0.7212\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.7053 - accuracy: 0.8069 - val_loss: 0.8146 - val_accuracy: 0.7276\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.7037 - accuracy: 0.8063 - val_loss: 0.8999 - val_accuracy: 0.7788\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.6801 - accuracy: 0.8029 - val_loss: 0.7812 - val_accuracy: 0.7628\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.6200 - accuracy: 0.8241 - val_loss: 0.8347 - val_accuracy: 0.7724\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.6084 - accuracy: 0.8207 - val_loss: 0.7078 - val_accuracy: 0.7756\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.5704 - accuracy: 0.8325 - val_loss: 0.6941 - val_accuracy: 0.8013\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.5508 - accuracy: 0.8327 - val_loss: 0.6626 - val_accuracy: 0.7821\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.5447 - accuracy: 0.8317 - val_loss: 0.6074 - val_accuracy: 0.8173\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.4865 - accuracy: 0.8591 - val_loss: 0.6194 - val_accuracy: 0.7821\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.4858 - accuracy: 0.8657 - val_loss: 0.6212 - val_accuracy: 0.7756\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.4608 - accuracy: 0.8649 - val_loss: 0.6273 - val_accuracy: 0.7788\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.4717 - accuracy: 0.8669 - val_loss: 0.5997 - val_accuracy: 0.8141\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.4200 - accuracy: 0.8812 - val_loss: 0.6073 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.4247 - accuracy: 0.8779 - val_loss: 0.5734 - val_accuracy: 0.8173\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.4081 - accuracy: 0.8869 - val_loss: 0.5762 - val_accuracy: 0.8173\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.3950 - accuracy: 0.8870 - val_loss: 0.5641 - val_accuracy: 0.8205\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.3600 - accuracy: 0.8977 - val_loss: 0.6101 - val_accuracy: 0.7917\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.3817 - accuracy: 0.8899 - val_loss: 0.5871 - val_accuracy: 0.8205\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.3563 - accuracy: 0.8945 - val_loss: 0.6172 - val_accuracy: 0.8173\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.3910 - accuracy: 0.8847 - val_loss: 0.5653 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.3229 - accuracy: 0.9087 - val_loss: 0.5459 - val_accuracy: 0.8365\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.3198 - accuracy: 0.9070 - val_loss: 0.5033 - val_accuracy: 0.8397\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2978 - accuracy: 0.9222 - val_loss: 0.5232 - val_accuracy: 0.8205\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2880 - accuracy: 0.9283 - val_loss: 0.5103 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.3140 - accuracy: 0.9114 - val_loss: 0.5153 - val_accuracy: 0.8397\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2915 - accuracy: 0.9203 - val_loss: 0.5444 - val_accuracy: 0.7981\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2847 - accuracy: 0.9256 - val_loss: 0.4581 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2749 - accuracy: 0.9326 - val_loss: 0.4609 - val_accuracy: 0.8590\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2584 - accuracy: 0.9368 - val_loss: 0.4563 - val_accuracy: 0.8622\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2550 - accuracy: 0.9350 - val_loss: 0.4541 - val_accuracy: 0.8526\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 68s 2s/step - loss: 0.2667 - accuracy: 0.9298 - val_loss: 0.4428 - val_accuracy: 0.8654\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 73s 2s/step - loss: 0.2567 - accuracy: 0.9404 - val_loss: 0.4441 - val_accuracy: 0.8654\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.2721 - accuracy: 0.9267 - val_loss: 0.4684 - val_accuracy: 0.8397\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2530 - accuracy: 0.9332 - val_loss: 0.4647 - val_accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2478 - accuracy: 0.9359 - val_loss: 0.4621 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2488 - accuracy: 0.9387 - val_loss: 0.4470 - val_accuracy: 0.8590\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.2338 - accuracy: 0.9403 - val_loss: 0.4440 - val_accuracy: 0.8558\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 69s 2s/step - loss: 0.2332 - accuracy: 0.9440 - val_loss: 0.4418 - val_accuracy: 0.8622\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2272 - accuracy: 0.9402 - val_loss: 0.4532 - val_accuracy: 0.8494\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2349 - accuracy: 0.9386 - val_loss: 0.4424 - val_accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2526 - accuracy: 0.9364 - val_loss: 0.4372 - val_accuracy: 0.8590\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2300 - accuracy: 0.9458 - val_loss: 0.4369 - val_accuracy: 0.8654\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2422 - accuracy: 0.9327 - val_loss: 0.4405 - val_accuracy: 0.8590\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 72s 2s/step - loss: 0.2616 - accuracy: 0.9290 - val_loss: 0.4407 - val_accuracy: 0.8654\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2506 - accuracy: 0.9373 - val_loss: 0.4443 - val_accuracy: 0.8654\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.2294 - accuracy: 0.9437 - val_loss: 0.4365 - val_accuracy: 0.8654\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2357 - accuracy: 0.9428 - val_loss: 0.4395 - val_accuracy: 0.8622\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2230 - accuracy: 0.9389 - val_loss: 0.4371 - val_accuracy: 0.8654\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2132 - accuracy: 0.9491 - val_loss: 0.4345 - val_accuracy: 0.8590\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2334 - accuracy: 0.9396 - val_loss: 0.4336 - val_accuracy: 0.8622\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2395 - accuracy: 0.9372 - val_loss: 0.4391 - val_accuracy: 0.8654\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2322 - accuracy: 0.9282 - val_loss: 0.4420 - val_accuracy: 0.8590\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2232 - accuracy: 0.9463 - val_loss: 0.4389 - val_accuracy: 0.8622\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2327 - accuracy: 0.9449 - val_loss: 0.4380 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2314 - accuracy: 0.9392 - val_loss: 0.4309 - val_accuracy: 0.8590\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2272 - accuracy: 0.9388 - val_loss: 0.4309 - val_accuracy: 0.8654\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2083 - accuracy: 0.9484 - val_loss: 0.4323 - val_accuracy: 0.8622\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2248 - accuracy: 0.9369 - val_loss: 0.4305 - val_accuracy: 0.8590\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2202 - accuracy: 0.9449 - val_loss: 0.4290 - val_accuracy: 0.8654\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2187 - accuracy: 0.9446 - val_loss: 0.4255 - val_accuracy: 0.8622\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2142 - accuracy: 0.9521 - val_loss: 0.4237 - val_accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2154 - accuracy: 0.9483 - val_loss: 0.4244 - val_accuracy: 0.8654\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2218 - accuracy: 0.9447 - val_loss: 0.4253 - val_accuracy: 0.8622\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2195 - accuracy: 0.9419 - val_loss: 0.4234 - val_accuracy: 0.8686\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2114 - accuracy: 0.9409 - val_loss: 0.4288 - val_accuracy: 0.8654\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2040 - accuracy: 0.9547 - val_loss: 0.4253 - val_accuracy: 0.8718\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2120 - accuracy: 0.9491 - val_loss: 0.4264 - val_accuracy: 0.8750\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2159 - accuracy: 0.9442 - val_loss: 0.4257 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2189 - accuracy: 0.9477 - val_loss: 0.4227 - val_accuracy: 0.8590\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.1956 - accuracy: 0.9552 - val_loss: 0.4234 - val_accuracy: 0.8654\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2163 - accuracy: 0.9508 - val_loss: 0.4215 - val_accuracy: 0.8686\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2146 - accuracy: 0.9425 - val_loss: 0.4213 - val_accuracy: 0.8686\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2170 - accuracy: 0.9436 - val_loss: 0.4224 - val_accuracy: 0.8654\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2095 - accuracy: 0.9468 - val_loss: 0.4214 - val_accuracy: 0.8654\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 61s 1s/step - loss: 0.2005 - accuracy: 0.9468 - val_loss: 0.4220 - val_accuracy: 0.8686\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 0.2039 - accuracy: 0.9464 - val_loss: 0.4216 - val_accuracy: 0.8686\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2091 - accuracy: 0.9506 - val_loss: 0.4206 - val_accuracy: 0.8686\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2076 - accuracy: 0.9501 - val_loss: 0.4206 - val_accuracy: 0.8654\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.1974 - accuracy: 0.9509 - val_loss: 0.4209 - val_accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 71s 2s/step - loss: 0.2033 - accuracy: 0.9443 - val_loss: 0.4207 - val_accuracy: 0.8686\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2057 - accuracy: 0.9507 - val_loss: 0.4208 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.1970 - accuracy: 0.9549 - val_loss: 0.4211 - val_accuracy: 0.8654\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.2034 - accuracy: 0.9494 - val_loss: 0.4206 - val_accuracy: 0.8654\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.1947 - accuracy: 0.9515 - val_loss: 0.4210 - val_accuracy: 0.8654\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.1958 - accuracy: 0.9494 - val_loss: 0.4201 - val_accuracy: 0.8622\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 62s 1s/step - loss: 0.2012 - accuracy: 0.9530 - val_loss: 0.4208 - val_accuracy: 0.8654\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.2103 - accuracy: 0.9505 - val_loss: 0.4208 - val_accuracy: 0.8654\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.1978 - accuracy: 0.9552 - val_loss: 0.4205 - val_accuracy: 0.8654\n",
      "10/10 [==============================] - 2s 169ms/step - loss: 0.4201 - accuracy: 0.8622\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 0.4201 - accuracy: 0.8622\n",
      "--------------------Fold9--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 3.3783 - accuracy: 0.3489 - val_loss: 2.9277 - val_accuracy: 0.4583\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 67s 2s/step - loss: 1.9826 - accuracy: 0.5604 - val_loss: 1.9077 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 1.7716 - accuracy: 0.5709 - val_loss: 1.8101 - val_accuracy: 0.5609\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 66s 1s/step - loss: 1.5371 - accuracy: 0.6250 - val_loss: 1.6881 - val_accuracy: 0.5609\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 1.3952 - accuracy: 0.6417 - val_loss: 1.5667 - val_accuracy: 0.5833\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 1.2643 - accuracy: 0.6653 - val_loss: 1.3261 - val_accuracy: 0.6282\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 68s 2s/step - loss: 1.1647 - accuracy: 0.6899 - val_loss: 1.2555 - val_accuracy: 0.6538\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 1.0607 - accuracy: 0.7219 - val_loss: 1.1661 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 1.0088 - accuracy: 0.7298 - val_loss: 1.0629 - val_accuracy: 0.7179\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.9020 - accuracy: 0.7562 - val_loss: 1.0353 - val_accuracy: 0.7115\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 66s 2s/step - loss: 0.8648 - accuracy: 0.7598 - val_loss: 1.0042 - val_accuracy: 0.6955\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.7519 - accuracy: 0.7977 - val_loss: 0.8942 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.7721 - accuracy: 0.7753 - val_loss: 0.8326 - val_accuracy: 0.7468\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 65s 1s/step - loss: 0.6742 - accuracy: 0.8146 - val_loss: 0.8399 - val_accuracy: 0.7628\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.6625 - accuracy: 0.8106 - val_loss: 0.7488 - val_accuracy: 0.7853\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.6016 - accuracy: 0.8284 - val_loss: 0.7360 - val_accuracy: 0.7788\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 63s 1s/step - loss: 0.6169 - accuracy: 0.8136 - val_loss: 0.7567 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 70s 2s/step - loss: 0.5578 - accuracy: 0.8350 - val_loss: 0.6685 - val_accuracy: 0.7885\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.5330 - accuracy: 0.8442 - val_loss: 0.6890 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.5303 - accuracy: 0.8423 - val_loss: 0.6879 - val_accuracy: 0.7724\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4784 - accuracy: 0.8558 - val_loss: 0.6771 - val_accuracy: 0.8141\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4970 - accuracy: 0.8475 - val_loss: 0.6220 - val_accuracy: 0.8013\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4607 - accuracy: 0.8743 - val_loss: 0.5939 - val_accuracy: 0.8109\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4350 - accuracy: 0.8708 - val_loss: 0.5829 - val_accuracy: 0.8077\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4526 - accuracy: 0.8660 - val_loss: 0.5759 - val_accuracy: 0.8237\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.3945 - accuracy: 0.8924 - val_loss: 0.5885 - val_accuracy: 0.8141\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4031 - accuracy: 0.8809 - val_loss: 0.5733 - val_accuracy: 0.8205\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 59s 1s/step - loss: 0.4385 - accuracy: 0.8678 - val_loss: 0.7068 - val_accuracy: 0.7628\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 60s 1s/step - loss: 0.3909 - accuracy: 0.8930 - val_loss: 0.5778 - val_accuracy: 0.8077\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.3830 - accuracy: 0.8884 - val_loss: 0.5183 - val_accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2011s 47s/step - loss: 0.3793 - accuracy: 0.8892 - val_loss: 0.5465 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 64s 1s/step - loss: 0.3406 - accuracy: 0.9035 - val_loss: 0.5952 - val_accuracy: 0.8013\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 70s 2s/step - loss: 0.3733 - accuracy: 0.8895 - val_loss: 0.5898 - val_accuracy: 0.7981\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 74s 2s/step - loss: 0.3273 - accuracy: 0.8992 - val_loss: 0.5340 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 75s 2s/step - loss: 0.3286 - accuracy: 0.9039 - val_loss: 0.5008 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 77s 2s/step - loss: 0.2771 - accuracy: 0.9204 - val_loss: 0.4862 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2988 - accuracy: 0.9138 - val_loss: 0.4888 - val_accuracy: 0.8301\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 78s 2s/step - loss: 0.2904 - accuracy: 0.9176 - val_loss: 0.4676 - val_accuracy: 0.8301\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 79s 2s/step - loss: 0.2779 - accuracy: 0.9223 - val_loss: 0.4737 - val_accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2919 - accuracy: 0.9202 - val_loss: 0.5125 - val_accuracy: 0.8301\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2577 - accuracy: 0.9294 - val_loss: 0.4613 - val_accuracy: 0.8365\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2893 - accuracy: 0.9184 - val_loss: 0.4791 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2850 - accuracy: 0.9141 - val_loss: 0.4996 - val_accuracy: 0.8301\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 80s 2s/step - loss: 0.2439 - accuracy: 0.9387 - val_loss: 0.5041 - val_accuracy: 0.8237\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2581 - accuracy: 0.9260 - val_loss: 0.4813 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2542 - accuracy: 0.9270 - val_loss: 0.4593 - val_accuracy: 0.8397\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2313 - accuracy: 0.9345 - val_loss: 0.4567 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2450 - accuracy: 0.9347 - val_loss: 0.4587 - val_accuracy: 0.8494\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2425 - accuracy: 0.9349 - val_loss: 0.4534 - val_accuracy: 0.8397\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2215 - accuracy: 0.9431 - val_loss: 0.4511 - val_accuracy: 0.8429\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2104 - accuracy: 0.9467 - val_loss: 0.4663 - val_accuracy: 0.8429\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 81s 2s/step - loss: 0.2447 - accuracy: 0.9357 - val_loss: 0.4320 - val_accuracy: 0.8590\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2394 - accuracy: 0.9393 - val_loss: 0.4769 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2224 - accuracy: 0.9330 - val_loss: 0.4500 - val_accuracy: 0.8365\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2031 - accuracy: 0.9521 - val_loss: 0.4402 - val_accuracy: 0.8397\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2075 - accuracy: 0.9439 - val_loss: 0.4719 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2025 - accuracy: 0.9434 - val_loss: 0.4377 - val_accuracy: 0.8397\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.2104 - accuracy: 0.9494 - val_loss: 0.4400 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.1972 - accuracy: 0.9507 - val_loss: 0.4442 - val_accuracy: 0.8526\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.2062 - accuracy: 0.9489 - val_loss: 0.4449 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.4320 - accuracy: 0.8590\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.4320 - accuracy: 0.8590\n",
      "--------------------Fold10--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 3.4090 - accuracy: 0.3351 - val_loss: 2.9954 - val_accuracy: 0.3814\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.9950 - accuracy: 0.5441 - val_loss: 1.8977 - val_accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 1.6928 - accuracy: 0.5890 - val_loss: 1.8547 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 1.5275 - accuracy: 0.6258 - val_loss: 1.6867 - val_accuracy: 0.5769\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.3816 - accuracy: 0.6516 - val_loss: 1.5446 - val_accuracy: 0.6090\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.3006 - accuracy: 0.6587 - val_loss: 1.3716 - val_accuracy: 0.6410\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.1706 - accuracy: 0.6903 - val_loss: 1.2791 - val_accuracy: 0.6603\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 1.0709 - accuracy: 0.7139 - val_loss: 1.1089 - val_accuracy: 0.7115\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 1.0144 - accuracy: 0.7090 - val_loss: 1.0174 - val_accuracy: 0.7115\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.8940 - accuracy: 0.7669 - val_loss: 0.9976 - val_accuracy: 0.7404\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.8485 - accuracy: 0.7619 - val_loss: 0.8757 - val_accuracy: 0.7468\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.7746 - accuracy: 0.7822 - val_loss: 0.8667 - val_accuracy: 0.7660\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.7796 - accuracy: 0.7886 - val_loss: 0.8666 - val_accuracy: 0.7628\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.7093 - accuracy: 0.8047 - val_loss: 0.8264 - val_accuracy: 0.7756\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.6754 - accuracy: 0.8139 - val_loss: 0.7546 - val_accuracy: 0.8077\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.6620 - accuracy: 0.8231 - val_loss: 0.6978 - val_accuracy: 0.8077\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.6063 - accuracy: 0.8238 - val_loss: 0.6710 - val_accuracy: 0.8109\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.5514 - accuracy: 0.8345 - val_loss: 0.6458 - val_accuracy: 0.8301\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.5386 - accuracy: 0.8443 - val_loss: 0.6280 - val_accuracy: 0.8237\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.5292 - accuracy: 0.8559 - val_loss: 0.6157 - val_accuracy: 0.8397\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.5342 - accuracy: 0.8494 - val_loss: 0.7220 - val_accuracy: 0.7917\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 82s 2s/step - loss: 0.5133 - accuracy: 0.8465 - val_loss: 0.5693 - val_accuracy: 0.8462\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.5066 - accuracy: 0.8540 - val_loss: 0.6085 - val_accuracy: 0.8173\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.4418 - accuracy: 0.8715 - val_loss: 0.6930 - val_accuracy: 0.7981\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.4591 - accuracy: 0.8656 - val_loss: 0.5267 - val_accuracy: 0.8141\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.4123 - accuracy: 0.8770 - val_loss: 0.6218 - val_accuracy: 0.8269\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.4378 - accuracy: 0.8633 - val_loss: 0.5487 - val_accuracy: 0.8269\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.4173 - accuracy: 0.8769 - val_loss: 0.5723 - val_accuracy: 0.8365\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 83s 2s/step - loss: 0.4014 - accuracy: 0.8800 - val_loss: 0.5517 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3628 - accuracy: 0.8946 - val_loss: 0.5099 - val_accuracy: 0.8301\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3384 - accuracy: 0.9096 - val_loss: 0.4940 - val_accuracy: 0.8429\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.3162 - accuracy: 0.9161 - val_loss: 0.5287 - val_accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3268 - accuracy: 0.9029 - val_loss: 0.4839 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.3418 - accuracy: 0.9006 - val_loss: 0.5343 - val_accuracy: 0.8141\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 85s 2s/step - loss: 0.3113 - accuracy: 0.9220 - val_loss: 0.5170 - val_accuracy: 0.8397\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3018 - accuracy: 0.9241 - val_loss: 0.4935 - val_accuracy: 0.8397\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 84s 2s/step - loss: 0.3219 - accuracy: 0.9115 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.3000 - accuracy: 0.9237 - val_loss: 0.4684 - val_accuracy: 0.8558\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.2885 - accuracy: 0.9250 - val_loss: 0.4780 - val_accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.3102 - accuracy: 0.9172 - val_loss: 0.4490 - val_accuracy: 0.8526\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.2679 - accuracy: 0.9342 - val_loss: 0.4617 - val_accuracy: 0.8429\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.2819 - accuracy: 0.9243 - val_loss: 0.4770 - val_accuracy: 0.8429\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 86s 2s/step - loss: 0.2803 - accuracy: 0.9282 - val_loss: 0.4666 - val_accuracy: 0.8494\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 87s 2s/step - loss: 0.2950 - accuracy: 0.9223 - val_loss: 0.4639 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 88s 2s/step - loss: 0.2652 - accuracy: 0.9332 - val_loss: 0.4515 - val_accuracy: 0.8590\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 88s 2s/step - loss: 0.2640 - accuracy: 0.9279 - val_loss: 0.4523 - val_accuracy: 0.8429\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2647 - accuracy: 0.9351 - val_loss: 0.4389 - val_accuracy: 0.8494\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2604 - accuracy: 0.9332 - val_loss: 0.4542 - val_accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2511 - accuracy: 0.9340 - val_loss: 0.4468 - val_accuracy: 0.8494\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 88s 2s/step - loss: 0.2457 - accuracy: 0.9422 - val_loss: 0.4496 - val_accuracy: 0.8622\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2590 - accuracy: 0.9353 - val_loss: 0.4655 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2612 - accuracy: 0.9373 - val_loss: 0.4499 - val_accuracy: 0.8558\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 89s 2s/step - loss: 0.2433 - accuracy: 0.9361 - val_loss: 0.4506 - val_accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 91s 2s/step - loss: 0.2526 - accuracy: 0.9328 - val_loss: 0.4424 - val_accuracy: 0.8558\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 90s 2s/step - loss: 0.2530 - accuracy: 0.9382 - val_loss: 0.4482 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 3s 298ms/step - loss: 0.4389 - accuracy: 0.8494\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 0.4389 - accuracy: 0.8494\n",
      "\n",
      "k-fold CV AUC : ['0.8530', '0.8435', '0.8690', '0.8339', '0.8626', '0.8397', '0.8590', '0.8622', '0.8590', '0.8494']\n",
      "\n",
      "k-fold CV Loss : ['0.5373', '0.4760', '0.4195', '0.6067', '0.4474', '0.6186', '0.4573', '0.4201', '0.4320', '0.4389']\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "loss = []\n",
    "models = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) : \n",
    "    \n",
    "    # 모델 저장 \n",
    "    mc = ModelCheckpoint(f'./workout_M/cv_study{i+1}.h5', save_best_only = True,\n",
    "                        verbose = 0, monitor = 'val_loss', mode ='min', save_weights_only = 'True')\n",
    "    \n",
    "    print('-'*20 + 'Fold' + str(i+1) + '-'*20)\n",
    "    \n",
    "    model = cnn_model((600, 18), 61)\n",
    "    history = model.fit(X[train], y[train], epochs = 100, \n",
    "                       validation_data = (X[validation], y[validation]), \n",
    "                       verbose = 1, batch_size = 64, callbacks = [es, mc, reLR])\n",
    "    \n",
    "    model.load_weights(f'./workout_M/cv_study{i+1}.h5')\n",
    "    \n",
    "    k_accuracy = '%.4f'%(model.evaluate(X[validation], y[validation])[1])\n",
    "    k_loss = '%.4f'%(model.evaluate(X[validation], y[validation])[0])\n",
    "    \n",
    "    accuracy.append(k_accuracy)\n",
    "    loss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "sec = time.time() - start\n",
    "    \n",
    "print('\\nk-fold CV AUC : {}'.format(accuracy))\n",
    "print('\\nk-fold CV Loss : {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델링 수행 시간 :  ['1 day, 3:58:29', '701422']\n"
     ]
    }
   ],
   "source": [
    "print('모델링 수행 시간 : ' , str(datetime.timedelta(seconds = sec)).split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 정확도 : 0.8531\n",
      "평균 loss : 0.4854\n"
     ]
    }
   ],
   "source": [
    "print('평균 정확도 : {0:.4f}'.format(sum(float(i) for i in accuracy)/10 ))\n",
    "print('평균 loss : {:.4f}'.format(sum(float(i) for i in loss)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.52831033e-06, 1.82786937e-06, 1.48055761e-07, ...,\n",
       "        4.71508643e-03, 1.09337225e-05, 2.10196731e-06],\n",
       "       [5.15806896e-04, 2.57043866e-05, 2.40184876e-04, ...,\n",
       "        1.03424727e-05, 3.31831543e-05, 1.31285633e-05],\n",
       "       [1.69565273e-03, 2.89031304e-02, 1.65807760e-05, ...,\n",
       "        6.97948621e-04, 1.06625026e-02, 2.08439166e-03],\n",
       "       ...,\n",
       "       [4.84825112e-04, 3.99380997e-06, 1.62373508e-05, ...,\n",
       "        2.08291185e-05, 1.70811109e-06, 8.31775193e-04],\n",
       "       [3.78538925e-06, 7.86759134e-04, 9.85837801e-07, ...,\n",
       "        8.53478781e-08, 1.15160392e-05, 3.43165008e-09],\n",
       "       [9.88745960e-05, 3.81942937e-06, 1.38630435e-06, ...,\n",
       "        8.41892615e-05, 8.89487524e-07, 1.45653437e-04]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_x)\n",
    "    preds.append(pred)\n",
    "    \n",
    "pred = np.mean(preds, axis = 0)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
