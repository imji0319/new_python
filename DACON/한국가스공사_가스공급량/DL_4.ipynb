{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aeb7e5-2f61-480e-8f55-178d997879a6",
   "metadata": {},
   "source": [
    "## LSTM 모델 활용 \n",
    "conda activate tf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123800b-42f9-419b-8ce7-889afc201566",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 데이터 로드 및 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba56540-e7f8-4d7f-bdd6-c66d00c21f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "plt.rc('font', family = 'AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "df = pd.read_csv('한국가스공사_시간별 공급량_20181231.csv', encoding = 'euc-kr')\n",
    "test = pd.read_csv('가스공급량 수요예측모델개발_data/test.csv')\n",
    "sub = pd.read_csv('가스공급량 수요예측모델개발_data/sample_submission.csv')\n",
    "\n",
    "def tohour(val):\n",
    "    if len(val) == 1:\n",
    "        return '0'+val+':00:00'\n",
    "    else:\n",
    "        return val+':00:00'\n",
    "    \n",
    "def gubun(df):\n",
    "    df = df[['연월일시간','공급량']]\n",
    "    df.columns = ['ds','y']\n",
    "    df = df.set_index('ds')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1ec209-e07a-46da-8d9a-7ede6bc88874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['시간_수정'] = df['시간'] -1 \n",
    "df['시간_수정'] = df['시간_수정'].astype(str)\n",
    "df['시간_수정'] = df['시간_수정'].apply(tohour)\n",
    "df['연월일시간'] = df['연월일']+' '+df['시간_수정']\n",
    "df['연월일시간'] = pd.to_datetime(df['연월일시간'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b618cd3f-2206-447b-8f0f-843c0682080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df[df['구분'] =='A']\n",
    "B = df[df['구분'] =='B']\n",
    "C = df[df['구분'] =='C']\n",
    "D = df[df['구분'] =='D']\n",
    "E = df[df['구분'] =='E']\n",
    "G = df[df['구분'] =='G']\n",
    "H = df[df['구분'] =='H']\n",
    "a = gubun(A)\n",
    "b = gubun(B)\n",
    "c = gubun(C)\n",
    "d = gubun(D)\n",
    "e = gubun(E)\n",
    "g = gubun(G)\n",
    "h = gubun(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a7be3-7eaf-4ac7-b0ca-27ca8894eefd",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1e804-7ae7-4871-9de9-bf5da96fb84a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 데이터 스케일링 및 분할 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe4376b-bee5-4fa9-9580-bc39f200bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, times):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    df = np.array(df)\n",
    "    for i in range(len(df) - times):\n",
    "        x = df[i:i+times]\n",
    "        y = df[i+times:i+times + times]\n",
    "        \n",
    "        if len(y) == times :\n",
    "            x_train.append(x)\n",
    "            y_train.append(y)\n",
    "        else :\n",
    "            break\n",
    "        \n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff606b2-2178-464a-ba41-73a616f939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b64e83-e5b2-45f2-b04f-f5927bf802ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 scaling \n",
    "scaler_a = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_b = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_c = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_d = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_e = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_g = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_h = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c43c23-bc65-4672-8804-b7861e474fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_a = scaler_a.fit_transform(a)\n",
    "sc_b = scaler_b.fit_transform(b)\n",
    "sc_c = scaler_c.fit_transform(c)\n",
    "sc_d = scaler_d.fit_transform(d)\n",
    "sc_e = scaler_e.fit_transform(e)\n",
    "sc_g = scaler_g.fit_transform(g)\n",
    "sc_h = scaler_h.fit_transform(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7abdd4f7-30ea-4809-be36-435473330b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7dc87e0-614e-4806-a687-4b54be95c5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd4dea3-7b5c-4f0e-bb83-5d88b94e8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(sc_df):\n",
    "    x_train, y_train = split_df(sc_df, 2160)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdaa161-a86c-4f62-ba25-696f88fc7bcd",
   "metadata": {},
   "source": [
    "#### LSTM 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6c1a5b-b9ff-47f2-b28d-cd1a7cfa57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b79023-8794-400b-9a48-01224a0bb9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc04676c-9cc4-4763-982b-dbdd2753d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # stateful = True 이전 배치의 학습 상태가 다음 배치 작업에 영향 \n",
    "    model.add(LSTM(32, batch_input_shape = (batch_size,2160,1), return_sequences = True)) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, batch_input_shape = (batch_size,2160,1), return_sequences = True)) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss ='mae', optimizer = 'adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25687c0d-8cfb-488b-8f2d-cd35ca222811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (1000, 2160, 32)          4352      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (1000, 2160, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (1000, 2160, 32)          8320      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (1000, 2160, 32)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (1000, 2160, 1)           33        \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "model = modeling(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b90f752-17c8-439b-aa91-abd99cebfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prep_df(sc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c217124a-4cab-4033-9d14-bf9eaf920247",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_train[:int(len(x_train)*0.8)]\n",
    "val_x = x_train[int(len(x_train)*0.8):]\n",
    "\n",
    "train_y = y_train[:int(len(x_train)*0.8)]\n",
    "val_y = y_train[int(len(x_train)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2f52133-12d3-4a74-939e-3b395e20a456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/39 [============================>.] - ETA: 7s - loss: 0.0505 "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "   Specified a list with shape [1000,1] from a tensor with shape [612,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_4/lstm_8/PartitionedCall]] [Op:__inference_train_function_23429]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lf/472dwzh15hqd9qhdk_3h5sx40000gp/T/ipykernel_14074/1238804317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(train_x, train_y,batch_size = batch_size , epochs = 10,\n\u001b[0m\u001b[1;32m      2\u001b[0m          validation_data = (val_x, val_y))\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf25/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [1000,1] from a tensor with shape [612,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_4/lstm_8/PartitionedCall]] [Op:__inference_train_function_23429]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,batch_size = batch_size , epochs = 10,\n",
    "         validation_data = (val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea864f63-098a-4a1b-9d36-853548ac7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_train, by_train = prep_df(sc_b)\n",
    "b_model = modeling(batch_size)\n",
    "b_model.fit(bx_train, by_train, batch_size = batch_size, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d05c1-86a9-4dab-8830-25c6b9ef83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_train, cy_train = prep_df(sc_c)\n",
    "c_model = modeling(batch_size)\n",
    "c_model.fit(cx_train, cy_train, batch_size = batch_size, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce87619d-b160-49ac-a0d2-3b1a402f5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_train, dy_train = prep_df(sc_d)\n",
    "d_model = modeling(batch_size)\n",
    "d_model.fit(dx_train, dy_train, batch_size = batch_size, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ce255-0e05-40d0-894c-d5177772a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_train, ey_train = prep_df(sc_e)\n",
    "e_model = modeling(batch_size)\n",
    "e_model.fit(ex_train, ey_train, batch_size = batch_size, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112873e-c7f1-4561-89c2-c05bb637f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_train, gy_train = prep_df(sc_g)\n",
    "g_model = modeling(batch_size)\n",
    "g_model.fit(gx_train, gy_train, batch_size = batch_size, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e0dcc-c2af-4d70-b691-f2d69e586bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hx_train, hy_train = prep_df(sc_h)\n",
    "h_model = modeling(batch_size)\n",
    "h_model.fit(hx_train, hy_train, batch_size = batch_size, epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
