{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 북극 관련 추가 데이터 활용 \n",
    "\n",
    "< 참조 논문 > \n",
    "### Prediction of monthly Arctic sea ice concentrations using satellite and reanalysis data based on convolutional neural networks      \n",
    "[NISDC](https://nsidc.org/data/search/#keywords=CLIMATE/sortKeys=score,,desc/facetFilters=%257B%257D/pageNumber=1/itemsPerPage=25)\n",
    "\n",
    "1. [일일 해빙 농도 데이터](https://nsidc.org/data/G02135/versions/3)   \n",
    "The first dataset is the daily sea ice concentration observation dataset, obtained from the National Snow and Ice Data Center (NSIDC), which is derived from the Nimbus-7 Scanning Multichannel Microwave Radiometer (SMMR) and the Defense Meteorological Satellite Program (DMSP) Special Sensor Microwave Imager (SSM/I and SS- MIS).\n",
    "\n",
    "2. [일일 해수면 온도 데이터](https://psl.noaa.gov/data/gridded/tables/arctic.html)   \n",
    "The second dataset is the daily sea surface temperature dataset, obtained from National Oceanic and Atmospheric Administration (NOAA) Optimal Interpolation Sea Surface Temperature (OISST) version 2, which is con- structed from Advanced Very High Resolution Radiometer (AVHRR) observation data with 0.25◦ resolution from 1988 to 2017. \n",
    "\n",
    "3. [유럽 중거리 일기 예보 센터](https://www.ecmwf.int/en/forecasts/datasets/browse-reanalysis-datasets)     \n",
    "The third dataset is the monthly European Centre for Medium-Range Weather Forecasts (ECMWF) reanalysis (ERA-Interim) dataset, which is used in order to construct predictors for 1-month SIC prediction, including the surface air temperature, albedo, and v-wind vector with 0.125◦ resolution.\n",
    "\n",
    "\n",
    "\n",
    "* 해수면 Dataset \n",
    "https://climatedataguide.ucar.edu/climate-data?page=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os , glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_list(path):\n",
    "    tmplist = glob.glob(path)\n",
    "    tmplist.sort()\n",
    "    \n",
    "    return tmplist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:02<00:00, 206.65it/s]\n"
     ]
    }
   ],
   "source": [
    "list_train = sorted_list(os.path.join('data/train','*'))\n",
    "filenames = os.listdir('data/train')\n",
    "filenames.sort()\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    data.append(\n",
    "        np.load(f\"data/train/{filename}\"))\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 448, 304, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 448, 304)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[...,0].shape # 해빙 농도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/total_data', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOM Error 문제 발생 \n",
    "data 의 image 크기가 너무 크기 때문에 기본 Colab에서 실행을 했을 때에도 ResoureExhaustedError가 발생한다.  \n",
    "\n",
    "\n",
    "OOM stands for \"out of memory\". Your GPU is running out of memory, so it can't allocate memory for this tensor. There are a few things you can do:\n",
    "\n",
    "* Decrease the number of filters in your Dense, Conv2D layers\n",
    "* Use a smaller batch_size (or increase steps_per_epoch and validation_steps)\n",
    "* Use grayscale images (you can use tf.image.rgb_to_grayscale)\n",
    "* Reduce the number of layers\n",
    "* Use MaxPooling2D layers after convolutional layers\n",
    "* Reduce the size of your images (you can use tf.image.resize for that)\n",
    "* Use smaller float precision for your input, namely np.float32\n",
    "* If you're using a pre-trained model, freeze the first layers (like this)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM2D \n",
    "\n",
    "CNN + LSTM : ConvLSTM2D    \n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series?hl=ko\n",
    "\n",
    "<고급 : 자기 회귀 모델> \n",
    "\n",
    "# 이미지 크기 조절 \n",
    "## Pooling \n",
    "https://keras.io/ko/layers/pooling/\n",
    "\n",
    "## 이미지 내 색상 압축 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, out_steps):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_steps = out_steps\n",
    "        self.convlstm = tf.keras.layers.ConvLSTM2D(256, 3, padding ='same', \n",
    "                                                    return_state = True ) \n",
    "        \n",
    "        # Also wrap the LSTMCell in an RNN to simplify the 'warmup' method \n",
    "        # batch normalization 정규화 \n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # activation funcation : Relu\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        \n",
    "        # output layers : conv2d\n",
    "        self.conv2d = tf.keras.layers.Conv2D(1,1, activation ='sigmoid')\n",
    "\n",
    "    \n",
    "    # 단일 타임스텝 예측과 LSTM 내부 상태 반환\n",
    "    def warmup(self, inputs):\n",
    "        # input.shape => (batch, time, features )\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        \n",
    "        x, *state = self.convlstm(inputs)\n",
    "        \n",
    "        # prediction.shape => (batch, features)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        prediction = self.conv2d(x)\n",
    "\n",
    "        return prediction, state\n",
    "    \n",
    "    # 출력 예측을 수집하는 가장 간단한 방법은 python 목록을 사용하여 루프 후 tf.stack을 사용하는 것 . \n",
    "    \n",
    "    def call(self, inputs, training = None):\n",
    "\n",
    "        # user a TensorArray to capture dynamically unrolled outputs \n",
    "        predictions =[]\n",
    "        \n",
    "        # lstm 모델 초기화 \n",
    "        prediction, state = self.warmup(inputs)\n",
    "        \n",
    "        # Insert the first prediction \n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Run the rest of the prediction steps \n",
    "        for _ in range(1, self.out_steps):\n",
    "            \n",
    "            x = prediction\n",
    "            # one lstm step \n",
    "            x, *state = self.convlstm(tf.expand_dims(x,axis =1),\n",
    "                                     initial_state = state, training = training  )\n",
    "\n",
    "            # prediction 값 변경 \n",
    "            x = self.bn(x)\n",
    "            x = self.relu(x)\n",
    "            prediction = self.conv2d(x)\n",
    "            \n",
    "            # add output \n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        \n",
    "        #prediction.shape = > (time, batch, features )\n",
    "        predictions = tf.stack(predictions)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 448, 304, 1) (48, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "ice_tr_npy = data[:-48, ..., [0]]\n",
    "ice_ts_npy = data[-48:, ..., [0]]\n",
    "print(ice_tr_npy.shape, ice_ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 448, 304, 1) (108, 448, 304, 1) (48, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "split_len = int(ice_tr_npy.shape[0] * 0.25)  # validation set : 25% \n",
    "ice_vl_npy = ice_tr_npy[-split_len:]\n",
    "ice_tr_npy = ice_tr_npy[:-split_len]\n",
    "print(ice_tr_npy.shape, ice_vl_npy.shape,ice_ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rescaling(images):\n",
    "    return (tf.cast(images, dtype = tf.dtypes.float32) / 250.)\n",
    "\n",
    "@tf.function\n",
    "def split_window(images):\n",
    "    inputs, target = tf.split(images, [4,1], axis =1)\n",
    "    return (inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tr_ten = tf.constant(ice_tr_npy)\n",
    "i_vl_ten = tf.constant(ice_vl_npy)\n",
    "i_ts_ten = tf.constant(ice_ts_npy)\n",
    "\n",
    "i_tr_ds = tf.data.Dataset.from_tensor_slices(i_tr_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    ).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "i_vl_ds = tf.data.Dataset.from_tensor_slices(i_vl_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "i_ts_ds = tf.data.Dataset.from_tensor_slices(i_vl_ten\n",
    "                                    ).window(4 , shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None)) \n",
      " (TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None)) \n",
      " TensorSpec(shape=(None, None, 448, 304, 1), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(f'{i_tr_ds.element_spec} \\n',\n",
    "      f'{i_vl_ds.element_spec} \\n',\n",
    "      f'{i_ts_ds.element_spec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (8, 4, 448, 304, 1)\n",
      "label shape : (8, 1, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "for inp, tag in i_tr_ds.take(1):\n",
    "    print(f'input shape : {inp.shape}')\n",
    "    print(f'label shape : {tag.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mae_score(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.math.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def f1_score(y_true, y_pred, lower_bound = 0.05, upper_bound = 0.5,\n",
    "            threshold = 0.3, epsilon = 1e-8): \n",
    "    \n",
    "    y_true = tf.where(y_true > upper_bound, 0., y_true)\n",
    "    y_true = tf.where(y_true < lower_bound, 0., y_true)\n",
    "    y_pred = tf.where(y_pred > upper_bound, 0., y_pred)\n",
    "    y_pred = tf.where(y_pred < lower_bound, 0., y_pred)\n",
    "    \n",
    "    y_true = tf.where(y_true < 0.15, 0., 1.)\n",
    "    y_pred = tf.where(y_pred < 0.15, 0., 1.)\n",
    "    \n",
    "    \n",
    "    tp = tf.math.reduce_sum(tf.where(y_true*y_pred == 1., 1., 0.))\n",
    "    precision = tp /(tf.math.reduce_sum(y_true) + epsilon)\n",
    "    recall = tp / (tf.math.reduce_sum(y_pred)+epsilon)\n",
    "    \n",
    "    return 2*precision*recall / (precision + recall+ precision)\n",
    "\n",
    "@tf.function\n",
    "def mae_over_f1(y_true, y_pred, epsilon = 1e-8):\n",
    "    return tf.math.divide_no_nan(mae_score(y_true, y_pred),\n",
    "                                f1_score(y_true, y_pred)+ epsilon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedBack(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam', \n",
    "             loss = mae_over_f1, \n",
    "             metrics = [mae_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(i_tr_ds, validation_data = i_vl_ds,\n",
    "                   epochs = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
