{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 ConvLSTM2D \n",
    "\n",
    "참고 자료 : https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "\n",
    "ConvLSTM2D class, by default, expects input data to have the shape :   \n",
    "`(samples, time, rows, cols, channels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os , glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# convlsm model \n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM, TimeDistributed\n",
    "from keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_list(path):\n",
    "    tmplist = glob.glob(path)\n",
    "    tmplist.sort()\n",
    "    \n",
    "    return tmplist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train = sorted_list(os.path.join('data/train','*'))\n",
    "len(list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('data/train')\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:02<00:00, 198.50it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    data.append(\n",
    "        np.load(f\"data/train/{filename}\"))\n",
    "    \n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 448, 304, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>file_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1978-11</td>\n",
       "      <td>197811.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978-12</td>\n",
       "      <td>197812.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1979-01</td>\n",
       "      <td>197901.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month     file_nm\n",
       "0  1978-11  197811.npy\n",
       "1  1978-12  197812.npy\n",
       "2  1979-01  197901.npy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 창 작업 \n",
    "참고 자료 :https://www.tensorflow.org/tutorials/structured_data/time_series?hl=ko\n",
    "\n",
    "\n",
    "window_size = 4    \n",
    "offset = 24  # 24개월     \n",
    "label width = 1    \n",
    "target = 1    \n",
    "window_stride = 24   \n",
    "window_shfit = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 448, 304, 5)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[...,3]+=data[...,2] # concat masks\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 448, 304, 2) (48, 448, 304, 2)\n"
     ]
    }
   ],
   "source": [
    "tr_npy = data[:-48, ..., [0, 3]]\n",
    "ts_npy = data[-48:, ..., [0, 3]]\n",
    "print(tr_npy.shape, ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_len = int(tr_npy.shape[0] * 0.25)  # validation set : 25% \n",
    "vl_npy = tr_npy[-split_len:]\n",
    "tr_npy = tr_npy[:-split_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 448, 304, 2) (108, 448, 304, 2) (48, 448, 304, 2)\n"
     ]
    }
   ],
   "source": [
    "print(tr_npy.shape, vl_npy.shape, ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def split_mask(x):\n",
    "    return tf.split(x, [1,1], axis = -1)\n",
    "\n",
    "@tf.function\n",
    "def rescaling(images, masks):\n",
    "    return (tf.cast(images, dtype = tf.dtypes.float32) / 250.,\n",
    "\n",
    "            tf.cast(masks[:,0], tf.dtypes.float32))\n",
    "\n",
    "@tf.function\n",
    "def split_window(images, masks):\n",
    "    inputs, target = tf.split(images, [4,1], axis =1)\n",
    "    return (inputs, masks), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ten = tf.constant(tr_npy)\n",
    "vl_ten = tf.constant(vl_npy)\n",
    "ts_ten = tf.constant(ts_npy)\n",
    "\n",
    "tr_ds = tf.data.Dataset.from_tensor_slices(tr_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride = 24, drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    ).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(split_mask\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window)\n",
    "\n",
    "vl_ds = tf.data.Dataset.from_tensor_slices(vl_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride =  24, drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(split_mask\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window)\n",
    "\n",
    "\n",
    "ts_ds = tf.data.Dataset.from_tensor_slices(vl_ten\n",
    "                                    ).window(4 , shift = 1, stride = 24, drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(split_mask\n",
    "                                    ).map(rescaling)\n",
    "                                    #).map(split_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, 448, 304, 1), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, 448, 304, 1), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, None, 448, 304, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 448, 304, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4, 448, 304, 1) (8, 448, 304, 1) (8, 1, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "for ele in tr_ds.take(1):\n",
    "    (foo, bar), qux = ele\n",
    "    print(foo.shape, bar.shape, qux.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only 해빙 농도 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 448, 304, 1) (48, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "ice_tr_npy = data[:-48, ..., [0]]\n",
    "ice_ts_npy = data[-48:, ..., [0]]\n",
    "print(ice_tr_npy.shape, ice_ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 448, 304, 1) (108, 448, 304, 1) (48, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "split_len = int(ice_tr_npy.shape[0] * 0.25)  # validation set : 25% \n",
    "ice_vl_npy = ice_tr_npy[-split_len:]\n",
    "ice_tr_npy = ice_tr_npy[:-split_len]\n",
    "print(ice_tr_npy.shape, ice_vl_npy.shape,ice_ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rescaling(images):\n",
    "    return (tf.cast(images, dtype = tf.dtypes.float32) / 250.)\n",
    "\n",
    "@tf.function\n",
    "def split_window(images):\n",
    "    inputs, target = tf.split(images, [4,1], axis =1)\n",
    "    return (inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_tr_ten = tf.constant(ice_tr_npy)\n",
    "i_vl_ten = tf.constant(ice_vl_npy)\n",
    "i_ts_ten = tf.constant(ice_ts_npy)\n",
    "\n",
    "i_tr_ds = tf.data.Dataset.from_tensor_slices(i_tr_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    ).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "i_vl_ds = tf.data.Dataset.from_tensor_slices(i_vl_ten\n",
    "                                    ).window(4 + 1, shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4+1)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).map(split_window\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "i_ts_ds = tf.data.Dataset.from_tensor_slices(i_vl_ten\n",
    "                                    ).window(4 , shift = 1, stride = 24,drop_remainder = True\n",
    "                                    ).flat_map(lambda x : x.batch(4)\n",
    "                                    #).shuffle(buffer_size = 1000\n",
    "                                    ).batch(8\n",
    "                                    ).map(rescaling\n",
    "                                    ).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None)) \n",
      " (TensorSpec(shape=(None, 4, 448, 304, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None)) \n",
      " TensorSpec(shape=(None, None, 448, 304, 1), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(f'{i_tr_ds.element_spec} \\n',\n",
    "      f'{i_vl_ds.element_spec} \\n',\n",
    "      f'{i_ts_ds.element_spec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : (8, 4, 448, 304, 1)\n",
      "label shape : (8, 1, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "for inp, tag in i_tr_ds.take(1):\n",
    "    print(f'input shape : {inp.shape}')\n",
    "    print(f'label shape : {tag.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mae_score(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.math.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def f1_score(y_true, y_pred, lower_bound = 0.05, upper_bound = 0.5,\n",
    "            threshold = 0.3, epsilon = 1e-8): \n",
    "    \n",
    "    y_true = tf.where(y_true > upper_bound, 0., y_true)\n",
    "    y_true = tf.where(y_true < lower_bound, 0., y_true)\n",
    "    y_pred = tf.where(y_pred > upper_bound, 0., y_pred)\n",
    "    y_pred = tf.where(y_pred < lower_bound, 0., y_pred)\n",
    "    \n",
    "    y_true = tf.where(y_true < 0.15, 0., 1.)\n",
    "    y_pred = tf.where(y_pred < 0.15, 0., 1.)\n",
    "    \n",
    "    \n",
    "    tp = tf.math.reduce_sum(tf.where(y_true*y_pred == 1., 1., 0.))\n",
    "    precision = tp /(tf.math.reduce_sum(y_true) + epsilon)\n",
    "    recall = tp / (tf.math.reduce_sum(y_pred)+epsilon)\n",
    "    \n",
    "    return 2*precision*recall / (precision + recall+ precision)\n",
    "\n",
    "@tf.function\n",
    "def mae_over_f1(y_true, y_pred, epsilon = 1e-8):\n",
    "    return tf.math.divide_no_nan(mae_score(y_true, y_pred),\n",
    "                                f1_score(y_true, y_pred)+ epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.ConvLSTM2D(filters = 10, \n",
    "                    input_shape = (4,488,304,1),\n",
    "                    kernel_size= (3,3),data_format = 'channels_last',\n",
    "                    padding ='same', return_sequences=True,\n",
    "                    recurrent_dropout = 0.4))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dense(488*304, activation ='sigmoid'))\n",
    "model.add(Reshape((-1, 488,304,1)))\n",
    "\n",
    "\n",
    "model.compile(optimizer ='adam', loss = mae_over_f1, \n",
    "             metrics = [mae_score, f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 4, 448, 304, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y for x, y in i_tr_ds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([x for x, y in i_tr_ds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = (np.concatenate([x for x, y in i_vl_ds], axis = 0), \n",
    "         np.concatenate([y for x, y in i_vl_ds], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 448, 304, 1) (108, 448, 304, 1) (48, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "ice_tr_npy = data[:-48, ..., [0]]\n",
    "ice_ts_npy = data[-48:, ..., [0]]\n",
    "\n",
    "\n",
    "split_len = int(ice_tr_npy.shape[0] * 0.25)  # validation set : 25% \n",
    "ice_vl_npy = ice_tr_npy[-split_len:]\n",
    "ice_tr_npy = ice_tr_npy[:-split_len]\n",
    "print(ice_tr_npy.shape, ice_vl_npy.shape,ice_ts_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator(tf.keras.Model):\n",
    "    def __init__(self, input_width, label_width , shift = 1, \n",
    "                 train = ice_tr_npy, val = ice_vl_npy, test = ice_ts_npy, label_columns = None):\n",
    "        self.train_df = train\n",
    "        self.val_df = val\n",
    "        self.test_df = test\n",
    "        \n",
    "        # workout the label columns indices : \n",
    "        self.label_columns = label_columns \n",
    "        if label_columns is not None: \n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        \n",
    "        self.total_window_size = input_width + shift \n",
    "        \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'toal window size : {self.total_window_size}',\n",
    "            f'input indices : {self.input_indices}',\n",
    "            f'label indices : {self.label_indices}'\n",
    "        ])\n",
    "    \n",
    "    def split_window(self, images):\n",
    "        inputs, target = tf.split(images, [1,1], axis =1)\n",
    "       \n",
    "        return inputs, target\n",
    "\n",
    "    \n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype = np.float32)\n",
    "        \n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "                data = data , \n",
    "                targets = None, sequence_length = self.total_window_size,\n",
    "                sequence_stride =1, \n",
    "                shuffle =True, batch_size = 8)\n",
    "        \n",
    "        ds = ds.map(self.split_window)\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "            \n",
    "        \n",
    "    @property \n",
    "    def example(self):\n",
    "        result = getattr(self, '_example', None)\n",
    "        \n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._example = result\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = WindowGenerator(input_width = 1,label_width = 1, shift = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 448, 304, 1)\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in wd.train.take(1):\n",
    "    print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index =None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_index = label_index\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None :\n",
    "            return inputs \n",
    "        \n",
    "        resutl = inputs[:,:,self.label_index]\n",
    "        return result[:,:,tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 선형 모델 \n",
    "\n",
    "def compile_and_fit(model, dataset, patience =2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor ='val_loss',\n",
    "                                                     patience = patience,\n",
    "                                                     mode ='min')\n",
    "    \n",
    "    model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                 optimizer = tf.optimizers.Adam(),\n",
    "                 metrics = [tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(dataset.train, epochs = 30, \n",
    "                       validation_data = dataset.val,\n",
    "                       callbacks = [early_stopping])\n",
    "    \n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toal window size : 25\n",
       "input indices : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "label indices : [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = WindowGenerator(input_width = 24, label_width = 24, shift =1)\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "41/41 [==============================] - 2s 46ms/step - loss: 3591.3772 - mean_absolute_error: 21.7579 - val_loss: 3068.6682 - val_mean_absolute_error: 19.4265\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 3245.2053 - mean_absolute_error: 20.7475 - val_loss: 2777.2234 - val_mean_absolute_error: 18.5364\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 2906.0427 - mean_absolute_error: 19.6574 - val_loss: 2511.0435 - val_mean_absolute_error: 17.6817\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 2608.7399 - mean_absolute_error: 18.6283 - val_loss: 2269.2397 - val_mean_absolute_error: 16.8636\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 2413.1470 - mean_absolute_error: 18.1473 - val_loss: 2050.6277 - val_mean_absolute_error: 16.0824\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 2127.3171 - mean_absolute_error: 16.9718 - val_loss: 1853.7819 - val_mean_absolute_error: 15.3383\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 1918.4956 - mean_absolute_error: 16.1880 - val_loss: 1677.1702 - val_mean_absolute_error: 14.6309\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1678.1017 - mean_absolute_error: 15.0167 - val_loss: 1519.7618 - val_mean_absolute_error: 13.9611\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 1568.3146 - mean_absolute_error: 14.7876 - val_loss: 1377.0594 - val_mean_absolute_error: 13.3146\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 1429.6026 - mean_absolute_error: 14.1316 - val_loss: 1252.5204 - val_mean_absolute_error: 12.7126\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1231.7661 - mean_absolute_error: 13.0274 - val_loss: 1142.2444 - val_mean_absolute_error: 12.1424\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 1144.2905 - mean_absolute_error: 12.6817 - val_loss: 1046.5582 - val_mean_absolute_error: 11.6123\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - 2s 44ms/step - loss: 1056.4286 - mean_absolute_error: 12.0657 - val_loss: 962.3935 - val_mean_absolute_error: 11.1119\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 968.4650 - mean_absolute_error: 11.5992 - val_loss: 889.4850 - val_mean_absolute_error: 10.6452\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 888.1150 - mean_absolute_error: 11.1082 - val_loss: 825.8445 - val_mean_absolute_error: 10.2060\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 815.7460 - mean_absolute_error: 10.5190 - val_loss: 772.2060 - val_mean_absolute_error: 9.8060\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 745.9700 - mean_absolute_error: 9.9806 - val_loss: 726.3704 - val_mean_absolute_error: 9.4360\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 700.3513 - mean_absolute_error: 9.5888 - val_loss: 687.5993 - val_mean_absolute_error: 9.0969\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 664.3183 - mean_absolute_error: 9.2824 - val_loss: 655.0792 - val_mean_absolute_error: 8.7881\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 603.6490 - mean_absolute_error: 8.7508 - val_loss: 627.8757 - val_mean_absolute_error: 8.5067\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - 2s 47ms/step - loss: 571.0721 - mean_absolute_error: 8.4427 - val_loss: 605.8235 - val_mean_absolute_error: 8.2575\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - 2s 59ms/step - loss: 560.5835 - mean_absolute_error: 8.3022 - val_loss: 587.2143 - val_mean_absolute_error: 8.0272\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - 3s 81ms/step - loss: 540.6174 - mean_absolute_error: 7.9728 - val_loss: 572.3755 - val_mean_absolute_error: 7.8255\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - 4s 91ms/step - loss: 545.6846 - mean_absolute_error: 7.9184 - val_loss: 560.0145 - val_mean_absolute_error: 7.6404\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - 3s 61ms/step - loss: 516.5666 - mean_absolute_error: 7.5973 - val_loss: 550.7920 - val_mean_absolute_error: 7.4872\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 507.4889 - mean_absolute_error: 7.4332 - val_loss: 542.9744 - val_mean_absolute_error: 7.3433\n",
      "Epoch 27/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 503.2358 - mean_absolute_error: 7.2608 - val_loss: 537.4051 - val_mean_absolute_error: 7.2283\n",
      "Epoch 28/30\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 498.4775 - mean_absolute_error: 7.1859 - val_loss: 532.6813 - val_mean_absolute_error: 7.1189\n",
      "Epoch 29/30\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 468.6165 - mean_absolute_error: 6.8900 - val_loss: 529.2974 - val_mean_absolute_error: 7.0296\n",
      "Epoch 30/30\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 482.8267 - mean_absolute_error: 6.9188 - val_loss: 526.7112 - val_mean_absolute_error: 6.9515\n"
     ]
    }
   ],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units =1 )\n",
    "])\n",
    "\n",
    "history = compile_and_fit(linear, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_per= {}\n",
    "perf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 27ms/step - loss: 526.7112 - mean_absolute_error: 6.9515\n"
     ]
    }
   ],
   "source": [
    "val_per['Linear'] = linear.evaluate(wd.val)\n",
    "perf['Linear'] = linear.evaluate(wd.test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 스텝 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toal window size : 48\n",
       "input indices : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "label indices : [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_width = 24\n",
    "out_steps = 24 \n",
    "\n",
    "multi_window = WindowGenerator(input_width = 24,\n",
    "                             label_width = label_width,\n",
    "                              shift = out_steps)\n",
    "\n",
    "multi_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 1, 448, 304, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wconv_window.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.tile(input[:, -1:, :], [1, out_steps, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_step_dense, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convlstm(tf.keras.Model) :\n",
    "    def __init__(self, name ):\n",
    "        \n",
    "        super(convlstm, self).__init__(name = name)\n",
    "        \n",
    "        self.convlstm = tf.keras.layers.ConvLSTM2D(256 , 3,  padding = 'same', \n",
    "                                                  return_state = True, recurrent_dropout = 0.4 )\n",
    "        \n",
    "        self.out_steps = 2\n",
    "    \n",
    "    def warmup(self, x):\n",
    "        prediction, *state = self.convlstm(x)\n",
    "        return prediction, state\n",
    "        \n",
    "    def call(self, inputs, traing =None):\n",
    "        x, masks = inputs\n",
    "        masks = tf.tile(tf.expand_dims(masks, axis = 1),[1,self.out_steps, 1,1,1])\n",
    "        predictions = []\n",
    "        \n",
    "        prediction, state = self.warmup(x)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        for _ in range(1,self.out_steps):\n",
    "                \n",
    "            x ,*state = self.convlstm(tf.expand_dims(x, axis =1 ),\n",
    "                                         inital_state = state)\n",
    "            prediction = x \n",
    "                \n",
    "            predictions.append(x)\n",
    "                \n",
    "        return tf.stack(predictions, axis = 1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "conv = convlstm(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.compile(optimizer = 'adam', loss = \"mean_absolute_error\",\n",
    "             metrics =[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conv.fit(tr_ds, validation_data = vl_ds,\n",
    "             epochs = 10,\n",
    "             verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
