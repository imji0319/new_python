{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('card_dataset/train.csv')\n",
    "test = pd.read_csv('card_dataset/test.csv')\n",
    "submission =pd.read_csv('card_dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train.copy()\n",
    "new_test = test.copy()\n",
    "\n",
    "new_train[['work_phone','phone','email','FLAG_MOBIL']] = new_train[['work_phone','phone','email','FLAG_MOBIL']].astype('object')\n",
    "new_test[['work_phone','phone','email','FLAG_MOBIL']] = new_test[['work_phone','phone','email','FLAG_MOBIL']].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. income_type = 'Pensioner' 일때 occyp_type = 'Retired' and DAYS_EMPLOYED \n",
    "new_train.loc[new_train['income_type'] == 'Pensioner', 'occyp_type'] = 'Retired'\n",
    "new_train.loc[new_train['income_type'] == 'Pensioner', 'DAYS_EMPLOYED'] = 0 \n",
    "\n",
    "## 2. occyp_type = NaN & income_type = 'State servant'인 경우 occyp_type ='State servant' 로 변경\n",
    "new_train.loc[(new_train.occyp_type.isna())  & (new_train.income_type == 'State servant'), 'occyp_type'] = 'State servant'\n",
    "\n",
    "## 3. occyp_type = NaN & income_type  in ('working', 'Commercial associate', 'Student) 일 경우 occyp_type ='Extra staff'로 변경 \n",
    "new_train.loc[(new_train.occyp_type.isna())  & (new_train.income_type.isin(['Working','Commercial associate','Student'])), 'occyp_type'] = 'Extra staff'\n",
    "\n",
    "\n",
    "## 1. income_type = 'Pensioner' 일때 occyp_type = 'Retired' and DAYS_EMPLOYED \n",
    "new_test.loc[new_test['income_type'] == 'Pensioner', 'occyp_type'] = 'Retired'\n",
    "new_test.loc[new_test['income_type'] == 'Pensioner', 'DAYS_EMPLOYED'] = 0 \n",
    "\n",
    "## 2. occyp_type = NaN & income_type = 'State servant'인 경우 occyp_type ='State servant' 로 변경\n",
    "new_test.loc[(new_test.occyp_type.isna())  & (new_test.income_type == 'State servant'), 'occyp_type'] = 'State servant' \n",
    "\n",
    "## 3. occyp_type = NaN & income_type  in ('working', 'Commercial associate', 'Student) 일 경우 occyp_type ='Extra staff'로 변경 \n",
    "new_test.loc[(new_test.occyp_type.isna())  & (new_test.income_type.isin(['Working','Commercial associate','Student'])), 'occyp_type'] = 'Extra staff' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_list = {'Academic degree':5,\n",
    "           'Higher education':4,\n",
    "           'Incomplete higher':3,\n",
    "           'Secondary / secondary special':2,\n",
    "           'Lower secondary':1}\n",
    "\n",
    "\n",
    "new_train['edu_type'] = train['edu_type'].map(edu_list)\n",
    "new_test['edu_type'] = test['edu_type'].map(edu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FLAG_MOBIL 변수 삭제\n",
    "m_train = new_train.drop('FLAG_MOBIL', axis = 1)\n",
    "m_test = new_test.drop(['FLAG_MOBIL','index'], axis =1)\n",
    "\n",
    "\n",
    "# 2. credit 변수 분할 \n",
    "target_credit = m_train['credit']\n",
    "target_credit = target_credit.astype('int')\n",
    "\n",
    "m_train_x = m_train.drop(['index','credit'], axis = 1)\n",
    "\n",
    "\n",
    "# 3. 더미변수 \n",
    "dum_train_x = pd.get_dummies(m_train_x, drop_first = True)\n",
    "dum_test_x = pd.get_dummies(m_test, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "folds = StratifiedKFold(n_splits=5, \n",
    "                        shuffle=True, random_state=42)\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over,y_train_over = smote.fit_sample(dum_train_x,target_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = scaler.fit_transform(X_train_over)\n",
    "\n",
    "dum_test_x = scaler.fit_transform(dum_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[1000]\ttraining's multi_logloss: 0.586066\tvalid_1's multi_logloss: 0.66891\n",
      "[2000]\ttraining's multi_logloss: 0.443405\tvalid_1's multi_logloss: 0.581662\n",
      "[3000]\ttraining's multi_logloss: 0.35409\tvalid_1's multi_logloss: 0.535356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's multi_logloss: 0.35409\tvalid_1's multi_logloss: 0.535356\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[1000]\ttraining's multi_logloss: 0.586308\tvalid_1's multi_logloss: 0.669882\n",
      "[2000]\ttraining's multi_logloss: 0.434991\tvalid_1's multi_logloss: 0.569073\n",
      "[3000]\ttraining's multi_logloss: 0.350214\tvalid_1's multi_logloss: 0.524967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's multi_logloss: 0.350214\tvalid_1's multi_logloss: 0.524967\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[1000]\ttraining's multi_logloss: 0.586276\tvalid_1's multi_logloss: 0.66758\n",
      "[2000]\ttraining's multi_logloss: 0.444352\tvalid_1's multi_logloss: 0.577412\n",
      "[3000]\ttraining's multi_logloss: 0.356259\tvalid_1's multi_logloss: 0.532674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's multi_logloss: 0.356259\tvalid_1's multi_logloss: 0.532674\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[1000]\ttraining's multi_logloss: 0.584521\tvalid_1's multi_logloss: 0.674916\n",
      "[2000]\ttraining's multi_logloss: 0.444377\tvalid_1's multi_logloss: 0.588676\n",
      "[3000]\ttraining's multi_logloss: 0.355359\tvalid_1's multi_logloss: 0.541508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's multi_logloss: 0.355359\tvalid_1's multi_logloss: 0.541508\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[1000]\ttraining's multi_logloss: 0.58508\tvalid_1's multi_logloss: 0.668598\n",
      "[2000]\ttraining's multi_logloss: 0.439089\tvalid_1's multi_logloss: 0.575771\n",
      "[3000]\ttraining's multi_logloss: 0.350384\tvalid_1's multi_logloss: 0.527648\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's multi_logloss: 0.350384\tvalid_1's multi_logloss: 0.527648\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "sub = np.zeros((dum_test_x.shape[0], 3))\n",
    "\n",
    "for n_folds, (train_index, val_index) in enumerate(folds.split(X_train_over, y_train_over)):\n",
    "    \n",
    "    print(f'===================================={n_folds+1}============================================')\n",
    "\n",
    "    X_train, X_val = X_train_over[train_index], X_train_over[val_index]\n",
    "    y_train, y_val = y_train_over.iloc[train_index], y_train_over.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    lgb = LGBMClassifier(n_estimators=3000,\n",
    "                        is_unbalance = True, n_jobs = -1,\n",
    "                        num_leaves = 128,\n",
    "                        max_depth = 16,\n",
    "                        random_state = 507,\n",
    "                        learning_rate = 0.005)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=1000)\n",
    "    y_val_onehot = pd.get_dummies(y_val)\n",
    "    prediction = lgb.predict_proba(X_val)\n",
    "    loss.append(log_loss(y_val_onehot, prediction))\n",
    "    sub+= lgb.predict_proba(dum_test_x)\n",
    "    \n",
    "    \n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5324307789858999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:]= sub/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/scaling.csv', index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
